{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ODIN method\n",
    "\n",
    "This notebook aims at evaluating the **ODIN method**.\n",
    "\n",
    "Here, we focus on a ResNet18 network trained on CIFAR-10. This model is challenged on\n",
    "LSUN OOD dataset.\n",
    "\n",
    "**Reference**  \n",
    "_Enhancing The Reliability of Out-of-distribution Image Detection in Neural Networks_  \n",
    "Liang, Shiyu and Li, Yixuan and Srikant, R.  \n",
    "International Conference on Learning Representations, 2018  \n",
    "<https://openreview.net/forum?id=H1VGkIxRZ>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load CIFAR-10 dataset and pretrained ResNet18 model\n",
    "\n",
    "The CIFAR-10 dataset is loaded and preprocessed (normalized to 0-1). This is our\n",
    "in-distribution dataset.\n",
    "\n",
    "A pretrained ResNet18 model is loaded and evaluated on CIFAR-10 test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\" \n",
    "import tensorflow as tf\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "from oodeel.datasets import OODDataset\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that models are saved at *~/.oodeel/saved_models* and data is supposed to be found at *~/.oodeel/datasets* by default. Change the following cell for a custom path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_path = os.path.expanduser(\"~/\") + \".oodeel/saved_models\"\n",
    "data_path = os.path.expanduser(\"~/\") + \".oodeel/datasets\"\n",
    "os.makedirs(model_path, exist_ok=True)\n",
    "os.makedirs(data_path, exist_ok=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Cifar10, our in-distribution from `tensorflow_datasets`. \n",
    "\n",
    "/!\\ We denote In-Distribution (ID) data with `_in` and Out-Of-Distribution (OOD) data with `_out` to avoid confusion with OOD detection which is the name of the task, and is therefore used to denote core classes such as `OODDataset` and `OODModel`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "oods_in = OODDataset('cifar10', split=\"test\", input_key=\"image\")\n",
    "oods_train = OODDataset('cifar10', split=\"train\", input_key=\"image\")\n",
    "\n",
    "def preprocess_fn(*inputs):\n",
    "    x = inputs[0] / 255\n",
    "    return tuple([x] + list(inputs[1:]))\n",
    "\n",
    "batch_size = 128\n",
    "ds_in = oods_in.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train or load a model on in-distribution data (Cifar10). Note that `.get_dataset()` is used to return the unprepared `tf.data.Dataset`, that is automatically prepare, preprocessed and augmented by `train_keras_app`. To prepare the dataset with your own pipeline, set `is_prepared=True` in `train_config` dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from oodeel.models.training_funs import train_keras_app\n",
    "\n",
    "model_path_cifar = os.path.join(model_path, \"cifar10\")\n",
    "try:\n",
    "    model = tf.keras.models.load_model(model_path_cifar)\n",
    "    \n",
    "except OSError:\n",
    "    train_config = {\n",
    "        \"input_shape\": (32, 32, 3),\n",
    "        \"num_classes\": 10,\n",
    "        \"batch_size\": 128,\n",
    "        \"epochs\": 200,\n",
    "        \"save_dir\": model_path_cifar,\n",
    "        \"validation_data\": oods_in.get_dataset() #ds_in is actually the test set of MNIST.\n",
    "    }\n",
    "\n",
    "    model = train_keras_app(oods_train.get_dataset(), \"resnet18\", **train_config) \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load LSUN cropped dataset\n",
    "\n",
    "Second, the LSUN cropped dataset is loaded and preprocessed. This is our\n",
    "out-of-distribution dataset.\n",
    "\n",
    "**Note**: see https://github.com/facebookresearch/odin to download OOD datasets from the\n",
    "original paper. Some OOD datasets have images of size 36x36 pixels: a black frame of 2 pixels surrounds the\n",
    "32x32 image. In this case, the image is cropped to 32x32 pixels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSUN_root = os.path.join(data_path, \"LSUN\")\n",
    "lsun_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    LSUN_root,\n",
    "    image_size=(32, 32),\n",
    "    shuffle=False,\n",
    "    batch_size=None\n",
    ")\n",
    "# ood dataset\n",
    "ds_out = OODDataset(lsun_ds).prepare(batch_size=batch_size, preprocess_fn=preprocess_fn)\n",
    "\n",
    "ood_name = \"LSUN\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OOD detection\n",
    "\n",
    "Here the ODIN method is applied on both ID and OOD images. The OOD score is computed for\n",
    "each image and some metrics are measured to evaluate the performance of the OOD\n",
    "detector.\n",
    "\n",
    "In a nutshell, the ODIN method consists of the three following steps:\n",
    "\n",
    "1. Perturb the input image by applying a gradient descent step in order to increase the\n",
    "   calibrated probability score of the predicted class.\n",
    "2. Compute the calibrated probability score of the perturbed image. This is defined as\n",
    "   the OOD score.\n",
    "3. If the OOD score is below a threshold, the image is considered as OOD.\n",
    "\n",
    "The _calibrated probability_ is the temperature-scaled softmax of the logits where the\n",
    "temperature is a hyper-parameter of the method. The step in the gradient descent\n",
    "perturbation of the image is also a hyper-parameter.\n",
    "\n",
    "First, fit ODIN to the model at hand, and score data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from oodeel.methods import ODIN\n",
    "\n",
    "oodmodel = ODIN(temperature=1000)\n",
    "oodmodel.fit(model)\n",
    "\n",
    "scores_in = oodmodel.score(ds_in)\n",
    "scores_out = oodmodel.score(ds_out)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the evaluation metrics based on the scores of the test data, and visualize the scores histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from oodeel.eval.metrics import bench_metrics\n",
    "\n",
    "\n",
    "metrics = bench_metrics(\n",
    "    (scores_in, scores_out),\n",
    "    metrics=[\"auroc\", \"fpr95tpr\"]\n",
    ")\n",
    "\n",
    "def plot_hist(scores_in, scores_out, bins, log=False, invert_order=False):\n",
    "    if log:\n",
    "        if invert_order:\n",
    "            scores_in = - scores_in\n",
    "            scores_out = - scores_out\n",
    "        minim = np.min([np.min(scores_in), np.min(scores_out)])\n",
    "        scores_in_ = scores_in - 2 * minim + np.min(scores_in[np.where(scores_in != minim)])\n",
    "        scores_out_ = scores_out - 2 * minim + np.min(scores_in[np.where(scores_in != minim)])\n",
    "        _, bins = np.histogram(np.concatenate([scores_in_, scores_out_]), bins=30)\n",
    "        logbins = np.logspace(np.log10(bins[0]),np.log10(bins[-1]),len(bins))\n",
    "        plt.xscale('log')\n",
    "        plt.xlabel(\"score (normalized log axis)\")\n",
    "    else:\n",
    "        logbins=bins\n",
    "        scores_in_ = scores_in \n",
    "        scores_out_ = scores_out\n",
    "        plt.xlabel(\"score\")\n",
    "    plt.hist((scores_out_, scores_in_), bins=logbins, color=(\"blue\", \"orange\"), label=(\"ood\", \"id\"))\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plt.figure(figsize=(13, 5))\n",
    "plot_hist(scores_in, scores_out, 30, log=True, invert_order=True)\n",
    "metrics = pd.Series(metrics)\n",
    "print(metrics)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BONUS\n",
    "\n",
    "Bonus experiment: \n",
    "* Compare calibrated softmax outputs from original and perturbed images for a single batch.\n",
    "* Compare the shift between outputs of original and pertubated images for in-distribution and out-of-distribution data. \n",
    "* Compute the number of output label shift after image perturbation for in-distribution and out-of-distribution data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in ds_out.take(1):\n",
    "    img_out = img[0]\n",
    "\n",
    "for img in ds_in.take(1):\n",
    "    img_in = img[0]\n",
    "\n",
    "img_perturbed_out = oodmodel._input_perturbation(img_out)\n",
    "img_perturbed_in = oodmodel._input_perturbation(img_in)\n",
    "perturbations_out = img_perturbed_out - img_out\n",
    "perturbations_in = img_perturbed_in - img_in\n",
    "\n",
    "def get_max_argmax(img):\n",
    "    preds = tf.nn.softmax(model.predict(img) / oodmodel.temperature).numpy()\n",
    "    maxx = preds.max(axis=-1)\n",
    "    argmaxx = preds.argmax(axis=-1).squeeze()\n",
    "    return maxx, argmaxx\n",
    "# Outputs for original images\n",
    "\n",
    "max_out, argmax_out = get_max_argmax(img_out)\n",
    "max_in, argmax_in = get_max_argmax(img_in)\n",
    "max_per_out, argmax_per_out = get_max_argmax(img_perturbed_out)\n",
    "max_per_in, argmax_per_in = get_max_argmax(img_perturbed_in)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13, 10))\n",
    "plt.subplot(221)\n",
    "plt.plot(max_out, \"*--\")\n",
    "plt.plot(max_per_out, \"*--\")\n",
    "plt.title(\"Max of calibrated OOD softmax outputs\")\n",
    "plt.legend([\"Original\", \"Perturbed\"])\n",
    "plt.subplot(222)\n",
    "plt.plot(max_in, \"*--\")\n",
    "plt.plot(max_per_in, \"*--\")\n",
    "plt.title(\"Max of calibrated ID softmax outputs\")\n",
    "plt.legend([\"Original\", \"Perturbed\"])\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(13, 5))\n",
    "plt.hist((max_per_out, max_per_in), bins=30, color=(\"blue\", \"orange\"), label=(\"ood\", \"id\"), density=True)\n",
    "plt.title(\"max perturbated softmax for OOD and ID data\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(13, 5))\n",
    "plt.hist((max_per_out - max_out, max_per_in - max_in), bins=30, color=(\"blue\", \"orange\"), label=(\"ood\", \"id\"), density=True)\n",
    "plt.title(\"difference between max perturbated softmax and max softmax for OOD and ID data\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "nb_label_shifts_out = np.where(argmax_out != argmax_per_out)[0].shape[0]\n",
    "nb_label_shifts_in = np.where(argmax_in != argmax_per_in)[0].shape[0]\n",
    "print(\"Number of label shift for OOD data: \", nb_label_shifts_out)\n",
    "print(\"Number of label shift for ID data: \", nb_label_shifts_in)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oodeel_dev_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d80a18d61e6ad16acc6e8a5ef082fbd0a65400a097e8fba89bb5761bc6bbc9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
