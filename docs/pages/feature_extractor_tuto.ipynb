{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using Oodeel, you have to keep in mind how `oodmodel` works, and specifically, how it extracts features from the model that is given as an argument to OODModel.fit(). Under the hood, `OODModel`uses an object called `FeatureExtractor` (with two child versions, `KerasFeatureExtractor`or `TorchFeatureExtractor`, depending on your model's implementation).\n",
    "\n",
    "The key point here is to be able to correctly identify the output layer(s) of your model so that the `FeatureExtractor` knows what to extract. The layer can be identified by a name or by a slice, if possible. Let's dive into different situations\n",
    "\n",
    "<div class=\"admonition warning\">\n",
    "  <p class=\"admonition-title\">Important</p>\n",
    "  <p>\n",
    "    In this notebook, we go through FeatureExtractor class, but this class is never explicitly used by the user. It works under the hood of OODModel. Still, understanding how it works is mandatory for correct usage of OODModel, see the Wrap-up section below.\n",
    "  </p>\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\" \n",
    "import tensorflow as tf\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "from oodeel.models import KerasFeatureExtractor\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### A keras Sequential model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model(input_shape=(32, 32, 3), output_shape=10):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Input(shape=input_shape))\n",
    "    model.add(tf.keras.layers.Conv2D(4, kernel_size=(2, 2), activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(tf.keras.layers.Dropout(0.25))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(output_shape))\n",
    "    model.add(tf.keras.layers.Activation(\"softmax\"))\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"sgd\")\n",
    "\n",
    "    return model\n",
    "\n",
    "model = generate_model()\n",
    "model.compile(optimizer=\"adam\")\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what's in there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 31, 31, 4)         52        \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 15, 15, 4)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 15, 15, 4)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 900)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                9010      \n",
      "                                                                 \n",
      " activation (Activation)     (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,062\n",
      "Trainable params: 9,062\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the time, it is of interest to take the output of neural networks' penultimate layers to apply OOD methods. Here, we can see that the layer can be identified as the $d-3$-th, with $d$ the depth of the network. To achieve that instantiate the `FeatureExtractor` as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 900)\n"
     ]
    }
   ],
   "source": [
    "extractor = KerasFeatureExtractor(model, output_layers_id=[-3])\n",
    "\n",
    "x = tf.ones((100, 32, 32,3))\n",
    "x_latent = extractor(x)\n",
    "print(x_latent.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can identify the layer by its name: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 900)\n"
     ]
    }
   ],
   "source": [
    "extractor = KerasFeatureExtractor(model, output_layers_id=[\"flatten\"])\n",
    "\n",
    "x = tf.ones((100, 32, 32,3))\n",
    "x_latent = extractor(x)\n",
    "print(x_latent.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also set the starting point of your extractor, which can be useful to avoid repeated forward passes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 900)\n",
      "(100, 10)\n"
     ]
    }
   ],
   "source": [
    "extractor_2 = KerasFeatureExtractor(model, input_layer_id = \"dense\", output_layers_id=[\"activation\"])\n",
    "\n",
    "x_latent = extractor(x)\n",
    "print(x_latent.shape)\n",
    "y = extractor_2(x_latent)\n",
    "print(y.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Warning:**\n",
    ">\n",
    "> * Be careful, the name of the input layer is that of the layer following the previous output layer\n",
    "> * The extractor may only have one input layer (hence the `str` format of the argument instead of `list`)\n",
    "\n",
    "If needed, you can get the output of several layers at the same time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 900) (100, 10)\n"
     ]
    }
   ],
   "source": [
    "extractor = KerasFeatureExtractor(model, output_layers_id=[-3, -1])\n",
    "\n",
    "x = tf.ones((100, 32, 32,3))\n",
    "x_latent = extractor(x)\n",
    "print(x_latent[0].shape, x_latent[1].shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Warning:**\n",
    "> \n",
    "> For this cell to work, you have to clear ipython kernel from the previous extractors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For non-sequential keras models\n",
    "\n",
    "When your model is built out of a set of layers that are not connected sequentially, your only option is to rely on the identification by layer name, as referred in `model`.summary()` \n",
    "\n",
    "## PyTorch Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from oodeel.models import TorchFeatureExtractor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's consider some Pytorch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)  # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "model = Net()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, let's display how the model is constructed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('', Net(\n",
      "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "))\n",
      "('conv1', Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1)))\n",
      "('pool', MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False))\n",
      "('conv2', Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1)))\n",
      "('fc1', Linear(in_features=400, out_features=120, bias=True))\n",
      "('fc2', Linear(in_features=120, out_features=84, bias=True))\n",
      "('fc3', Linear(in_features=84, out_features=10, bias=True))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for layer in model.named_modules():\n",
    "    print(layer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That case is pretty much the same as for Tensorflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numbered output:\n",
      " torch.Size([100, 120])\n",
      "named output:\n",
      " torch.Size([100, 120])\n",
      "multi output:\n",
      " torch.Size([100, 120]) torch.Size([100, 10])\n"
     ]
    }
   ],
   "source": [
    "extractor = TorchFeatureExtractor(model, output_layers_id=[-3])\n",
    "\n",
    "x = torch.ones((100, 3, 32, 32))\n",
    "x_latent = extractor(x)\n",
    "print(\"numbered output:\\n\", x_latent.shape)\n",
    "\n",
    "extractor = TorchFeatureExtractor(model, output_layers_id=[\"fc1\"])\n",
    "\n",
    "x = torch.ones((100, 3, 32, 32))\n",
    "x_latent = extractor(x)\n",
    "print(\"named output:\\n\", x_latent.shape)\n",
    "\n",
    "extractor = TorchFeatureExtractor(model, output_layers_id=[\"fc1\", \"fc3\"])\n",
    "\n",
    "x = torch.ones((100, 3, 32, 32))\n",
    "x_latent = extractor(x)\n",
    "print(\"multi output:\\n\", x_latent[0].shape, x_latent[1].shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Warning:**\n",
    ">\n",
    "> As opposed to Tensorflow, PyTorch extractor can only take internal layers as input for `nn.Sequential` models.\n",
    "\n",
    "Will not work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = TorchFeatureExtractor(model, output_layers_id=[\"fc1\"])\n",
    "extractor_2 = TorchFeatureExtractor(model, input_layer_id = \"fc2\", output_layers_id=[\"fc3\"])\n",
    "\n",
    "x_latent = extractor(x)\n",
    "print(x_latent.shape)\n",
    "y = extractor_2(x_latent)\n",
    "print(y.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 120])\n",
      "torch.Size([100, 10])\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "def named_sequential_model():\n",
    "    return nn.Sequential(\n",
    "        OrderedDict(\n",
    "            [\n",
    "                (\"conv1\", nn.Conv2d(3, 6, 5)),\n",
    "                (\"relu1\", nn.ReLU()),\n",
    "                (\"pool1\", nn.MaxPool2d(2, 2)),\n",
    "                (\"conv2\", nn.Conv2d(6, 16, 5)),\n",
    "                (\"relu2\", nn.ReLU()),\n",
    "                (\"pool2\", nn.MaxPool2d(2, 2)),\n",
    "                (\"flatten\", nn.Flatten()),\n",
    "                (\"fc1\", nn.Linear(16 * 5 * 5, 120)),\n",
    "                (\"fc2\", nn.Linear(120, 84)),\n",
    "                (\"fc3\", nn.Linear(84, 10)),\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "\n",
    "model = named_sequential_model()\n",
    "extractor = TorchFeatureExtractor(model, output_layers_id=[\"fc1\"])\n",
    "extractor_2 = TorchFeatureExtractor(model, input_layer_id = \"fc2\", output_layers_id=[\"fc3\"])\n",
    "\n",
    "x_latent = extractor(x)\n",
    "print(x_latent.shape)\n",
    "y = extractor_2(x_latent)\n",
    "print(y.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrap-up"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have identified the way you want to extract data from your model, which boils down to correctly identifying what to put under the `output_layers_id`and `input_layer_id` arguments, you can properly instantiate your `OODModel` like this (example with DKNN):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from oodeel.methods import DKNN\n",
    "\n",
    "oodmodel = DKNN(output_layers_id=[\"fc1\"])\n",
    "# Then:\n",
    "# oodmodel.fit(model, #some_fit_dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact, you never have to instantiate the feature extractor by yourself, it is automatically performed by `OODModel` (here `DKNN`). It detects the underlying library of `model`, and instantiates the adapted `FeatureExtractor` using the arguments given as input to `OODModel`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:**\n",
    ">\n",
    "> We recommend that you only identify layers by name; we experienced that it is less error prone."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oodeel_dev_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
