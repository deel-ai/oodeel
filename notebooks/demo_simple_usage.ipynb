{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-04 15:06:53.192594: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-10-04 15:06:53.293806: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-10-04 15:06:53.293912: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "/home/pnovello/.virtualenvs/full/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from oodeel.utils.load_utils import get_model\n",
    "from oodeel.methods import MLS\n",
    "from oodeel.methods import DKNN\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from oodeel.eval.metrics import bench_metrics, get_curve\n",
    "from oodeel.datasets import DataHandler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data and model loading\n",
    "ID data: MNIST, OOD data: Fashion MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = get_model(\"../saved_models/mnist_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-04 10:43:23.147930: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-10-04 10:43:23.148822: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-10-04 10:43:23.149263: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (B20212474): /proc/driver/nvidia/version does not exist\n",
      "2022-10-04 10:43:23.162807: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/pnovello/workspace/oodeel/notebooks/demo_simple_usage.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/pnovello/workspace/oodeel/notebooks/demo_simple_usage.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m x, y \u001b[39m=\u001b[39m data_handler\u001b[39m.\u001b[39mconvert_to_numpy(x_id)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/pnovello/workspace/oodeel/notebooks/demo_simple_usage.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m x_test \u001b[39m=\u001b[39m data_handler\u001b[39m.\u001b[39mmerge_tfds(x_id, x_ood, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/pnovello/workspace/oodeel/notebooks/demo_simple_usage.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m fe \u001b[39m=\u001b[39m KerasFeatureExtractor(model, output_layers_id \u001b[39m=\u001b[39m [\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/pnovello/workspace/oodeel/notebooks/demo_simple_usage.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m features \u001b[39m=\u001b[39m fe\u001b[39m.\u001b[39mpredict(x)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/pnovello/workspace/oodeel/notebooks/demo_simple_usage.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m fe2 \u001b[39m=\u001b[39m KerasFeatureExtractor(model, output_layers_id \u001b[39m=\u001b[39m [], input_layer_id \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m2\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "from oodeel.models.feature_extractor import KerasFeatureExtractor\n",
    "data_handler = DataHandler()\n",
    "ds1 = data_handler.load_tfds('mnist')\n",
    "ds2 = data_handler.load_tfds('fashion_mnist')\n",
    "x_id = ds1[\"test\"]\n",
    "x_ood = ds2[\"test\"]\n",
    "x, y = data_handler.convert_to_numpy(x_id)\n",
    "\n",
    "x_test = data_handler.merge_tfds(x_id, x_ood, shuffle=True)\n",
    "\n",
    "fe = KerasFeatureExtractor(model, output_layers_id = [-2])\n",
    "features = fe.predict(x)\n",
    "fe2 = KerasFeatureExtractor(model, output_layers_id = [], input_layer_id = -2)\n",
    "output = fe2.predict(features[0])\n",
    "output_true = model.predict(x)\n",
    "print(np.sum(np.abs(output - output_true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-04 10:46:54.684866: W tensorflow/core/platform/cloud/google_auth_provider.cc:184] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with \"NOT_FOUND: Could not locate the credentials file.\". Retrieving token from GCE failed with \"FAILED_PRECONDITION: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Could not resolve host: metadata\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset 162.17 MiB (download: 162.17 MiB, generated: 132.40 MiB, total: 294.58 MiB) to ~/tensorflow_datasets/cifar10/3.0.2...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dl Completed...: 0 url [00:00, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:00<?, ? url/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00, 27.70 url/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00, 17.34 url/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00, 12.91 url/s]\n",
      "Extraction completed...: 0 file [00:00, ? file/s]\n",
      "Dl Size...: 100%|██████████| 170052171/170052171 [00:00<00:00, 1707186336.38 MiB/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:00<00:00,  9.52 url/s]\n",
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset cifar10 downloaded and prepared to ~/tensorflow_datasets/cifar10/3.0.2. Subsequent calls will reuse this data.\u001b[0m\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/home/pnovello/.virtualenvs/full/lib/python3.8/site-packages/keras/engine/training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/pnovello/.virtualenvs/full/lib/python3.8/site-packages/keras/engine/training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/pnovello/.virtualenvs/full/lib/python3.8/site-packages/keras/engine/training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/pnovello/.virtualenvs/full/lib/python3.8/site-packages/keras/engine/training.py\", line 890, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/home/pnovello/.virtualenvs/full/lib/python3.8/site-packages/keras/engine/training.py\", line 948, in compute_loss\n        return self.compiled_loss(\n    File \"/home/pnovello/.virtualenvs/full/lib/python3.8/site-packages/keras/engine/compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/home/pnovello/.virtualenvs/full/lib/python3.8/site-packages/keras/losses.py\", line 139, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/home/pnovello/.virtualenvs/full/lib/python3.8/site-packages/keras/losses.py\", line 243, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/home/pnovello/.virtualenvs/full/lib/python3.8/site-packages/keras/losses.py\", line 1787, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/home/pnovello/.virtualenvs/full/lib/python3.8/site-packages/keras/backend.py\", line 5119, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 10) and (None, 1000) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/pnovello/workspace/oodeel/notebooks/demo_simple_usage.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/pnovello/workspace/oodeel/notebooks/demo_simple_usage.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m#model = train_convnet(x_id, **train_config)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/pnovello/workspace/oodeel/notebooks/demo_simple_usage.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m x_id \u001b[39m=\u001b[39m x_id\u001b[39m.\u001b[39mmap(\u001b[39mlambda\u001b[39;00m x, y: reshape_im(x, y, (\u001b[39m224\u001b[39m, \u001b[39m224\u001b[39m)))\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/pnovello/workspace/oodeel/notebooks/demo_simple_usage.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m model \u001b[39m=\u001b[39m train_keras_app(x_id, model_name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mEfficientNetB0\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mtrain_config)\n",
      "File \u001b[0;32m~/workspace/oodeel/notebooks/../oodeel/models/training_funs/keras_models.py:33\u001b[0m, in \u001b[0;36mtrain_keras_app\u001b[0;34m(train_data, model_name, batch_size, epochs, loss, optimizer, metrics, imagenet_pretrained)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[39m#### TODO \u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[39m# Add preprocessing (data augmentation)\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[39m# Add learning rate schedule\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[39m# Add early stopping ?\u001b[39;00m\n\u001b[1;32m     32\u001b[0m model\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39mloss, optimizer\u001b[39m=\u001b[39moptimizer, metrics\u001b[39m=\u001b[39mmetrics)\n\u001b[0;32m---> 33\u001b[0m model\u001b[39m.\u001b[39;49mfit(train_data, epochs\u001b[39m=\u001b[39;49mepochs) \n\u001b[1;32m     35\u001b[0m \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/.virtualenvs/full/lib/python3.8/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filedozi2s2p.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/home/pnovello/.virtualenvs/full/lib/python3.8/site-packages/keras/engine/training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/pnovello/.virtualenvs/full/lib/python3.8/site-packages/keras/engine/training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/pnovello/.virtualenvs/full/lib/python3.8/site-packages/keras/engine/training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/pnovello/.virtualenvs/full/lib/python3.8/site-packages/keras/engine/training.py\", line 890, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/home/pnovello/.virtualenvs/full/lib/python3.8/site-packages/keras/engine/training.py\", line 948, in compute_loss\n        return self.compiled_loss(\n    File \"/home/pnovello/.virtualenvs/full/lib/python3.8/site-packages/keras/engine/compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/home/pnovello/.virtualenvs/full/lib/python3.8/site-packages/keras/losses.py\", line 139, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/home/pnovello/.virtualenvs/full/lib/python3.8/site-packages/keras/losses.py\", line 243, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/home/pnovello/.virtualenvs/full/lib/python3.8/site-packages/keras/losses.py\", line 1787, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/home/pnovello/.virtualenvs/full/lib/python3.8/site-packages/keras/backend.py\", line 5119, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 10) and (None, 1000) are incompatible\n"
     ]
    }
   ],
   "source": [
    "%autoreload 2\n",
    "from oodeel.models.training_funs import train_convnet, train_keras_app\n",
    "\n",
    "train_config = {\n",
    "    \"batch_size\": 128,\n",
    "    \"epochs\": 5\n",
    "}\n",
    "ds1 = data_handler.load_tfds('cifar10')\n",
    "x_id = ds1[\"test\"]\n",
    "\n",
    "def reshape_im(x, y, shape):\n",
    "    x = tf.image.resize(x, shape)\n",
    "    return x, y\n",
    "\n",
    "#model = train_convnet(x_id, **train_config)\n",
    "\n",
    "x_id = x_id.map(lambda x, y: reshape_im(x, y, (224, 224)))\n",
    "\n",
    "model = train_keras_app(x_id, model_name='EfficientNetB0', **train_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum Logit Score\n",
    "(A good classifier is all you need ?)\n",
    "\n",
    "Example of method that does not need ID data to compute statistics to compare against"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1600)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-30 19:04:08.694902: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "%autoreload 2\n",
    "\n",
    "data_handler = DataHandler()\n",
    "ds1 = data_handler.load_tfds('mnist')\n",
    "ds2 = data_handler.load_tfds('fashion_mnist')\n",
    "x_id = ds1[\"test\"]\n",
    "x_ood = ds2[\"test\"]\n",
    "\n",
    "\n",
    "x_test = data_handler.merge_tfds(x_id, x_ood, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 1s 24ms/step\n"
     ]
    }
   ],
   "source": [
    "%autoreload 2\n",
    "from oodeel.models.feature_extractor import KerasFeatureExtractor\n",
    "\n",
    "fextr = KerasFeatureExtractor(model, output_layers_id = [], output_activation=\"linear\")\n",
    "a = fextr.predict(x_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 5s 47ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%autoreload 2\n",
    "\n",
    "oodmodel = MLS()\n",
    "oodmodel.fit(model)\n",
    "scores = oodmodel.score(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(a[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 1s 27ms/step\n",
      "40/40 [==============================] - 1s 28ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%autoreload 2\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "\n",
    "scores_id, scores_ood = oodmodel.score([x_id, x_ood])\n",
    "plt.hist((scores_ood, scores_id), bins=10, color=(\"blue\", \"orange\"), label=(\"ood\", \"id\"), density=True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check to test the `__call__` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 1s 30ms/step\n",
      "40/40 [==============================] - 1s 24ms/step\n",
      "0.0\n",
      "tf.Tensor(0.949, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "oodmodel.threshold = -5\n",
    "isooddata = oodmodel.isood(inputs=x_ood)\n",
    "isooddata2 = oodmodel(x_ood)\n",
    "print(np.sum(isooddata - isooddata2))\n",
    "print(np.sum(isooddata)/x_ood.cardinality())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep KNN\n",
    "Example of method that needs ID data to compute statistics to compare against"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-04 15:30:01.820368: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=1.0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_handler = DataHandler()\n",
    "ds1 = data_handler.load_tfds('mnist')\n",
    "ds2 = data_handler.load_tfds('fashion_mnist')\n",
    "x_id = ds1[\"test\"]\n",
    "x_ood = ds2[\"test\"]\n",
    "x_train = ds1[\"train\"]\n",
    "\n",
    "\n",
    "x_test = data_handler.merge_tfds(x_id.take(1000), x_ood.take(1000), shuffle='True')\n",
    "\n",
    "x_tf = x_id.map(lambda x, y: x)\n",
    "a = tf.constant(1)\n",
    "print(float(tf.math.reduce_max(a)))\n",
    "\n",
    "x_tf.reduce(0., lambda x, y: float(tf.math.reduce_max(tf.maximum(x, y))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-30 19:16:30.462170: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 2s 29ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-30 19:16:32.008838: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2022-09-30 19:16:32.621969: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2022-09-30 19:16:32.725778: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/8 [==>...........................] - ETA: 3s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-30 19:16:33.076569: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2022-09-30 19:16:33.234970: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 22ms/step\n"
     ]
    }
   ],
   "source": [
    "%autoreload 2\n",
    "oodmodel = DKNN()\n",
    "oodmodel.fit(model, x_train.take(10000))\n",
    "scores = oodmodel.score(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function DataHandler.convert_to_numpy.<locals>.<lambda> at 0x7f048c2d2670> and will run it as-is.\n",
      "Cause: could not parse the source code of <function DataHandler.convert_to_numpy.<locals>.<lambda> at 0x7f048c2d2670>: no matching AST found among candidates:\n",
      "# coding=utf-8\n",
      "(lambda x, y: tf.reduce_any(tf.equal(y, split)))\n",
      "# coding=utf-8\n",
      "(lambda x, y: (not tf.reduce_any(tf.equal(y, split))))\n",
      "# coding=utf-8\n",
      "(lambda x, y: reshape_im(x, y, shape))\n",
      "# coding=utf-8\n",
      "(lambda x, y: reshape_im(x, y, shape))\n",
      "# coding=utf-8\n",
      "(lambda x, y: add_label(x, y, 0))\n",
      "# coding=utf-8\n",
      "(lambda x, y: add_label(x, y, 1))\n",
      "# coding=utf-8\n",
      "(lambda x, y, z: z)\n",
      "# coding=utf-8\n",
      "(lambda x, y: x)\n",
      "# coding=utf-8\n",
      "(lambda x, y: y)\n",
      "# coding=utf-8\n",
      "(lambda x, y: ((x / 255), y))\n",
      "# coding=utf-8\n",
      "(lambda x, y: ((x / 255), y))\n",
      "# coding=utf-8\n",
      "(lambda x, y: y)\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function DataHandler.convert_to_numpy.<locals>.<lambda> at 0x7f048c2d2670> and will run it as-is.\n",
      "Cause: could not parse the source code of <function DataHandler.convert_to_numpy.<locals>.<lambda> at 0x7f048c2d2670>: no matching AST found among candidates:\n",
      "# coding=utf-8\n",
      "(lambda x, y: tf.reduce_any(tf.equal(y, split)))\n",
      "# coding=utf-8\n",
      "(lambda x, y: (not tf.reduce_any(tf.equal(y, split))))\n",
      "# coding=utf-8\n",
      "(lambda x, y: reshape_im(x, y, shape))\n",
      "# coding=utf-8\n",
      "(lambda x, y: reshape_im(x, y, shape))\n",
      "# coding=utf-8\n",
      "(lambda x, y: add_label(x, y, 0))\n",
      "# coding=utf-8\n",
      "(lambda x, y: add_label(x, y, 1))\n",
      "# coding=utf-8\n",
      "(lambda x, y, z: z)\n",
      "# coding=utf-8\n",
      "(lambda x, y: x)\n",
      "# coding=utf-8\n",
      "(lambda x, y: y)\n",
      "# coding=utf-8\n",
      "(lambda x, y: ((x / 255), y))\n",
      "# coding=utf-8\n",
      "(lambda x, y: ((x / 255), y))\n",
      "# coding=utf-8\n",
      "(lambda x, y: y)\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function DataHandler.convert_to_numpy.<locals>.<lambda> at 0x7f048c2d2670> and will run it as-is.\n",
      "Cause: could not parse the source code of <function DataHandler.convert_to_numpy.<locals>.<lambda> at 0x7f048c2d2670>: no matching AST found among candidates:\n",
      "# coding=utf-8\n",
      "(lambda x, y: tf.reduce_any(tf.equal(y, split)))\n",
      "# coding=utf-8\n",
      "(lambda x, y: (not tf.reduce_any(tf.equal(y, split))))\n",
      "# coding=utf-8\n",
      "(lambda x, y: reshape_im(x, y, shape))\n",
      "# coding=utf-8\n",
      "(lambda x, y: reshape_im(x, y, shape))\n",
      "# coding=utf-8\n",
      "(lambda x, y: add_label(x, y, 0))\n",
      "# coding=utf-8\n",
      "(lambda x, y: add_label(x, y, 1))\n",
      "# coding=utf-8\n",
      "(lambda x, y, z: z)\n",
      "# coding=utf-8\n",
      "(lambda x, y: x)\n",
      "# coding=utf-8\n",
      "(lambda x, y: y)\n",
      "# coding=utf-8\n",
      "(lambda x, y: ((x / 255), y))\n",
      "# coding=utf-8\n",
      "(lambda x, y: ((x / 255), y))\n",
      "# coding=utf-8\n",
      "(lambda x, y: y)\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function DataHandler.convert_to_numpy.<locals>.<lambda> at 0x7f04ac5a35e0> and will run it as-is.\n",
      "Cause: could not parse the source code of <function DataHandler.convert_to_numpy.<locals>.<lambda> at 0x7f04ac5a35e0>: no matching AST found among candidates:\n",
      "# coding=utf-8\n",
      "(lambda x, y: tf.reduce_any(tf.equal(y, split)))\n",
      "# coding=utf-8\n",
      "(lambda x, y: (not tf.reduce_any(tf.equal(y, split))))\n",
      "# coding=utf-8\n",
      "(lambda x, y: reshape_im(x, y, shape))\n",
      "# coding=utf-8\n",
      "(lambda x, y: reshape_im(x, y, shape))\n",
      "# coding=utf-8\n",
      "(lambda x, y: add_label(x, y, 0))\n",
      "# coding=utf-8\n",
      "(lambda x, y: add_label(x, y, 1))\n",
      "# coding=utf-8\n",
      "(lambda x, y, z: z)\n",
      "# coding=utf-8\n",
      "(lambda x, y: x)\n",
      "# coding=utf-8\n",
      "(lambda x, y: y)\n",
      "# coding=utf-8\n",
      "(lambda x, y: ((x / 255), y))\n",
      "# coding=utf-8\n",
      "(lambda x, y: ((x / 255), y))\n",
      "# coding=utf-8\n",
      "(lambda x, y: y)\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function DataHandler.convert_to_numpy.<locals>.<lambda> at 0x7f04ac5a35e0> and will run it as-is.\n",
      "Cause: could not parse the source code of <function DataHandler.convert_to_numpy.<locals>.<lambda> at 0x7f04ac5a35e0>: no matching AST found among candidates:\n",
      "# coding=utf-8\n",
      "(lambda x, y: tf.reduce_any(tf.equal(y, split)))\n",
      "# coding=utf-8\n",
      "(lambda x, y: (not tf.reduce_any(tf.equal(y, split))))\n",
      "# coding=utf-8\n",
      "(lambda x, y: reshape_im(x, y, shape))\n",
      "# coding=utf-8\n",
      "(lambda x, y: reshape_im(x, y, shape))\n",
      "# coding=utf-8\n",
      "(lambda x, y: add_label(x, y, 0))\n",
      "# coding=utf-8\n",
      "(lambda x, y: add_label(x, y, 1))\n",
      "# coding=utf-8\n",
      "(lambda x, y, z: z)\n",
      "# coding=utf-8\n",
      "(lambda x, y: x)\n",
      "# coding=utf-8\n",
      "(lambda x, y: y)\n",
      "# coding=utf-8\n",
      "(lambda x, y: ((x / 255), y))\n",
      "# coding=utf-8\n",
      "(lambda x, y: ((x / 255), y))\n",
      "# coding=utf-8\n",
      "(lambda x, y: y)\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function DataHandler.convert_to_numpy.<locals>.<lambda> at 0x7f04ac5a35e0> and will run it as-is.\n",
      "Cause: could not parse the source code of <function DataHandler.convert_to_numpy.<locals>.<lambda> at 0x7f04ac5a35e0>: no matching AST found among candidates:\n",
      "# coding=utf-8\n",
      "(lambda x, y: tf.reduce_any(tf.equal(y, split)))\n",
      "# coding=utf-8\n",
      "(lambda x, y: (not tf.reduce_any(tf.equal(y, split))))\n",
      "# coding=utf-8\n",
      "(lambda x, y: reshape_im(x, y, shape))\n",
      "# coding=utf-8\n",
      "(lambda x, y: reshape_im(x, y, shape))\n",
      "# coding=utf-8\n",
      "(lambda x, y: add_label(x, y, 0))\n",
      "# coding=utf-8\n",
      "(lambda x, y: add_label(x, y, 1))\n",
      "# coding=utf-8\n",
      "(lambda x, y, z: z)\n",
      "# coding=utf-8\n",
      "(lambda x, y: x)\n",
      "# coding=utf-8\n",
      "(lambda x, y: y)\n",
      "# coding=utf-8\n",
      "(lambda x, y: ((x / 255), y))\n",
      "# coding=utf-8\n",
      "(lambda x, y: ((x / 255), y))\n",
      "# coding=utf-8\n",
      "(lambda x, y: y)\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function DataHandler.convert_to_numpy.<locals>.<lambda> at 0x7f04ac5a35e0> and will run it as-is.\n",
      "Cause: could not parse the source code of <function DataHandler.convert_to_numpy.<locals>.<lambda> at 0x7f04ac5a35e0>: no matching AST found among candidates:\n",
      "# coding=utf-8\n",
      "(lambda x, y: tf.reduce_any(tf.equal(y, split)))\n",
      "# coding=utf-8\n",
      "(lambda x, y: (not tf.reduce_any(tf.equal(y, split))))\n",
      "# coding=utf-8\n",
      "(lambda x, y: reshape_im(x, y, shape))\n",
      "# coding=utf-8\n",
      "(lambda x, y: reshape_im(x, y, shape))\n",
      "# coding=utf-8\n",
      "(lambda x, y: add_label(x, y, 0))\n",
      "# coding=utf-8\n",
      "(lambda x, y: add_label(x, y, 1))\n",
      "# coding=utf-8\n",
      "(lambda x, y, z: z)\n",
      "# coding=utf-8\n",
      "(lambda x, y: x)\n",
      "# coding=utf-8\n",
      "(lambda x, y: y)\n",
      "# coding=utf-8\n",
      "(lambda x, y: ((x / 255), y))\n",
      "# coding=utf-8\n",
      "(lambda x, y: ((x / 255), y))\n",
      "# coding=utf-8\n",
      "(lambda x, y: y)\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function DataHandler.convert_to_numpy.<locals>.<lambda> at 0x7f04ac5a35e0> and will run it as-is.\n",
      "Cause: could not parse the source code of <function DataHandler.convert_to_numpy.<locals>.<lambda> at 0x7f04ac5a35e0>: no matching AST found among candidates:\n",
      "# coding=utf-8\n",
      "(lambda x, y: tf.reduce_any(tf.equal(y, split)))\n",
      "# coding=utf-8\n",
      "(lambda x, y: (not tf.reduce_any(tf.equal(y, split))))\n",
      "# coding=utf-8\n",
      "(lambda x, y: reshape_im(x, y, shape))\n",
      "# coding=utf-8\n",
      "(lambda x, y: reshape_im(x, y, shape))\n",
      "# coding=utf-8\n",
      "(lambda x, y: add_label(x, y, 0))\n",
      "# coding=utf-8\n",
      "(lambda x, y: add_label(x, y, 1))\n",
      "# coding=utf-8\n",
      "(lambda x, y, z: z)\n",
      "# coding=utf-8\n",
      "(lambda x, y: x)\n",
      "# coding=utf-8\n",
      "(lambda x, y: y)\n",
      "# coding=utf-8\n",
      "(lambda x, y: ((x / 255), y))\n",
      "# coding=utf-8\n",
      "(lambda x, y: ((x / 255), y))\n",
      "# coding=utf-8\n",
      "(lambda x, y: y)\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function DataHandler.convert_to_numpy.<locals>.<lambda> at 0x7f04ac5a35e0> and will run it as-is.\n",
      "Cause: could not parse the source code of <function DataHandler.convert_to_numpy.<locals>.<lambda> at 0x7f04ac5a35e0>: no matching AST found among candidates:\n",
      "# coding=utf-8\n",
      "(lambda x, y: tf.reduce_any(tf.equal(y, split)))\n",
      "# coding=utf-8\n",
      "(lambda x, y: (not tf.reduce_any(tf.equal(y, split))))\n",
      "# coding=utf-8\n",
      "(lambda x, y: reshape_im(x, y, shape))\n",
      "# coding=utf-8\n",
      "(lambda x, y: reshape_im(x, y, shape))\n",
      "# coding=utf-8\n",
      "(lambda x, y: add_label(x, y, 0))\n",
      "# coding=utf-8\n",
      "(lambda x, y: add_label(x, y, 1))\n",
      "# coding=utf-8\n",
      "(lambda x, y, z: z)\n",
      "# coding=utf-8\n",
      "(lambda x, y: x)\n",
      "# coding=utf-8\n",
      "(lambda x, y: y)\n",
      "# coding=utf-8\n",
      "(lambda x, y: ((x / 255), y))\n",
      "# coding=utf-8\n",
      "(lambda x, y: ((x / 255), y))\n",
      "# coding=utf-8\n",
      "(lambda x, y: y)\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function DataHandler.convert_to_numpy.<locals>.<lambda> at 0x7f048c4f9700> and will run it as-is.\n",
      "Cause: could not parse the source code of <function DataHandler.convert_to_numpy.<locals>.<lambda> at 0x7f048c4f9700>: no matching AST found among candidates:\n",
      "# coding=utf-8\n",
      "(lambda x, y: tf.reduce_any(tf.equal(y, split)))\n",
      "# coding=utf-8\n",
      "(lambda x, y: (not tf.reduce_any(tf.equal(y, split))))\n",
      "# coding=utf-8\n",
      "(lambda x, y: reshape_im(x, y, shape))\n",
      "# coding=utf-8\n",
      "(lambda x, y: reshape_im(x, y, shape))\n",
      "# coding=utf-8\n",
      "(lambda x, y: add_label(x, y, 0))\n",
      "# coding=utf-8\n",
      "(lambda x, y: add_label(x, y, 1))\n",
      "# coding=utf-8\n",
      "(lambda x, y, z: z)\n",
      "# coding=utf-8\n",
      "(lambda x, y: x)\n",
      "# coding=utf-8\n",
      "(lambda x, y: y)\n",
      "# coding=utf-8\n",
      "(lambda x, y: ((x / 255), y))\n",
      "# coding=utf-8\n",
      "(lambda x, y: ((x / 255), y))\n",
      "# coding=utf-8\n",
      "(lambda x, y: y)\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function DataHandler.convert_to_numpy.<locals>.<lambda> at 0x7f048c4f9700> and will run it as-is.\n",
      "Cause: could not parse the source code of <function DataHandler.convert_to_numpy.<locals>.<lambda> at 0x7f048c4f9700>: no matching AST found among candidates:\n",
      "# coding=utf-8\n",
      "(lambda x, y: tf.reduce_any(tf.equal(y, split)))\n",
      "# coding=utf-8\n",
      "(lambda x, y: (not tf.reduce_any(tf.equal(y, split))))\n",
      "# coding=utf-8\n",
      "(lambda x, y: reshape_im(x, y, shape))\n",
      "# coding=utf-8\n",
      "(lambda x, y: reshape_im(x, y, shape))\n",
      "# coding=utf-8\n",
      "(lambda x, y: add_label(x, y, 0))\n",
      "# coding=utf-8\n",
      "(lambda x, y: add_label(x, y, 1))\n",
      "# coding=utf-8\n",
      "(lambda x, y, z: z)\n",
      "# coding=utf-8\n",
      "(lambda x, y: x)\n",
      "# coding=utf-8\n",
      "(lambda x, y: y)\n",
      "# coding=utf-8\n",
      "(lambda x, y: ((x / 255), y))\n",
      "# coding=utf-8\n",
      "(lambda x, y: ((x / 255), y))\n",
      "# coding=utf-8\n",
      "(lambda x, y: y)\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function DataHandler.convert_to_numpy.<locals>.<lambda> at 0x7f048c4f9700> and will run it as-is.\n",
      "Cause: could not parse the source code of <function DataHandler.convert_to_numpy.<locals>.<lambda> at 0x7f048c4f9700>: no matching AST found among candidates:\n",
      "# coding=utf-8\n",
      "(lambda x, y: tf.reduce_any(tf.equal(y, split)))\n",
      "# coding=utf-8\n",
      "(lambda x, y: (not tf.reduce_any(tf.equal(y, split))))\n",
      "# coding=utf-8\n",
      "(lambda x, y: reshape_im(x, y, shape))\n",
      "# coding=utf-8\n",
      "(lambda x, y: reshape_im(x, y, shape))\n",
      "# coding=utf-8\n",
      "(lambda x, y: add_label(x, y, 0))\n",
      "# coding=utf-8\n",
      "(lambda x, y: add_label(x, y, 1))\n",
      "# coding=utf-8\n",
      "(lambda x, y, z: z)\n",
      "# coding=utf-8\n",
      "(lambda x, y: x)\n",
      "# coding=utf-8\n",
      "(lambda x, y: y)\n",
      "# coding=utf-8\n",
      "(lambda x, y: ((x / 255), y))\n",
      "# coding=utf-8\n",
      "(lambda x, y: ((x / 255), y))\n",
      "# coding=utf-8\n",
      "(lambda x, y: y)\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'oodmodel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/pnovello/workspace/oodeel/notebooks/demo_simple_usage.ipynb Cell 20\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/pnovello/workspace/oodeel/notebooks/demo_simple_usage.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m x_id, y_id \u001b[39m=\u001b[39m data_handler\u001b[39m.\u001b[39mconvert_to_numpy(x_id)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/pnovello/workspace/oodeel/notebooks/demo_simple_usage.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m x_ood, y_ood \u001b[39m=\u001b[39m data_handler\u001b[39m.\u001b[39mconvert_to_numpy(x_ood)\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/pnovello/workspace/oodeel/notebooks/demo_simple_usage.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m scores_id, scores_ood \u001b[39m=\u001b[39m oodmodel\u001b[39m.\u001b[39mscore([x_id[:\u001b[39m1000\u001b[39m], x_ood[:\u001b[39m1000\u001b[39m]])\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/pnovello/workspace/oodeel/notebooks/demo_simple_usage.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m plt\u001b[39m.\u001b[39mhist((scores_ood, scores_id), bins\u001b[39m=\u001b[39m\u001b[39m30\u001b[39m, color\u001b[39m=\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mblue\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39morange\u001b[39m\u001b[39m\"\u001b[39m), label\u001b[39m=\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mood\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mid\u001b[39m\u001b[39m\"\u001b[39m), density\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/pnovello/workspace/oodeel/notebooks/demo_simple_usage.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m plt\u001b[39m.\u001b[39mlegend()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'oodmodel' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%autoreload 2\n",
    "plt.figure(figsize=(8,5))\n",
    "\n",
    "\n",
    "x_id, y_id = data_handler.convert_to_numpy(x_id)\n",
    "x_ood, y_ood = data_handler.convert_to_numpy(x_ood)\n",
    "scores_id, scores_ood = oodmodel.score([x_id[:1000], x_ood[:1000]])\n",
    "plt.hist((scores_ood, scores_id), bins=30, color=(\"blue\", \"orange\"), label=(\"ood\", \"id\"), density=True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "data_handler = DataHandler()\n",
    "(x_train, y_train),  (x_test, y_test) = data_handler.load_tfds('mnist', as_numpy=True)\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('full')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "637dace9d8dde2e6ff8e06a4f5409e85c7b1c4f3cbdfb1d699dedf835551a47d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
