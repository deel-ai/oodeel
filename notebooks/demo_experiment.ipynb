{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%env TFDS_DATA_DIR=/Users/paul/datasets/tensorflow_datasets\n",
    "%env PYTHONPATH=../\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import os\n",
    "print(os.environ[\"PYTHONPATH\"])\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from oodeel.methods import MLS, DKNN, ODIN\n",
    "from oodeel.methods import DKNN\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from oodeel.eval.metrics import bench_metrics, get_curve\n",
    "from oodeel.datasets import DataHandler\n",
    "\n",
    "from sklearn.metrics import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two datasets experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "\n",
    "def normalize(x):\n",
    "    return x/255\n",
    "    \n",
    "data_handler = DataHandler()\n",
    "ds1 = data_handler.load_tfds('mnist', preprocess=True, preprocessing_fun=normalize)\n",
    "ds2 = data_handler.load_tfds('fashion_mnist', preprocess=True, preprocessing_fun=normalize)\n",
    "x_id = ds1[\"test\"]\n",
    "x_ood = ds2[\"test\"]\n",
    "x_train = ds1[\"train\"]\n",
    "\n",
    "x_test = data_handler.merge_tfds(x_id, x_ood, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = tf.keras.models.load_model(\"../saved_models/mnist_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "MLS two datasets"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "oodmodel = MLS()\n",
    "oodmodel.fit(model)\n",
    "scores = oodmodel.score(x_test.batch(100))\n",
    "labels = data_handler.get_ood_labels(x_test)\n",
    "\n",
    "fpr, tpr = get_curve(scores, labels)\n",
    "\n",
    "metrics = bench_metrics(\n",
    "    scores, labels, \n",
    "    metrics = [\"auroc\", \"fpr95tpr\", accuracy_score, roc_auc_score], \n",
    "    threshold = -5\n",
    "    )\n",
    "\n",
    "print(metrics)\n",
    "plt.plot(fpr, tpr)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DKNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "\n",
    "## This time need a dataset to fit KNN score\n",
    "x_test = data_handler.merge_tfds(x_id.take(1000), x_ood.take(1000))\n",
    "\n",
    "oodmodel = DKNN()\n",
    "oodmodel.fit(model, x_train.take(10000).batch(100))\n",
    "scores = oodmodel.score(x_test.batch(100))\n",
    "labels = data_handler.get_ood_labels(x_test)\n",
    "\n",
    "fpr, tpr = get_curve(scores, labels)\n",
    "metrics = bench_metrics(\n",
    "    scores, labels, \n",
    "    metrics = [\"auroc\", \"fpr95tpr\", accuracy_score, roc_auc_score], \n",
    "    threshold = -5\n",
    "    )\n",
    "\n",
    "print(metrics)\n",
    "plt.plot(fpr, tpr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ODIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%autoreload 2\n",
    "from oodeel.methods import ODIN\n",
    "\n",
    "x_test = data_handler.merge_tfds(x_id, x_ood)\n",
    "labels = data_handler.get_ood_labels(x_test)\n",
    "\n",
    "\n",
    "oodmodel = ODIN()\n",
    "oodmodel.fit(model)\n",
    "scores_id = oodmodel.score(x_id.batch(100))\n",
    "scores_ood = oodmodel.score(x_ood.batch(100))\n",
    "\n",
    "scores = np.append(scores_id, scores_ood)\n",
    "#labels = data_handler.get_ood_labels(x_test)\n",
    "\n",
    "fpr, tpr = get_curve(scores, labels)\n",
    "metrics = bench_metrics(\n",
    "    scores, labels, \n",
    "    metrics = [\"auroc\", \"fpr95tpr\", accuracy_score, roc_auc_score], \n",
    "    threshold = -5\n",
    "    )\n",
    "\n",
    "print(metrics)\n",
    "plt.plot(fpr, tpr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single dataset experiment\n",
    "\n",
    "(Leave-$k$-classes-out training).\n",
    "First, we need to define a training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "inc_labels = [0, 1, 2, 3, 4]\n",
    "data_handler = DataHandler()\n",
    "ds = data_handler.load_tfds('mnist', preprocess=True, preprocessing_fun=normalize)\n",
    "x_id, x_ood = data_handler.filter_tfds(ds[\"test\"], inc_labels = inc_labels )\n",
    "x_train_id, _ = data_handler.filter_tfds(ds[\"train\"], inc_labels = inc_labels )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "from oodeel.models.training_funs import train_convnet\n",
    "\n",
    "train_config = {\n",
    "    \"batch_size\": 128,\n",
    "    \"epochs\": 5\n",
    "}\n",
    "\n",
    "model = train_convnet(x_train_id, **train_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "\n",
    "\n",
    "x_test = data_handler.merge_tfds(x_id, x_ood, shuffle=False)\n",
    "\n",
    "oodmodel = MLS()\n",
    "oodmodel.fit(model)\n",
    "scores = oodmodel.score(x_test.batch(100))\n",
    "labels = data_handler.get_ood_labels(x_test)\n",
    "\n",
    "fpr, tpr = get_curve(scores, labels)\n",
    "metrics = bench_metrics(\n",
    "    scores, labels, \n",
    "    metrics = [\"auroc\", \"fpr95tpr\", accuracy_score, roc_auc_score], \n",
    "    threshold = -5\n",
    "    )\n",
    "\n",
    "print(metrics)\n",
    "plt.plot(fpr, tpr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DKNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "\n",
    "x_test = data_handler.merge_tfds(x_id.take(1000), x_ood.take(1000))\n",
    "\n",
    "oodmodel = DKNN()\n",
    "oodmodel.fit(model, x_train_id.take(10000).batch(100))\n",
    "scores = oodmodel.score(x_test.batch(100))\n",
    "labels = data_handler.get_ood_labels(x_test)\n",
    "\n",
    "fpr, tpr = get_curve(scores, labels)\n",
    "metrics = bench_metrics(\n",
    "    scores, labels, \n",
    "    metrics = [\"auroc\", \"fpr95tpr\", accuracy_score, roc_auc_score], \n",
    "    threshold = -5\n",
    "    )\n",
    "\n",
    "print(metrics)\n",
    "plt.plot(fpr, tpr)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ODIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "\n",
    "\n",
    "x_test = data_handler.merge_tfds(x_id, x_ood, shuffle=False)\n",
    "#x_test, y_id = data_handler.convert_to_numpy(x_id)\n",
    "\n",
    "oodmodel = ODIN()\n",
    "oodmodel.fit(model)\n",
    "scores = oodmodel.score(x_test.batch(100))\n",
    "labels = data_handler.get_ood_labels(x_test)\n",
    "\n",
    "fpr, tpr = get_curve(scores, labels)\n",
    "metrics = bench_metrics(\n",
    "    scores, labels, \n",
    "    metrics = [\"auroc\", \"fpr95tpr\", accuracy_score, roc_auc_score], \n",
    "    threshold = -5\n",
    "    )\n",
    "\n",
    "print(metrics)\n",
    "plt.plot(fpr, tpr)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('tfmetal')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16 (main, Dec  7 2022, 10:16:11) \n[Clang 14.0.0 (clang-1400.0.29.202)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dada21ee7726b34311237058025d0293bf4743ff9612a3722201b24280433f0a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
