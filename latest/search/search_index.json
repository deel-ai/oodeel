{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>Oodeel is a library that performs post-hoc deep OOD (Out-of-Distribution) detection on already trained neural network image classifiers. The philosophy of the library is to favor quality over quantity and to foster easy adoption. As a result, we provide a simple, compact and easily customizable API and carefully integrate and test each proposed baseline into a coherent framework that is designed to enable their use in tensorflow and pytorch.</p> <pre><code>from oodeel.methods import MLS\n\nmls = MLS()\nmls.fit(model) # A tensorflow or torch model\nscores, info = mls.score(ds) # ds is a tf.data.Dataset or a torch.DataLoader\n</code></pre>"},{"location":"#table-of-contents","title":"Table of contents","text":"<ul> <li>Installation</li> <li>Quick Start</li> <li>Tutorials</li> <li>What's Included</li> <li>Development roadmap</li> <li>Contributing</li> <li>See Also</li> <li>Acknowledgments</li> <li>Creator</li> <li>License</li> </ul>"},{"location":"#installation","title":"Installation","text":"<p>Installation can be done using:</p> <p><pre><code>pip install oodeel\n</code></pre> oodeel requires either <code>tensorflow</code> or <code>pytorch</code> to be already installed (it will not install them automatically not to mess-up with existing installations). It is regularly tested with:</p> Python version Pytorch version Tensorflow version <code>3.8</code> <code>1.11</code> <code>2.5</code> <code>3.9</code> <code>1.13</code> <code>2.8</code> <code>3.10</code> <code>2.00</code> <code>2.11</code>"},{"location":"#quick-start","title":"Quick Start","text":"<p>Now that oodeel is installed, here are some basic examples of what you can do with the available modules. See also the notebooks directory for more advanced examples.</p>"},{"location":"#for-benchmarking-with-one-dataset-as-in-distribution-and-another-as-out-of-distribution","title":"For benchmarking with one dataset as in-distribution and another as out-of-distribution","text":"<p>Load in-distribution and out-of-distribution datasets.</p> <pre><code>from oodeel.datasets import OODDataset\n\nds_in = OODDataset(\n  'mnist', load_kwargs={\"split\":\"test\"},\n  backend=\"tensorflow\").prepare(batch_size) # use backend=\"torch\" if you prefer torch.DataLoader\nds_out = OODDataset(\n  'fashion_mnist', load_kwargs={\"split\":\"test\"},\n  backend=\"tensorflow\").prepare(batch_size)\n</code></pre>"},{"location":"#for-benchmarking-with-a-classes-subset-as-in-distribution-and-another-classes-subset-as-out-of-distribution","title":"For benchmarking with a classes subset as in-distribution and another classes subset as out-of-distribution","text":"<p>Load a dataset and split it into an in-distribution dataset and ou-of-distribution dataset depending on its label values (a common practice of anomaly detection and open set recognition).</p> <pre><code>from oodeel.datasets import OODDataset\n\nin_labels = [0, 1, 2, 3, 4]\noods_in, oods_out = oods_test.split_by_class(in_labels=in_labels)\n# info contains model predictions and labels if avail\nds_in = oods_in.prepare(batch_size=batch_size)\nds_out = oods_out.prepare(batch_size=batch_size)\n</code></pre>"},{"location":"#run-an-ood-method","title":"Run an OOD method","text":"<p>Load an OOD method and use it on an already-trained model</p> <pre><code>from oodeel.methods import MLS\n\nmls = MLS()\nmls.fit(model)\nscores_in, info_in = mls.score(ds_in)\nscores_out, info_out = mls.score(ds_in)\n</code></pre> <p>Evaluate the method</p> <pre><code>from oodeel.eval.metrics import bench_metrics\n\nmetrics = bench_metrics(\n    (scores_in, scores_out),\n    metrics = [\"auroc\", \"fpr95tpr\"],\n    )\n</code></pre>"},{"location":"#and-visualize-the-results","title":"And visualize the results!","text":"<p>2D t-SNE (3D is also available).</p> <pre><code>plot_2D_features(\n    model=model,\n    in_dataset=ds_in,\n    out_dataset=ds_out,\n    output_layer_id=-2,\n)\n</code></pre> <p> </p> <p>Classical histograms and AUROC curve. <pre><code>plot_ood_scores(scores_in, scores_out, log_scale=False)\nplot_roc_curve(scores_in, scores_out)\n</code></pre></p> <p> </p>"},{"location":"#tutorials","title":"Tutorials","text":"<p>We propose some tutorials to get familiar with the library and its API. See the Tutorial section of the doc.</p>"},{"location":"#whats-included","title":"What's Included","text":"<p>The library is based on a class, <code>OODBaseDetector</code>, that fits a model and then scores new samples. Some baselines use extra data, so <code>OODBaseDetector</code> can also fit additional data if needed. The library uses <code>OODDataset</code> to properly load data from different sources and prepare it for OOD detection. It can perform OOD-specific operations like adding extra OOD data for tuning with Outlier Exposure or filters according to label values for anomaly detection or open set recognition benchmarks.</p> <p>Currently, oodeel includes the following baselines:</p> Name Reference Venue Status MLS Open-Set Recognition: a Good Closed-Set Classifier is All You Need? ICLR 2022 avail tensorflow &amp; torch MSP A Baseline for Detecting Misclassified and Out-of-Distribution Examples in Neural Networks ICLR 2017 avail tensorflow &amp; torch Mahalanobis A Simple Unified Framework for Detecting Out-of-Distribution Samples and Adversarial Attacks NeurIPS 2018 avail tensorflow or  torch Energy Energy-based Out-of-distribution Detection NeurIPS 2020 avail tensorflow or  torch Odin Enhancing The Reliability of Out-of-distribution Image Detection in Neural Networks ICLR 2018 avail tensorflow or  torch DKNN Out-of-Distribution Detection with Deep Nearest Neighbors ICML 2022 avail tensorflow or  torch VIM ViM: Out-Of-Distribution with Virtual-logit Matching CVPR 2022 avail tensorflow or  torch Entropy Likelihood Ratios for Out-of-Distribution Detection NeurIPS 2019 avail tensorflow or  torch GODIN Generalized ODIN: Detecting Out-of-Distribution Image Without Learning From Out-of-Distribution Data CVPR 2020 planned ReAct ReAct: Out-of-distribution Detection With Rectified Activations NeurIPS 2021 avail tensorflow or  torch NMD Neural Mean Discrepancy for Efficient Out-of-Distribution Detection CVPR 2022 planned Gram Detecting Out-of-Distribution Examples with Gram Matrices ICML 2020 avail tensorflow or  torch GEN GEN: Pushing the Limits of Softmax-Based Out-of-Distribution Detection CVPR 2023 avail tensorflow or torch SHE Out-of-Distribution Detection based on In-Distribution Data Patterns Memorization with Modern Hopfield Energy ICLR 2023 avail tensorflow or torch RMDS A Simple Fix to Mahalanobis Distance for Improving Near-OOD Detection preprint avail tensorflow or torch ASH Extremely Simple Activation Shaping for Out-of-Distribution Detection ICLR 2023 avail tensorflow or torch SCALE Scaling for Training Time and Post-hoc Out-of-distribution Detection Enhancement ICLR 2024 avail tensorflow or torch <p>Oodeel also includes standard training functions with data augmentation and learning rate scheduler for toy convnet models or models from <code>keras.applications</code> in tf_training_tools.py and <code>torchvision.models</code> in torch_training_tools.py files. These functions come in handy for benchmarks like leave-k-classes-out that requires retraining models on a subset of dataset classes.</p>"},{"location":"#development-roadmap","title":"Development Roadmap","text":"<ul> <li> More baselines!</li> <li> A module for thorough visualizations (result plots and feature space visualizations)</li> <li> Integrate model loading and uploading with hugginface's transformers library for pretraining</li> <li> Extend the library to more diverse tasks like object detection, segmentation, NLP ...</li> <li> Towards OOD Generalization?</li> </ul>"},{"location":"#contributing","title":"Contributing","text":"<p>Feel free to propose your ideas or come and contribute with us on the oodeel toolbox! We have a specific document where we describe in a simple way how to make your first pull request: just here.</p>"},{"location":"#see-also","title":"See Also","text":"<p>Other great tools in the field of OOD:</p> <ul> <li>OpenOOD: Benchmarking Generalized Out-of-Distribution Detection</li> <li>Pytorch-OOD: Out-of-Distribution (OOD) Detection with Deep Neural Networks based on PyTorch.</li> <li>ADBench: Official Implement of \"ADBench: Anomaly Detection Benchmark\".</li> <li>PyOD: A Comprehensive and Scalable Python Library for Outlier Detection (Anomaly Detection)</li> <li>Anomalib: An anomaly detection library comprising state-of-the-art algorithms and features such as experiment management, hyper-parameter optimization, and edge inference.</li> </ul> <p>More from the DEEL project:</p> <ul> <li>Xplique a Python library exclusively dedicated to explaining neural networks.</li> <li>deel-lip a Python library for training k-Lipschitz neural networks on TF.</li> <li>Influenciae Python toolkit dedicated to computing influence values for the discovery of potentially problematic samples in a dataset.</li> <li>deel-torchlip a Python library for training k-Lipschitz neural networks on PyTorch.</li> <li>DEEL White paper a summary of the DEEL team on the challenges of certifiable AI and the role of data quality, representativity and explainability for this purpose.</li> </ul>"},{"location":"#acknowledgments","title":"Acknowledgments","text":"<p>This project received funding from the French \u201dInvesting for the Future \u2013 PIA3\u201d program within the Artificial and Natural Intelligence Toulouse Institute (ANITI). The authors gratefully acknowledge the support of the  DEEL , a research project jointly conducted in France and Quebec.</p>"},{"location":"#creators","title":"Creators","text":"<p>The library was created by Paul Novello to streamline DEEL research on post-hoc deep OOD methods and foster their adoption by DEEL industrial partners. He was soon joined by Yann Pequignot, Yannick Prudent, Corentin Friedrich and Matthieu Le Goff.</p>"},{"location":"#license","title":"License","text":"<p>The package is released under MIT license.</p>"},{"location":"CONTRIBUTING/","title":"Contributing","text":"<p>Thanks for taking the time to contribute!</p> <p>From opening a bug report to creating a pull request: every contribution is appreciated and welcome. If you're planning to implement a new feature or change the API please create an issue first. This way we can ensure that your precious work is not in vain.</p>"},{"location":"CONTRIBUTING/#setup-with-make","title":"Setup with make","text":"<ul> <li>Clone the repo <code>git clone https://github.com/deel-ai/oodeel.git</code>.</li> <li>Go to your freshly downloaded repo <code>cd oodeel</code></li> <li>Create a virtual environment and install the necessary dependencies for development:</li> </ul> <p><code>make prepare-dev &amp;&amp; source oodeel_dev_env/bin/activate</code>.</p> <p>Welcome to the team!</p>"},{"location":"CONTRIBUTING/#tests","title":"Tests","text":"<p>To run test <code>make test</code> This command activates your virtual environment and launch the <code>tox</code> command.</p> <p><code>tox</code> on the other hand will do the following: - run pytest on the tests folder with python 3.8, python 3.9 and python 3.10</p> <p>Note: If you do not have those 4 interpreters the tests would be only performed with your current interpreter - run flake8 on the oodeel main files, with python 3.8, 3.9 and python 3.10. Note: It is possible that flake8 throws false-positive errors. If the linting test failed please check first flake8 output to point out the reasons.</p> <p>Please, make sure you run all the tests at least once before opening a pull request.</p> <p>We advise that you run <code>docsig</code> before each push. Docsig is an utilitary checking for the coherence between docstrings and functions' signatures. You can obtain a report by running:</p> <pre><code>docsig -c -D -o -P -p -i oodeel\n</code></pre> <p>This awesome repository is way underrated (14 stars only at the time of the present commit), so drop by and add a star to help them!</p> <p>A word toward flake8 for those that don't know it:</p> <p>Flake8 is a Python static code analysis tool which looks for programming errors, helps enforcing a coding standard, sniffs for code smells and offers simple refactoring suggestions.</p> <p>Basically, it will check that your code follows a certain number of conventions. Any Pull Request will go through a Github workflow ensuring that your code respects the flake8 conventions (most of them at least).</p>"},{"location":"CONTRIBUTING/#submitting-changes","title":"Submitting Changes","text":"<p>After getting some feedback, push to your fork and submit a pull request. We may suggest some changes or improvements or alternatives, but for small changes, your pull request should be accepted quickly (see Governance policy).</p> <p>Something that will increase the chance that your pull request is accepted:</p> <ul> <li>Write tests and ensure that the existing ones pass.</li> <li>If <code>make test</code> is successful, you have fair chance to pass the CI workflows (linting and test)</li> <li>Follow the existing coding style and run <code>make check_all</code> to check all files format.</li> <li>Write a good commit message (we follow a lowercase convention, see below).</li> <li>For a major fix/feature make sure your PR has an issue and if it doesn't, please create one. This would help discussion with the community, and polishing ideas in case of a new feature.</li> </ul>"},{"location":"CONTRIBUTING/#pre-commit-conventional-commits-100","title":"pre-commit : Conventional Commits 1.0.0","text":"<p>The commit message should be structured as follows:</p> <pre><code>&lt;type&gt;[optional scope]: &lt;description&gt;\n\n[optional body]\n\n[optional footer(s)]\n</code></pre> <p>The commit contains the following structural elements, to communicate intent to the consumers of your library:</p> <ul> <li> <p>fix: a commit of the type fix patches a bug in your codebase (this correlates with PATCH in Semantic Versioning).</p> </li> <li> <p>feat: a commit of the type feat introduces a new feature to the codebase (this correlates with MINOR in Semantic Versioning).</p> </li> <li> <p>BREAKING CHANGE: a commit that has a footer BREAKING CHANGE:, or appends a ! after the type/scope, introduces a breaking API change (correlating with MAJOR in Semantic Versioning). A BREAKING CHANGE can be part of commits of any type.</p> </li> <li> <p>types other than fix: and feat: are allowed, for example @commitlint/config-conventional (based on the Angular convention) recommends build:, chore:, ci:, docs:, style:, refactor:, perf:, test:, and others.</p> </li> <li> <p>footers other than BREAKING CHANGE:  may be provided and follow a convention similar to git trailer format. <li> <p>Additional types are not mandated by the Conventional Commits specification and have no implicit effect in Semantic Versioning (unless they include a BREAKING CHANGE). A scope may be provided to a commit\u2019s type, to provide additional contextual information and is contained within parenthesis, e.g., feat(parser): add the ability to parse arrays.</p> </li>"},{"location":"GOVERNANCE/","title":"GOVERNANCE","text":"<p><code>oodeel</code> is developed as part of the Artificial and Natural Intelligence Toulouse Institute (DEEL/ANITI) program.</p> <p>DEEL/ANITI is the repository owner and the write rights manager.</p> <p>These management rules are intended to be collaborative and all those involved in the project are invited to contribute to its improvement.</p>"},{"location":"GOVERNANCE/#functions","title":"Functions","text":""},{"location":"GOVERNANCE/#governance-committee","title":"Governance committee","text":"<p>The governance committee is initially composed of DEEL members who contributed to the first version of <code>oodeel</code> and are the only contributors to the master branch.</p> <p>The governance committee is responsible for the master branch that contains the code of the version of the library that is officially recognised.</p> <p>These governance committee members are the only ones able to merge pull requests into this branch which from contributions branches.</p> <p>The governance committee identifies among the contributors who by their merits can join the committee.</p> <p>.....</p>"},{"location":"GOVERNANCE/#contributors","title":"Contributors","text":"<p>A contributor is anyone who comments on any aspects relating to the project: comments on an issue or pull request, documentation, architecture, code and validation tests or anybody with a merged pull request.</p> <p>All governance committee members are contributors.</p>"},{"location":"GOVERNANCE/#maintainers","title":"Maintainers","text":"<p>All contributors with write rights (commit rights) are maintainers.</p> <p>....</p>"},{"location":"GOVERNANCE/#contributions","title":"Contributions","text":"<p>Contributions rules are defined and developed here: CONTRIBUTING.md</p> <p>Pull requests with major changes must be approved by at least two members of the governance committee.</p> <p>Pull requests with minor changes must be approved by at least one member of the governance committee. .....</p>"},{"location":"GOVERNANCE/#moderators","title":"Moderators","text":"<p>....</p>"},{"location":"api/datahandlers/","title":"Datahandlers","text":""},{"location":"api/datahandlers/#oodeel.datasets.tf_data_handler.TFDataHandler","title":"<code>TFDataHandler</code>","text":"<p>         Bases: <code>DataHandler</code></p> <p>Class to manage tf.data.Dataset. The aim is to provide a simple interface for working with tf.data.Datasets and manage them without having to use tensorflow syntax.</p> Source code in <code>oodeel/datasets/tf_data_handler.py</code> <pre><code>class TFDataHandler(DataHandler):\n\"\"\"\n    Class to manage tf.data.Dataset. The aim is to provide a simple interface for\n    working with tf.data.Datasets and manage them without having to use\n    tensorflow syntax.\n    \"\"\"\n\n    @classmethod\n    def load_dataset(\n        cls,\n        dataset_id: Union[tf.data.Dataset, ItemType, str],\n        keys: Optional[list] = None,\n        load_kwargs: dict = {},\n    ) -&gt; tf.data.Dataset:\n\"\"\"Load dataset from different manners, ensuring to return a dict based\n        tf.data.Dataset.\n\n        Args:\n            dataset_id (Any): dataset identification\n            keys (list, optional): Features keys. If None, assigned as \"input_i\"\n                for i-th feature. Defaults to None.\n            load_kwargs (dict, optional): Additional args for loading from\n                tensorflow_datasets. Defaults to {}.\n\n        Returns:\n            tf.data.Dataset: A dict based tf.data.Dataset\n        \"\"\"\n        if isinstance(dataset_id, get_args(ItemType)):\n            dataset = cls.load_dataset_from_arrays(dataset_id, keys)\n        elif isinstance(dataset_id, tf.data.Dataset):\n            dataset = cls.load_custom_dataset(dataset_id, keys)\n        elif isinstance(dataset_id, str):\n            dataset = cls.load_from_tensorflow_datasets(dataset_id, load_kwargs)\n        return dataset\n\n    @staticmethod\n    def load_dataset_from_arrays(\n        dataset_id: ItemType, keys: Optional[list] = None\n    ) -&gt; tf.data.Dataset:\n\"\"\"Load a tf.data.Dataset from a np.ndarray, a tf.Tensor or a tuple/dict\n        of np.ndarrays/td.Tensors.\n\n        Args:\n            dataset_id (ItemType): numpy array(s) to load.\n            keys (list, optional): Features keys. If None, assigned as \"input_i\"\n                for i-th feature. Defaults to None.\n\n        Returns:\n            tf.data.Dataset\n        \"\"\"\n        # If dataset_id is a numpy array, convert it to a dict\n        if isinstance(dataset_id, get_args(TensorType)):\n            dataset_dict = {\"input\": dataset_id}\n\n        # If dataset_id is a tuple, convert it to a dict\n        elif isinstance(dataset_id, tuple):\n            len_elem = len(dataset_id)\n            if keys is None:\n                if len_elem == 2:\n                    dataset_dict = {\"input\": dataset_id[0], \"label\": dataset_id[1]}\n                else:\n                    dataset_dict = {\n                        f\"input_{i}\": dataset_id[i] for i in range(len_elem - 1)\n                    }\n                    dataset_dict[\"label\"] = dataset_id[-1]\n                print(\n                    'Loading tf.data.Dataset with elems as dicts, assigning \"input_i\" '\n                    'key to the i-th tuple dimension and \"label\" key to the last '\n                    \"tuple dimension.\"\n                )\n            else:\n                assert (\n                    len(keys) == len_elem\n                ), \"Number of keys mismatch with the number of features\"\n                dataset_dict = {keys[i]: dataset_id[i] for i in range(len_elem)}\n\n        elif isinstance(dataset_id, dict):\n            if keys is not None:\n                len_elem = len(dataset_id)\n                assert (\n                    len(keys) == len_elem\n                ), \"Number of keys mismatch with the number of features\"\n                original_keys = list(dataset_id.keys())\n                dataset_dict = {\n                    keys[i]: dataset_id[original_keys[i]] for i in range(len_elem)\n                }\n\n        dataset = tf.data.Dataset.from_tensor_slices(dataset_dict)\n        return dataset\n\n    @classmethod\n    def load_custom_dataset(\n        cls, dataset_id: tf.data.Dataset, keys: Optional[list] = None\n    ) -&gt; tf.data.Dataset:\n\"\"\"Load a custom Dataset by ensuring it has the correct format (dict-based)\n\n        Args:\n            dataset_id (tf.data.Dataset): tf.data.Dataset\n            keys (list, optional): Features keys. If None, assigned as \"input_i\"\n                for i-th feature. Defaults to None.\n\n        Returns:\n            tf.data.Dataset\n        \"\"\"\n        # If dataset_id is a tuple based tf.data.dataset, convert it to a dict\n        if not isinstance(dataset_id.element_spec, dict):\n            len_elem = len(dataset_id.element_spec)\n            if keys is None:\n                print(\n                    \"Feature name not found, assigning 'input_i' \"\n                    \"key to the i-th tensor and 'label' key to the last\"\n                )\n                if len_elem == 2:\n                    keys = [\"input\", \"label\"]\n                else:\n                    keys = [f\"input_{i}\" for i in range(len_elem)]\n                    keys[-1] = \"label\"\n            else:\n                assert (\n                    len(keys) == len_elem\n                ), \"Number of keys mismatch with the number of features\"\n\n            dataset_id = cls.tuple_to_dict(dataset_id, keys)\n\n        dataset = dataset_id\n        return dataset\n\n    @staticmethod\n    def load_from_tensorflow_datasets(\n        dataset_id: str,\n        load_kwargs: dict = {},\n    ) -&gt; tf.data.Dataset:\n\"\"\"Load a tf.data.Dataset from the tensorflow_datasets catalog\n\n        Args:\n            dataset_id (str): Identifier of the dataset\n            load_kwargs (dict, optional): Loading kwargs to add to tfds.load().\n                Defaults to {}.\n\n        Returns:\n            tf.data.Dataset\n        \"\"\"\n        assert (\n            dataset_id in tfds.list_builders()\n        ), \"Dataset not available on tensorflow datasets catalog\"\n        dataset = tfds.load(dataset_id, **load_kwargs)\n        return dataset\n\n    @staticmethod\n    @dict_only_ds\n    def dict_to_tuple(\n        dataset: tf.data.Dataset, keys: Optional[list] = None\n    ) -&gt; tf.data.Dataset:\n\"\"\"Turn a dict based tf.data.Dataset to a tuple based tf.data.Dataset\n\n        Args:\n            dataset (tf.data.Dataset): Dict based tf.data.Dataset\n            keys (list, optional): Features to use for the tuples based\n                tf.data.Dataset. If None, takes all the features. Defaults to None.\n\n        Returns:\n            tf.data.Dataset\n        \"\"\"\n        if keys is None:\n            keys = list(dataset.element_spec.keys())\n        dataset = dataset.map(lambda x: tuple(x[k] for k in keys))\n        return dataset\n\n    @staticmethod\n    def tuple_to_dict(dataset: tf.data.Dataset, keys: list) -&gt; tf.data.Dataset:\n\"\"\"Turn a tuple based tf.data.Dataset to a dict based tf.data.Dataset\n\n        Args:\n            dataset (tf.data.Dataset): Tuple based tf.data.Dataset\n            keys (list): Keys to use for the dict based tf.data.Dataset\n\n        Returns:\n            tf.data.Dataset\n        \"\"\"\n        assert isinstance(\n            dataset.element_spec, tuple\n        ), \"dataset elements must be tuples\"\n        len_elem = len(dataset.element_spec)\n        assert len_elem == len(\n            keys\n        ), \"The number of keys must be equal to the number of tuple elements\"\n\n        def tuple_to_dict(*inputs):\n            return {keys[i]: inputs[i] for i in range(len_elem)}\n\n        dataset = dataset.map(tuple_to_dict)\n        return dataset\n\n    @staticmethod\n    def assign_feature_value(\n        dataset: tf.data.Dataset, feature_key: str, value: int\n    ) -&gt; tf.data.Dataset:\n\"\"\"Assign a value to a feature for every sample in a tf.data.Dataset\n\n        Args:\n            dataset (tf.data.Dataset): tf.data.Dataset to assign the value to\n            feature_key (str): Feature to assign the value to\n            value (int): Value to assign\n\n        Returns:\n            tf.data.Dataset\n        \"\"\"\n        assert isinstance(dataset.element_spec, dict), \"dataset elements must be dicts\"\n\n        def assign_value_to_feature(x):\n            x[feature_key] = value\n            return x\n\n        dataset = dataset.map(assign_value_to_feature)\n        return dataset\n\n    @staticmethod\n    @dict_only_ds\n    def get_feature_from_ds(dataset: tf.data.Dataset, feature_key: str) -&gt; np.ndarray:\n\"\"\"Get a feature from a tf.data.Dataset\n\n        !!! note\n            This function can be a bit time consuming since it needs to iterate\n            over the whole dataset.\n\n        Args:\n            dataset (tf.data.Dataset): tf.data.Dataset to get the feature from\n            feature_key (str): Feature value to get\n\n        Returns:\n            np.ndarray: Feature values for dataset\n        \"\"\"\n        features = dataset.map(lambda x: x[feature_key])\n        features = list(features.as_numpy_iterator())\n        features = np.array(features)\n        return features\n\n    @staticmethod\n    @dict_only_ds\n    def get_ds_feature_keys(dataset: tf.data.Dataset) -&gt; list:\n\"\"\"Get the feature keys of a tf.data.Dataset\n\n        Args:\n            dataset (tf.data.Dataset): tf.data.Dataset to get the feature keys from\n\n        Returns:\n            list: List of feature keys\n        \"\"\"\n        return list(dataset.element_spec.keys())\n\n    @staticmethod\n    def has_feature_key(dataset: tf.data.Dataset, key: str) -&gt; bool:\n\"\"\"Check if a tf.data.Dataset has a feature denoted by key\n\n        Args:\n            dataset (tf.data.Dataset): tf.data.Dataset to check\n            key (str): Key to check\n\n        Returns:\n            bool: If the tf.data.Dataset has a feature denoted by key\n        \"\"\"\n        assert isinstance(dataset.element_spec, dict), \"dataset elements must be dicts\"\n        return True if (key in dataset.element_spec.keys()) else False\n\n    @staticmethod\n    def map_ds(\n        dataset: tf.data.Dataset,\n        map_fn: Callable,\n        num_parallel_calls: Optional[int] = None,\n    ) -&gt; tf.data.Dataset:\n\"\"\"Map a function to a tf.data.Dataset\n\n        Args:\n            dataset (tf.data.Dataset): tf.data.Dataset to map the function to\n            map_fn (Callable): Function to map\n            num_parallel_calls (Optional[int], optional): Number of parallel processes\n                to use. Defaults to None.\n\n        Returns:\n            tf.data.Dataset: Maped dataset\n        \"\"\"\n        if num_parallel_calls is None:\n            num_parallel_calls = tf.data.experimental.AUTOTUNE\n        dataset = dataset.map(map_fn, num_parallel_calls=num_parallel_calls)\n        return dataset\n\n    @staticmethod\n    @dict_only_ds\n    def filter_by_feature_value(\n        dataset: tf.data.Dataset,\n        feature_key: str,\n        values: list,\n        excluded: bool = False,\n    ) -&gt; tf.data.Dataset:\n\"\"\"Filter a tf.data.Dataset by checking the value of a feature is in 'values'\n\n        Args:\n            dataset (tf.data.Dataset): tf.data.Dataset to filter\n            feature_key (str): Feature name to check the value\n            values (list): Feature_key values to keep (if excluded is False)\n                or to exclude\n            excluded (bool, optional): To keep (False) or exclude (True) the samples\n                with Feature_key value included in Values. Defaults to False.\n\n        Returns:\n            tf.data.Dataset: Filtered dataset\n        \"\"\"\n        # If the labels are one-hot encoded, prepare a function to get the label as int\n        if len(dataset.element_spec[feature_key].shape) &gt; 0:\n\n            def get_label_int(elem):\n                return int(tf.argmax(elem[feature_key]))\n\n        else:\n\n            def get_label_int(elem):\n                return elem[feature_key]\n\n        def filter_fn(elem):\n            value = get_label_int(elem)\n            if excluded:\n                return not tf.reduce_any(tf.equal(value, values))\n            else:\n                return tf.reduce_any(tf.equal(value, values))\n\n        dataset_to_filter = dataset\n        dataset_to_filter = dataset_to_filter.filter(filter_fn)\n        return dataset_to_filter\n\n    @classmethod\n    def prepare_for_training(\n        cls,\n        dataset: tf.data.Dataset,\n        batch_size: int,\n        shuffle: bool = False,\n        preprocess_fn: Optional[Callable] = None,\n        augment_fn: Optional[Callable] = None,\n        output_keys: Optional[list] = None,\n        dict_based_fns: bool = False,\n        shuffle_buffer_size: Optional[int] = None,\n        prefetch_buffer_size: Optional[int] = None,\n        drop_remainder: Optional[bool] = False,\n    ) -&gt; tf.data.Dataset:\n\"\"\"Prepare a tf.data.Dataset for training\n\n        Args:\n            dataset (tf.data.Dataset): tf.data.Dataset to prepare\n            batch_size (int): Batch size\n            shuffle (bool, optional): To shuffle the returned dataset or not.\n                Defaults to False.\n            preprocess_fn (Callable, optional): Preprocessing function to apply to\\\n                the dataset. Defaults to None.\n            augment_fn (Callable, optional): Augment function to be used (when the\\\n                returned dataset is to be used for training). Defaults to None.\n            output_keys (list, optional): List of keys corresponding to the features\n                that will be returned. Keep all features if None. Defaults to None.\n            dict_based_fns (bool, optional): If the augment and preprocess functions are\n                dict based or not. Defaults to False.\n            shuffle_buffer_size (int, optional): Size of the shuffle buffer. If None,\n                taken as the number of samples in the dataset. Defaults to None.\n            prefetch_buffer_size (Optional[int], optional): Buffer size for prefetch.\n                If None, automatically chose using tf.data.experimental.AUTOTUNE.\n                Defaults to None.\n            drop_remainder (Optional[bool], optional): To drop the last batch when\n                its size is lower than batch_size. Defaults to False.\n\n        Returns:\n            tf.data.Dataset: Prepared dataset\n        \"\"\"\n        # dict based to tuple based\n        output_keys = output_keys or cls.get_ds_feature_keys(dataset)\n        if not dict_based_fns:\n            dataset = cls.dict_to_tuple(dataset, output_keys)\n\n        # preprocess + DA\n        if preprocess_fn is not None:\n            dataset = cls.map_ds(dataset, preprocess_fn)\n        if augment_fn is not None:\n            dataset = cls.map_ds(dataset, augment_fn)\n\n        if dict_based_fns:\n            dataset = cls.dict_to_tuple(dataset, output_keys)\n\n        dataset = dataset.cache()\n\n        # shuffle\n        if shuffle:\n            num_samples = cls.get_dataset_length(dataset)\n            shuffle_buffer_size = (\n                num_samples if shuffle_buffer_size is None else shuffle_buffer_size\n            )\n            dataset = dataset.shuffle(shuffle_buffer_size)\n        # batch\n        dataset = dataset.batch(batch_size, drop_remainder=drop_remainder)\n        # prefetch\n        if prefetch_buffer_size is not None:\n            prefetch_buffer_size = tf.data.experimental.AUTOTUNE\n        dataset = dataset.prefetch(prefetch_buffer_size)\n        return dataset\n\n    @staticmethod\n    def make_channel_first(input_key: str, dataset: tf.data.Dataset) -&gt; tf.data.Dataset:\n\"\"\"Make a tf.data.Dataset channel first. Make sure that the dataset is not\n            already Channel first. If so, the tensor will have the format\n            (batch_size, x_size, channel, y_size).\n\n        Args:\n            input_key (str): input key of the dict-based tf.data.Dataset\n            dataset (tf.data.Dataset): tf.data.Dataset to make channel first\n\n        Returns:\n            tf.data.Dataset: Channel first dataset\n        \"\"\"\n\n        def channel_first(x):\n            x[input_key] = tf.transpose(x[input_key], perm=[2, 0, 1])\n            return x\n\n        dataset = dataset.map(channel_first)\n        return dataset\n\n    @classmethod\n    def merge(\n        cls,\n        id_dataset: tf.data.Dataset,\n        ood_dataset: tf.data.Dataset,\n        resize: Optional[bool] = False,\n        shape: Optional[Tuple[int]] = None,\n        channel_order: Optional[str] = \"channels_last\",\n    ) -&gt; tf.data.Dataset:\n\"\"\"Merge two tf.data.Datasets\n\n        Args:\n            id_dataset (tf.data.Dataset): dataset of in-distribution data\n            ood_dataset (tf.data.Dataset): dataset of out-of-distribution data\n            resize (Optional[bool], optional): toggles if input tensors of the\n                datasets have to be resized to have the same shape. Defaults to True.\n            shape (Optional[Tuple[int]], optional): shape to use for resizing input\n                tensors. If None, the tensors are resized with the shape of the\n                id_dataset input tensors. Defaults to None.\n            channel_order (Optional[str], optional): channel order of the input\n\n        Returns:\n            tf.data.Dataset: merged dataset\n        \"\"\"\n        len_elem_id = cls.get_item_length(id_dataset)\n        len_elem_ood = cls.get_item_length(ood_dataset)\n        assert (\n            len_elem_id == len_elem_ood\n        ), \"incompatible dataset elements (different elem dict length)\"\n\n        # If a desired shape is given, triggers the resize\n        if shape is not None:\n            resize = True\n\n        id_elem_spec = id_dataset.element_spec\n        ood_elem_spec = ood_dataset.element_spec\n        assert isinstance(id_elem_spec, dict), \"dataset elements must be dicts\"\n        assert isinstance(ood_elem_spec, dict), \"dataset elements must be dicts\"\n\n        input_key_id = list(id_elem_spec.keys())[0]\n        input_key_ood = list(ood_elem_spec.keys())[0]\n        shape_id = id_dataset.element_spec[input_key_id].shape\n        shape_ood = ood_dataset.element_spec[input_key_ood].shape\n\n        # If the shape of the two datasets are different, triggers the resize\n        if shape_id != shape_ood:\n            resize = True\n\n            if shape is None:\n                print(\n                    \"Resizing the first item of elem (usually the image)\",\n                    \" with the shape of id_dataset\",\n                )\n                if channel_order == \"channels_first\":\n                    shape = shape_id[1:]\n                else:\n                    shape = shape_id[:2]\n\n        if resize:\n\n            def reshape_im_id(elem):\n                elem[input_key_id] = tf.image.resize(elem[input_key_id], shape)\n                return elem\n\n            def reshape_im_ood(elem):\n                elem[input_key_ood] = tf.image.resize(elem[input_key_ood], shape)\n                return elem\n\n            id_dataset = id_dataset.map(reshape_im_id)\n            ood_dataset = ood_dataset.map(reshape_im_ood)\n\n        merged_dataset = id_dataset.concatenate(ood_dataset)\n        return merged_dataset\n\n    @staticmethod\n    def get_item_length(dataset: tf.data.Dataset) -&gt; int:\n\"\"\"Get the length of a dataset element. If an element is a tensor, the length is\n        one and if it is a sequence (list or tuple), it is len(elem).\n\n        Args:\n            dataset (tf.data.Dataset): Dataset to process\n\n        Returns:\n            int: length of the dataset elems\n        \"\"\"\n        if isinstance(dataset.element_spec, (tuple, list, dict)):\n            return len(dataset.element_spec)\n        return 1\n\n    @staticmethod\n    def get_dataset_length(dataset: tf.data.Dataset) -&gt; int:\n\"\"\"Get the length of a dataset. Try to access it with len(), and if not\n        available, with a reduce op.\n\n        Args:\n            dataset (tf.data.Dataset): Dataset to process\n\n        Returns:\n            int: _description_\n        \"\"\"\n        try:\n            return len(dataset)\n        except TypeError:\n            cardinality = dataset.reduce(0, lambda x, _: x + 1)\n            return int(cardinality)\n\n    @staticmethod\n    def get_feature_shape(\n        dataset: tf.data.Dataset, feature_key: Union[str, int]\n    ) -&gt; tuple:\n\"\"\"Get the shape of a feature of dataset identified by feature_key\n\n        Args:\n            dataset (tf.data.Dataset): a tf.data.dataset\n            feature_key (Union[str, int]): The identifier of the feature\n\n        Returns:\n            tuple: the shape of feature_id\n        \"\"\"\n        return tuple(dataset.element_spec[feature_key].shape)\n\n    @staticmethod\n    def get_input_from_dataset_item(elem: ItemType) -&gt; TensorType:\n\"\"\"Get the tensor that is to be feed as input to a model from a dataset element.\n\n        Args:\n            elem (ItemType): dataset element to extract input from\n\n        Returns:\n            TensorType: Input tensor\n        \"\"\"\n        if isinstance(elem, (tuple, list)):\n            tensor = elem[0]\n        elif isinstance(elem, dict):\n            tensor = elem[list(elem.keys())[0]]\n        else:\n            tensor = elem\n        return tensor\n\n    @staticmethod\n    def get_label_from_dataset_item(item: ItemType):\n\"\"\"Retrieve label tensor from item as a tuple/list. Label must be at index 1\n        in the item tuple. If one-hot encoded, labels are converted to single value.\n\n        Args:\n            elem (ItemType): dataset element to extract label from\n\n        Returns:\n            Any: Label tensor\n        \"\"\"\n        label = item[1]  # labels must be at index 1 in the item tuple\n        # If labels are one-hot encoded, take the argmax\n        if tf.rank(label) &gt; 1 and label.shape[1] &gt; 1:\n            label = tf.reshape(label, shape=[label.shape[0], -1])\n            label = tf.argmax(label, axis=1)\n        # If labels are in two dimensions, squeeze them\n        if len(label.shape) &gt; 1:\n            label = tf.reshape(label, [label.shape[0]])\n        return label\n\n    @staticmethod\n    def get_feature(\n        dataset: tf.data.Dataset, feature_key: Union[str, int]\n    ) -&gt; tf.data.Dataset:\n\"\"\"Extract a feature from a dataset\n\n        Args:\n            dataset (tf.data.Dataset): Dataset to extract the feature from\n            feature_key (Union[str, int]): feature to extract\n\n        Returns:\n            tf.data.Dataset: dataset built with the extracted feature only\n        \"\"\"\n\n        def _get_feature_elem(elem):\n            return elem[feature_key]\n\n        return dataset.map(_get_feature_elem)\n</code></pre>"},{"location":"api/datahandlers/#oodeel.datasets.tf_data_handler.TFDataHandler.assign_feature_value","title":"<code>assign_feature_value(dataset, feature_key, value)</code>  <code>staticmethod</code>","text":"<p>Assign a value to a feature for every sample in a tf.data.Dataset</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>tf.data.Dataset</code> <p>tf.data.Dataset to assign the value to</p> required <code>feature_key</code> <code>str</code> <p>Feature to assign the value to</p> required <code>value</code> <code>int</code> <p>Value to assign</p> required <p>Returns:</p> Type Description <code>tf.data.Dataset</code> <p>tf.data.Dataset</p> Source code in <code>oodeel/datasets/tf_data_handler.py</code> <pre><code>@staticmethod\ndef assign_feature_value(\n    dataset: tf.data.Dataset, feature_key: str, value: int\n) -&gt; tf.data.Dataset:\n\"\"\"Assign a value to a feature for every sample in a tf.data.Dataset\n\n    Args:\n        dataset (tf.data.Dataset): tf.data.Dataset to assign the value to\n        feature_key (str): Feature to assign the value to\n        value (int): Value to assign\n\n    Returns:\n        tf.data.Dataset\n    \"\"\"\n    assert isinstance(dataset.element_spec, dict), \"dataset elements must be dicts\"\n\n    def assign_value_to_feature(x):\n        x[feature_key] = value\n        return x\n\n    dataset = dataset.map(assign_value_to_feature)\n    return dataset\n</code></pre>"},{"location":"api/datahandlers/#oodeel.datasets.tf_data_handler.TFDataHandler.dict_to_tuple","title":"<code>dict_to_tuple(dataset, keys=None)</code>  <code>staticmethod</code>","text":"<p>Turn a dict based tf.data.Dataset to a tuple based tf.data.Dataset</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>tf.data.Dataset</code> <p>Dict based tf.data.Dataset</p> required <code>keys</code> <code>list</code> <p>Features to use for the tuples based tf.data.Dataset. If None, takes all the features. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>tf.data.Dataset</code> <p>tf.data.Dataset</p> Source code in <code>oodeel/datasets/tf_data_handler.py</code> <pre><code>@staticmethod\n@dict_only_ds\ndef dict_to_tuple(\n    dataset: tf.data.Dataset, keys: Optional[list] = None\n) -&gt; tf.data.Dataset:\n\"\"\"Turn a dict based tf.data.Dataset to a tuple based tf.data.Dataset\n\n    Args:\n        dataset (tf.data.Dataset): Dict based tf.data.Dataset\n        keys (list, optional): Features to use for the tuples based\n            tf.data.Dataset. If None, takes all the features. Defaults to None.\n\n    Returns:\n        tf.data.Dataset\n    \"\"\"\n    if keys is None:\n        keys = list(dataset.element_spec.keys())\n    dataset = dataset.map(lambda x: tuple(x[k] for k in keys))\n    return dataset\n</code></pre>"},{"location":"api/datahandlers/#oodeel.datasets.tf_data_handler.TFDataHandler.filter_by_feature_value","title":"<code>filter_by_feature_value(dataset, feature_key, values, excluded=False)</code>  <code>staticmethod</code>","text":"<p>Filter a tf.data.Dataset by checking the value of a feature is in 'values'</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>tf.data.Dataset</code> <p>tf.data.Dataset to filter</p> required <code>feature_key</code> <code>str</code> <p>Feature name to check the value</p> required <code>values</code> <code>list</code> <p>Feature_key values to keep (if excluded is False) or to exclude</p> required <code>excluded</code> <code>bool</code> <p>To keep (False) or exclude (True) the samples with Feature_key value included in Values. Defaults to False.</p> <code>False</code> <p>Returns:</p> Type Description <code>tf.data.Dataset</code> <p>tf.data.Dataset: Filtered dataset</p> Source code in <code>oodeel/datasets/tf_data_handler.py</code> <pre><code>@staticmethod\n@dict_only_ds\ndef filter_by_feature_value(\n    dataset: tf.data.Dataset,\n    feature_key: str,\n    values: list,\n    excluded: bool = False,\n) -&gt; tf.data.Dataset:\n\"\"\"Filter a tf.data.Dataset by checking the value of a feature is in 'values'\n\n    Args:\n        dataset (tf.data.Dataset): tf.data.Dataset to filter\n        feature_key (str): Feature name to check the value\n        values (list): Feature_key values to keep (if excluded is False)\n            or to exclude\n        excluded (bool, optional): To keep (False) or exclude (True) the samples\n            with Feature_key value included in Values. Defaults to False.\n\n    Returns:\n        tf.data.Dataset: Filtered dataset\n    \"\"\"\n    # If the labels are one-hot encoded, prepare a function to get the label as int\n    if len(dataset.element_spec[feature_key].shape) &gt; 0:\n\n        def get_label_int(elem):\n            return int(tf.argmax(elem[feature_key]))\n\n    else:\n\n        def get_label_int(elem):\n            return elem[feature_key]\n\n    def filter_fn(elem):\n        value = get_label_int(elem)\n        if excluded:\n            return not tf.reduce_any(tf.equal(value, values))\n        else:\n            return tf.reduce_any(tf.equal(value, values))\n\n    dataset_to_filter = dataset\n    dataset_to_filter = dataset_to_filter.filter(filter_fn)\n    return dataset_to_filter\n</code></pre>"},{"location":"api/datahandlers/#oodeel.datasets.tf_data_handler.TFDataHandler.get_dataset_length","title":"<code>get_dataset_length(dataset)</code>  <code>staticmethod</code>","text":"<p>Get the length of a dataset. Try to access it with len(), and if not available, with a reduce op.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>tf.data.Dataset</code> <p>Dataset to process</p> required <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>description</p> Source code in <code>oodeel/datasets/tf_data_handler.py</code> <pre><code>@staticmethod\ndef get_dataset_length(dataset: tf.data.Dataset) -&gt; int:\n\"\"\"Get the length of a dataset. Try to access it with len(), and if not\n    available, with a reduce op.\n\n    Args:\n        dataset (tf.data.Dataset): Dataset to process\n\n    Returns:\n        int: _description_\n    \"\"\"\n    try:\n        return len(dataset)\n    except TypeError:\n        cardinality = dataset.reduce(0, lambda x, _: x + 1)\n        return int(cardinality)\n</code></pre>"},{"location":"api/datahandlers/#oodeel.datasets.tf_data_handler.TFDataHandler.get_ds_feature_keys","title":"<code>get_ds_feature_keys(dataset)</code>  <code>staticmethod</code>","text":"<p>Get the feature keys of a tf.data.Dataset</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>tf.data.Dataset</code> <p>tf.data.Dataset to get the feature keys from</p> required <p>Returns:</p> Name Type Description <code>list</code> <code>list</code> <p>List of feature keys</p> Source code in <code>oodeel/datasets/tf_data_handler.py</code> <pre><code>@staticmethod\n@dict_only_ds\ndef get_ds_feature_keys(dataset: tf.data.Dataset) -&gt; list:\n\"\"\"Get the feature keys of a tf.data.Dataset\n\n    Args:\n        dataset (tf.data.Dataset): tf.data.Dataset to get the feature keys from\n\n    Returns:\n        list: List of feature keys\n    \"\"\"\n    return list(dataset.element_spec.keys())\n</code></pre>"},{"location":"api/datahandlers/#oodeel.datasets.tf_data_handler.TFDataHandler.get_feature","title":"<code>get_feature(dataset, feature_key)</code>  <code>staticmethod</code>","text":"<p>Extract a feature from a dataset</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>tf.data.Dataset</code> <p>Dataset to extract the feature from</p> required <code>feature_key</code> <code>Union[str, int]</code> <p>feature to extract</p> required <p>Returns:</p> Type Description <code>tf.data.Dataset</code> <p>tf.data.Dataset: dataset built with the extracted feature only</p> Source code in <code>oodeel/datasets/tf_data_handler.py</code> <pre><code>@staticmethod\ndef get_feature(\n    dataset: tf.data.Dataset, feature_key: Union[str, int]\n) -&gt; tf.data.Dataset:\n\"\"\"Extract a feature from a dataset\n\n    Args:\n        dataset (tf.data.Dataset): Dataset to extract the feature from\n        feature_key (Union[str, int]): feature to extract\n\n    Returns:\n        tf.data.Dataset: dataset built with the extracted feature only\n    \"\"\"\n\n    def _get_feature_elem(elem):\n        return elem[feature_key]\n\n    return dataset.map(_get_feature_elem)\n</code></pre>"},{"location":"api/datahandlers/#oodeel.datasets.tf_data_handler.TFDataHandler.get_feature_from_ds","title":"<code>get_feature_from_ds(dataset, feature_key)</code>  <code>staticmethod</code>","text":"<p>Get a feature from a tf.data.Dataset</p> <p>Note</p> <p>This function can be a bit time consuming since it needs to iterate over the whole dataset.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>tf.data.Dataset</code> <p>tf.data.Dataset to get the feature from</p> required <code>feature_key</code> <code>str</code> <p>Feature value to get</p> required <p>Returns:</p> Type Description <code>np.ndarray</code> <p>np.ndarray: Feature values for dataset</p> Source code in <code>oodeel/datasets/tf_data_handler.py</code> <pre><code>@staticmethod\n@dict_only_ds\ndef get_feature_from_ds(dataset: tf.data.Dataset, feature_key: str) -&gt; np.ndarray:\n\"\"\"Get a feature from a tf.data.Dataset\n\n    !!! note\n        This function can be a bit time consuming since it needs to iterate\n        over the whole dataset.\n\n    Args:\n        dataset (tf.data.Dataset): tf.data.Dataset to get the feature from\n        feature_key (str): Feature value to get\n\n    Returns:\n        np.ndarray: Feature values for dataset\n    \"\"\"\n    features = dataset.map(lambda x: x[feature_key])\n    features = list(features.as_numpy_iterator())\n    features = np.array(features)\n    return features\n</code></pre>"},{"location":"api/datahandlers/#oodeel.datasets.tf_data_handler.TFDataHandler.get_feature_shape","title":"<code>get_feature_shape(dataset, feature_key)</code>  <code>staticmethod</code>","text":"<p>Get the shape of a feature of dataset identified by feature_key</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>tf.data.Dataset</code> <p>a tf.data.dataset</p> required <code>feature_key</code> <code>Union[str, int]</code> <p>The identifier of the feature</p> required <p>Returns:</p> Name Type Description <code>tuple</code> <code>tuple</code> <p>the shape of feature_id</p> Source code in <code>oodeel/datasets/tf_data_handler.py</code> <pre><code>@staticmethod\ndef get_feature_shape(\n    dataset: tf.data.Dataset, feature_key: Union[str, int]\n) -&gt; tuple:\n\"\"\"Get the shape of a feature of dataset identified by feature_key\n\n    Args:\n        dataset (tf.data.Dataset): a tf.data.dataset\n        feature_key (Union[str, int]): The identifier of the feature\n\n    Returns:\n        tuple: the shape of feature_id\n    \"\"\"\n    return tuple(dataset.element_spec[feature_key].shape)\n</code></pre>"},{"location":"api/datahandlers/#oodeel.datasets.tf_data_handler.TFDataHandler.get_input_from_dataset_item","title":"<code>get_input_from_dataset_item(elem)</code>  <code>staticmethod</code>","text":"<p>Get the tensor that is to be feed as input to a model from a dataset element.</p> <p>Parameters:</p> Name Type Description Default <code>elem</code> <code>ItemType</code> <p>dataset element to extract input from</p> required <p>Returns:</p> Name Type Description <code>TensorType</code> <code>TensorType</code> <p>Input tensor</p> Source code in <code>oodeel/datasets/tf_data_handler.py</code> <pre><code>@staticmethod\ndef get_input_from_dataset_item(elem: ItemType) -&gt; TensorType:\n\"\"\"Get the tensor that is to be feed as input to a model from a dataset element.\n\n    Args:\n        elem (ItemType): dataset element to extract input from\n\n    Returns:\n        TensorType: Input tensor\n    \"\"\"\n    if isinstance(elem, (tuple, list)):\n        tensor = elem[0]\n    elif isinstance(elem, dict):\n        tensor = elem[list(elem.keys())[0]]\n    else:\n        tensor = elem\n    return tensor\n</code></pre>"},{"location":"api/datahandlers/#oodeel.datasets.tf_data_handler.TFDataHandler.get_item_length","title":"<code>get_item_length(dataset)</code>  <code>staticmethod</code>","text":"<p>Get the length of a dataset element. If an element is a tensor, the length is one and if it is a sequence (list or tuple), it is len(elem).</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>tf.data.Dataset</code> <p>Dataset to process</p> required <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>length of the dataset elems</p> Source code in <code>oodeel/datasets/tf_data_handler.py</code> <pre><code>@staticmethod\ndef get_item_length(dataset: tf.data.Dataset) -&gt; int:\n\"\"\"Get the length of a dataset element. If an element is a tensor, the length is\n    one and if it is a sequence (list or tuple), it is len(elem).\n\n    Args:\n        dataset (tf.data.Dataset): Dataset to process\n\n    Returns:\n        int: length of the dataset elems\n    \"\"\"\n    if isinstance(dataset.element_spec, (tuple, list, dict)):\n        return len(dataset.element_spec)\n    return 1\n</code></pre>"},{"location":"api/datahandlers/#oodeel.datasets.tf_data_handler.TFDataHandler.get_label_from_dataset_item","title":"<code>get_label_from_dataset_item(item)</code>  <code>staticmethod</code>","text":"<p>Retrieve label tensor from item as a tuple/list. Label must be at index 1 in the item tuple. If one-hot encoded, labels are converted to single value.</p> <p>Parameters:</p> Name Type Description Default <code>elem</code> <code>ItemType</code> <p>dataset element to extract label from</p> required <p>Returns:</p> Name Type Description <code>Any</code> <p>Label tensor</p> Source code in <code>oodeel/datasets/tf_data_handler.py</code> <pre><code>@staticmethod\ndef get_label_from_dataset_item(item: ItemType):\n\"\"\"Retrieve label tensor from item as a tuple/list. Label must be at index 1\n    in the item tuple. If one-hot encoded, labels are converted to single value.\n\n    Args:\n        elem (ItemType): dataset element to extract label from\n\n    Returns:\n        Any: Label tensor\n    \"\"\"\n    label = item[1]  # labels must be at index 1 in the item tuple\n    # If labels are one-hot encoded, take the argmax\n    if tf.rank(label) &gt; 1 and label.shape[1] &gt; 1:\n        label = tf.reshape(label, shape=[label.shape[0], -1])\n        label = tf.argmax(label, axis=1)\n    # If labels are in two dimensions, squeeze them\n    if len(label.shape) &gt; 1:\n        label = tf.reshape(label, [label.shape[0]])\n    return label\n</code></pre>"},{"location":"api/datahandlers/#oodeel.datasets.tf_data_handler.TFDataHandler.has_feature_key","title":"<code>has_feature_key(dataset, key)</code>  <code>staticmethod</code>","text":"<p>Check if a tf.data.Dataset has a feature denoted by key</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>tf.data.Dataset</code> <p>tf.data.Dataset to check</p> required <code>key</code> <code>str</code> <p>Key to check</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>If the tf.data.Dataset has a feature denoted by key</p> Source code in <code>oodeel/datasets/tf_data_handler.py</code> <pre><code>@staticmethod\ndef has_feature_key(dataset: tf.data.Dataset, key: str) -&gt; bool:\n\"\"\"Check if a tf.data.Dataset has a feature denoted by key\n\n    Args:\n        dataset (tf.data.Dataset): tf.data.Dataset to check\n        key (str): Key to check\n\n    Returns:\n        bool: If the tf.data.Dataset has a feature denoted by key\n    \"\"\"\n    assert isinstance(dataset.element_spec, dict), \"dataset elements must be dicts\"\n    return True if (key in dataset.element_spec.keys()) else False\n</code></pre>"},{"location":"api/datahandlers/#oodeel.datasets.tf_data_handler.TFDataHandler.load_custom_dataset","title":"<code>load_custom_dataset(dataset_id, keys=None)</code>  <code>classmethod</code>","text":"<p>Load a custom Dataset by ensuring it has the correct format (dict-based)</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>tf.data.Dataset</code> <p>tf.data.Dataset</p> required <code>keys</code> <code>list</code> <p>Features keys. If None, assigned as \"input_i\" for i-th feature. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>tf.data.Dataset</code> <p>tf.data.Dataset</p> Source code in <code>oodeel/datasets/tf_data_handler.py</code> <pre><code>@classmethod\ndef load_custom_dataset(\n    cls, dataset_id: tf.data.Dataset, keys: Optional[list] = None\n) -&gt; tf.data.Dataset:\n\"\"\"Load a custom Dataset by ensuring it has the correct format (dict-based)\n\n    Args:\n        dataset_id (tf.data.Dataset): tf.data.Dataset\n        keys (list, optional): Features keys. If None, assigned as \"input_i\"\n            for i-th feature. Defaults to None.\n\n    Returns:\n        tf.data.Dataset\n    \"\"\"\n    # If dataset_id is a tuple based tf.data.dataset, convert it to a dict\n    if not isinstance(dataset_id.element_spec, dict):\n        len_elem = len(dataset_id.element_spec)\n        if keys is None:\n            print(\n                \"Feature name not found, assigning 'input_i' \"\n                \"key to the i-th tensor and 'label' key to the last\"\n            )\n            if len_elem == 2:\n                keys = [\"input\", \"label\"]\n            else:\n                keys = [f\"input_{i}\" for i in range(len_elem)]\n                keys[-1] = \"label\"\n        else:\n            assert (\n                len(keys) == len_elem\n            ), \"Number of keys mismatch with the number of features\"\n\n        dataset_id = cls.tuple_to_dict(dataset_id, keys)\n\n    dataset = dataset_id\n    return dataset\n</code></pre>"},{"location":"api/datahandlers/#oodeel.datasets.tf_data_handler.TFDataHandler.load_dataset","title":"<code>load_dataset(dataset_id, keys=None, load_kwargs={})</code>  <code>classmethod</code>","text":"<p>Load dataset from different manners, ensuring to return a dict based tf.data.Dataset.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>Any</code> <p>dataset identification</p> required <code>keys</code> <code>list</code> <p>Features keys. If None, assigned as \"input_i\" for i-th feature. Defaults to None.</p> <code>None</code> <code>load_kwargs</code> <code>dict</code> <p>Additional args for loading from tensorflow_datasets. Defaults to {}.</p> <code>{}</code> <p>Returns:</p> Type Description <code>tf.data.Dataset</code> <p>tf.data.Dataset: A dict based tf.data.Dataset</p> Source code in <code>oodeel/datasets/tf_data_handler.py</code> <pre><code>@classmethod\ndef load_dataset(\n    cls,\n    dataset_id: Union[tf.data.Dataset, ItemType, str],\n    keys: Optional[list] = None,\n    load_kwargs: dict = {},\n) -&gt; tf.data.Dataset:\n\"\"\"Load dataset from different manners, ensuring to return a dict based\n    tf.data.Dataset.\n\n    Args:\n        dataset_id (Any): dataset identification\n        keys (list, optional): Features keys. If None, assigned as \"input_i\"\n            for i-th feature. Defaults to None.\n        load_kwargs (dict, optional): Additional args for loading from\n            tensorflow_datasets. Defaults to {}.\n\n    Returns:\n        tf.data.Dataset: A dict based tf.data.Dataset\n    \"\"\"\n    if isinstance(dataset_id, get_args(ItemType)):\n        dataset = cls.load_dataset_from_arrays(dataset_id, keys)\n    elif isinstance(dataset_id, tf.data.Dataset):\n        dataset = cls.load_custom_dataset(dataset_id, keys)\n    elif isinstance(dataset_id, str):\n        dataset = cls.load_from_tensorflow_datasets(dataset_id, load_kwargs)\n    return dataset\n</code></pre>"},{"location":"api/datahandlers/#oodeel.datasets.tf_data_handler.TFDataHandler.load_dataset_from_arrays","title":"<code>load_dataset_from_arrays(dataset_id, keys=None)</code>  <code>staticmethod</code>","text":"<p>Load a tf.data.Dataset from a np.ndarray, a tf.Tensor or a tuple/dict of np.ndarrays/td.Tensors.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>ItemType</code> <p>numpy array(s) to load.</p> required <code>keys</code> <code>list</code> <p>Features keys. If None, assigned as \"input_i\" for i-th feature. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>tf.data.Dataset</code> <p>tf.data.Dataset</p> Source code in <code>oodeel/datasets/tf_data_handler.py</code> <pre><code>@staticmethod\ndef load_dataset_from_arrays(\n    dataset_id: ItemType, keys: Optional[list] = None\n) -&gt; tf.data.Dataset:\n\"\"\"Load a tf.data.Dataset from a np.ndarray, a tf.Tensor or a tuple/dict\n    of np.ndarrays/td.Tensors.\n\n    Args:\n        dataset_id (ItemType): numpy array(s) to load.\n        keys (list, optional): Features keys. If None, assigned as \"input_i\"\n            for i-th feature. Defaults to None.\n\n    Returns:\n        tf.data.Dataset\n    \"\"\"\n    # If dataset_id is a numpy array, convert it to a dict\n    if isinstance(dataset_id, get_args(TensorType)):\n        dataset_dict = {\"input\": dataset_id}\n\n    # If dataset_id is a tuple, convert it to a dict\n    elif isinstance(dataset_id, tuple):\n        len_elem = len(dataset_id)\n        if keys is None:\n            if len_elem == 2:\n                dataset_dict = {\"input\": dataset_id[0], \"label\": dataset_id[1]}\n            else:\n                dataset_dict = {\n                    f\"input_{i}\": dataset_id[i] for i in range(len_elem - 1)\n                }\n                dataset_dict[\"label\"] = dataset_id[-1]\n            print(\n                'Loading tf.data.Dataset with elems as dicts, assigning \"input_i\" '\n                'key to the i-th tuple dimension and \"label\" key to the last '\n                \"tuple dimension.\"\n            )\n        else:\n            assert (\n                len(keys) == len_elem\n            ), \"Number of keys mismatch with the number of features\"\n            dataset_dict = {keys[i]: dataset_id[i] for i in range(len_elem)}\n\n    elif isinstance(dataset_id, dict):\n        if keys is not None:\n            len_elem = len(dataset_id)\n            assert (\n                len(keys) == len_elem\n            ), \"Number of keys mismatch with the number of features\"\n            original_keys = list(dataset_id.keys())\n            dataset_dict = {\n                keys[i]: dataset_id[original_keys[i]] for i in range(len_elem)\n            }\n\n    dataset = tf.data.Dataset.from_tensor_slices(dataset_dict)\n    return dataset\n</code></pre>"},{"location":"api/datahandlers/#oodeel.datasets.tf_data_handler.TFDataHandler.load_from_tensorflow_datasets","title":"<code>load_from_tensorflow_datasets(dataset_id, load_kwargs={})</code>  <code>staticmethod</code>","text":"<p>Load a tf.data.Dataset from the tensorflow_datasets catalog</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>str</code> <p>Identifier of the dataset</p> required <code>load_kwargs</code> <code>dict</code> <p>Loading kwargs to add to tfds.load(). Defaults to {}.</p> <code>{}</code> <p>Returns:</p> Type Description <code>tf.data.Dataset</code> <p>tf.data.Dataset</p> Source code in <code>oodeel/datasets/tf_data_handler.py</code> <pre><code>@staticmethod\ndef load_from_tensorflow_datasets(\n    dataset_id: str,\n    load_kwargs: dict = {},\n) -&gt; tf.data.Dataset:\n\"\"\"Load a tf.data.Dataset from the tensorflow_datasets catalog\n\n    Args:\n        dataset_id (str): Identifier of the dataset\n        load_kwargs (dict, optional): Loading kwargs to add to tfds.load().\n            Defaults to {}.\n\n    Returns:\n        tf.data.Dataset\n    \"\"\"\n    assert (\n        dataset_id in tfds.list_builders()\n    ), \"Dataset not available on tensorflow datasets catalog\"\n    dataset = tfds.load(dataset_id, **load_kwargs)\n    return dataset\n</code></pre>"},{"location":"api/datahandlers/#oodeel.datasets.tf_data_handler.TFDataHandler.make_channel_first","title":"<code>make_channel_first(input_key, dataset)</code>  <code>staticmethod</code>","text":"<p>Make a tf.data.Dataset channel first. Make sure that the dataset is not     already Channel first. If so, the tensor will have the format     (batch_size, x_size, channel, y_size).</p> <p>Parameters:</p> Name Type Description Default <code>input_key</code> <code>str</code> <p>input key of the dict-based tf.data.Dataset</p> required <code>dataset</code> <code>tf.data.Dataset</code> <p>tf.data.Dataset to make channel first</p> required <p>Returns:</p> Type Description <code>tf.data.Dataset</code> <p>tf.data.Dataset: Channel first dataset</p> Source code in <code>oodeel/datasets/tf_data_handler.py</code> <pre><code>@staticmethod\ndef make_channel_first(input_key: str, dataset: tf.data.Dataset) -&gt; tf.data.Dataset:\n\"\"\"Make a tf.data.Dataset channel first. Make sure that the dataset is not\n        already Channel first. If so, the tensor will have the format\n        (batch_size, x_size, channel, y_size).\n\n    Args:\n        input_key (str): input key of the dict-based tf.data.Dataset\n        dataset (tf.data.Dataset): tf.data.Dataset to make channel first\n\n    Returns:\n        tf.data.Dataset: Channel first dataset\n    \"\"\"\n\n    def channel_first(x):\n        x[input_key] = tf.transpose(x[input_key], perm=[2, 0, 1])\n        return x\n\n    dataset = dataset.map(channel_first)\n    return dataset\n</code></pre>"},{"location":"api/datahandlers/#oodeel.datasets.tf_data_handler.TFDataHandler.map_ds","title":"<code>map_ds(dataset, map_fn, num_parallel_calls=None)</code>  <code>staticmethod</code>","text":"<p>Map a function to a tf.data.Dataset</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>tf.data.Dataset</code> <p>tf.data.Dataset to map the function to</p> required <code>map_fn</code> <code>Callable</code> <p>Function to map</p> required <code>num_parallel_calls</code> <code>Optional[int]</code> <p>Number of parallel processes to use. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>tf.data.Dataset</code> <p>tf.data.Dataset: Maped dataset</p> Source code in <code>oodeel/datasets/tf_data_handler.py</code> <pre><code>@staticmethod\ndef map_ds(\n    dataset: tf.data.Dataset,\n    map_fn: Callable,\n    num_parallel_calls: Optional[int] = None,\n) -&gt; tf.data.Dataset:\n\"\"\"Map a function to a tf.data.Dataset\n\n    Args:\n        dataset (tf.data.Dataset): tf.data.Dataset to map the function to\n        map_fn (Callable): Function to map\n        num_parallel_calls (Optional[int], optional): Number of parallel processes\n            to use. Defaults to None.\n\n    Returns:\n        tf.data.Dataset: Maped dataset\n    \"\"\"\n    if num_parallel_calls is None:\n        num_parallel_calls = tf.data.experimental.AUTOTUNE\n    dataset = dataset.map(map_fn, num_parallel_calls=num_parallel_calls)\n    return dataset\n</code></pre>"},{"location":"api/datahandlers/#oodeel.datasets.tf_data_handler.TFDataHandler.merge","title":"<code>merge(id_dataset, ood_dataset, resize=False, shape=None, channel_order='channels_last')</code>  <code>classmethod</code>","text":"<p>Merge two tf.data.Datasets</p> <p>Parameters:</p> Name Type Description Default <code>id_dataset</code> <code>tf.data.Dataset</code> <p>dataset of in-distribution data</p> required <code>ood_dataset</code> <code>tf.data.Dataset</code> <p>dataset of out-of-distribution data</p> required <code>resize</code> <code>Optional[bool]</code> <p>toggles if input tensors of the datasets have to be resized to have the same shape. Defaults to True.</p> <code>False</code> <code>shape</code> <code>Optional[Tuple[int]]</code> <p>shape to use for resizing input tensors. If None, the tensors are resized with the shape of the id_dataset input tensors. Defaults to None.</p> <code>None</code> <code>channel_order</code> <code>Optional[str]</code> <p>channel order of the input</p> <code>'channels_last'</code> <p>Returns:</p> Type Description <code>tf.data.Dataset</code> <p>tf.data.Dataset: merged dataset</p> Source code in <code>oodeel/datasets/tf_data_handler.py</code> <pre><code>@classmethod\ndef merge(\n    cls,\n    id_dataset: tf.data.Dataset,\n    ood_dataset: tf.data.Dataset,\n    resize: Optional[bool] = False,\n    shape: Optional[Tuple[int]] = None,\n    channel_order: Optional[str] = \"channels_last\",\n) -&gt; tf.data.Dataset:\n\"\"\"Merge two tf.data.Datasets\n\n    Args:\n        id_dataset (tf.data.Dataset): dataset of in-distribution data\n        ood_dataset (tf.data.Dataset): dataset of out-of-distribution data\n        resize (Optional[bool], optional): toggles if input tensors of the\n            datasets have to be resized to have the same shape. Defaults to True.\n        shape (Optional[Tuple[int]], optional): shape to use for resizing input\n            tensors. If None, the tensors are resized with the shape of the\n            id_dataset input tensors. Defaults to None.\n        channel_order (Optional[str], optional): channel order of the input\n\n    Returns:\n        tf.data.Dataset: merged dataset\n    \"\"\"\n    len_elem_id = cls.get_item_length(id_dataset)\n    len_elem_ood = cls.get_item_length(ood_dataset)\n    assert (\n        len_elem_id == len_elem_ood\n    ), \"incompatible dataset elements (different elem dict length)\"\n\n    # If a desired shape is given, triggers the resize\n    if shape is not None:\n        resize = True\n\n    id_elem_spec = id_dataset.element_spec\n    ood_elem_spec = ood_dataset.element_spec\n    assert isinstance(id_elem_spec, dict), \"dataset elements must be dicts\"\n    assert isinstance(ood_elem_spec, dict), \"dataset elements must be dicts\"\n\n    input_key_id = list(id_elem_spec.keys())[0]\n    input_key_ood = list(ood_elem_spec.keys())[0]\n    shape_id = id_dataset.element_spec[input_key_id].shape\n    shape_ood = ood_dataset.element_spec[input_key_ood].shape\n\n    # If the shape of the two datasets are different, triggers the resize\n    if shape_id != shape_ood:\n        resize = True\n\n        if shape is None:\n            print(\n                \"Resizing the first item of elem (usually the image)\",\n                \" with the shape of id_dataset\",\n            )\n            if channel_order == \"channels_first\":\n                shape = shape_id[1:]\n            else:\n                shape = shape_id[:2]\n\n    if resize:\n\n        def reshape_im_id(elem):\n            elem[input_key_id] = tf.image.resize(elem[input_key_id], shape)\n            return elem\n\n        def reshape_im_ood(elem):\n            elem[input_key_ood] = tf.image.resize(elem[input_key_ood], shape)\n            return elem\n\n        id_dataset = id_dataset.map(reshape_im_id)\n        ood_dataset = ood_dataset.map(reshape_im_ood)\n\n    merged_dataset = id_dataset.concatenate(ood_dataset)\n    return merged_dataset\n</code></pre>"},{"location":"api/datahandlers/#oodeel.datasets.tf_data_handler.TFDataHandler.prepare_for_training","title":"<code>prepare_for_training(dataset, batch_size, shuffle=False, preprocess_fn=None, augment_fn=None, output_keys=None, dict_based_fns=False, shuffle_buffer_size=None, prefetch_buffer_size=None, drop_remainder=False)</code>  <code>classmethod</code>","text":"<p>Prepare a tf.data.Dataset for training</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>tf.data.Dataset</code> <p>tf.data.Dataset to prepare</p> required <code>batch_size</code> <code>int</code> <p>Batch size</p> required <code>shuffle</code> <code>bool</code> <p>To shuffle the returned dataset or not. Defaults to False.</p> <code>False</code> <code>preprocess_fn</code> <code>Callable</code> <p>Preprocessing function to apply to                the dataset. Defaults to None.</p> <code>None</code> <code>augment_fn</code> <code>Callable</code> <p>Augment function to be used (when the                returned dataset is to be used for training). Defaults to None.</p> <code>None</code> <code>output_keys</code> <code>list</code> <p>List of keys corresponding to the features that will be returned. Keep all features if None. Defaults to None.</p> <code>None</code> <code>dict_based_fns</code> <code>bool</code> <p>If the augment and preprocess functions are dict based or not. Defaults to False.</p> <code>False</code> <code>shuffle_buffer_size</code> <code>int</code> <p>Size of the shuffle buffer. If None, taken as the number of samples in the dataset. Defaults to None.</p> <code>None</code> <code>prefetch_buffer_size</code> <code>Optional[int]</code> <p>Buffer size for prefetch. If None, automatically chose using tf.data.experimental.AUTOTUNE. Defaults to None.</p> <code>None</code> <code>drop_remainder</code> <code>Optional[bool]</code> <p>To drop the last batch when its size is lower than batch_size. Defaults to False.</p> <code>False</code> <p>Returns:</p> Type Description <code>tf.data.Dataset</code> <p>tf.data.Dataset: Prepared dataset</p> Source code in <code>oodeel/datasets/tf_data_handler.py</code> <pre><code>@classmethod\ndef prepare_for_training(\n    cls,\n    dataset: tf.data.Dataset,\n    batch_size: int,\n    shuffle: bool = False,\n    preprocess_fn: Optional[Callable] = None,\n    augment_fn: Optional[Callable] = None,\n    output_keys: Optional[list] = None,\n    dict_based_fns: bool = False,\n    shuffle_buffer_size: Optional[int] = None,\n    prefetch_buffer_size: Optional[int] = None,\n    drop_remainder: Optional[bool] = False,\n) -&gt; tf.data.Dataset:\n\"\"\"Prepare a tf.data.Dataset for training\n\n    Args:\n        dataset (tf.data.Dataset): tf.data.Dataset to prepare\n        batch_size (int): Batch size\n        shuffle (bool, optional): To shuffle the returned dataset or not.\n            Defaults to False.\n        preprocess_fn (Callable, optional): Preprocessing function to apply to\\\n            the dataset. Defaults to None.\n        augment_fn (Callable, optional): Augment function to be used (when the\\\n            returned dataset is to be used for training). Defaults to None.\n        output_keys (list, optional): List of keys corresponding to the features\n            that will be returned. Keep all features if None. Defaults to None.\n        dict_based_fns (bool, optional): If the augment and preprocess functions are\n            dict based or not. Defaults to False.\n        shuffle_buffer_size (int, optional): Size of the shuffle buffer. If None,\n            taken as the number of samples in the dataset. Defaults to None.\n        prefetch_buffer_size (Optional[int], optional): Buffer size for prefetch.\n            If None, automatically chose using tf.data.experimental.AUTOTUNE.\n            Defaults to None.\n        drop_remainder (Optional[bool], optional): To drop the last batch when\n            its size is lower than batch_size. Defaults to False.\n\n    Returns:\n        tf.data.Dataset: Prepared dataset\n    \"\"\"\n    # dict based to tuple based\n    output_keys = output_keys or cls.get_ds_feature_keys(dataset)\n    if not dict_based_fns:\n        dataset = cls.dict_to_tuple(dataset, output_keys)\n\n    # preprocess + DA\n    if preprocess_fn is not None:\n        dataset = cls.map_ds(dataset, preprocess_fn)\n    if augment_fn is not None:\n        dataset = cls.map_ds(dataset, augment_fn)\n\n    if dict_based_fns:\n        dataset = cls.dict_to_tuple(dataset, output_keys)\n\n    dataset = dataset.cache()\n\n    # shuffle\n    if shuffle:\n        num_samples = cls.get_dataset_length(dataset)\n        shuffle_buffer_size = (\n            num_samples if shuffle_buffer_size is None else shuffle_buffer_size\n        )\n        dataset = dataset.shuffle(shuffle_buffer_size)\n    # batch\n    dataset = dataset.batch(batch_size, drop_remainder=drop_remainder)\n    # prefetch\n    if prefetch_buffer_size is not None:\n        prefetch_buffer_size = tf.data.experimental.AUTOTUNE\n    dataset = dataset.prefetch(prefetch_buffer_size)\n    return dataset\n</code></pre>"},{"location":"api/datahandlers/#oodeel.datasets.tf_data_handler.TFDataHandler.tuple_to_dict","title":"<code>tuple_to_dict(dataset, keys)</code>  <code>staticmethod</code>","text":"<p>Turn a tuple based tf.data.Dataset to a dict based tf.data.Dataset</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>tf.data.Dataset</code> <p>Tuple based tf.data.Dataset</p> required <code>keys</code> <code>list</code> <p>Keys to use for the dict based tf.data.Dataset</p> required <p>Returns:</p> Type Description <code>tf.data.Dataset</code> <p>tf.data.Dataset</p> Source code in <code>oodeel/datasets/tf_data_handler.py</code> <pre><code>@staticmethod\ndef tuple_to_dict(dataset: tf.data.Dataset, keys: list) -&gt; tf.data.Dataset:\n\"\"\"Turn a tuple based tf.data.Dataset to a dict based tf.data.Dataset\n\n    Args:\n        dataset (tf.data.Dataset): Tuple based tf.data.Dataset\n        keys (list): Keys to use for the dict based tf.data.Dataset\n\n    Returns:\n        tf.data.Dataset\n    \"\"\"\n    assert isinstance(\n        dataset.element_spec, tuple\n    ), \"dataset elements must be tuples\"\n    len_elem = len(dataset.element_spec)\n    assert len_elem == len(\n        keys\n    ), \"The number of keys must be equal to the number of tuple elements\"\n\n    def tuple_to_dict(*inputs):\n        return {keys[i]: inputs[i] for i in range(len_elem)}\n\n    dataset = dataset.map(tuple_to_dict)\n    return dataset\n</code></pre>"},{"location":"api/datahandlers/#oodeel.datasets.tf_data_handler.dict_only_ds","title":"<code>dict_only_ds(ds_handling_method)</code>","text":"<p>Decorator to ensure that the dataset is a dict dataset and that the input key matches one of the feature keys. The signature of decorated functions must be function(dataset, args, *kwargs) with feature_key either in kwargs or args[0] when relevant.</p> <p>Parameters:</p> Name Type Description Default <code>ds_handling_method</code> <code>Callable</code> <p>method to decorate</p> required <p>Returns:</p> Type Description <code>Callable</code> <p>decorated method</p> Source code in <code>oodeel/datasets/tf_data_handler.py</code> <pre><code>def dict_only_ds(ds_handling_method: Callable) -&gt; Callable:\n\"\"\"Decorator to ensure that the dataset is a dict dataset and that the input key\n    matches one of the feature keys. The signature of decorated functions\n    must be function(dataset, *args, **kwargs) with feature_key either in kwargs or\n    args[0] when relevant.\n\n\n    Args:\n        ds_handling_method: method to decorate\n\n    Returns:\n        decorated method\n    \"\"\"\n\n    def wrapper(dataset: tf.data.Dataset, *args, **kwargs):\n        assert isinstance(dataset.element_spec, dict), \"dataset elements must be dicts\"\n\n        if \"feature_key\" in kwargs.keys():\n            feature_key = kwargs[\"feature_key\"]\n        elif len(args) &gt; 0:\n            feature_key = args[0]\n\n        # If feature_key is provided, check that it is in the dataset feature keys\n        if (len(args) &gt; 0) or (\"feature_key\" in kwargs):\n            if isinstance(feature_key, str):\n                feature_key = [feature_key]\n            for key in feature_key:\n                assert (\n                    key in dataset.element_spec.keys()\n                ), f\"The input dataset has no feature names {key}\"\n        return ds_handling_method(dataset, *args, **kwargs)\n\n    return wrapper\n</code></pre>"},{"location":"api/datahandlers/#oodeel.datasets.torch_data_handler.DictDataset","title":"<code>DictDataset</code>","text":"<p>         Bases: <code>Dataset</code></p> <p>Dictionary pytorch dataset</p> <p>Wrapper to output a dictionary of tensors at the getitem call of a dataset. Some mapping, filtering and concatenation methods are implemented to imitate tensorflow datasets features.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>Dataset</code> <p>Dataset to wrap.</p> required <code>output_keys</code> <code>output_keys[str]</code> <p>Keys describing the output tensors.</p> <code>['input', 'label']</code> Source code in <code>oodeel/datasets/torch_data_handler.py</code> <pre><code>class DictDataset(Dataset):\nr\"\"\"Dictionary pytorch dataset\n\n    Wrapper to output a dictionary of tensors at the __getitem__ call of a dataset.\n    Some mapping, filtering and concatenation methods are implemented to imitate\n    tensorflow datasets features.\n\n    Args:\n        dataset (Dataset): Dataset to wrap.\n        output_keys (output_keys[str]): Keys describing the output tensors.\n    \"\"\"\n\n    def __init__(\n        self, dataset: Dataset, output_keys: List[str] = [\"input\", \"label\"]\n    ) -&gt; None:\n        self._dataset = dataset\n        self._raw_output_keys = output_keys\n        self.map_fns = []\n        self._check_init_args()\n\n    @property\n    def output_keys(self) -&gt; list:\n\"\"\"Get the list of keys in a dict-based item from the dataset.\n\n        Returns:\n            list: feature keys of the dataset.\n        \"\"\"\n        dummy_item = self[0]\n        return list(dummy_item.keys())\n\n    @property\n    def output_shapes(self) -&gt; list:\n\"\"\"Get a list of the tensor shapes in an item from the dataset.\n\n        Returns:\n            list: tensor shapes of an dataset item.\n        \"\"\"\n        dummy_item = self[0]\n        return [dummy_item[key].shape for key in self.output_keys]\n\n    def _check_init_args(self) -&gt; None:\n\"\"\"Check validity of dataset and output keys provided at init\"\"\"\n        dummy_item = self._dataset[0]\n        assert isinstance(\n            dummy_item, (tuple, dict, list, torch.Tensor)\n        ), \"Dataset to be wrapped needs to return tuple, list or dict of tensors\"\n        if isinstance(dummy_item, torch.Tensor):\n            dummy_item = [dummy_item]\n        assert len(dummy_item) == len(\n            self._raw_output_keys\n        ), \"Length mismatch between dataset item and provided keys\"\n\n    def __getitem__(self, index: int) -&gt; dict:\n\"\"\"Return a dictionary of tensors corresponding to a specfic index.\n\n        Args:\n            index (int): the index of the item to retrieve.\n\n        Returns:\n            dict: tensors for the item at the specific index.\n        \"\"\"\n        item = self._dataset[index]\n\n        # convert item to a list / tuple of tensors\n        if isinstance(item, torch.Tensor):\n            tensors = [item]\n        elif isinstance(item, dict):\n            tensors = list(item.values())\n        else:\n            tensors = item\n\n        # build output dictionary\n        output_dict = {\n            key: tensor for (key, tensor) in zip(self._raw_output_keys, tensors)\n        }\n\n        # apply map functions\n        for map_fn in self.map_fns:\n            output_dict = map_fn(output_dict)\n        return output_dict\n\n    def map(self, map_fn: Callable, inplace: bool = False) -&gt; \"DictDataset\":\n\"\"\"Map the dataset\n\n        Args:\n            map_fn (Callable): map function f: dict -&gt; dict\n            inplace (bool): if False, applies the mapping on a copied version of\\\n                the dataset. Defaults to False.\n\n        Return:\n            DictDataset: Mapped dataset\n        \"\"\"\n        dataset = self if inplace else copy.deepcopy(self)\n        dataset.map_fns.append(map_fn)\n        return dataset\n\n    def filter(self, filter_fn: Callable, inplace: bool = False) -&gt; \"DictDataset\":\n\"\"\"Filter the dataset\n\n        Args:\n            filter_fn (Callable): filter function f: dict -&gt; bool\n            inplace (bool): if False, applies the filtering on a copied version of\\\n                the dataset. Defaults to False.\n\n        Returns:\n            DictDataset: Filtered dataset\n        \"\"\"\n        indices = [i for i in range(len(self)) if filter_fn(self[i])]\n        dataset = self if inplace else copy.deepcopy(self)\n        dataset._dataset = Subset(self._dataset, indices)\n        return dataset\n\n    def concatenate(\n        self, other_dataset: Dataset, inplace: bool = False\n    ) -&gt; \"DictDataset\":\n\"\"\"Concatenate with another dataset\n\n        Args:\n            other_dataset (DictDataset): Dataset to concatenate with\n            inplace (bool): if False, applies the filtering on a copied version of\\\n                the dataset. Defaults to False.\n\n        Returns:\n            DictDataset: Concatenated dataset\n        \"\"\"\n        assert isinstance(\n            other_dataset, DictDataset\n        ), \"Second dataset should be an instance of DictDataset\"\n        assert (\n            self.output_keys == other_dataset.output_keys\n        ), \"Incompatible dataset elements (different dict keys)\"\n        if inplace:\n            dataset_copy = copy.deepcopy(self)\n            self._raw_output_keys = self.output_keys\n            self.map_fns = []\n            self._dataset = ConcatDataset([dataset_copy, other_dataset])\n            dataset = self\n        else:\n            dataset = DictDataset(\n                ConcatDataset([self, other_dataset]), self.output_keys\n            )\n        return dataset\n\n    def __len__(self) -&gt; int:\n\"\"\"Return the length of the dataset, i.e. the number of items.\n\n        Returns:\n            int: length of the dataset.\n        \"\"\"\n        return len(self._dataset)\n</code></pre>"},{"location":"api/datahandlers/#oodeel.datasets.torch_data_handler.DictDataset.output_keys","title":"<code>output_keys: list</code>  <code>property</code>","text":"<p>Get the list of keys in a dict-based item from the dataset.</p> <p>Returns:</p> Name Type Description <code>list</code> <code>list</code> <p>feature keys of the dataset.</p>"},{"location":"api/datahandlers/#oodeel.datasets.torch_data_handler.DictDataset.output_shapes","title":"<code>output_shapes: list</code>  <code>property</code>","text":"<p>Get a list of the tensor shapes in an item from the dataset.</p> <p>Returns:</p> Name Type Description <code>list</code> <code>list</code> <p>tensor shapes of an dataset item.</p>"},{"location":"api/datahandlers/#oodeel.datasets.torch_data_handler.DictDataset.__getitem__","title":"<code>__getitem__(index)</code>","text":"<p>Return a dictionary of tensors corresponding to a specfic index.</p> <p>Parameters:</p> Name Type Description Default <code>index</code> <code>int</code> <p>the index of the item to retrieve.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>tensors for the item at the specific index.</p> Source code in <code>oodeel/datasets/torch_data_handler.py</code> <pre><code>def __getitem__(self, index: int) -&gt; dict:\n\"\"\"Return a dictionary of tensors corresponding to a specfic index.\n\n    Args:\n        index (int): the index of the item to retrieve.\n\n    Returns:\n        dict: tensors for the item at the specific index.\n    \"\"\"\n    item = self._dataset[index]\n\n    # convert item to a list / tuple of tensors\n    if isinstance(item, torch.Tensor):\n        tensors = [item]\n    elif isinstance(item, dict):\n        tensors = list(item.values())\n    else:\n        tensors = item\n\n    # build output dictionary\n    output_dict = {\n        key: tensor for (key, tensor) in zip(self._raw_output_keys, tensors)\n    }\n\n    # apply map functions\n    for map_fn in self.map_fns:\n        output_dict = map_fn(output_dict)\n    return output_dict\n</code></pre>"},{"location":"api/datahandlers/#oodeel.datasets.torch_data_handler.DictDataset.__len__","title":"<code>__len__()</code>","text":"<p>Return the length of the dataset, i.e. the number of items.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>length of the dataset.</p> Source code in <code>oodeel/datasets/torch_data_handler.py</code> <pre><code>def __len__(self) -&gt; int:\n\"\"\"Return the length of the dataset, i.e. the number of items.\n\n    Returns:\n        int: length of the dataset.\n    \"\"\"\n    return len(self._dataset)\n</code></pre>"},{"location":"api/datahandlers/#oodeel.datasets.torch_data_handler.DictDataset.concatenate","title":"<code>concatenate(other_dataset, inplace=False)</code>","text":"<p>Concatenate with another dataset</p> <p>Parameters:</p> Name Type Description Default <code>other_dataset</code> <code>DictDataset</code> <p>Dataset to concatenate with</p> required <code>inplace</code> <code>bool</code> <p>if False, applies the filtering on a copied version of                the dataset. Defaults to False.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>DictDataset</code> <code>DictDataset</code> <p>Concatenated dataset</p> Source code in <code>oodeel/datasets/torch_data_handler.py</code> <pre><code>def concatenate(\n    self, other_dataset: Dataset, inplace: bool = False\n) -&gt; \"DictDataset\":\n\"\"\"Concatenate with another dataset\n\n    Args:\n        other_dataset (DictDataset): Dataset to concatenate with\n        inplace (bool): if False, applies the filtering on a copied version of\\\n            the dataset. Defaults to False.\n\n    Returns:\n        DictDataset: Concatenated dataset\n    \"\"\"\n    assert isinstance(\n        other_dataset, DictDataset\n    ), \"Second dataset should be an instance of DictDataset\"\n    assert (\n        self.output_keys == other_dataset.output_keys\n    ), \"Incompatible dataset elements (different dict keys)\"\n    if inplace:\n        dataset_copy = copy.deepcopy(self)\n        self._raw_output_keys = self.output_keys\n        self.map_fns = []\n        self._dataset = ConcatDataset([dataset_copy, other_dataset])\n        dataset = self\n    else:\n        dataset = DictDataset(\n            ConcatDataset([self, other_dataset]), self.output_keys\n        )\n    return dataset\n</code></pre>"},{"location":"api/datahandlers/#oodeel.datasets.torch_data_handler.DictDataset.filter","title":"<code>filter(filter_fn, inplace=False)</code>","text":"<p>Filter the dataset</p> <p>Parameters:</p> Name Type Description Default <code>filter_fn</code> <code>Callable</code> <p>filter function f: dict -&gt; bool</p> required <code>inplace</code> <code>bool</code> <p>if False, applies the filtering on a copied version of                the dataset. Defaults to False.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>DictDataset</code> <code>DictDataset</code> <p>Filtered dataset</p> Source code in <code>oodeel/datasets/torch_data_handler.py</code> <pre><code>def filter(self, filter_fn: Callable, inplace: bool = False) -&gt; \"DictDataset\":\n\"\"\"Filter the dataset\n\n    Args:\n        filter_fn (Callable): filter function f: dict -&gt; bool\n        inplace (bool): if False, applies the filtering on a copied version of\\\n            the dataset. Defaults to False.\n\n    Returns:\n        DictDataset: Filtered dataset\n    \"\"\"\n    indices = [i for i in range(len(self)) if filter_fn(self[i])]\n    dataset = self if inplace else copy.deepcopy(self)\n    dataset._dataset = Subset(self._dataset, indices)\n    return dataset\n</code></pre>"},{"location":"api/datahandlers/#oodeel.datasets.torch_data_handler.DictDataset.map","title":"<code>map(map_fn, inplace=False)</code>","text":"<p>Map the dataset</p> <p>Parameters:</p> Name Type Description Default <code>map_fn</code> <code>Callable</code> <p>map function f: dict -&gt; dict</p> required <code>inplace</code> <code>bool</code> <p>if False, applies the mapping on a copied version of                the dataset. Defaults to False.</p> <code>False</code> Return <p>DictDataset: Mapped dataset</p> Source code in <code>oodeel/datasets/torch_data_handler.py</code> <pre><code>def map(self, map_fn: Callable, inplace: bool = False) -&gt; \"DictDataset\":\n\"\"\"Map the dataset\n\n    Args:\n        map_fn (Callable): map function f: dict -&gt; dict\n        inplace (bool): if False, applies the mapping on a copied version of\\\n            the dataset. Defaults to False.\n\n    Return:\n        DictDataset: Mapped dataset\n    \"\"\"\n    dataset = self if inplace else copy.deepcopy(self)\n    dataset.map_fns.append(map_fn)\n    return dataset\n</code></pre>"},{"location":"api/datahandlers/#oodeel.datasets.torch_data_handler.TorchDataHandler","title":"<code>TorchDataHandler</code>","text":"<p>         Bases: <code>DataHandler</code></p> <p>Class to manage torch DictDataset. The aim is to provide a simple interface for working with torch datasets and manage them without having to use torch syntax.</p> Source code in <code>oodeel/datasets/torch_data_handler.py</code> <pre><code>class TorchDataHandler(DataHandler):\n\"\"\"\n    Class to manage torch DictDataset. The aim is to provide a simple interface\n    for working with torch datasets and manage them without having to use\n    torch syntax.\n    \"\"\"\n\n    @staticmethod\n    def _default_target_transform(y: Any) -&gt; torch.Tensor:\n\"\"\"Format int or float item target as a torch tensor\n\n        Args:\n            y (Any): dataset item target\n\n        Returns:\n            torch.Tensor: target as a torch.Tensor\n        \"\"\"\n        return torch.tensor(y) if isinstance(y, (float, int)) else y\n\n    DEFAULT_TRANSFORM = torchvision.transforms.PILToTensor()\n    DEFAULT_TARGET_TRANSFORM = _default_target_transform.__func__\n\n    @classmethod\n    def load_dataset(\n        cls,\n        dataset_id: Union[Dataset, ItemType, str],\n        keys: Optional[list] = None,\n        load_kwargs: dict = {},\n    ) -&gt; DictDataset:\n\"\"\"Load dataset from different manners\n\n        Args:\n            dataset_id (Union[Dataset, ItemType, str]): dataset identification\n            keys (list, optional): Features keys. If None, assigned as \"input_i\"\n                for i-th feature. Defaults to None.\n            load_kwargs (dict, optional): Additional loading kwargs. Defaults to {}.\n\n        Returns:\n            DictDataset: dataset\n        \"\"\"\n        if isinstance(dataset_id, str):\n            assert \"root\" in load_kwargs.keys()\n            dataset = cls.load_from_torchvision(dataset_id, **load_kwargs)\n        elif isinstance(dataset_id, Dataset):\n            dataset = cls.load_custom_dataset(dataset_id, keys)\n        elif isinstance(dataset_id, get_args(ItemType)):\n            dataset = cls.load_dataset_from_arrays(dataset_id, keys)\n        return dataset\n\n    @staticmethod\n    def load_dataset_from_arrays(\n        dataset_id: ItemType,\n        keys: Optional[list] = None,\n    ) -&gt; DictDataset:\n\"\"\"Load a torch.utils.data.Dataset from an array or a tuple/dict of arrays.\n\n        Args:\n            dataset_id (ItemType):\n                numpy / torch array(s) to load.\n            keys (list, optional): Features keys. If None, assigned as \"input_i\"\n                for i-th feature. Defaults to None.\n\n        Returns:\n            DictDataset: dataset\n        \"\"\"\n        # If dataset_id is an array\n        if isinstance(dataset_id, get_args(TensorType)):\n            tensors = tuple(to_torch(dataset_id))\n            output_keys = keys or [\"input\"]\n\n        # If dataset_id is a tuple of arrays\n        elif isinstance(dataset_id, tuple):\n            len_elem = len(dataset_id)\n            output_keys = keys\n            if output_keys is None:\n                if len_elem == 2:\n                    output_keys = [\"input\", \"label\"]\n                else:\n                    output_keys = [f\"input_{i}\" for i in range(len_elem - 1)] + [\n                        \"label\"\n                    ]\n                    print(\n                        \"Loading torch.utils.data.Dataset with elems as dicts, \"\n                        'assigning \"input_i\" key to the i-th tuple dimension and'\n                        ' \"label\" key to the last tuple dimension.'\n                    )\n            assert len(output_keys) == len(dataset_id)\n            tensors = tuple(to_torch(array) for array in dataset_id)\n\n        # If dataset_id is a dictionary of arrays\n        elif isinstance(dataset_id, dict):\n            output_keys = keys or list(dataset_id.keys())\n            assert len(output_keys) == len(dataset_id)\n            tensors = tuple(to_torch(array) for array in dataset_id.values())\n\n        # create torch dictionary dataset from tensors tuple and keys\n        dataset = DictDataset(TensorDataset(*tensors), output_keys)\n        return dataset\n\n    @staticmethod\n    def load_custom_dataset(\n        dataset_id: Dataset, keys: Optional[list] = None\n    ) -&gt; DictDataset:\n\"\"\"Load a custom Dataset by ensuring it has the correct format (dict-based)\n\n        Args:\n            dataset_id (Dataset): Dataset\n            keys (list, optional): Keys to use for features if dataset_id is\n                tuple based. Defaults to None.\n\n        Returns:\n            DictDataset\n        \"\"\"\n        # If dataset_id is a tuple based Dataset, convert it to a DictDataset\n        dummy_item = dataset_id[0]\n        if not isinstance(dummy_item, dict):\n            assert isinstance(\n                dummy_item, (Tuple, torch.Tensor)\n            ), \"Custom dataset should be either dictionary based or tuple based\"\n            output_keys = keys\n            if output_keys is None:\n                len_elem = len(dummy_item)\n                if len_elem == 2:\n                    output_keys = [\"input\", \"label\"]\n                else:\n                    output_keys = [f\"input_{i}\" for i in range(len_elem - 1)] + [\n                        \"label\"\n                    ]\n                    print(\n                        \"Feature name not found, assigning 'input_i' \"\n                        \"key to the i-th tensor and 'label' key to the last\"\n                    )\n            dataset_id = DictDataset(dataset_id, output_keys)\n\n        dataset = dataset_id\n        return dataset\n\n    @classmethod\n    def load_from_torchvision(\n        cls,\n        dataset_id: str,\n        root: str,\n        transform: Callable = DEFAULT_TRANSFORM,\n        target_transform: Callable = DEFAULT_TARGET_TRANSFORM,\n        download: bool = False,\n        **load_kwargs,\n    ) -&gt; DictDataset:\n\"\"\"Load a Dataset from the torchvision datasets catalog\n\n        Args:\n            dataset_id (str): Identifier of the dataset\n            root (str): Root directory of dataset\n            transform (Callable, optional): Transform function to apply to the input.\n                Defaults to DEFAULT_TRANSFORM.\n            target_transform (Callable, optional): Transform function to apply\n                to the target. Defaults to DEFAULT_TARGET_TRANSFORM.\n            download (bool):  If true, downloads the dataset from the internet and puts\n                it in root directory. If dataset is already downloaded, it is not\n                downloaded again. Defaults to False.\n            load_kwargs (dict): Loading kwargs to add to the initialization\n                of dataset.\n\n        Returns:\n            DictDataset: dataset\n        \"\"\"\n        assert (\n            dataset_id in torchvision.datasets.__all__\n        ), \"Dataset not available on torchvision datasets catalog\"\n        dataset = getattr(torchvision.datasets, dataset_id)(\n            root=root,\n            download=download,\n            transform=transform,\n            target_transform=target_transform,\n            **load_kwargs,\n        )\n        return cls.load_custom_dataset(dataset)\n\n    @staticmethod\n    def assign_feature_value(\n        dataset: DictDataset, feature_key: str, value: int\n    ) -&gt; DictDataset:\n\"\"\"Assign a value to a feature for every sample in a DictDataset\n\n        Args:\n            dataset (DictDataset): DictDataset to assign the value to\n            feature_key (str): Feature to assign the value to\n            value (int): Value to assign\n\n        Returns:\n            DictDataset\n        \"\"\"\n        assert isinstance(\n            dataset, DictDataset\n        ), \"Dataset must be an instance of DictDataset\"\n\n        def assign_value_to_feature(x):\n            x[feature_key] = torch.tensor(value)\n            return x\n\n        dataset = dataset.map(assign_value_to_feature)\n        return dataset\n\n    @staticmethod\n    @dict_only_ds\n    def get_feature_from_ds(dataset: DictDataset, feature_key: str) -&gt; np.ndarray:\n\"\"\"Get a feature from a DictDataset\n\n        !!! note\n            This function can be a bit time consuming since it needs to iterate\n            over the whole dataset.\n\n        Args:\n            dataset (DictDataset): Dataset to get the feature from\n            feature_key (str): Feature value to get\n\n        Returns:\n            np.ndarray: Feature values for dataset\n        \"\"\"\n\n        features = dataset.map(lambda x: x[feature_key])\n        features = np.stack([f.numpy() for f in features])\n        return features\n\n    @staticmethod\n    @dict_only_ds\n    def get_ds_feature_keys(dataset: DictDataset) -&gt; list:\n\"\"\"Get the feature keys of a DictDataset\n\n        Args:\n            dataset (DictDataset): Dataset to get the feature keys from\n\n        Returns:\n            list: List of feature keys\n        \"\"\"\n        return dataset.output_keys\n\n    @staticmethod\n    def has_feature_key(dataset: DictDataset, key: str) -&gt; bool:\n\"\"\"Check if a DictDataset has a feature denoted by key\n\n        Args:\n            dataset (DictDataset): Dataset to check\n            key (str): Key to check\n\n        Returns:\n            bool: If the dataset has a feature denoted by key\n        \"\"\"\n        assert isinstance(\n            dataset, DictDataset\n        ), \"Dataset must be an instance of DictDataset\"\n\n        return key in dataset.output_keys\n\n    @staticmethod\n    def map_ds(\n        dataset: DictDataset,\n        map_fn: Callable,\n    ) -&gt; DictDataset:\n\"\"\"Map a function to a DictDataset\n\n        Args:\n            dataset (DictDataset): Dataset to map the function to\n            map_fn (Callable): Function to map\n\n        Returns:\n            DictDataset: Mapped dataset\n        \"\"\"\n        return dataset.map(map_fn)\n\n    @staticmethod\n    @dict_only_ds\n    def filter_by_feature_value(\n        dataset: DictDataset,\n        feature_key: str,\n        values: list,\n        excluded: bool = False,\n    ) -&gt; DictDataset:\n\"\"\"Filter the dataset by checking the value of a feature is in `values`\n\n        !!! note\n            This function can be a bit of time consuming since it needs to iterate\n            over the whole dataset.\n\n        Args:\n            dataset (DictDataset): Dataset to filter\n            feature_key (str): Feature name to check the value\n            values (list): Feature_key values to keep\n            excluded (bool, optional): To keep (False) or exclude (True) the samples\n                with Feature_key value included in Values. Defaults to False.\n\n        Returns:\n            DictDataset: Filtered dataset\n        \"\"\"\n\n        if len(dataset[0][feature_key].shape) &gt; 0:\n            value_dim = dataset[0][feature_key].shape[-1]\n            values = [\n                F.one_hot(torch.tensor(value).long(), value_dim) for value in values\n            ]\n\n        def filter_fn(x):\n            keep = any([torch.all(x[feature_key] == v) for v in values])\n            return keep if not excluded else not keep\n\n        filtered_dataset = dataset.filter(filter_fn)\n        return filtered_dataset\n\n    @classmethod\n    def prepare_for_training(\n        cls,\n        dataset: DictDataset,\n        batch_size: int,\n        shuffle: bool = False,\n        preprocess_fn: Optional[Callable] = None,\n        augment_fn: Optional[Callable] = None,\n        output_keys: Optional[list] = None,\n        dict_based_fns: bool = False,\n        shuffle_buffer_size: Optional[int] = None,\n        num_workers: int = 8,\n    ) -&gt; DataLoader:\n\"\"\"Prepare a DataLoader for training\n\n        Args:\n            dataset (DictDataset): Dataset to prepare\n            batch_size (int): Batch size\n            shuffle (bool): Wether to shuffle the dataloader or not\n            preprocess_fn (Callable, optional): Preprocessing function to apply to\n                the dataset. Defaults to None.\n            augment_fn (Callable, optional): Augment function to be used (when the\n                returned dataset is to be used for training). Defaults to None.\n            output_keys (list): List of keys corresponding to the features that will be\n                returned. Keep all features if None. Defaults to None.\n            dict_based_fns (bool): Whether to use preprocess and DA functions as dict\n                based (if True) or as tuple based (if False). Defaults to False.\n            shuffle_buffer_size (int, optional): Size of the shuffle buffer. Not used\n                in torch because we only rely on Map-Style datasets. Still as argument\n                for API consistency. Defaults to None.\n            num_workers (int, optional): Number of workers to use for the dataloader.\n\n        Returns:\n            DataLoader: dataloader\n        \"\"\"\n        output_keys = output_keys or cls.get_ds_feature_keys(dataset)\n\n        def collate_fn(batch: List[dict]):\n            if dict_based_fns:\n                # preprocess + DA: List[dict] -&gt; List[dict]\n                preprocess_func = preprocess_fn or (lambda x: x)\n                augment_func = augment_fn or (lambda x: x)\n                batch = [augment_func(preprocess_func(d)) for d in batch]\n                # to tuple of batchs\n                return tuple(\n                    default_collate([d[key] for d in batch]) for key in output_keys\n                )\n            else:\n                # preprocess + DA: List[dict] -&gt; List[tuple]\n                preprocess_func = preprocess_fn or (lambda *x: x)\n                augment_func = augment_fn or (lambda *x: x)\n                batch = [\n                    augment_func(\n                        *preprocess_func(*tuple(d[key] for key in output_keys))\n                    )\n                    for d in batch\n                ]\n                # to tuple of batchs\n                return default_collate(batch)\n\n        loader = DataLoader(\n            dataset,\n            batch_size=batch_size,\n            shuffle=shuffle,\n            collate_fn=collate_fn,\n            num_workers=num_workers,\n        )\n        return loader\n\n    @staticmethod\n    def merge(\n        id_dataset: DictDataset,\n        ood_dataset: DictDataset,\n        resize: Optional[bool] = False,\n        shape: Optional[Tuple[int]] = None,\n    ) -&gt; DictDataset:\n\"\"\"Merge two instances of DictDataset\n\n        Args:\n            id_dataset (DictDataset): dataset of in-distribution data\n            ood_dataset (DictDataset): dataset of out-of-distribution data\n            resize (Optional[bool], optional): toggles if input tensors of the\n                datasets have to be resized to have the same shape. Defaults to True.\n            shape (Optional[Tuple[int]], optional): shape to use for resizing input\n                tensors. If None, the tensors are resized with the shape of the\n                id_dataset input tensors. Defaults to None.\n\n        Returns:\n            DictDataset: merged dataset\n        \"\"\"\n        # If a desired shape is given, triggers the resize\n        if shape is not None:\n            resize = True\n\n        # If the shape of the two datasets are different, triggers the resize\n        if id_dataset.output_shapes[0] != ood_dataset.output_shapes[0]:\n            resize = True\n            if shape is None:\n                print(\n                    \"Resizing the first item of elem (usually the image)\",\n                    \" with the shape of id_dataset\",\n                )\n                shape = id_dataset.output_shapes[0][1:]\n\n        if resize:\n            resize_fn = torchvision.transforms.Resize(shape)\n\n            def reshape_fn(item_dict):\n                item_dict[\"input\"] = resize_fn(item_dict[\"input\"])\n                return item_dict\n\n            id_dataset = id_dataset.map(reshape_fn)\n            ood_dataset = ood_dataset.map(reshape_fn)\n\n        merged_dataset = id_dataset.concatenate(ood_dataset)\n        return merged_dataset\n\n    @staticmethod\n    def get_item_length(dataset: Dataset) -&gt; int:\n\"\"\"Number of elements in a dataset item\n\n        Args:\n            dataset (DictDataset): Dataset\n\n        Returns:\n            int: Item length\n        \"\"\"\n        return len(dataset[0])\n\n    @staticmethod\n    def get_dataset_length(dataset: Dataset) -&gt; int:\n\"\"\"Number of items in a dataset\n\n        Args:\n            dataset (DictDataset): Dataset\n\n        Returns:\n            int: Dataset length\n        \"\"\"\n        return len(dataset)\n\n    @staticmethod\n    def get_feature_shape(dataset: Dataset, feature_key: Union[str, int]) -&gt; tuple:\n\"\"\"Get the shape of a feature of dataset identified by feature_key\n\n        Args:\n            dataset (Dataset): a Dataset\n            feature_key (Union[str, int]): The identifier of the feature\n\n        Returns:\n            tuple: the shape of feature_id\n        \"\"\"\n        return tuple(dataset[0][feature_key].shape)\n\n    @staticmethod\n    def get_input_from_dataset_item(elem: ItemType) -&gt; Any:\n\"\"\"Get the tensor that is to be feed as input to a model from a dataset element.\n\n        Args:\n            elem (ItemType): dataset element to extract input from\n\n        Returns:\n            Any: Input tensor\n        \"\"\"\n        if isinstance(elem, (tuple, list)):\n            tensor = elem[0]\n        elif isinstance(elem, dict):\n            tensor = elem[list(elem.keys())[0]]\n        else:\n            tensor = elem\n        return tensor\n\n    @staticmethod\n    def get_label_from_dataset_item(item: ItemType):\n\"\"\"Retrieve label tensor from item as a tuple/list. Label must be at index 1\n        in the item tuple. If one-hot encoded, labels are converted to single value.\n\n        Args:\n            elem (ItemType): dataset element to extract label from\n\n        Returns:\n            Any: Label tensor\n        \"\"\"\n        label = item[1]  # labels must be at index 1 in the batch tuple\n        # If labels are one-hot encoded, take the argmax\n        if len(label.shape) &gt; 1 and label.shape[1] &gt; 1:\n            label = label.view(label.size(0), -1)\n            label = torch.argmax(label, dim=1)\n        # If labels are in two dimensions, squeeze them\n        if len(label.shape) &gt; 1:\n            label = label.view([label.shape[0]])\n        return label\n\n    @staticmethod\n    def get_feature(dataset: DictDataset, feature_key: Union[str, int]) -&gt; DictDataset:\n\"\"\"Extract a feature from a dataset\n\n        Args:\n            dataset (tf.data.Dataset): Dataset to extract the feature from\n            feature_key (Union[str, int]): feature to extract\n\n        Returns:\n            tf.data.Dataset: dataset built with the extracted feature only\n        \"\"\"\n\n        def _get_feature_item(item):\n            return item[feature_key]\n\n        return dataset.map(_get_feature_item)\n</code></pre>"},{"location":"api/datahandlers/#oodeel.datasets.torch_data_handler.TorchDataHandler.assign_feature_value","title":"<code>assign_feature_value(dataset, feature_key, value)</code>  <code>staticmethod</code>","text":"<p>Assign a value to a feature for every sample in a DictDataset</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>DictDataset</code> <p>DictDataset to assign the value to</p> required <code>feature_key</code> <code>str</code> <p>Feature to assign the value to</p> required <code>value</code> <code>int</code> <p>Value to assign</p> required <p>Returns:</p> Type Description <code>DictDataset</code> <p>DictDataset</p> Source code in <code>oodeel/datasets/torch_data_handler.py</code> <pre><code>@staticmethod\ndef assign_feature_value(\n    dataset: DictDataset, feature_key: str, value: int\n) -&gt; DictDataset:\n\"\"\"Assign a value to a feature for every sample in a DictDataset\n\n    Args:\n        dataset (DictDataset): DictDataset to assign the value to\n        feature_key (str): Feature to assign the value to\n        value (int): Value to assign\n\n    Returns:\n        DictDataset\n    \"\"\"\n    assert isinstance(\n        dataset, DictDataset\n    ), \"Dataset must be an instance of DictDataset\"\n\n    def assign_value_to_feature(x):\n        x[feature_key] = torch.tensor(value)\n        return x\n\n    dataset = dataset.map(assign_value_to_feature)\n    return dataset\n</code></pre>"},{"location":"api/datahandlers/#oodeel.datasets.torch_data_handler.TorchDataHandler.filter_by_feature_value","title":"<code>filter_by_feature_value(dataset, feature_key, values, excluded=False)</code>  <code>staticmethod</code>","text":"<p>Filter the dataset by checking the value of a feature is in <code>values</code></p> <p>Note</p> <p>This function can be a bit of time consuming since it needs to iterate over the whole dataset.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>DictDataset</code> <p>Dataset to filter</p> required <code>feature_key</code> <code>str</code> <p>Feature name to check the value</p> required <code>values</code> <code>list</code> <p>Feature_key values to keep</p> required <code>excluded</code> <code>bool</code> <p>To keep (False) or exclude (True) the samples with Feature_key value included in Values. Defaults to False.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>DictDataset</code> <code>DictDataset</code> <p>Filtered dataset</p> Source code in <code>oodeel/datasets/torch_data_handler.py</code> <pre><code>@staticmethod\n@dict_only_ds\ndef filter_by_feature_value(\n    dataset: DictDataset,\n    feature_key: str,\n    values: list,\n    excluded: bool = False,\n) -&gt; DictDataset:\n\"\"\"Filter the dataset by checking the value of a feature is in `values`\n\n    !!! note\n        This function can be a bit of time consuming since it needs to iterate\n        over the whole dataset.\n\n    Args:\n        dataset (DictDataset): Dataset to filter\n        feature_key (str): Feature name to check the value\n        values (list): Feature_key values to keep\n        excluded (bool, optional): To keep (False) or exclude (True) the samples\n            with Feature_key value included in Values. Defaults to False.\n\n    Returns:\n        DictDataset: Filtered dataset\n    \"\"\"\n\n    if len(dataset[0][feature_key].shape) &gt; 0:\n        value_dim = dataset[0][feature_key].shape[-1]\n        values = [\n            F.one_hot(torch.tensor(value).long(), value_dim) for value in values\n        ]\n\n    def filter_fn(x):\n        keep = any([torch.all(x[feature_key] == v) for v in values])\n        return keep if not excluded else not keep\n\n    filtered_dataset = dataset.filter(filter_fn)\n    return filtered_dataset\n</code></pre>"},{"location":"api/datahandlers/#oodeel.datasets.torch_data_handler.TorchDataHandler.get_dataset_length","title":"<code>get_dataset_length(dataset)</code>  <code>staticmethod</code>","text":"<p>Number of items in a dataset</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>DictDataset</code> <p>Dataset</p> required <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>Dataset length</p> Source code in <code>oodeel/datasets/torch_data_handler.py</code> <pre><code>@staticmethod\ndef get_dataset_length(dataset: Dataset) -&gt; int:\n\"\"\"Number of items in a dataset\n\n    Args:\n        dataset (DictDataset): Dataset\n\n    Returns:\n        int: Dataset length\n    \"\"\"\n    return len(dataset)\n</code></pre>"},{"location":"api/datahandlers/#oodeel.datasets.torch_data_handler.TorchDataHandler.get_ds_feature_keys","title":"<code>get_ds_feature_keys(dataset)</code>  <code>staticmethod</code>","text":"<p>Get the feature keys of a DictDataset</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>DictDataset</code> <p>Dataset to get the feature keys from</p> required <p>Returns:</p> Name Type Description <code>list</code> <code>list</code> <p>List of feature keys</p> Source code in <code>oodeel/datasets/torch_data_handler.py</code> <pre><code>@staticmethod\n@dict_only_ds\ndef get_ds_feature_keys(dataset: DictDataset) -&gt; list:\n\"\"\"Get the feature keys of a DictDataset\n\n    Args:\n        dataset (DictDataset): Dataset to get the feature keys from\n\n    Returns:\n        list: List of feature keys\n    \"\"\"\n    return dataset.output_keys\n</code></pre>"},{"location":"api/datahandlers/#oodeel.datasets.torch_data_handler.TorchDataHandler.get_feature","title":"<code>get_feature(dataset, feature_key)</code>  <code>staticmethod</code>","text":"<p>Extract a feature from a dataset</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>tf.data.Dataset</code> <p>Dataset to extract the feature from</p> required <code>feature_key</code> <code>Union[str, int]</code> <p>feature to extract</p> required <p>Returns:</p> Type Description <code>DictDataset</code> <p>tf.data.Dataset: dataset built with the extracted feature only</p> Source code in <code>oodeel/datasets/torch_data_handler.py</code> <pre><code>@staticmethod\ndef get_feature(dataset: DictDataset, feature_key: Union[str, int]) -&gt; DictDataset:\n\"\"\"Extract a feature from a dataset\n\n    Args:\n        dataset (tf.data.Dataset): Dataset to extract the feature from\n        feature_key (Union[str, int]): feature to extract\n\n    Returns:\n        tf.data.Dataset: dataset built with the extracted feature only\n    \"\"\"\n\n    def _get_feature_item(item):\n        return item[feature_key]\n\n    return dataset.map(_get_feature_item)\n</code></pre>"},{"location":"api/datahandlers/#oodeel.datasets.torch_data_handler.TorchDataHandler.get_feature_from_ds","title":"<code>get_feature_from_ds(dataset, feature_key)</code>  <code>staticmethod</code>","text":"<p>Get a feature from a DictDataset</p> <p>Note</p> <p>This function can be a bit time consuming since it needs to iterate over the whole dataset.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>DictDataset</code> <p>Dataset to get the feature from</p> required <code>feature_key</code> <code>str</code> <p>Feature value to get</p> required <p>Returns:</p> Type Description <code>np.ndarray</code> <p>np.ndarray: Feature values for dataset</p> Source code in <code>oodeel/datasets/torch_data_handler.py</code> <pre><code>@staticmethod\n@dict_only_ds\ndef get_feature_from_ds(dataset: DictDataset, feature_key: str) -&gt; np.ndarray:\n\"\"\"Get a feature from a DictDataset\n\n    !!! note\n        This function can be a bit time consuming since it needs to iterate\n        over the whole dataset.\n\n    Args:\n        dataset (DictDataset): Dataset to get the feature from\n        feature_key (str): Feature value to get\n\n    Returns:\n        np.ndarray: Feature values for dataset\n    \"\"\"\n\n    features = dataset.map(lambda x: x[feature_key])\n    features = np.stack([f.numpy() for f in features])\n    return features\n</code></pre>"},{"location":"api/datahandlers/#oodeel.datasets.torch_data_handler.TorchDataHandler.get_feature_shape","title":"<code>get_feature_shape(dataset, feature_key)</code>  <code>staticmethod</code>","text":"<p>Get the shape of a feature of dataset identified by feature_key</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>Dataset</code> <p>a Dataset</p> required <code>feature_key</code> <code>Union[str, int]</code> <p>The identifier of the feature</p> required <p>Returns:</p> Name Type Description <code>tuple</code> <code>tuple</code> <p>the shape of feature_id</p> Source code in <code>oodeel/datasets/torch_data_handler.py</code> <pre><code>@staticmethod\ndef get_feature_shape(dataset: Dataset, feature_key: Union[str, int]) -&gt; tuple:\n\"\"\"Get the shape of a feature of dataset identified by feature_key\n\n    Args:\n        dataset (Dataset): a Dataset\n        feature_key (Union[str, int]): The identifier of the feature\n\n    Returns:\n        tuple: the shape of feature_id\n    \"\"\"\n    return tuple(dataset[0][feature_key].shape)\n</code></pre>"},{"location":"api/datahandlers/#oodeel.datasets.torch_data_handler.TorchDataHandler.get_input_from_dataset_item","title":"<code>get_input_from_dataset_item(elem)</code>  <code>staticmethod</code>","text":"<p>Get the tensor that is to be feed as input to a model from a dataset element.</p> <p>Parameters:</p> Name Type Description Default <code>elem</code> <code>ItemType</code> <p>dataset element to extract input from</p> required <p>Returns:</p> Name Type Description <code>Any</code> <code>Any</code> <p>Input tensor</p> Source code in <code>oodeel/datasets/torch_data_handler.py</code> <pre><code>@staticmethod\ndef get_input_from_dataset_item(elem: ItemType) -&gt; Any:\n\"\"\"Get the tensor that is to be feed as input to a model from a dataset element.\n\n    Args:\n        elem (ItemType): dataset element to extract input from\n\n    Returns:\n        Any: Input tensor\n    \"\"\"\n    if isinstance(elem, (tuple, list)):\n        tensor = elem[0]\n    elif isinstance(elem, dict):\n        tensor = elem[list(elem.keys())[0]]\n    else:\n        tensor = elem\n    return tensor\n</code></pre>"},{"location":"api/datahandlers/#oodeel.datasets.torch_data_handler.TorchDataHandler.get_item_length","title":"<code>get_item_length(dataset)</code>  <code>staticmethod</code>","text":"<p>Number of elements in a dataset item</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>DictDataset</code> <p>Dataset</p> required <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>Item length</p> Source code in <code>oodeel/datasets/torch_data_handler.py</code> <pre><code>@staticmethod\ndef get_item_length(dataset: Dataset) -&gt; int:\n\"\"\"Number of elements in a dataset item\n\n    Args:\n        dataset (DictDataset): Dataset\n\n    Returns:\n        int: Item length\n    \"\"\"\n    return len(dataset[0])\n</code></pre>"},{"location":"api/datahandlers/#oodeel.datasets.torch_data_handler.TorchDataHandler.get_label_from_dataset_item","title":"<code>get_label_from_dataset_item(item)</code>  <code>staticmethod</code>","text":"<p>Retrieve label tensor from item as a tuple/list. Label must be at index 1 in the item tuple. If one-hot encoded, labels are converted to single value.</p> <p>Parameters:</p> Name Type Description Default <code>elem</code> <code>ItemType</code> <p>dataset element to extract label from</p> required <p>Returns:</p> Name Type Description <code>Any</code> <p>Label tensor</p> Source code in <code>oodeel/datasets/torch_data_handler.py</code> <pre><code>@staticmethod\ndef get_label_from_dataset_item(item: ItemType):\n\"\"\"Retrieve label tensor from item as a tuple/list. Label must be at index 1\n    in the item tuple. If one-hot encoded, labels are converted to single value.\n\n    Args:\n        elem (ItemType): dataset element to extract label from\n\n    Returns:\n        Any: Label tensor\n    \"\"\"\n    label = item[1]  # labels must be at index 1 in the batch tuple\n    # If labels are one-hot encoded, take the argmax\n    if len(label.shape) &gt; 1 and label.shape[1] &gt; 1:\n        label = label.view(label.size(0), -1)\n        label = torch.argmax(label, dim=1)\n    # If labels are in two dimensions, squeeze them\n    if len(label.shape) &gt; 1:\n        label = label.view([label.shape[0]])\n    return label\n</code></pre>"},{"location":"api/datahandlers/#oodeel.datasets.torch_data_handler.TorchDataHandler.has_feature_key","title":"<code>has_feature_key(dataset, key)</code>  <code>staticmethod</code>","text":"<p>Check if a DictDataset has a feature denoted by key</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>DictDataset</code> <p>Dataset to check</p> required <code>key</code> <code>str</code> <p>Key to check</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>If the dataset has a feature denoted by key</p> Source code in <code>oodeel/datasets/torch_data_handler.py</code> <pre><code>@staticmethod\ndef has_feature_key(dataset: DictDataset, key: str) -&gt; bool:\n\"\"\"Check if a DictDataset has a feature denoted by key\n\n    Args:\n        dataset (DictDataset): Dataset to check\n        key (str): Key to check\n\n    Returns:\n        bool: If the dataset has a feature denoted by key\n    \"\"\"\n    assert isinstance(\n        dataset, DictDataset\n    ), \"Dataset must be an instance of DictDataset\"\n\n    return key in dataset.output_keys\n</code></pre>"},{"location":"api/datahandlers/#oodeel.datasets.torch_data_handler.TorchDataHandler.load_custom_dataset","title":"<code>load_custom_dataset(dataset_id, keys=None)</code>  <code>staticmethod</code>","text":"<p>Load a custom Dataset by ensuring it has the correct format (dict-based)</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>Dataset</code> <p>Dataset</p> required <code>keys</code> <code>list</code> <p>Keys to use for features if dataset_id is tuple based. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>DictDataset</code> <p>DictDataset</p> Source code in <code>oodeel/datasets/torch_data_handler.py</code> <pre><code>@staticmethod\ndef load_custom_dataset(\n    dataset_id: Dataset, keys: Optional[list] = None\n) -&gt; DictDataset:\n\"\"\"Load a custom Dataset by ensuring it has the correct format (dict-based)\n\n    Args:\n        dataset_id (Dataset): Dataset\n        keys (list, optional): Keys to use for features if dataset_id is\n            tuple based. Defaults to None.\n\n    Returns:\n        DictDataset\n    \"\"\"\n    # If dataset_id is a tuple based Dataset, convert it to a DictDataset\n    dummy_item = dataset_id[0]\n    if not isinstance(dummy_item, dict):\n        assert isinstance(\n            dummy_item, (Tuple, torch.Tensor)\n        ), \"Custom dataset should be either dictionary based or tuple based\"\n        output_keys = keys\n        if output_keys is None:\n            len_elem = len(dummy_item)\n            if len_elem == 2:\n                output_keys = [\"input\", \"label\"]\n            else:\n                output_keys = [f\"input_{i}\" for i in range(len_elem - 1)] + [\n                    \"label\"\n                ]\n                print(\n                    \"Feature name not found, assigning 'input_i' \"\n                    \"key to the i-th tensor and 'label' key to the last\"\n                )\n        dataset_id = DictDataset(dataset_id, output_keys)\n\n    dataset = dataset_id\n    return dataset\n</code></pre>"},{"location":"api/datahandlers/#oodeel.datasets.torch_data_handler.TorchDataHandler.load_dataset","title":"<code>load_dataset(dataset_id, keys=None, load_kwargs={})</code>  <code>classmethod</code>","text":"<p>Load dataset from different manners</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>Union[Dataset, ItemType, str]</code> <p>dataset identification</p> required <code>keys</code> <code>list</code> <p>Features keys. If None, assigned as \"input_i\" for i-th feature. Defaults to None.</p> <code>None</code> <code>load_kwargs</code> <code>dict</code> <p>Additional loading kwargs. Defaults to {}.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>DictDataset</code> <code>DictDataset</code> <p>dataset</p> Source code in <code>oodeel/datasets/torch_data_handler.py</code> <pre><code>@classmethod\ndef load_dataset(\n    cls,\n    dataset_id: Union[Dataset, ItemType, str],\n    keys: Optional[list] = None,\n    load_kwargs: dict = {},\n) -&gt; DictDataset:\n\"\"\"Load dataset from different manners\n\n    Args:\n        dataset_id (Union[Dataset, ItemType, str]): dataset identification\n        keys (list, optional): Features keys. If None, assigned as \"input_i\"\n            for i-th feature. Defaults to None.\n        load_kwargs (dict, optional): Additional loading kwargs. Defaults to {}.\n\n    Returns:\n        DictDataset: dataset\n    \"\"\"\n    if isinstance(dataset_id, str):\n        assert \"root\" in load_kwargs.keys()\n        dataset = cls.load_from_torchvision(dataset_id, **load_kwargs)\n    elif isinstance(dataset_id, Dataset):\n        dataset = cls.load_custom_dataset(dataset_id, keys)\n    elif isinstance(dataset_id, get_args(ItemType)):\n        dataset = cls.load_dataset_from_arrays(dataset_id, keys)\n    return dataset\n</code></pre>"},{"location":"api/datahandlers/#oodeel.datasets.torch_data_handler.TorchDataHandler.load_dataset_from_arrays","title":"<code>load_dataset_from_arrays(dataset_id, keys=None)</code>  <code>staticmethod</code>","text":"<p>Load a torch.utils.data.Dataset from an array or a tuple/dict of arrays.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>ItemType</code> <p>numpy / torch array(s) to load.</p> required <code>keys</code> <code>list</code> <p>Features keys. If None, assigned as \"input_i\" for i-th feature. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>DictDataset</code> <code>DictDataset</code> <p>dataset</p> Source code in <code>oodeel/datasets/torch_data_handler.py</code> <pre><code>@staticmethod\ndef load_dataset_from_arrays(\n    dataset_id: ItemType,\n    keys: Optional[list] = None,\n) -&gt; DictDataset:\n\"\"\"Load a torch.utils.data.Dataset from an array or a tuple/dict of arrays.\n\n    Args:\n        dataset_id (ItemType):\n            numpy / torch array(s) to load.\n        keys (list, optional): Features keys. If None, assigned as \"input_i\"\n            for i-th feature. Defaults to None.\n\n    Returns:\n        DictDataset: dataset\n    \"\"\"\n    # If dataset_id is an array\n    if isinstance(dataset_id, get_args(TensorType)):\n        tensors = tuple(to_torch(dataset_id))\n        output_keys = keys or [\"input\"]\n\n    # If dataset_id is a tuple of arrays\n    elif isinstance(dataset_id, tuple):\n        len_elem = len(dataset_id)\n        output_keys = keys\n        if output_keys is None:\n            if len_elem == 2:\n                output_keys = [\"input\", \"label\"]\n            else:\n                output_keys = [f\"input_{i}\" for i in range(len_elem - 1)] + [\n                    \"label\"\n                ]\n                print(\n                    \"Loading torch.utils.data.Dataset with elems as dicts, \"\n                    'assigning \"input_i\" key to the i-th tuple dimension and'\n                    ' \"label\" key to the last tuple dimension.'\n                )\n        assert len(output_keys) == len(dataset_id)\n        tensors = tuple(to_torch(array) for array in dataset_id)\n\n    # If dataset_id is a dictionary of arrays\n    elif isinstance(dataset_id, dict):\n        output_keys = keys or list(dataset_id.keys())\n        assert len(output_keys) == len(dataset_id)\n        tensors = tuple(to_torch(array) for array in dataset_id.values())\n\n    # create torch dictionary dataset from tensors tuple and keys\n    dataset = DictDataset(TensorDataset(*tensors), output_keys)\n    return dataset\n</code></pre>"},{"location":"api/datahandlers/#oodeel.datasets.torch_data_handler.TorchDataHandler.load_from_torchvision","title":"<code>load_from_torchvision(dataset_id, root, transform=DEFAULT_TRANSFORM, target_transform=DEFAULT_TARGET_TRANSFORM, download=False, **load_kwargs)</code>  <code>classmethod</code>","text":"<p>Load a Dataset from the torchvision datasets catalog</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>str</code> <p>Identifier of the dataset</p> required <code>root</code> <code>str</code> <p>Root directory of dataset</p> required <code>transform</code> <code>Callable</code> <p>Transform function to apply to the input. Defaults to DEFAULT_TRANSFORM.</p> <code>DEFAULT_TRANSFORM</code> <code>target_transform</code> <code>Callable</code> <p>Transform function to apply to the target. Defaults to DEFAULT_TARGET_TRANSFORM.</p> <code>DEFAULT_TARGET_TRANSFORM</code> <code>download</code> <code>bool</code> <p>If true, downloads the dataset from the internet and puts it in root directory. If dataset is already downloaded, it is not downloaded again. Defaults to False.</p> <code>False</code> <code>load_kwargs</code> <code>dict</code> <p>Loading kwargs to add to the initialization of dataset.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>DictDataset</code> <code>DictDataset</code> <p>dataset</p> Source code in <code>oodeel/datasets/torch_data_handler.py</code> <pre><code>@classmethod\ndef load_from_torchvision(\n    cls,\n    dataset_id: str,\n    root: str,\n    transform: Callable = DEFAULT_TRANSFORM,\n    target_transform: Callable = DEFAULT_TARGET_TRANSFORM,\n    download: bool = False,\n    **load_kwargs,\n) -&gt; DictDataset:\n\"\"\"Load a Dataset from the torchvision datasets catalog\n\n    Args:\n        dataset_id (str): Identifier of the dataset\n        root (str): Root directory of dataset\n        transform (Callable, optional): Transform function to apply to the input.\n            Defaults to DEFAULT_TRANSFORM.\n        target_transform (Callable, optional): Transform function to apply\n            to the target. Defaults to DEFAULT_TARGET_TRANSFORM.\n        download (bool):  If true, downloads the dataset from the internet and puts\n            it in root directory. If dataset is already downloaded, it is not\n            downloaded again. Defaults to False.\n        load_kwargs (dict): Loading kwargs to add to the initialization\n            of dataset.\n\n    Returns:\n        DictDataset: dataset\n    \"\"\"\n    assert (\n        dataset_id in torchvision.datasets.__all__\n    ), \"Dataset not available on torchvision datasets catalog\"\n    dataset = getattr(torchvision.datasets, dataset_id)(\n        root=root,\n        download=download,\n        transform=transform,\n        target_transform=target_transform,\n        **load_kwargs,\n    )\n    return cls.load_custom_dataset(dataset)\n</code></pre>"},{"location":"api/datahandlers/#oodeel.datasets.torch_data_handler.TorchDataHandler.map_ds","title":"<code>map_ds(dataset, map_fn)</code>  <code>staticmethod</code>","text":"<p>Map a function to a DictDataset</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>DictDataset</code> <p>Dataset to map the function to</p> required <code>map_fn</code> <code>Callable</code> <p>Function to map</p> required <p>Returns:</p> Name Type Description <code>DictDataset</code> <code>DictDataset</code> <p>Mapped dataset</p> Source code in <code>oodeel/datasets/torch_data_handler.py</code> <pre><code>@staticmethod\ndef map_ds(\n    dataset: DictDataset,\n    map_fn: Callable,\n) -&gt; DictDataset:\n\"\"\"Map a function to a DictDataset\n\n    Args:\n        dataset (DictDataset): Dataset to map the function to\n        map_fn (Callable): Function to map\n\n    Returns:\n        DictDataset: Mapped dataset\n    \"\"\"\n    return dataset.map(map_fn)\n</code></pre>"},{"location":"api/datahandlers/#oodeel.datasets.torch_data_handler.TorchDataHandler.merge","title":"<code>merge(id_dataset, ood_dataset, resize=False, shape=None)</code>  <code>staticmethod</code>","text":"<p>Merge two instances of DictDataset</p> <p>Parameters:</p> Name Type Description Default <code>id_dataset</code> <code>DictDataset</code> <p>dataset of in-distribution data</p> required <code>ood_dataset</code> <code>DictDataset</code> <p>dataset of out-of-distribution data</p> required <code>resize</code> <code>Optional[bool]</code> <p>toggles if input tensors of the datasets have to be resized to have the same shape. Defaults to True.</p> <code>False</code> <code>shape</code> <code>Optional[Tuple[int]]</code> <p>shape to use for resizing input tensors. If None, the tensors are resized with the shape of the id_dataset input tensors. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>DictDataset</code> <code>DictDataset</code> <p>merged dataset</p> Source code in <code>oodeel/datasets/torch_data_handler.py</code> <pre><code>@staticmethod\ndef merge(\n    id_dataset: DictDataset,\n    ood_dataset: DictDataset,\n    resize: Optional[bool] = False,\n    shape: Optional[Tuple[int]] = None,\n) -&gt; DictDataset:\n\"\"\"Merge two instances of DictDataset\n\n    Args:\n        id_dataset (DictDataset): dataset of in-distribution data\n        ood_dataset (DictDataset): dataset of out-of-distribution data\n        resize (Optional[bool], optional): toggles if input tensors of the\n            datasets have to be resized to have the same shape. Defaults to True.\n        shape (Optional[Tuple[int]], optional): shape to use for resizing input\n            tensors. If None, the tensors are resized with the shape of the\n            id_dataset input tensors. Defaults to None.\n\n    Returns:\n        DictDataset: merged dataset\n    \"\"\"\n    # If a desired shape is given, triggers the resize\n    if shape is not None:\n        resize = True\n\n    # If the shape of the two datasets are different, triggers the resize\n    if id_dataset.output_shapes[0] != ood_dataset.output_shapes[0]:\n        resize = True\n        if shape is None:\n            print(\n                \"Resizing the first item of elem (usually the image)\",\n                \" with the shape of id_dataset\",\n            )\n            shape = id_dataset.output_shapes[0][1:]\n\n    if resize:\n        resize_fn = torchvision.transforms.Resize(shape)\n\n        def reshape_fn(item_dict):\n            item_dict[\"input\"] = resize_fn(item_dict[\"input\"])\n            return item_dict\n\n        id_dataset = id_dataset.map(reshape_fn)\n        ood_dataset = ood_dataset.map(reshape_fn)\n\n    merged_dataset = id_dataset.concatenate(ood_dataset)\n    return merged_dataset\n</code></pre>"},{"location":"api/datahandlers/#oodeel.datasets.torch_data_handler.TorchDataHandler.prepare_for_training","title":"<code>prepare_for_training(dataset, batch_size, shuffle=False, preprocess_fn=None, augment_fn=None, output_keys=None, dict_based_fns=False, shuffle_buffer_size=None, num_workers=8)</code>  <code>classmethod</code>","text":"<p>Prepare a DataLoader for training</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>DictDataset</code> <p>Dataset to prepare</p> required <code>batch_size</code> <code>int</code> <p>Batch size</p> required <code>shuffle</code> <code>bool</code> <p>Wether to shuffle the dataloader or not</p> <code>False</code> <code>preprocess_fn</code> <code>Callable</code> <p>Preprocessing function to apply to the dataset. Defaults to None.</p> <code>None</code> <code>augment_fn</code> <code>Callable</code> <p>Augment function to be used (when the returned dataset is to be used for training). Defaults to None.</p> <code>None</code> <code>output_keys</code> <code>list</code> <p>List of keys corresponding to the features that will be returned. Keep all features if None. Defaults to None.</p> <code>None</code> <code>dict_based_fns</code> <code>bool</code> <p>Whether to use preprocess and DA functions as dict based (if True) or as tuple based (if False). Defaults to False.</p> <code>False</code> <code>shuffle_buffer_size</code> <code>int</code> <p>Size of the shuffle buffer. Not used in torch because we only rely on Map-Style datasets. Still as argument for API consistency. Defaults to None.</p> <code>None</code> <code>num_workers</code> <code>int</code> <p>Number of workers to use for the dataloader.</p> <code>8</code> <p>Returns:</p> Name Type Description <code>DataLoader</code> <code>DataLoader</code> <p>dataloader</p> Source code in <code>oodeel/datasets/torch_data_handler.py</code> <pre><code>@classmethod\ndef prepare_for_training(\n    cls,\n    dataset: DictDataset,\n    batch_size: int,\n    shuffle: bool = False,\n    preprocess_fn: Optional[Callable] = None,\n    augment_fn: Optional[Callable] = None,\n    output_keys: Optional[list] = None,\n    dict_based_fns: bool = False,\n    shuffle_buffer_size: Optional[int] = None,\n    num_workers: int = 8,\n) -&gt; DataLoader:\n\"\"\"Prepare a DataLoader for training\n\n    Args:\n        dataset (DictDataset): Dataset to prepare\n        batch_size (int): Batch size\n        shuffle (bool): Wether to shuffle the dataloader or not\n        preprocess_fn (Callable, optional): Preprocessing function to apply to\n            the dataset. Defaults to None.\n        augment_fn (Callable, optional): Augment function to be used (when the\n            returned dataset is to be used for training). Defaults to None.\n        output_keys (list): List of keys corresponding to the features that will be\n            returned. Keep all features if None. Defaults to None.\n        dict_based_fns (bool): Whether to use preprocess and DA functions as dict\n            based (if True) or as tuple based (if False). Defaults to False.\n        shuffle_buffer_size (int, optional): Size of the shuffle buffer. Not used\n            in torch because we only rely on Map-Style datasets. Still as argument\n            for API consistency. Defaults to None.\n        num_workers (int, optional): Number of workers to use for the dataloader.\n\n    Returns:\n        DataLoader: dataloader\n    \"\"\"\n    output_keys = output_keys or cls.get_ds_feature_keys(dataset)\n\n    def collate_fn(batch: List[dict]):\n        if dict_based_fns:\n            # preprocess + DA: List[dict] -&gt; List[dict]\n            preprocess_func = preprocess_fn or (lambda x: x)\n            augment_func = augment_fn or (lambda x: x)\n            batch = [augment_func(preprocess_func(d)) for d in batch]\n            # to tuple of batchs\n            return tuple(\n                default_collate([d[key] for d in batch]) for key in output_keys\n            )\n        else:\n            # preprocess + DA: List[dict] -&gt; List[tuple]\n            preprocess_func = preprocess_fn or (lambda *x: x)\n            augment_func = augment_fn or (lambda *x: x)\n            batch = [\n                augment_func(\n                    *preprocess_func(*tuple(d[key] for key in output_keys))\n                )\n                for d in batch\n            ]\n            # to tuple of batchs\n            return default_collate(batch)\n\n    loader = DataLoader(\n        dataset,\n        batch_size=batch_size,\n        shuffle=shuffle,\n        collate_fn=collate_fn,\n        num_workers=num_workers,\n    )\n    return loader\n</code></pre>"},{"location":"api/datahandlers/#oodeel.datasets.torch_data_handler.dict_only_ds","title":"<code>dict_only_ds(ds_handling_method)</code>","text":"<p>Decorator to ensure that the dataset is a dict dataset and that the input key matches one of the feature keys. The signature of decorated functions must be function(dataset, args, *kwargs) with feature_key either in kwargs or args[0] when relevant.</p> <p>Parameters:</p> Name Type Description Default <code>ds_handling_method</code> <code>Callable</code> <p>method to decorate</p> required <p>Returns:</p> Type Description <code>Callable</code> <p>decorated method</p> Source code in <code>oodeel/datasets/torch_data_handler.py</code> <pre><code>def dict_only_ds(ds_handling_method: Callable) -&gt; Callable:\n\"\"\"Decorator to ensure that the dataset is a dict dataset and that the input key\n    matches one of the feature keys. The signature of decorated functions\n    must be function(dataset, *args, **kwargs) with feature_key either in kwargs or\n    args[0] when relevant.\n\n\n    Args:\n        ds_handling_method: method to decorate\n\n    Returns:\n        decorated method\n    \"\"\"\n\n    def wrapper(dataset: Dataset, *args, **kwargs):\n        assert isinstance(\n            dataset, DictDataset\n        ), \"Dataset must be an instance of DictDataset\"\n\n        if \"feature_key\" in kwargs:\n            feature_key = kwargs[\"feature_key\"]\n        elif len(args) &gt; 0:\n            feature_key = args[0]\n\n        # If feature_key is provided, check that it is in the dataset feature keys\n        if (len(args) &gt; 0) or (\"feature_key\" in kwargs):\n            if isinstance(feature_key, str):\n                feature_key = [feature_key]\n            for key in feature_key:\n                assert (\n                    key in dataset.output_keys\n                ), f\"The input dataset has no feature names {key}\"\n        return ds_handling_method(dataset, *args, **kwargs)\n\n    return wrapper\n</code></pre>"},{"location":"api/datahandlers/#oodeel.datasets.torch_data_handler.to_torch","title":"<code>to_torch(array)</code>","text":"<p>Convert an array into a torch Tensor</p> <p>Parameters:</p> Name Type Description Default <code>array</code> <code>TensorType</code> <p>array to convert</p> required <p>Returns:</p> Type Description <code>torch.Tensor</code> <p>torch.Tensor: converted array</p> Source code in <code>oodeel/datasets/torch_data_handler.py</code> <pre><code>def to_torch(array: TensorType) -&gt; torch.Tensor:\n\"\"\"Convert an array into a torch Tensor\n\n    Args:\n        array (TensorType): array to convert\n\n    Returns:\n        torch.Tensor: converted array\n    \"\"\"\n    if isinstance(array, np.ndarray):\n        return torch.Tensor(array)\n    elif isinstance(array, torch.Tensor):\n        return array\n    else:\n        raise TypeError(\"Input array must be of numpy or torch type\")\n</code></pre>"},{"location":"api/keras_feature_extractor/","title":"KerasFeatureExtractor","text":""},{"location":"api/keras_feature_extractor/#oodeel.extractor.keras_feature_extractor.KerasFeatureExtractor","title":"<code>KerasFeatureExtractor</code>","text":"<p>         Bases: <code>FeatureExtractor</code></p> <p>Feature extractor based on \"model\" to construct a feature space on which OOD detection is performed. The features can be the output activation values of internal model layers, or the output of the model (softmax/logits).</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Callable</code> <p>model to extract the features from</p> required <code>feature_layers_id</code> <code>List[Union[int, str]]</code> <p>list of str or int that identify features to output. If int, the rank of the layer in the layer list If str, the name of the layer. Defaults to [].</p> <code>[-1]</code> <code>input_layer_id</code> <code>Optional[Union[int, str]]</code> <p>input layer of the feature extractor (to avoid useless forwards when working on the feature space without finetuning the bottom of the model). Defaults to None.</p> <code>None</code> <code>react_threshold</code> <code>Optional[float]</code> <p>if not None, penultimate layer activations are clipped under this threshold value (useful for ReAct). Defaults to None.</p> <code>None</code> <code>scale_percentile</code> <code>Optional[float]</code> <p>if not None, the features are scaled following the method of Xu et al., ICLR 2024. Defaults to None.</p> <code>None</code> <code>ash_percentile</code> <code>Optional[float]</code> <p>if not None, the features are scaled following the method of Djurisic et al., ICLR 2023.</p> <code>None</code> Source code in <code>oodeel/extractor/keras_feature_extractor.py</code> <pre><code>class KerasFeatureExtractor(FeatureExtractor):\n\"\"\"\n    Feature extractor based on \"model\" to construct a feature space\n    on which OOD detection is performed. The features can be the output\n    activation values of internal model layers, or the output of the model\n    (softmax/logits).\n\n    Args:\n        model: model to extract the features from\n        feature_layers_id: list of str or int that identify features to output.\n            If int, the rank of the layer in the layer list\n            If str, the name of the layer. Defaults to [].\n        input_layer_id: input layer of the feature extractor (to avoid useless forwards\n            when working on the feature space without finetuning the bottom of the\n            model).\n            Defaults to None.\n        react_threshold: if not None, penultimate layer activations are clipped under\n            this threshold value (useful for ReAct). Defaults to None.\n        scale_percentile: if not None, the features are scaled\n            following the method of Xu et al., ICLR 2024.\n            Defaults to None.\n        ash_percentile: if not None, the features are scaled following\n            the method of Djurisic et al., ICLR 2023.\n    \"\"\"\n\n    def __init__(\n        self,\n        model: Callable,\n        feature_layers_id: List[Union[int, str]] = [-1],\n        input_layer_id: Optional[Union[int, str]] = None,\n        react_threshold: Optional[float] = None,\n        scale_percentile: Optional[float] = None,\n        ash_percentile: Optional[float] = None,\n    ):\n        if input_layer_id is None:\n            input_layer_id = 0\n        super().__init__(\n            model=model,\n            feature_layers_id=feature_layers_id,\n            input_layer_id=input_layer_id,\n            react_threshold=react_threshold,\n            scale_percentile=scale_percentile,\n            ash_percentile=ash_percentile,\n        )\n\n        self.backend = \"tensorflow\"\n        self.model.layers[-1].activation = getattr(tf.keras.activations, \"linear\")\n        self._last_logits = None\n\n    @staticmethod\n    def find_layer(\n        model: Callable,\n        layer_id: Union[str, int],\n        index_offset: int = 0,\n        return_id: bool = False,\n    ) -&gt; Union[tf.keras.layers.Layer, Tuple[tf.keras.layers.Layer, str]]:\n\"\"\"Find a layer in a model either by his name or by his index.\n\n        Args:\n            model (Callable): model whose identified layer will be returned\n            layer_id (Union[str, int]): layer identifier\n            index_offset (int): index offset to find layers located before (negative\n                offset) or after (positive offset) the identified layer\n            return_id (bool): if True, the layer will be returned with its id\n\n        Raises:\n            ValueError: if the layer is not found\n\n        Returns:\n            Union[tf.keras.layers.Layer, Tuple[tf.keras.layers.Layer, str]]:\n                the corresponding layer and its id if return_id is True.\n        \"\"\"\n        if isinstance(layer_id, str):\n            layers_names = [layer.name for layer in model.layers]\n            layer_id = layers_names.index(layer_id)\n        if isinstance(layer_id, int):\n            layer_id += index_offset\n            layer = model.get_layer(index=layer_id)\n        else:\n            raise ValueError(f\"Could not find any layer {layer_id}.\")\n\n        if return_id:\n            return layer, layer_id\n        else:\n            return layer\n\n    # @tf.function\n    # TODO check with Thomas about @tf.function\n    def prepare_extractor(self) -&gt; tf.keras.models.Model:\n\"\"\"Constructs the feature extractor model\n\n        Returns:\n            tf.keras.models.Model: truncated model (extractor)\n        \"\"\"\n        input_layer = self.find_layer(self.model, self.input_layer_id)\n        new_input = tf.keras.layers.Input(tensor=input_layer.input)\n        output_tensors = [\n            self.find_layer(self.model, id).output for id in self.feature_layers_id\n        ]\n\n        # === If react method, clip activations from penultimate layer ===\n        if self.react_threshold is not None:\n            penultimate_layer = self.find_layer(self.model, -2)\n            penult_extractor = tf.keras.models.Model(\n                new_input, penultimate_layer.output\n            )\n            last_layer = self.find_layer(self.model, -1)\n\n            # clip penultimate activations\n            x = tf.clip_by_value(\n                penult_extractor(new_input),\n                clip_value_min=tf.float32.min,\n                clip_value_max=self.react_threshold,\n            )\n            # apply ultimate layer on clipped activations\n            output_tensors.append(last_layer(x))\n\n        # === If SCALE method, scale activations from penultimate layer ===\n        # === If ASH method, scale and prune activations from penultimate layer ===\n        elif (self.scale_percentile is not None) or (self.ash_percentile is not None):\n            penultimate_layer = self.find_layer(self.model, -2)\n            penult_extractor = tf.keras.models.Model(\n                new_input, penultimate_layer.output\n            )\n            last_layer = self.find_layer(self.model, -1)\n\n            # apply scaling on penultimate activations\n            penultimate = penult_extractor(new_input)\n            if self.scale_percentile is not None:\n                output_percentile = tfp.stats.percentile(\n                    penultimate, 100 * self.scale_percentile, axis=1\n                )\n            else:\n                output_percentile = tfp.stats.percentile(\n                    penultimate, 100 * self.ash_percentile, axis=1\n                )\n\n            mask = penultimate &gt; tf.reshape(output_percentile, (-1, 1))\n            filtered_penultimate = tf.where(\n                mask, penultimate, tf.zeros_like(penultimate)\n            )\n            s = tf.math.exp(\n                tf.reduce_sum(penultimate, axis=1)\n                / tf.reduce_sum(filtered_penultimate, axis=1)\n            )\n\n            if self.scale_percentile is not None:\n                x = penultimate * tf.expand_dims(s, 1)\n            else:\n                x = filtered_penultimate * tf.expand_dims(s, 1)\n            # apply ultimate layer on scaled activations\n            output_tensors.append(last_layer(x))\n\n        else:\n            output_tensors.append(self.find_layer(self.model, -1).output)\n\n        extractor = tf.keras.models.Model(new_input, output_tensors)\n        return extractor\n\n    @sanitize_input\n    def predict_tensor(\n        self,\n        tensor: TensorType,\n        postproc_fns: Optional[List[Callable]] = None,\n    ) -&gt; Tuple[List[tf.Tensor], tf.Tensor]:\n\"\"\"Get the projection of tensor in the feature space of self.model\n\n        Args:\n            tensor (TensorType): input tensor (or dataset elem)\n            postproc_fns (Optional[List[Callable]]): postprocessing function to apply to\n                each feature immediately after forward. Default to None.\n\n        Returns:\n            Tuple[List[tf.Tensor], tf.Tensor]: features, logits\n        \"\"\"\n        features = self.forward(tensor)\n\n        if type(features) is not list:\n            features = [features]\n\n        # split features and logits\n        logits = features.pop()\n\n        if postproc_fns is not None:\n            features = [\n                postproc_fn(feature)\n                for feature, postproc_fn in zip(features, postproc_fns)\n            ]\n\n        self._last_logits = logits\n        return features, logits\n\n    @tf.function\n    def forward(self, tensor: TensorType) -&gt; List[tf.Tensor]:\n        return self.extractor(tensor, training=False)\n\n    def predict(\n        self,\n        dataset: Union[ItemType, tf.data.Dataset],\n        postproc_fns: Optional[List[Callable]] = None,\n        verbose: bool = False,\n        **kwargs,\n    ) -&gt; Tuple[List[tf.Tensor], dict]:\n\"\"\"Get the projection of the dataset in the feature space of self.model\n\n        Args:\n            dataset (Union[ItemType, tf.data.Dataset]): input dataset\n            postproc_fns (Optional[Callable]): postprocessing function to apply to each\n                feature immediately after forward. Default to None.\n            verbose (bool): if True, display a progress bar. Defaults to False.\n            kwargs (dict): additional arguments not considered for prediction\n\n        Returns:\n            List[tf.Tensor], dict: features and extra information (logits, labels) as a\n                dictionary.\n        \"\"\"\n        labels = None\n\n        if isinstance(dataset, get_args(ItemType)):\n            tensor = TFDataHandler.get_input_from_dataset_item(dataset)\n            features, logits = self.predict_tensor(tensor, postproc_fns)\n\n            # Get labels if dataset is a tuple/list\n            if isinstance(dataset, (list, tuple)):\n                labels = TFDataHandler.get_label_from_dataset_item(dataset)\n\n        else:  # if dataset is a tf.data.Dataset\n            features = [None for i in range(len(self.feature_layers_id))]\n            logits = None\n            contains_labels = TFDataHandler.get_item_length(dataset) &gt; 1\n            for elem in tqdm(dataset, desc=\"Predicting\", disable=not verbose):\n                tensor = TFDataHandler.get_input_from_dataset_item(elem)\n                features_batch, logits_batch = self.predict_tensor(tensor, postproc_fns)\n\n                for i, f in enumerate(features_batch):\n                    features[i] = (\n                        f\n                        if features[i] is None\n                        else tf.concat([features[i], f], axis=0)\n                    )\n                # concatenate logits\n                logits = (\n                    logits_batch\n                    if logits is None\n                    else tf.concat([logits, logits_batch], axis=0)\n                )\n                # concatenate labels of current batch with previous batches\n                if contains_labels:\n                    lbl_batch = TFDataHandler.get_label_from_dataset_item(elem)\n\n                    if labels is None:\n                        labels = lbl_batch\n                    else:\n                        labels = tf.concat([labels, lbl_batch], axis=0)\n\n        # store extra information in a dict\n        info = dict(labels=labels, logits=logits)\n        return features, info\n\n    def get_weights(self, layer_id: Union[int, str]) -&gt; List[tf.Tensor]:\n\"\"\"Get the weights of a layer\n\n        Args:\n            layer_id (Union[int, str]): layer identifier\n\n        Returns:\n            List[tf.Tensor]: weights and biases matrixes\n        \"\"\"\n        return self.find_layer(self.model, layer_id).get_weights()\n</code></pre>"},{"location":"api/keras_feature_extractor/#oodeel.extractor.keras_feature_extractor.KerasFeatureExtractor.find_layer","title":"<code>find_layer(model, layer_id, index_offset=0, return_id=False)</code>  <code>staticmethod</code>","text":"<p>Find a layer in a model either by his name or by his index.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Callable</code> <p>model whose identified layer will be returned</p> required <code>layer_id</code> <code>Union[str, int]</code> <p>layer identifier</p> required <code>index_offset</code> <code>int</code> <p>index offset to find layers located before (negative offset) or after (positive offset) the identified layer</p> <code>0</code> <code>return_id</code> <code>bool</code> <p>if True, the layer will be returned with its id</p> <code>False</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>if the layer is not found</p> <p>Returns:</p> Type Description <code>Union[tf.keras.layers.Layer, Tuple[tf.keras.layers.Layer, str]]</code> <p>Union[tf.keras.layers.Layer, Tuple[tf.keras.layers.Layer, str]]: the corresponding layer and its id if return_id is True.</p> Source code in <code>oodeel/extractor/keras_feature_extractor.py</code> <pre><code>@staticmethod\ndef find_layer(\n    model: Callable,\n    layer_id: Union[str, int],\n    index_offset: int = 0,\n    return_id: bool = False,\n) -&gt; Union[tf.keras.layers.Layer, Tuple[tf.keras.layers.Layer, str]]:\n\"\"\"Find a layer in a model either by his name or by his index.\n\n    Args:\n        model (Callable): model whose identified layer will be returned\n        layer_id (Union[str, int]): layer identifier\n        index_offset (int): index offset to find layers located before (negative\n            offset) or after (positive offset) the identified layer\n        return_id (bool): if True, the layer will be returned with its id\n\n    Raises:\n        ValueError: if the layer is not found\n\n    Returns:\n        Union[tf.keras.layers.Layer, Tuple[tf.keras.layers.Layer, str]]:\n            the corresponding layer and its id if return_id is True.\n    \"\"\"\n    if isinstance(layer_id, str):\n        layers_names = [layer.name for layer in model.layers]\n        layer_id = layers_names.index(layer_id)\n    if isinstance(layer_id, int):\n        layer_id += index_offset\n        layer = model.get_layer(index=layer_id)\n    else:\n        raise ValueError(f\"Could not find any layer {layer_id}.\")\n\n    if return_id:\n        return layer, layer_id\n    else:\n        return layer\n</code></pre>"},{"location":"api/keras_feature_extractor/#oodeel.extractor.keras_feature_extractor.KerasFeatureExtractor.get_weights","title":"<code>get_weights(layer_id)</code>","text":"<p>Get the weights of a layer</p> <p>Parameters:</p> Name Type Description Default <code>layer_id</code> <code>Union[int, str]</code> <p>layer identifier</p> required <p>Returns:</p> Type Description <code>List[tf.Tensor]</code> <p>List[tf.Tensor]: weights and biases matrixes</p> Source code in <code>oodeel/extractor/keras_feature_extractor.py</code> <pre><code>def get_weights(self, layer_id: Union[int, str]) -&gt; List[tf.Tensor]:\n\"\"\"Get the weights of a layer\n\n    Args:\n        layer_id (Union[int, str]): layer identifier\n\n    Returns:\n        List[tf.Tensor]: weights and biases matrixes\n    \"\"\"\n    return self.find_layer(self.model, layer_id).get_weights()\n</code></pre>"},{"location":"api/keras_feature_extractor/#oodeel.extractor.keras_feature_extractor.KerasFeatureExtractor.predict","title":"<code>predict(dataset, postproc_fns=None, verbose=False, **kwargs)</code>","text":"<p>Get the projection of the dataset in the feature space of self.model</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>Union[ItemType, tf.data.Dataset]</code> <p>input dataset</p> required <code>postproc_fns</code> <code>Optional[Callable]</code> <p>postprocessing function to apply to each feature immediately after forward. Default to None.</p> <code>None</code> <code>verbose</code> <code>bool</code> <p>if True, display a progress bar. Defaults to False.</p> <code>False</code> <code>kwargs</code> <code>dict</code> <p>additional arguments not considered for prediction</p> <code>{}</code> <p>Returns:</p> Type Description <code>Tuple[List[tf.Tensor], dict]</code> <p>List[tf.Tensor], dict: features and extra information (logits, labels) as a dictionary.</p> Source code in <code>oodeel/extractor/keras_feature_extractor.py</code> <pre><code>def predict(\n    self,\n    dataset: Union[ItemType, tf.data.Dataset],\n    postproc_fns: Optional[List[Callable]] = None,\n    verbose: bool = False,\n    **kwargs,\n) -&gt; Tuple[List[tf.Tensor], dict]:\n\"\"\"Get the projection of the dataset in the feature space of self.model\n\n    Args:\n        dataset (Union[ItemType, tf.data.Dataset]): input dataset\n        postproc_fns (Optional[Callable]): postprocessing function to apply to each\n            feature immediately after forward. Default to None.\n        verbose (bool): if True, display a progress bar. Defaults to False.\n        kwargs (dict): additional arguments not considered for prediction\n\n    Returns:\n        List[tf.Tensor], dict: features and extra information (logits, labels) as a\n            dictionary.\n    \"\"\"\n    labels = None\n\n    if isinstance(dataset, get_args(ItemType)):\n        tensor = TFDataHandler.get_input_from_dataset_item(dataset)\n        features, logits = self.predict_tensor(tensor, postproc_fns)\n\n        # Get labels if dataset is a tuple/list\n        if isinstance(dataset, (list, tuple)):\n            labels = TFDataHandler.get_label_from_dataset_item(dataset)\n\n    else:  # if dataset is a tf.data.Dataset\n        features = [None for i in range(len(self.feature_layers_id))]\n        logits = None\n        contains_labels = TFDataHandler.get_item_length(dataset) &gt; 1\n        for elem in tqdm(dataset, desc=\"Predicting\", disable=not verbose):\n            tensor = TFDataHandler.get_input_from_dataset_item(elem)\n            features_batch, logits_batch = self.predict_tensor(tensor, postproc_fns)\n\n            for i, f in enumerate(features_batch):\n                features[i] = (\n                    f\n                    if features[i] is None\n                    else tf.concat([features[i], f], axis=0)\n                )\n            # concatenate logits\n            logits = (\n                logits_batch\n                if logits is None\n                else tf.concat([logits, logits_batch], axis=0)\n            )\n            # concatenate labels of current batch with previous batches\n            if contains_labels:\n                lbl_batch = TFDataHandler.get_label_from_dataset_item(elem)\n\n                if labels is None:\n                    labels = lbl_batch\n                else:\n                    labels = tf.concat([labels, lbl_batch], axis=0)\n\n    # store extra information in a dict\n    info = dict(labels=labels, logits=logits)\n    return features, info\n</code></pre>"},{"location":"api/keras_feature_extractor/#oodeel.extractor.keras_feature_extractor.KerasFeatureExtractor.predict_tensor","title":"<code>predict_tensor(tensor, postproc_fns=None)</code>","text":"<p>Get the projection of tensor in the feature space of self.model</p> <p>Parameters:</p> Name Type Description Default <code>tensor</code> <code>TensorType</code> <p>input tensor (or dataset elem)</p> required <code>postproc_fns</code> <code>Optional[List[Callable]]</code> <p>postprocessing function to apply to each feature immediately after forward. Default to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tuple[List[tf.Tensor], tf.Tensor]</code> <p>Tuple[List[tf.Tensor], tf.Tensor]: features, logits</p> Source code in <code>oodeel/extractor/keras_feature_extractor.py</code> <pre><code>@sanitize_input\ndef predict_tensor(\n    self,\n    tensor: TensorType,\n    postproc_fns: Optional[List[Callable]] = None,\n) -&gt; Tuple[List[tf.Tensor], tf.Tensor]:\n\"\"\"Get the projection of tensor in the feature space of self.model\n\n    Args:\n        tensor (TensorType): input tensor (or dataset elem)\n        postproc_fns (Optional[List[Callable]]): postprocessing function to apply to\n            each feature immediately after forward. Default to None.\n\n    Returns:\n        Tuple[List[tf.Tensor], tf.Tensor]: features, logits\n    \"\"\"\n    features = self.forward(tensor)\n\n    if type(features) is not list:\n        features = [features]\n\n    # split features and logits\n    logits = features.pop()\n\n    if postproc_fns is not None:\n        features = [\n            postproc_fn(feature)\n            for feature, postproc_fn in zip(features, postproc_fns)\n        ]\n\n    self._last_logits = logits\n    return features, logits\n</code></pre>"},{"location":"api/keras_feature_extractor/#oodeel.extractor.keras_feature_extractor.KerasFeatureExtractor.prepare_extractor","title":"<code>prepare_extractor()</code>","text":"<p>Constructs the feature extractor model</p> <p>Returns:</p> Type Description <code>tf.keras.models.Model</code> <p>tf.keras.models.Model: truncated model (extractor)</p> Source code in <code>oodeel/extractor/keras_feature_extractor.py</code> <pre><code>def prepare_extractor(self) -&gt; tf.keras.models.Model:\n\"\"\"Constructs the feature extractor model\n\n    Returns:\n        tf.keras.models.Model: truncated model (extractor)\n    \"\"\"\n    input_layer = self.find_layer(self.model, self.input_layer_id)\n    new_input = tf.keras.layers.Input(tensor=input_layer.input)\n    output_tensors = [\n        self.find_layer(self.model, id).output for id in self.feature_layers_id\n    ]\n\n    # === If react method, clip activations from penultimate layer ===\n    if self.react_threshold is not None:\n        penultimate_layer = self.find_layer(self.model, -2)\n        penult_extractor = tf.keras.models.Model(\n            new_input, penultimate_layer.output\n        )\n        last_layer = self.find_layer(self.model, -1)\n\n        # clip penultimate activations\n        x = tf.clip_by_value(\n            penult_extractor(new_input),\n            clip_value_min=tf.float32.min,\n            clip_value_max=self.react_threshold,\n        )\n        # apply ultimate layer on clipped activations\n        output_tensors.append(last_layer(x))\n\n    # === If SCALE method, scale activations from penultimate layer ===\n    # === If ASH method, scale and prune activations from penultimate layer ===\n    elif (self.scale_percentile is not None) or (self.ash_percentile is not None):\n        penultimate_layer = self.find_layer(self.model, -2)\n        penult_extractor = tf.keras.models.Model(\n            new_input, penultimate_layer.output\n        )\n        last_layer = self.find_layer(self.model, -1)\n\n        # apply scaling on penultimate activations\n        penultimate = penult_extractor(new_input)\n        if self.scale_percentile is not None:\n            output_percentile = tfp.stats.percentile(\n                penultimate, 100 * self.scale_percentile, axis=1\n            )\n        else:\n            output_percentile = tfp.stats.percentile(\n                penultimate, 100 * self.ash_percentile, axis=1\n            )\n\n        mask = penultimate &gt; tf.reshape(output_percentile, (-1, 1))\n        filtered_penultimate = tf.where(\n            mask, penultimate, tf.zeros_like(penultimate)\n        )\n        s = tf.math.exp(\n            tf.reduce_sum(penultimate, axis=1)\n            / tf.reduce_sum(filtered_penultimate, axis=1)\n        )\n\n        if self.scale_percentile is not None:\n            x = penultimate * tf.expand_dims(s, 1)\n        else:\n            x = filtered_penultimate * tf.expand_dims(s, 1)\n        # apply ultimate layer on scaled activations\n        output_tensors.append(last_layer(x))\n\n    else:\n        output_tensors.append(self.find_layer(self.model, -1).output)\n\n    extractor = tf.keras.models.Model(new_input, output_tensors)\n    return extractor\n</code></pre>"},{"location":"api/methods/","title":"OOD methods","text":""},{"location":"api/methods/#oodeel.methods.base.OODBaseDetector","title":"<code>OODBaseDetector</code>","text":"<p>         Bases: <code>ABC</code></p> <p>Base Class for methods that assign a score to unseen samples.</p> <p>Parameters:</p> Name Type Description Default <code>use_react</code> <code>bool</code> <p>if true, apply ReAct method by clipping penultimate activations under a threshold value.</p> <code>False</code> <code>react_quantile</code> <code>Optional[float]</code> <p>q value in the range [0, 1] used to compute the react clipping threshold defined as the q-th quantile penultimate layer activations. Defaults to 0.8.</p> <code>None</code> Source code in <code>oodeel/methods/base.py</code> <pre><code>class OODBaseDetector(ABC):\n\"\"\"Base Class for methods that assign a score to unseen samples.\n\n    Args:\n        use_react (bool): if true, apply ReAct method by clipping penultimate\n            activations under a threshold value.\n        react_quantile (Optional[float]): q value in the range [0, 1] used to compute\n            the react clipping threshold defined as the q-th quantile penultimate layer\n            activations. Defaults to 0.8.\n    \"\"\"\n\n    def __init__(\n        self,\n        use_react: Optional[bool] = False,\n        use_scale: Optional[bool] = False,\n        use_ash: Optional[bool] = False,\n        react_quantile: Optional[float] = None,\n        scale_percentile: Optional[float] = None,\n        ash_percentile: Optional[float] = None,\n        postproc_fns: Optional[List[Callable]] = None,\n    ):\n        self.feature_extractor: FeatureExtractor = None\n        self.use_react = use_react\n        self.use_scale = use_scale\n        self.use_ash = use_ash\n        self.react_quantile = react_quantile\n        self.scale_percentile = scale_percentile\n        self.ash_percentile = ash_percentile\n        self.react_threshold = None\n        self.postproc_fns = self._sanitize_posproc_fns(postproc_fns)\n\n        if use_scale and use_react:\n            raise ValueError(\"Cannot use both ReAct and scale at the same time\")\n        if use_scale and use_ash:\n            raise ValueError(\"Cannot use both ASH and scale at the same time\")\n        if use_ash and use_react:\n            raise ValueError(\"Cannot use both ReAct and ASH at the same time\")\n\n    @abstractmethod\n    def _score_tensor(self, inputs: TensorType) -&gt; np.ndarray:\n\"\"\"Computes an OOD score for input samples \"inputs\".\n\n        Method to override with child classes.\n\n        Args:\n            inputs (TensorType): tensor to score\n        Returns:\n            Tuple[TensorType]: OOD scores, predicted logits\n        \"\"\"\n        raise NotImplementedError()\n\n    def _sanitize_posproc_fns(\n        self,\n        postproc_fns: Union[List[Callable], None],\n    ) -&gt; List[Callable]:\n\"\"\"Sanitize postproc fns used at each layer output of the feature extractor.\n\n        Args:\n            postproc_fns (Optional[List[Callable]], optional): List of postproc\n                functions, one per output layer. Defaults to None.\n\n        Returns:\n            List[Callable]: Sanitized postproc_fns list\n        \"\"\"\n        if postproc_fns is not None:\n            assert len(postproc_fns) == len(\n                self.output_layers_id\n            ), \"len of postproc_fns and output_layers_id must match\"\n\n            def identity(x):\n                return x\n\n            postproc_fns = [identity if fn is None else fn for fn in postproc_fns]\n\n        return postproc_fns\n\n    def fit(\n        self,\n        model: Callable,\n        fit_dataset: Optional[Union[ItemType, DatasetType]] = None,\n        feature_layers_id: List[Union[int, str]] = [],\n        input_layer_id: Optional[Union[int, str]] = None,\n        verbose: bool = False,\n        **kwargs,\n    ) -&gt; None:\n\"\"\"Prepare the detector for scoring:\n        * Constructs the feature extractor based on the model\n        * Calibrates the detector on ID data \"fit_dataset\" if needed,\n            using self._fit_to_dataset\n\n        Args:\n            model: model to extract the features from\n            fit_dataset: dataset to fit the detector on\n            feature_layers_id (List[int]): list of str or int that identify\n                features to output.\n                If int, the rank of the layer in the layer list\n                If str, the name of the layer. Defaults to [-1]\n            input_layer_id (List[int]): = list of str or int that identify the input\n                layer of the feature extractor.\n                If int, the rank of the layer in the layer list\n                If str, the name of the layer. Defaults to None.\n            verbose (bool): if True, display a progress bar. Defaults to False.\n        \"\"\"\n        (\n            self.backend,\n            self.data_handler,\n            self.op,\n            self.FeatureExtractorClass,\n        ) = import_backend_specific_stuff(model)\n\n        # if required by the method, check that fit_dataset is not None\n        if self.requires_to_fit_dataset and fit_dataset is None:\n            raise ValueError(\n                \"`fit_dataset` argument must be provided for this OOD detector\"\n            )\n\n        # react: compute threshold (activation percentiles)\n        if self.use_react:\n            if fit_dataset is None:\n                raise ValueError(\n                    \"if react quantile is not None, fit_dataset must be\"\n                    \" provided to compute react activation threshold\"\n                )\n            else:\n                self.compute_react_threshold(model, fit_dataset, verbose=verbose)\n\n        if (feature_layers_id == []) and (self.requires_internal_features):\n            raise ValueError(\n                \"Explicitly specify feature_layers_id=[layer0, layer1,...], \"\n                + \"where layer0, layer1,... are the names of the desired output \"\n                + \"layers of your model. These can be int or str (even though str\"\n                + \" is safer). To know what to put, have a look at model.summary() \"\n                + \"with keras or model.named_modules() with pytorch\"\n            )\n\n        self.feature_extractor = self._load_feature_extractor(\n            model, feature_layers_id, input_layer_id\n        )\n\n        if fit_dataset is not None:\n            if \"verbose\" in inspect.signature(self._fit_to_dataset).parameters.keys():\n                kwargs.update({\"verbose\": verbose})\n            self._fit_to_dataset(fit_dataset, **kwargs)\n\n    def _load_feature_extractor(\n        self,\n        model: Callable,\n        feature_layers_id: List[Union[int, str]] = None,\n        input_layer_id: Optional[Union[int, str]] = None,\n    ) -&gt; Callable:\n\"\"\"\n        Loads feature extractor\n\n        Args:\n            model: a model (Keras or PyTorch) to load.\n            feature_layers_id (List[int]): list of str or int that identify\n                features to output.\n                If int, the rank of the layer in the layer list\n                If str, the name of the layer. Defaults to [-1]\n            input_layer_id (List[int]): = list of str or int that identify the input\n                layer of the feature extractor.\n                If int, the rank of the layer in the layer list\n                If str, the name of the layer. Defaults to None.\n\n        Returns:\n            FeatureExtractor: a feature extractor instance\n        \"\"\"\n        if not self.use_ash:\n            self.ash_percentile = None\n        if not self.use_scale:\n            self.scale_percentile = None\n\n        feature_extractor = self.FeatureExtractorClass(\n            model,\n            feature_layers_id=feature_layers_id,\n            input_layer_id=input_layer_id,\n            react_threshold=self.react_threshold,\n            scale_percentile=self.scale_percentile,\n            ash_percentile=self.ash_percentile,\n        )\n        return feature_extractor\n\n    def _fit_to_dataset(self, fit_dataset: DatasetType) -&gt; None:\n\"\"\"\n        Fits the OOD detector to fit_dataset.\n\n        To be overrided in child classes (if needed)\n\n        Args:\n            fit_dataset: dataset to fit the OOD detector on\n        \"\"\"\n        raise NotImplementedError()\n\n    def score(\n        self,\n        dataset: Union[ItemType, DatasetType],\n        verbose: bool = False,\n    ) -&gt; np.ndarray:\n\"\"\"\n        Computes an OOD score for input samples \"inputs\".\n\n        Args:\n            dataset (Union[ItemType, DatasetType]): dataset or tensors to score\n            verbose (bool): if True, display a progress bar. Defaults to False.\n\n        Returns:\n            tuple: scores or list of scores (depending on the input) and a dictionary\n                containing logits and labels.\n        \"\"\"\n        assert self.feature_extractor is not None, \"Call .fit() before .score()\"\n        labels = None\n        # Case 1: dataset is neither a tf.data.Dataset nor a torch.DataLoader\n        if isinstance(dataset, get_args(ItemType)):\n            tensor = self.data_handler.get_input_from_dataset_item(dataset)\n            scores = self._score_tensor(tensor)\n            logits = self.op.convert_to_numpy(self.feature_extractor._last_logits)\n\n            # Get labels if dataset is a tuple/list\n            if isinstance(dataset, (list, tuple)):\n                labels = self.data_handler.get_label_from_dataset_item(dataset)\n                labels = self.op.convert_to_numpy(labels)\n\n        # Case 2: dataset is a tf.data.Dataset or a torch.DataLoader\n        elif isinstance(dataset, get_args(DatasetType)):\n            scores = np.array([])\n            logits = None\n\n            for item in tqdm(dataset, desc=\"Scoring\", disable=not verbose):\n                tensor = self.data_handler.get_input_from_dataset_item(item)\n                score_batch = self._score_tensor(tensor)\n                logits_batch = self.op.convert_to_numpy(\n                    self.feature_extractor._last_logits\n                )\n\n                # get the label if available\n                if len(item) &gt; 1:\n                    labels_batch = self.data_handler.get_label_from_dataset_item(item)\n                    labels = (\n                        labels_batch\n                        if labels is None\n                        else np.append(labels, self.op.convert_to_numpy(labels_batch))\n                    )\n\n                scores = np.append(scores, score_batch)\n                logits = (\n                    logits_batch\n                    if logits is None\n                    else np.concatenate([logits, logits_batch], axis=0)\n                )\n\n        else:\n            raise NotImplementedError(\n                f\"OODBaseDetector.score() not implemented for {type(dataset)}\"\n            )\n\n        info = dict(labels=labels, logits=logits)\n        return scores, info\n\n    def compute_react_threshold(\n        self, model: Callable, fit_dataset: DatasetType, verbose: bool = False\n    ):\n        penult_feat_extractor = self._load_feature_extractor(model, [-2])\n        unclipped_features, _ = penult_feat_extractor.predict(\n            fit_dataset, verbose=verbose\n        )\n        self.react_threshold = self.op.quantile(\n            unclipped_features[0], self.react_quantile\n        )\n\n    def __call__(self, inputs: Union[ItemType, DatasetType]) -&gt; np.ndarray:\n\"\"\"\n        Convenience wrapper for score\n\n        Args:\n            inputs (Union[ItemType, DatasetType]): dataset or tensors to score.\n            threshold (float): threshold to use for distinguishing between OOD and ID\n\n        Returns:\n            np.ndarray: array of 0 for ID samples and 1 for OOD samples\n        \"\"\"\n        return self.score(inputs)\n\n    @property\n    def requires_to_fit_dataset(self) -&gt; bool:\n\"\"\"\n        Whether an OOD detector needs a `fit_dataset` argument in the fit function.\n\n        Returns:\n            bool: True if `fit_dataset` is required else False.\n        \"\"\"\n        raise NotImplementedError(\n            \"Property `requires_to_fit_dataset` is not implemented. It should return\"\n            + \" a True or False boolean.\"\n        )\n\n    @property\n    def requires_internal_features(self) -&gt; bool:\n\"\"\"\n        Whether an OOD detector acts on internal model features.\n\n        Returns:\n            bool: True if the detector perform computations on an intermediate layer\n            else False.\n        \"\"\"\n        raise NotImplementedError(\n            \"Property `requires_internal_dataset` is not implemented. It should return\"\n            + \" a True or False boolean.\"\n        )\n</code></pre>"},{"location":"api/methods/#oodeel.methods.base.OODBaseDetector.requires_internal_features","title":"<code>requires_internal_features: bool</code>  <code>property</code>","text":"<p>Whether an OOD detector acts on internal model features.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the detector perform computations on an intermediate layer</p> <code>bool</code> <p>else False.</p>"},{"location":"api/methods/#oodeel.methods.base.OODBaseDetector.requires_to_fit_dataset","title":"<code>requires_to_fit_dataset: bool</code>  <code>property</code>","text":"<p>Whether an OOD detector needs a <code>fit_dataset</code> argument in the fit function.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if <code>fit_dataset</code> is required else False.</p>"},{"location":"api/methods/#oodeel.methods.base.OODBaseDetector.__call__","title":"<code>__call__(inputs)</code>","text":"<p>Convenience wrapper for score</p> <p>Parameters:</p> Name Type Description Default <code>inputs</code> <code>Union[ItemType, DatasetType]</code> <p>dataset or tensors to score.</p> required <code>threshold</code> <code>float</code> <p>threshold to use for distinguishing between OOD and ID</p> required <p>Returns:</p> Type Description <code>np.ndarray</code> <p>np.ndarray: array of 0 for ID samples and 1 for OOD samples</p> Source code in <code>oodeel/methods/base.py</code> <pre><code>def __call__(self, inputs: Union[ItemType, DatasetType]) -&gt; np.ndarray:\n\"\"\"\n    Convenience wrapper for score\n\n    Args:\n        inputs (Union[ItemType, DatasetType]): dataset or tensors to score.\n        threshold (float): threshold to use for distinguishing between OOD and ID\n\n    Returns:\n        np.ndarray: array of 0 for ID samples and 1 for OOD samples\n    \"\"\"\n    return self.score(inputs)\n</code></pre>"},{"location":"api/methods/#oodeel.methods.base.OODBaseDetector.fit","title":"<code>fit(model, fit_dataset=None, feature_layers_id=[], input_layer_id=None, verbose=False, **kwargs)</code>","text":"<p>Prepare the detector for scoring: * Constructs the feature extractor based on the model * Calibrates the detector on ID data \"fit_dataset\" if needed,     using self._fit_to_dataset</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Callable</code> <p>model to extract the features from</p> required <code>fit_dataset</code> <code>Optional[Union[ItemType, DatasetType]]</code> <p>dataset to fit the detector on</p> <code>None</code> <code>feature_layers_id</code> <code>List[int]</code> <p>list of str or int that identify features to output. If int, the rank of the layer in the layer list If str, the name of the layer. Defaults to [-1]</p> <code>[]</code> <code>input_layer_id</code> <code>List[int]</code> <p>= list of str or int that identify the input layer of the feature extractor. If int, the rank of the layer in the layer list If str, the name of the layer. Defaults to None.</p> <code>None</code> <code>verbose</code> <code>bool</code> <p>if True, display a progress bar. Defaults to False.</p> <code>False</code> Source code in <code>oodeel/methods/base.py</code> <pre><code>def fit(\n    self,\n    model: Callable,\n    fit_dataset: Optional[Union[ItemType, DatasetType]] = None,\n    feature_layers_id: List[Union[int, str]] = [],\n    input_layer_id: Optional[Union[int, str]] = None,\n    verbose: bool = False,\n    **kwargs,\n) -&gt; None:\n\"\"\"Prepare the detector for scoring:\n    * Constructs the feature extractor based on the model\n    * Calibrates the detector on ID data \"fit_dataset\" if needed,\n        using self._fit_to_dataset\n\n    Args:\n        model: model to extract the features from\n        fit_dataset: dataset to fit the detector on\n        feature_layers_id (List[int]): list of str or int that identify\n            features to output.\n            If int, the rank of the layer in the layer list\n            If str, the name of the layer. Defaults to [-1]\n        input_layer_id (List[int]): = list of str or int that identify the input\n            layer of the feature extractor.\n            If int, the rank of the layer in the layer list\n            If str, the name of the layer. Defaults to None.\n        verbose (bool): if True, display a progress bar. Defaults to False.\n    \"\"\"\n    (\n        self.backend,\n        self.data_handler,\n        self.op,\n        self.FeatureExtractorClass,\n    ) = import_backend_specific_stuff(model)\n\n    # if required by the method, check that fit_dataset is not None\n    if self.requires_to_fit_dataset and fit_dataset is None:\n        raise ValueError(\n            \"`fit_dataset` argument must be provided for this OOD detector\"\n        )\n\n    # react: compute threshold (activation percentiles)\n    if self.use_react:\n        if fit_dataset is None:\n            raise ValueError(\n                \"if react quantile is not None, fit_dataset must be\"\n                \" provided to compute react activation threshold\"\n            )\n        else:\n            self.compute_react_threshold(model, fit_dataset, verbose=verbose)\n\n    if (feature_layers_id == []) and (self.requires_internal_features):\n        raise ValueError(\n            \"Explicitly specify feature_layers_id=[layer0, layer1,...], \"\n            + \"where layer0, layer1,... are the names of the desired output \"\n            + \"layers of your model. These can be int or str (even though str\"\n            + \" is safer). To know what to put, have a look at model.summary() \"\n            + \"with keras or model.named_modules() with pytorch\"\n        )\n\n    self.feature_extractor = self._load_feature_extractor(\n        model, feature_layers_id, input_layer_id\n    )\n\n    if fit_dataset is not None:\n        if \"verbose\" in inspect.signature(self._fit_to_dataset).parameters.keys():\n            kwargs.update({\"verbose\": verbose})\n        self._fit_to_dataset(fit_dataset, **kwargs)\n</code></pre>"},{"location":"api/methods/#oodeel.methods.base.OODBaseDetector.score","title":"<code>score(dataset, verbose=False)</code>","text":"<p>Computes an OOD score for input samples \"inputs\".</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>Union[ItemType, DatasetType]</code> <p>dataset or tensors to score</p> required <code>verbose</code> <code>bool</code> <p>if True, display a progress bar. Defaults to False.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>tuple</code> <code>np.ndarray</code> <p>scores or list of scores (depending on the input) and a dictionary containing logits and labels.</p> Source code in <code>oodeel/methods/base.py</code> <pre><code>def score(\n    self,\n    dataset: Union[ItemType, DatasetType],\n    verbose: bool = False,\n) -&gt; np.ndarray:\n\"\"\"\n    Computes an OOD score for input samples \"inputs\".\n\n    Args:\n        dataset (Union[ItemType, DatasetType]): dataset or tensors to score\n        verbose (bool): if True, display a progress bar. Defaults to False.\n\n    Returns:\n        tuple: scores or list of scores (depending on the input) and a dictionary\n            containing logits and labels.\n    \"\"\"\n    assert self.feature_extractor is not None, \"Call .fit() before .score()\"\n    labels = None\n    # Case 1: dataset is neither a tf.data.Dataset nor a torch.DataLoader\n    if isinstance(dataset, get_args(ItemType)):\n        tensor = self.data_handler.get_input_from_dataset_item(dataset)\n        scores = self._score_tensor(tensor)\n        logits = self.op.convert_to_numpy(self.feature_extractor._last_logits)\n\n        # Get labels if dataset is a tuple/list\n        if isinstance(dataset, (list, tuple)):\n            labels = self.data_handler.get_label_from_dataset_item(dataset)\n            labels = self.op.convert_to_numpy(labels)\n\n    # Case 2: dataset is a tf.data.Dataset or a torch.DataLoader\n    elif isinstance(dataset, get_args(DatasetType)):\n        scores = np.array([])\n        logits = None\n\n        for item in tqdm(dataset, desc=\"Scoring\", disable=not verbose):\n            tensor = self.data_handler.get_input_from_dataset_item(item)\n            score_batch = self._score_tensor(tensor)\n            logits_batch = self.op.convert_to_numpy(\n                self.feature_extractor._last_logits\n            )\n\n            # get the label if available\n            if len(item) &gt; 1:\n                labels_batch = self.data_handler.get_label_from_dataset_item(item)\n                labels = (\n                    labels_batch\n                    if labels is None\n                    else np.append(labels, self.op.convert_to_numpy(labels_batch))\n                )\n\n            scores = np.append(scores, score_batch)\n            logits = (\n                logits_batch\n                if logits is None\n                else np.concatenate([logits, logits_batch], axis=0)\n            )\n\n    else:\n        raise NotImplementedError(\n            f\"OODBaseDetector.score() not implemented for {type(dataset)}\"\n        )\n\n    info = dict(labels=labels, logits=logits)\n    return scores, info\n</code></pre>"},{"location":"api/methods/#oodeel.methods.DKNN","title":"<code>DKNN</code>","text":"<p>         Bases: <code>OODBaseDetector</code></p> <p>\"Out-of-Distribution Detection with Deep Nearest Neighbors\" https://arxiv.org/abs/2204.06507</p> <p>Parameters:</p> Name Type Description Default <code>nearest</code> <code>int</code> <p>number of nearest neighbors to consider. Defaults to 1.</p> <code>50</code> <code>use_gpu</code> <code>bool</code> <p>Flag to enable GPU acceleration for FAISS. Defaults to False.</p> <code>False</code> Source code in <code>oodeel/methods/dknn.py</code> <pre><code>class DKNN(OODBaseDetector):\n\"\"\"\n    \"Out-of-Distribution Detection with Deep Nearest Neighbors\"\n    https://arxiv.org/abs/2204.06507\n\n    Args:\n        nearest: number of nearest neighbors to consider.\n            Defaults to 1.\n        use_gpu (bool): Flag to enable GPU acceleration for FAISS. Defaults to False.\n    \"\"\"\n\n    def __init__(self, nearest: int = 50, use_gpu: bool = False):\n        super().__init__()\n        self.index = None\n        self.nearest = nearest\n        self.use_gpu = use_gpu\n\n        if self.use_gpu:\n            try:\n                self.res = faiss.StandardGpuResources()\n            except AttributeError as e:\n                raise ImportError(\n                    \"faiss-gpu is not installed, but use_gpu was set to True.\"\n                    + \"Please install faiss-gpu or set use_gpu to False.\"\n                ) from e\n\n    def _fit_to_dataset(self, fit_dataset: Union[TensorType, DatasetType]) -&gt; None:\n\"\"\"\n        Constructs the index from ID data \"fit_dataset\", which will be used for\n        nearest neighbor search. Can operate on CPU or GPU based on the `use_gpu` flag.\n\n        Args:\n            fit_dataset: input dataset (ID) to construct the index with.\n        \"\"\"\n        fit_projected, _ = self.feature_extractor.predict(fit_dataset)\n        fit_projected = self.op.convert_to_numpy(fit_projected[0])\n        fit_projected = fit_projected.reshape(fit_projected.shape[0], -1)\n        norm_fit_projected = self._l2_normalization(fit_projected)\n\n        if self.use_gpu:\n            cpu_index = faiss.IndexFlatL2(norm_fit_projected.shape[1])\n            self.index = faiss.index_cpu_to_gpu(self.res, 0, cpu_index)\n        else:\n            self.index = faiss.IndexFlatL2(norm_fit_projected.shape[1])\n\n        self.index.add(norm_fit_projected)\n\n    def _score_tensor(self, inputs: TensorType) -&gt; Tuple[np.ndarray]:\n\"\"\"\n        Computes an OOD score for input samples \"inputs\" based on\n        the distance to nearest neighbors in the feature space of self.model\n\n        Args:\n            inputs: input samples to score\n\n        Returns:\n            Tuple[np.ndarray]: scores, logits\n        \"\"\"\n\n        input_projected, _ = self.feature_extractor.predict_tensor(inputs)\n        input_projected = self.op.convert_to_numpy(input_projected[0])\n        input_projected = input_projected.reshape(input_projected.shape[0], -1)\n        norm_input_projected = self._l2_normalization(input_projected)\n        scores, _ = self.index.search(norm_input_projected, self.nearest)\n        return scores[:, -1]\n\n    def _l2_normalization(self, feat: np.ndarray) -&gt; np.ndarray:\n\"\"\"L2 normalization of a tensor along the last dimension.\n\n        Args:\n            feat (np.ndarray): the tensor to normalize\n\n        Returns:\n            np.ndarray: the normalized tensor\n        \"\"\"\n        return feat / (np.linalg.norm(feat, ord=2, axis=-1, keepdims=True) + 1e-10)\n\n    @property\n    def requires_to_fit_dataset(self) -&gt; bool:\n\"\"\"\n        Whether an OOD detector needs a `fit_dataset` argument in the fit function.\n\n        Returns:\n            bool: True if `fit_dataset` is required else False.\n        \"\"\"\n        return True\n\n    @property\n    def requires_internal_features(self) -&gt; bool:\n\"\"\"\n        Whether an OOD detector acts on internal model features.\n\n        Returns:\n            bool: True if the detector perform computations on an intermediate layer\n            else False.\n        \"\"\"\n        return True\n</code></pre>"},{"location":"api/methods/#oodeel.methods.dknn.DKNN.requires_internal_features","title":"<code>requires_internal_features: bool</code>  <code>property</code>","text":"<p>Whether an OOD detector acts on internal model features.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the detector perform computations on an intermediate layer</p> <code>bool</code> <p>else False.</p>"},{"location":"api/methods/#oodeel.methods.dknn.DKNN.requires_to_fit_dataset","title":"<code>requires_to_fit_dataset: bool</code>  <code>property</code>","text":"<p>Whether an OOD detector needs a <code>fit_dataset</code> argument in the fit function.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if <code>fit_dataset</code> is required else False.</p>"},{"location":"api/methods/#oodeel.methods.dknn.DKNN._fit_to_dataset","title":"<code>_fit_to_dataset(fit_dataset)</code>","text":"<p>Constructs the index from ID data \"fit_dataset\", which will be used for nearest neighbor search. Can operate on CPU or GPU based on the <code>use_gpu</code> flag.</p> <p>Parameters:</p> Name Type Description Default <code>fit_dataset</code> <code>Union[TensorType, DatasetType]</code> <p>input dataset (ID) to construct the index with.</p> required Source code in <code>oodeel/methods/dknn.py</code> <pre><code>def _fit_to_dataset(self, fit_dataset: Union[TensorType, DatasetType]) -&gt; None:\n\"\"\"\n    Constructs the index from ID data \"fit_dataset\", which will be used for\n    nearest neighbor search. Can operate on CPU or GPU based on the `use_gpu` flag.\n\n    Args:\n        fit_dataset: input dataset (ID) to construct the index with.\n    \"\"\"\n    fit_projected, _ = self.feature_extractor.predict(fit_dataset)\n    fit_projected = self.op.convert_to_numpy(fit_projected[0])\n    fit_projected = fit_projected.reshape(fit_projected.shape[0], -1)\n    norm_fit_projected = self._l2_normalization(fit_projected)\n\n    if self.use_gpu:\n        cpu_index = faiss.IndexFlatL2(norm_fit_projected.shape[1])\n        self.index = faiss.index_cpu_to_gpu(self.res, 0, cpu_index)\n    else:\n        self.index = faiss.IndexFlatL2(norm_fit_projected.shape[1])\n\n    self.index.add(norm_fit_projected)\n</code></pre>"},{"location":"api/methods/#oodeel.methods.dknn.DKNN._l2_normalization","title":"<code>_l2_normalization(feat)</code>","text":"<p>L2 normalization of a tensor along the last dimension.</p> <p>Parameters:</p> Name Type Description Default <code>feat</code> <code>np.ndarray</code> <p>the tensor to normalize</p> required <p>Returns:</p> Type Description <code>np.ndarray</code> <p>np.ndarray: the normalized tensor</p> Source code in <code>oodeel/methods/dknn.py</code> <pre><code>def _l2_normalization(self, feat: np.ndarray) -&gt; np.ndarray:\n\"\"\"L2 normalization of a tensor along the last dimension.\n\n    Args:\n        feat (np.ndarray): the tensor to normalize\n\n    Returns:\n        np.ndarray: the normalized tensor\n    \"\"\"\n    return feat / (np.linalg.norm(feat, ord=2, axis=-1, keepdims=True) + 1e-10)\n</code></pre>"},{"location":"api/methods/#oodeel.methods.dknn.DKNN._score_tensor","title":"<code>_score_tensor(inputs)</code>","text":"<p>Computes an OOD score for input samples \"inputs\" based on the distance to nearest neighbors in the feature space of self.model</p> <p>Parameters:</p> Name Type Description Default <code>inputs</code> <code>TensorType</code> <p>input samples to score</p> required <p>Returns:</p> Type Description <code>Tuple[np.ndarray]</code> <p>Tuple[np.ndarray]: scores, logits</p> Source code in <code>oodeel/methods/dknn.py</code> <pre><code>def _score_tensor(self, inputs: TensorType) -&gt; Tuple[np.ndarray]:\n\"\"\"\n    Computes an OOD score for input samples \"inputs\" based on\n    the distance to nearest neighbors in the feature space of self.model\n\n    Args:\n        inputs: input samples to score\n\n    Returns:\n        Tuple[np.ndarray]: scores, logits\n    \"\"\"\n\n    input_projected, _ = self.feature_extractor.predict_tensor(inputs)\n    input_projected = self.op.convert_to_numpy(input_projected[0])\n    input_projected = input_projected.reshape(input_projected.shape[0], -1)\n    norm_input_projected = self._l2_normalization(input_projected)\n    scores, _ = self.index.search(norm_input_projected, self.nearest)\n    return scores[:, -1]\n</code></pre>"},{"location":"api/methods/#oodeel.methods.Energy","title":"<code>Energy</code>","text":"<p>         Bases: <code>OODBaseDetector</code></p> <p>Energy Score method for OOD detection. \"Energy-based Out-of-distribution Detection\" https://arxiv.org/abs/2010.03759</p> <p>This method assumes that the model has been trained with cross entropy loss $CE(model(x))$ where $model(x)=(l_{c})_{c=1}^{C}$ are the logits predicted for input $x$. The implementation assumes that the logits are retreieved using the output with linear activation.</p> <p>The energy score for input $x$ is given by $$ -\\log \\sum_{c=0}^C \\exp(l_c)$$</p> <p>where $model(x)=(l_{c})_{c=1}^{C}$ are the logits predicted by the model on $x$. As always, training data is expected to have lower score than OOD data.</p> <p>Parameters:</p> Name Type Description Default <code>use_react</code> <code>bool</code> <p>if true, apply ReAct method by clipping penultimate activations under a threshold value.</p> <code>False</code> <code>react_quantile</code> <code>Optional[float]</code> <p>q value in the range [0, 1] used to compute the react clipping threshold defined as the q-th quantile penultimate layer activations. Defaults to 0.8.</p> <code>0.8</code> Source code in <code>oodeel/methods/energy.py</code> <pre><code>class Energy(OODBaseDetector):\nr\"\"\"\n    Energy Score method for OOD detection.\n    \"Energy-based Out-of-distribution Detection\"\n    https://arxiv.org/abs/2010.03759\n\n    This method assumes that the model has been trained with cross entropy loss\n    $CE(model(x))$ where $model(x)=(l_{c})_{c=1}^{C}$ are the logits\n    predicted for input $x$.\n    The implementation assumes that the logits are retreieved using the output with\n    linear activation.\n\n    The energy score for input $x$ is given by\n    $$ -\\log \\sum_{c=0}^C \\exp(l_c)$$\n\n    where $model(x)=(l_{c})_{c=1}^{C}$ are the logits predicted by the model on\n    $x$.\n    As always, training data is expected to have lower score than OOD data.\n\n    Args:\n        use_react (bool): if true, apply ReAct method by clipping penultimate\n            activations under a threshold value.\n        react_quantile (Optional[float]): q value in the range [0, 1] used to compute\n            the react clipping threshold defined as the q-th quantile penultimate layer\n            activations. Defaults to 0.8.\n    \"\"\"\n\n    def __init__(\n        self,\n        use_react: bool = False,\n        use_scale: bool = False,\n        use_ash: bool = False,\n        react_quantile: float = 0.8,\n        scale_percentile: float = 0.85,\n        ash_percentile: float = 0.90,\n    ):\n        super().__init__(\n            use_react=use_react,\n            use_scale=use_scale,\n            use_ash=use_ash,\n            react_quantile=react_quantile,\n            scale_percentile=scale_percentile,\n            ash_percentile=ash_percentile,\n        )\n\n    def _score_tensor(self, inputs: TensorType) -&gt; Tuple[np.ndarray]:\n\"\"\"\n        Computes an OOD score for input samples \"inputs\" based on\n        energy, namey $-logsumexp(logits(inputs))$.\n\n        Args:\n            inputs: input samples to score\n\n        Returns:\n            Tuple[np.ndarray]: scores, logits\n        \"\"\"\n        # compute logits (softmax(logits,axis=1) is the actual softmax\n        # output minimized using binary cross entropy)\n        _, logits = self.feature_extractor.predict_tensor(inputs)\n        logits = self.op.convert_to_numpy(logits)\n        scores = -logsumexp(logits, axis=1)\n        return scores\n\n    def _fit_to_dataset(self, fit_dataset: DatasetType) -&gt; None:\n\"\"\"\n        Fits the OOD detector to fit_dataset.\n\n        Args:\n            fit_dataset: dataset to fit the OOD detector on\n        \"\"\"\n        pass\n\n    @property\n    def requires_to_fit_dataset(self) -&gt; bool:\n\"\"\"\n        Whether an OOD detector needs a `fit_dataset` argument in the fit function.\n\n        Returns:\n            bool: True if `fit_dataset` is required else False.\n        \"\"\"\n        return False\n\n    @property\n    def requires_internal_features(self) -&gt; bool:\n\"\"\"\n        Whether an OOD detector acts on internal model features.\n\n        Returns:\n            bool: True if the detector perform computations on an intermediate layer\n            else False.\n        \"\"\"\n        return False\n</code></pre>"},{"location":"api/methods/#oodeel.methods.energy.Energy.requires_internal_features","title":"<code>requires_internal_features: bool</code>  <code>property</code>","text":"<p>Whether an OOD detector acts on internal model features.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the detector perform computations on an intermediate layer</p> <code>bool</code> <p>else False.</p>"},{"location":"api/methods/#oodeel.methods.energy.Energy.requires_to_fit_dataset","title":"<code>requires_to_fit_dataset: bool</code>  <code>property</code>","text":"<p>Whether an OOD detector needs a <code>fit_dataset</code> argument in the fit function.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if <code>fit_dataset</code> is required else False.</p>"},{"location":"api/methods/#oodeel.methods.energy.Energy._fit_to_dataset","title":"<code>_fit_to_dataset(fit_dataset)</code>","text":"<p>Fits the OOD detector to fit_dataset.</p> <p>Parameters:</p> Name Type Description Default <code>fit_dataset</code> <code>DatasetType</code> <p>dataset to fit the OOD detector on</p> required Source code in <code>oodeel/methods/energy.py</code> <pre><code>def _fit_to_dataset(self, fit_dataset: DatasetType) -&gt; None:\n\"\"\"\n    Fits the OOD detector to fit_dataset.\n\n    Args:\n        fit_dataset: dataset to fit the OOD detector on\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/methods/#oodeel.methods.energy.Energy._score_tensor","title":"<code>_score_tensor(inputs)</code>","text":"<p>Computes an OOD score for input samples \"inputs\" based on energy, namey $-logsumexp(logits(inputs))$.</p> <p>Parameters:</p> Name Type Description Default <code>inputs</code> <code>TensorType</code> <p>input samples to score</p> required <p>Returns:</p> Type Description <code>Tuple[np.ndarray]</code> <p>Tuple[np.ndarray]: scores, logits</p> Source code in <code>oodeel/methods/energy.py</code> <pre><code>def _score_tensor(self, inputs: TensorType) -&gt; Tuple[np.ndarray]:\n\"\"\"\n    Computes an OOD score for input samples \"inputs\" based on\n    energy, namey $-logsumexp(logits(inputs))$.\n\n    Args:\n        inputs: input samples to score\n\n    Returns:\n        Tuple[np.ndarray]: scores, logits\n    \"\"\"\n    # compute logits (softmax(logits,axis=1) is the actual softmax\n    # output minimized using binary cross entropy)\n    _, logits = self.feature_extractor.predict_tensor(inputs)\n    logits = self.op.convert_to_numpy(logits)\n    scores = -logsumexp(logits, axis=1)\n    return scores\n</code></pre>"},{"location":"api/methods/#oodeel.methods.Entropy","title":"<code>Entropy</code>","text":"<p>         Bases: <code>OODBaseDetector</code></p> <p>Entropy OOD score</p> <p>The method consists in using the Entropy of the input data computed using the Entropy $\\sum_{c=0}^C p(y=c| x) \\times log(p(y=c | x))$ where $p(y=c| x) = \\text{model}(x)$.</p> <p>Reference https://proceedings.neurips.cc/paper/2019/hash/1e79596878b2320cac26dd792a6c51c9-Abstract.html, Neurips 2019.</p> <p>Parameters:</p> Name Type Description Default <code>use_react</code> <code>bool</code> <p>if true, apply ReAct method by clipping penultimate activations under a threshold value.</p> <code>False</code> <code>react_quantile</code> <code>Optional[float]</code> <p>q value in the range [0, 1] used to compute the react clipping threshold defined as the q-th quantile penultimate layer activations. Defaults to 0.8.</p> <code>0.8</code> Source code in <code>oodeel/methods/entropy.py</code> <pre><code>class Entropy(OODBaseDetector):\nr\"\"\"\n    Entropy OOD score\n\n\n    The method consists in using the Entropy of the input data computed using the\n    Entropy $\\sum_{c=0}^C p(y=c| x) \\times log(p(y=c | x))$ where\n    $p(y=c| x) = \\text{model}(x)$.\n\n    **Reference**\n    https://proceedings.neurips.cc/paper/2019/hash/1e79596878b2320cac26dd792a6c51c9-Abstract.html,\n    Neurips 2019.\n\n    Args:\n        use_react (bool): if true, apply ReAct method by clipping penultimate\n            activations under a threshold value.\n        react_quantile (Optional[float]): q value in the range [0, 1] used to compute\n            the react clipping threshold defined as the q-th quantile penultimate layer\n            activations. Defaults to 0.8.\n    \"\"\"\n\n    def __init__(\n        self,\n        use_react: bool = False,\n        use_scale: bool = False,\n        use_ash: bool = False,\n        react_quantile: float = 0.8,\n        scale_percentile: float = 0.85,\n        ash_percentile: float = 0.90,\n    ):\n        super().__init__(\n            use_react=use_react,\n            use_scale=use_scale,\n            use_ash=use_ash,\n            react_quantile=react_quantile,\n            scale_percentile=scale_percentile,\n            ash_percentile=ash_percentile,\n        )\n\n    def _score_tensor(self, inputs: TensorType) -&gt; Tuple[np.ndarray]:\n\"\"\"\n        Computes an OOD score for input samples \"inputs\" based on\n        entropy.\n\n        Args:\n            inputs: input samples to score\n\n        Returns:\n            Tuple[np.ndarray]: scores, logits\n        \"\"\"\n\n        # compute logits (softmax(logits,axis=1) is the actual softmax\n        # output minimized using binary cross entropy)\n        _, logits = self.feature_extractor.predict_tensor(inputs)\n        probits = self.op.softmax(logits)\n        probits = self.op.convert_to_numpy(probits)\n        scores = np.sum(probits * np.log(probits), axis=1)\n        return -scores\n\n    def _fit_to_dataset(self, fit_dataset: DatasetType) -&gt; None:\n\"\"\"\n        Fits the OOD detector to fit_dataset.\n\n        Args:\n            fit_dataset: dataset to fit the OOD detector on\n        \"\"\"\n        pass\n\n    @property\n    def requires_to_fit_dataset(self) -&gt; bool:\n\"\"\"\n        Whether an OOD detector needs a `fit_dataset` argument in the fit function.\n\n        Returns:\n            bool: True if `fit_dataset` is required else False.\n        \"\"\"\n        return False\n\n    @property\n    def requires_internal_features(self) -&gt; bool:\n\"\"\"\n        Whether an OOD detector acts on internal model features.\n\n        Returns:\n            bool: True if the detector perform computations on an intermediate layer\n            else False.\n        \"\"\"\n        return False\n</code></pre>"},{"location":"api/methods/#oodeel.methods.entropy.Entropy.requires_internal_features","title":"<code>requires_internal_features: bool</code>  <code>property</code>","text":"<p>Whether an OOD detector acts on internal model features.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the detector perform computations on an intermediate layer</p> <code>bool</code> <p>else False.</p>"},{"location":"api/methods/#oodeel.methods.entropy.Entropy.requires_to_fit_dataset","title":"<code>requires_to_fit_dataset: bool</code>  <code>property</code>","text":"<p>Whether an OOD detector needs a <code>fit_dataset</code> argument in the fit function.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if <code>fit_dataset</code> is required else False.</p>"},{"location":"api/methods/#oodeel.methods.entropy.Entropy._fit_to_dataset","title":"<code>_fit_to_dataset(fit_dataset)</code>","text":"<p>Fits the OOD detector to fit_dataset.</p> <p>Parameters:</p> Name Type Description Default <code>fit_dataset</code> <code>DatasetType</code> <p>dataset to fit the OOD detector on</p> required Source code in <code>oodeel/methods/entropy.py</code> <pre><code>def _fit_to_dataset(self, fit_dataset: DatasetType) -&gt; None:\n\"\"\"\n    Fits the OOD detector to fit_dataset.\n\n    Args:\n        fit_dataset: dataset to fit the OOD detector on\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/methods/#oodeel.methods.entropy.Entropy._score_tensor","title":"<code>_score_tensor(inputs)</code>","text":"<p>Computes an OOD score for input samples \"inputs\" based on entropy.</p> <p>Parameters:</p> Name Type Description Default <code>inputs</code> <code>TensorType</code> <p>input samples to score</p> required <p>Returns:</p> Type Description <code>Tuple[np.ndarray]</code> <p>Tuple[np.ndarray]: scores, logits</p> Source code in <code>oodeel/methods/entropy.py</code> <pre><code>def _score_tensor(self, inputs: TensorType) -&gt; Tuple[np.ndarray]:\n\"\"\"\n    Computes an OOD score for input samples \"inputs\" based on\n    entropy.\n\n    Args:\n        inputs: input samples to score\n\n    Returns:\n        Tuple[np.ndarray]: scores, logits\n    \"\"\"\n\n    # compute logits (softmax(logits,axis=1) is the actual softmax\n    # output minimized using binary cross entropy)\n    _, logits = self.feature_extractor.predict_tensor(inputs)\n    probits = self.op.softmax(logits)\n    probits = self.op.convert_to_numpy(probits)\n    scores = np.sum(probits * np.log(probits), axis=1)\n    return -scores\n</code></pre>"},{"location":"api/methods/#oodeel.methods.GEN","title":"<code>GEN</code>","text":"<p>         Bases: <code>OODBaseDetector</code></p> <p>Generalized Entropy method for OOD detection. \"GEN: Pushing the Limits of Softmax-Based Out-of-Distribution Detection\" https://openaccess.thecvf.com/content/CVPR2023/html/Liu_GEN_Pushing_the_Limits_of_Softmax-Based_Out-of-Distribution_Detection_CVPR_2023_paper.html,</p> <p>Parameters:</p> Name Type Description Default <code>gamma</code> <code>float</code> <p>parameter for the generalized entropy. Must be between 0 and 1. Defaults to 0.1.</p> <code>0.1</code> <code>k</code> <code>int</code> <p>number of softmax values to keep for the entropy computation. Only the top-k softmax probabilities will be used. Defaults to 100.</p> <code>100</code> <code>use_react</code> <code>bool</code> <p>if true, apply ReAct method by clipping penultimate activations under a threshold value.</p> <code>False</code> <code>react_quantile</code> <code>Optional[float]</code> <p>q value in the range [0, 1] used to compute the react clipping threshold defined as the q-th quantile penultimate layer activations. Defaults to 0.8.</p> <code>0.8</code> Source code in <code>oodeel/methods/gen.py</code> <pre><code>class GEN(OODBaseDetector):\n\"\"\"\n    Generalized Entropy method for OOD detection.\n    \"GEN: Pushing the Limits of Softmax-Based Out-of-Distribution Detection\"\n    https://openaccess.thecvf.com/content/CVPR2023/html/Liu_GEN_Pushing_the_Limits_of_Softmax-Based_Out-of-Distribution_Detection_CVPR_2023_paper.html,\n\n    Args:\n        gamma (float): parameter for the generalized entropy. Must be between 0 and 1.\n            Defaults to 0.1.\n        k (int): number of softmax values to keep for the entropy computation. Only the\n            top-k softmax probabilities will be used. Defaults to 100.\n        use_react (bool): if true, apply ReAct method by clipping penultimate\n            activations under a threshold value.\n        react_quantile (Optional[float]): q value in the range [0, 1] used to compute\n            the react clipping threshold defined as the q-th quantile penultimate layer\n            activations. Defaults to 0.8.\n    \"\"\"\n\n    def __init__(\n        self,\n        gamma: float = 0.1,\n        k: int = 100,\n        use_react: bool = False,\n        use_scale: bool = False,\n        use_ash: bool = False,\n        react_quantile: float = 0.8,\n        scale_percentile: float = 0.85,\n        ash_percentile: float = 0.90,\n    ):\n        super().__init__(\n            use_react=use_react,\n            use_scale=use_scale,\n            use_ash=use_ash,\n            react_quantile=react_quantile,\n            scale_percentile=scale_percentile,\n            ash_percentile=ash_percentile,\n        )\n        self.gamma = gamma\n        self.k = k\n\n    def _score_tensor(self, inputs: TensorType) -&gt; Tuple[np.ndarray]:\n\"\"\"\n        Computes an OOD score for input samples \"inputs\" based on\n        the distance to nearest neighbors in the feature space of self.model\n\n        Args:\n            inputs: input samples to score\n\n        Returns:\n            Tuple[np.ndarray]: scores, logits\n        \"\"\"\n\n        _, logits = self.feature_extractor.predict_tensor(inputs)\n        probs = self.op.softmax(logits)\n        probs = self.op.convert_to_numpy(probs)\n        probs = np.sort(probs)[:, -self.k :]  # Keep the k largest probabilities\n        scores = np.sum(probs**self.gamma * (1 - probs) ** (self.gamma), axis=-1)\n        return scores\n\n    def _fit_to_dataset(self, fit_dataset: DatasetType) -&gt; None:\n\"\"\"\n        Fits the OOD detector to fit_dataset.\n\n        Args:\n            fit_dataset: dataset to fit the OOD detector on\n        \"\"\"\n        pass\n\n    @property\n    def requires_to_fit_dataset(self) -&gt; bool:\n\"\"\"\n        Whether an OOD detector needs a `fit_dataset` argument in the fit function.\n\n        Returns:\n            bool: True if `fit_dataset` is required else False.\n        \"\"\"\n        return False\n\n    @property\n    def requires_internal_features(self) -&gt; bool:\n\"\"\"\n        Whether an OOD detector acts on internal model features.\n\n        Returns:\n            bool: True if the detector perform computations on an intermediate layer\n            else False.\n        \"\"\"\n        return False\n</code></pre>"},{"location":"api/methods/#oodeel.methods.gen.GEN.requires_internal_features","title":"<code>requires_internal_features: bool</code>  <code>property</code>","text":"<p>Whether an OOD detector acts on internal model features.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the detector perform computations on an intermediate layer</p> <code>bool</code> <p>else False.</p>"},{"location":"api/methods/#oodeel.methods.gen.GEN.requires_to_fit_dataset","title":"<code>requires_to_fit_dataset: bool</code>  <code>property</code>","text":"<p>Whether an OOD detector needs a <code>fit_dataset</code> argument in the fit function.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if <code>fit_dataset</code> is required else False.</p>"},{"location":"api/methods/#oodeel.methods.gen.GEN._fit_to_dataset","title":"<code>_fit_to_dataset(fit_dataset)</code>","text":"<p>Fits the OOD detector to fit_dataset.</p> <p>Parameters:</p> Name Type Description Default <code>fit_dataset</code> <code>DatasetType</code> <p>dataset to fit the OOD detector on</p> required Source code in <code>oodeel/methods/gen.py</code> <pre><code>def _fit_to_dataset(self, fit_dataset: DatasetType) -&gt; None:\n\"\"\"\n    Fits the OOD detector to fit_dataset.\n\n    Args:\n        fit_dataset: dataset to fit the OOD detector on\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/methods/#oodeel.methods.gen.GEN._score_tensor","title":"<code>_score_tensor(inputs)</code>","text":"<p>Computes an OOD score for input samples \"inputs\" based on the distance to nearest neighbors in the feature space of self.model</p> <p>Parameters:</p> Name Type Description Default <code>inputs</code> <code>TensorType</code> <p>input samples to score</p> required <p>Returns:</p> Type Description <code>Tuple[np.ndarray]</code> <p>Tuple[np.ndarray]: scores, logits</p> Source code in <code>oodeel/methods/gen.py</code> <pre><code>def _score_tensor(self, inputs: TensorType) -&gt; Tuple[np.ndarray]:\n\"\"\"\n    Computes an OOD score for input samples \"inputs\" based on\n    the distance to nearest neighbors in the feature space of self.model\n\n    Args:\n        inputs: input samples to score\n\n    Returns:\n        Tuple[np.ndarray]: scores, logits\n    \"\"\"\n\n    _, logits = self.feature_extractor.predict_tensor(inputs)\n    probs = self.op.softmax(logits)\n    probs = self.op.convert_to_numpy(probs)\n    probs = np.sort(probs)[:, -self.k :]  # Keep the k largest probabilities\n    scores = np.sum(probs**self.gamma * (1 - probs) ** (self.gamma), axis=-1)\n    return scores\n</code></pre>"},{"location":"api/methods/#oodeel.methods.Gram","title":"<code>Gram</code>","text":"<p>         Bases: <code>OODBaseDetector</code></p> <p>\"Detecting Out-of-Distribution Examples with Gram Matrices\" link</p> <p>Important Disclaimer: Taking the statistics of min/max deviation, as in the paper raises some problems.</p> <p>The method often yields a score of zero for some tasks. This is expected since the min/max among the samples of a random variable becomes more and more extreme with the sample size. As a result, computing the min/max over the training set is likely to produce min/max values that are so extreme that none of the in distribution correlations of the validation set goes beyond these threshold. The worst is that a significant part of ood data does not exceed the thresholds either. This can be aleviated by computing the min/max over a limited number of sample. However, it is counter-intuitive and, in our opinion, not desirable: adding some more information should only improve a method.</p> <p>Hence, we decided to replace the min/max by the q / 1-q quantile, with q a new parameter of the method. Specifically, instead of the deviation as defined in eq. 3 of the paper, we use the definition $$ \\delta(t_q, t_{1-q}, value) = \\begin{cases}     0 &amp; \\text{if} \\; t_q \\leq value \\leq t_{1-q},  \\;\\;     \\frac{t_q - value}{|t_q|} &amp; \\text{if } value &lt; t_q,  \\;\\;     \\frac{value - t_{1-q}}{|t_q|} &amp; \\text{if } value &gt; t_{1-q} \\end{cases} $$ With this new deviation, the more point we add, the more accurate the quantile becomes. In addition, the method can be made more or less discriminative by toggling the value of q.</p> <p>Finally, we found that this approach improved the performance of the baseline in our experiments.</p> <p>Parameters:</p> Name Type Description Default <code>orders</code> <code>List[int]</code> <p>power orders to consider for the correlation matrix</p> <code>[i for i in range(1, 6)]</code> <code>quantile</code> <code>float</code> <p>quantile to consider for the correlations to build the deviation threshold.</p> <code>0.01</code> Source code in <code>oodeel/methods/gram.py</code> <pre><code>class Gram(OODBaseDetector):\nr\"\"\"\n    \"Detecting Out-of-Distribution Examples with Gram Matrices\"\n    [link](https://proceedings.mlr.press/v119/sastry20a.html)\n\n    **Important Disclaimer**: Taking the statistics of min/max deviation,\n    as in the paper raises some problems.\n\n    The method often yields a score of zero for some tasks.\n    This is expected since the min/max among the samples of a random\n    variable becomes more and more extreme with the sample\n    size. As a result, computing the min/max over the training set is likely to produce\n    min/max values that are so extreme that none of the in distribution correlations of\n    the validation set goes beyond these threshold. The worst is that a significant\n    part of ood data does not exceed the thresholds either. This can be aleviated by\n    computing the min/max over a limited number of sample. However, it is\n    counter-intuitive and, in our opinion, not desirable: adding\n    some more information should only improve a method.\n\n    Hence, we decided to replace the min/max by the q / 1-q quantile, with q a new\n    parameter of the method. Specifically, instead of the deviation as defined in\n    eq. 3 of the paper, we use the definition\n    $$\n    \\delta(t_q, t_{1-q}, value) =\n    \\begin{cases}\n        0 &amp; \\text{if} \\; t_q \\leq value \\leq t_{1-q},  \\;\\;\n        \\frac{t_q - value}{|t_q|} &amp; \\text{if } value &lt; t_q,  \\;\\;\n        \\frac{value - t_{1-q}}{|t_q|} &amp; \\text{if } value &gt; t_{1-q}\n    \\end{cases}\n    $$\n    With this new deviation, the more point we add, the more accurate the quantile\n    becomes. In addition, the method can be made more or less discriminative by\n    toggling the value of q.\n\n    Finally, we found that this approach improved the performance of the baseline in\n    our experiments.\n\n    Args:\n        orders (List[int]): power orders to consider for the correlation matrix\n        quantile (float): quantile to consider for the correlations to build the\n            deviation threshold.\n\n    \"\"\"\n\n    def __init__(\n        self,\n        orders: List[int] = [i for i in range(1, 6)],\n        quantile: float = 0.01,\n    ):\n        super().__init__()\n        if isinstance(orders, int):\n            orders = [orders]\n        self.orders = orders\n        self.postproc_fns = None\n        self.quantile = quantile\n\n    def _fit_to_dataset(\n        self,\n        fit_dataset: Union[TensorType, DatasetType],\n        val_split: float = 0.2,\n        verbose: bool = False,\n    ) -&gt; None:\n\"\"\"\n        Compute the quantiles of channelwise correlations for each layer, power of\n        gram matrices, and class. Then, compute the normalization constants for the\n        deviation. To stay faithful to the spirit of the original method, we still name\n        the quantiles min/max\n\n        Args:\n            fit_dataset (Union[TensorType, DatasetType]): input dataset (ID) to\n                construct the index with.\n            val_split (float): The percentage of fit data to use as validation data for\n                normalization. Default to 0.2.\n            verbose (bool): Whether to print information during the fitting process.\n                Default to False.\n        \"\"\"\n        self.postproc_fns = [\n            self._stat for i in range(len(self.feature_extractor.feature_layers_id))\n        ]\n\n        # fit_stats shape: [n_features, n_samples, n_orders, n_channels]\n        fit_stats, info = self.feature_extractor.predict(\n            fit_dataset,\n            postproc_fns=self.postproc_fns,\n            return_labels=True,\n            verbose=verbose,\n        )\n        labels = info[\"labels\"]\n        self._classes = np.sort(np.unique(self.op.convert_to_numpy(labels)))\n\n        full_indices = np.arange(labels.shape[0])\n        train_indices, val_indices = train_test_split(full_indices, test_size=val_split)\n        train_indices = self.op.from_numpy(\n            [bool(ind in train_indices) for ind in full_indices]\n        )\n        val_indices = self.op.from_numpy(\n            [bool(ind in val_indices) for ind in full_indices]\n        )\n\n        val_stats = [fit_stat[val_indices] for fit_stat in fit_stats]\n        fit_stats = [fit_stat[train_indices] for fit_stat in fit_stats]\n        labels = labels[train_indices]\n\n        self.min_maxs = dict()\n        for cls in self._classes:\n            indexes = self.op.equal(labels, cls)\n            min_maxs = []\n            for fit_stat in fit_stats:\n                fit_stat = fit_stat[indexes]\n                mins = self.op.unsqueeze(\n                    self.op.quantile(fit_stat, self.quantile, dim=0), -1\n                )\n                maxs = self.op.unsqueeze(\n                    self.op.quantile(fit_stat, 1 - self.quantile, dim=0), -1\n                )\n                min_max = self.op.cat([mins, maxs], dim=-1)\n                min_maxs.append(min_max)\n\n            self.min_maxs[cls] = min_maxs\n\n        devnorm = []\n        for cls in self._classes:\n            min_maxs = []\n            for min_max in self.min_maxs[cls]:\n                min_maxs.append(\n                    self.op.stack([min_max for i in range(val_stats[0].shape[0])])\n                )\n            devnorm.append(\n                [\n                    float(self.op.mean(dev))\n                    for dev in self._deviation(val_stats, min_maxs)\n                ]\n            )\n        self.devnorm = np.mean(np.array(devnorm), axis=0)\n\n    def _score_tensor(self, inputs: TensorType) -&gt; np.ndarray:\n\"\"\"\n        Computes an OOD score for input samples \"inputs\" based on\n        the aggregation of deviations from quantiles of in-distribution channel-wise\n        correlations evaluate for each layer, power of gram matrices, and class.\n\n        Args:\n            inputs: input samples to score\n\n        Returns:\n            scores\n        \"\"\"\n\n        tensor_stats, _ = self.feature_extractor.predict_tensor(\n            inputs, postproc_fns=self.postproc_fns\n        )\n\n        _, logits = self.feature_extractor.predict_tensor(inputs)\n        preds = self.op.convert_to_numpy(self.op.argmax(logits, dim=1))\n\n        # We stack the min_maxs for each class depending on the prediction for each\n        # samples\n        min_maxs = []\n        for i in range(len(tensor_stats)):\n            min_maxs.append(self.op.stack([self.min_maxs[label][i] for label in preds]))\n\n        tensor_dev = self._deviation(tensor_stats, min_maxs)\n        score = self.op.mean(\n            self.op.cat(\n                [\n                    self.op.unsqueeze(tensor_dev_l, dim=0) / devnorm_l\n                    for tensor_dev_l, devnorm_l in zip(tensor_dev, self.devnorm)\n                ]\n            ),\n            dim=0,\n        )\n        return self.op.convert_to_numpy(score)\n\n    def _deviation(\n        self, stats: List[TensorType], min_maxs: List[TensorType]\n    ) -&gt; List[TensorType]:\n\"\"\"Compute the deviation wrt quantiles (min/max) for feature_maps\n\n        Args:\n            stats (TensorType): The list of gram matrices (stacked power-wise)\n                for which we want to compute the deviation.\n            min_maxs (TensorType): The quantiles (tensorised) to compute the deviation\n                against.\n\n        Returns:\n            List(TensorType): A list with one element per layer containing a tensor of\n                per-sample deviation.\n        \"\"\"\n        deviation = []\n        for stat, min_max in zip(stats, min_maxs):\n            where_min = self.op.where(stat &lt; min_max[..., 0], 1.0, 0.0)\n            where_max = self.op.where(stat &gt; min_max[..., 1], 1.0, 0.0)\n            deviation_min = (\n                (min_max[..., 0] - stat)\n                / (self.op.abs(min_max[..., 0]) + 1e-6)\n                * where_min\n            )\n            deviation_max = (\n                (stat - min_max[..., 1])\n                / (self.op.abs(min_max[..., 1]) + 1e-6)\n                * where_max\n            )\n            deviation.append(self.op.sum(deviation_min + deviation_max, dim=(1, 2)))\n        return deviation\n\n    def _stat(self, feature_map: TensorType) -&gt; TensorType:\n\"\"\"Compute the correlation map (stat) for a given feature map. The values\n        for each power of gram matrix are contained in the same tensor\n\n        Args:\n            feature_map (TensorType): The input feature_map\n\n        Returns:\n            TensorType: The stacked gram matrices power-wise.\n        \"\"\"\n        fm_s = feature_map.shape\n        stat = []\n        for p in self.orders:\n            feature_map_p = feature_map**p\n            # construct the Gram matrix\n            if len(fm_s) == 2:\n                # build gram matrix for feature map of shape [dim_dense_layer, 1]\n                feature_map_p = self.op.einsum(\n                    \"bi,bj-&gt;bij\", feature_map_p, feature_map_p\n                )\n            elif len(fm_s) &gt;= 3:\n                # flatten the feature map\n                if self.backend == \"tensorflow\":\n                    feature_map_p = self.op.reshape(\n                        self.op.einsum(\"i...j-&gt;ij...\", feature_map_p),\n                        (fm_s[0], fm_s[-1], -1),\n                    )\n                else:\n                    # batch, channel, spatial\n                    feature_map_p = self.op.reshape(\n                        feature_map_p, (fm_s[0], fm_s[1], -1)\n                    )\n                # batch, channel, channel\n                feature_map_p = self.op.matmul(\n                    feature_map_p, self.op.permute(feature_map_p, (0, 2, 1))\n                )\n            # normalize the Gram matrix\n            feature_map_p = self.op.sign(feature_map_p) * (\n                self.op.abs(feature_map_p) ** (1 / p)\n            )\n            # get the lower triangular part of the matrix\n            feature_map_p = self.op.tril(feature_map_p)\n            # directly sum row-wise (to limit computational burden) -&gt; batch, channel\n            feature_map_p = self.op.sum(feature_map_p, dim=2)\n            # stat.append(self.op.t(feature_map_p))\n            stat.append(feature_map_p)\n        # batch, n_orders, channel\n        stat = self.op.stack(stat, 1)\n        return stat\n\n    @property\n    def requires_to_fit_dataset(self) -&gt; bool:\n\"\"\"\n        Whether an OOD detector needs a `fit_dataset` argument in the fit function.\n\n        Returns:\n            bool: True if `fit_dataset` is required else False.\n        \"\"\"\n        return True\n\n    @property\n    def requires_internal_features(self) -&gt; bool:\n\"\"\"\n        Whether an OOD detector acts on internal model features.\n\n        Returns:\n            bool: True if the detector perform computations on an intermediate layer\n            else False.\n        \"\"\"\n        return True\n</code></pre>"},{"location":"api/methods/#oodeel.methods.gram.Gram.requires_internal_features","title":"<code>requires_internal_features: bool</code>  <code>property</code>","text":"<p>Whether an OOD detector acts on internal model features.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the detector perform computations on an intermediate layer</p> <code>bool</code> <p>else False.</p>"},{"location":"api/methods/#oodeel.methods.gram.Gram.requires_to_fit_dataset","title":"<code>requires_to_fit_dataset: bool</code>  <code>property</code>","text":"<p>Whether an OOD detector needs a <code>fit_dataset</code> argument in the fit function.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if <code>fit_dataset</code> is required else False.</p>"},{"location":"api/methods/#oodeel.methods.gram.Gram._deviation","title":"<code>_deviation(stats, min_maxs)</code>","text":"<p>Compute the deviation wrt quantiles (min/max) for feature_maps</p> <p>Parameters:</p> Name Type Description Default <code>stats</code> <code>TensorType</code> <p>The list of gram matrices (stacked power-wise) for which we want to compute the deviation.</p> required <code>min_maxs</code> <code>TensorType</code> <p>The quantiles (tensorised) to compute the deviation against.</p> required <p>Returns:</p> Name Type Description <code>List</code> <code>TensorType</code> <p>A list with one element per layer containing a tensor of per-sample deviation.</p> Source code in <code>oodeel/methods/gram.py</code> <pre><code>def _deviation(\n    self, stats: List[TensorType], min_maxs: List[TensorType]\n) -&gt; List[TensorType]:\n\"\"\"Compute the deviation wrt quantiles (min/max) for feature_maps\n\n    Args:\n        stats (TensorType): The list of gram matrices (stacked power-wise)\n            for which we want to compute the deviation.\n        min_maxs (TensorType): The quantiles (tensorised) to compute the deviation\n            against.\n\n    Returns:\n        List(TensorType): A list with one element per layer containing a tensor of\n            per-sample deviation.\n    \"\"\"\n    deviation = []\n    for stat, min_max in zip(stats, min_maxs):\n        where_min = self.op.where(stat &lt; min_max[..., 0], 1.0, 0.0)\n        where_max = self.op.where(stat &gt; min_max[..., 1], 1.0, 0.0)\n        deviation_min = (\n            (min_max[..., 0] - stat)\n            / (self.op.abs(min_max[..., 0]) + 1e-6)\n            * where_min\n        )\n        deviation_max = (\n            (stat - min_max[..., 1])\n            / (self.op.abs(min_max[..., 1]) + 1e-6)\n            * where_max\n        )\n        deviation.append(self.op.sum(deviation_min + deviation_max, dim=(1, 2)))\n    return deviation\n</code></pre>"},{"location":"api/methods/#oodeel.methods.gram.Gram._fit_to_dataset","title":"<code>_fit_to_dataset(fit_dataset, val_split=0.2, verbose=False)</code>","text":"<p>Compute the quantiles of channelwise correlations for each layer, power of gram matrices, and class. Then, compute the normalization constants for the deviation. To stay faithful to the spirit of the original method, we still name the quantiles min/max</p> <p>Parameters:</p> Name Type Description Default <code>fit_dataset</code> <code>Union[TensorType, DatasetType]</code> <p>input dataset (ID) to construct the index with.</p> required <code>val_split</code> <code>float</code> <p>The percentage of fit data to use as validation data for normalization. Default to 0.2.</p> <code>0.2</code> <code>verbose</code> <code>bool</code> <p>Whether to print information during the fitting process. Default to False.</p> <code>False</code> Source code in <code>oodeel/methods/gram.py</code> <pre><code>def _fit_to_dataset(\n    self,\n    fit_dataset: Union[TensorType, DatasetType],\n    val_split: float = 0.2,\n    verbose: bool = False,\n) -&gt; None:\n\"\"\"\n    Compute the quantiles of channelwise correlations for each layer, power of\n    gram matrices, and class. Then, compute the normalization constants for the\n    deviation. To stay faithful to the spirit of the original method, we still name\n    the quantiles min/max\n\n    Args:\n        fit_dataset (Union[TensorType, DatasetType]): input dataset (ID) to\n            construct the index with.\n        val_split (float): The percentage of fit data to use as validation data for\n            normalization. Default to 0.2.\n        verbose (bool): Whether to print information during the fitting process.\n            Default to False.\n    \"\"\"\n    self.postproc_fns = [\n        self._stat for i in range(len(self.feature_extractor.feature_layers_id))\n    ]\n\n    # fit_stats shape: [n_features, n_samples, n_orders, n_channels]\n    fit_stats, info = self.feature_extractor.predict(\n        fit_dataset,\n        postproc_fns=self.postproc_fns,\n        return_labels=True,\n        verbose=verbose,\n    )\n    labels = info[\"labels\"]\n    self._classes = np.sort(np.unique(self.op.convert_to_numpy(labels)))\n\n    full_indices = np.arange(labels.shape[0])\n    train_indices, val_indices = train_test_split(full_indices, test_size=val_split)\n    train_indices = self.op.from_numpy(\n        [bool(ind in train_indices) for ind in full_indices]\n    )\n    val_indices = self.op.from_numpy(\n        [bool(ind in val_indices) for ind in full_indices]\n    )\n\n    val_stats = [fit_stat[val_indices] for fit_stat in fit_stats]\n    fit_stats = [fit_stat[train_indices] for fit_stat in fit_stats]\n    labels = labels[train_indices]\n\n    self.min_maxs = dict()\n    for cls in self._classes:\n        indexes = self.op.equal(labels, cls)\n        min_maxs = []\n        for fit_stat in fit_stats:\n            fit_stat = fit_stat[indexes]\n            mins = self.op.unsqueeze(\n                self.op.quantile(fit_stat, self.quantile, dim=0), -1\n            )\n            maxs = self.op.unsqueeze(\n                self.op.quantile(fit_stat, 1 - self.quantile, dim=0), -1\n            )\n            min_max = self.op.cat([mins, maxs], dim=-1)\n            min_maxs.append(min_max)\n\n        self.min_maxs[cls] = min_maxs\n\n    devnorm = []\n    for cls in self._classes:\n        min_maxs = []\n        for min_max in self.min_maxs[cls]:\n            min_maxs.append(\n                self.op.stack([min_max for i in range(val_stats[0].shape[0])])\n            )\n        devnorm.append(\n            [\n                float(self.op.mean(dev))\n                for dev in self._deviation(val_stats, min_maxs)\n            ]\n        )\n    self.devnorm = np.mean(np.array(devnorm), axis=0)\n</code></pre>"},{"location":"api/methods/#oodeel.methods.gram.Gram._score_tensor","title":"<code>_score_tensor(inputs)</code>","text":"<p>Computes an OOD score for input samples \"inputs\" based on the aggregation of deviations from quantiles of in-distribution channel-wise correlations evaluate for each layer, power of gram matrices, and class.</p> <p>Parameters:</p> Name Type Description Default <code>inputs</code> <code>TensorType</code> <p>input samples to score</p> required <p>Returns:</p> Type Description <code>np.ndarray</code> <p>scores</p> Source code in <code>oodeel/methods/gram.py</code> <pre><code>def _score_tensor(self, inputs: TensorType) -&gt; np.ndarray:\n\"\"\"\n    Computes an OOD score for input samples \"inputs\" based on\n    the aggregation of deviations from quantiles of in-distribution channel-wise\n    correlations evaluate for each layer, power of gram matrices, and class.\n\n    Args:\n        inputs: input samples to score\n\n    Returns:\n        scores\n    \"\"\"\n\n    tensor_stats, _ = self.feature_extractor.predict_tensor(\n        inputs, postproc_fns=self.postproc_fns\n    )\n\n    _, logits = self.feature_extractor.predict_tensor(inputs)\n    preds = self.op.convert_to_numpy(self.op.argmax(logits, dim=1))\n\n    # We stack the min_maxs for each class depending on the prediction for each\n    # samples\n    min_maxs = []\n    for i in range(len(tensor_stats)):\n        min_maxs.append(self.op.stack([self.min_maxs[label][i] for label in preds]))\n\n    tensor_dev = self._deviation(tensor_stats, min_maxs)\n    score = self.op.mean(\n        self.op.cat(\n            [\n                self.op.unsqueeze(tensor_dev_l, dim=0) / devnorm_l\n                for tensor_dev_l, devnorm_l in zip(tensor_dev, self.devnorm)\n            ]\n        ),\n        dim=0,\n    )\n    return self.op.convert_to_numpy(score)\n</code></pre>"},{"location":"api/methods/#oodeel.methods.gram.Gram._stat","title":"<code>_stat(feature_map)</code>","text":"<p>Compute the correlation map (stat) for a given feature map. The values for each power of gram matrix are contained in the same tensor</p> <p>Parameters:</p> Name Type Description Default <code>feature_map</code> <code>TensorType</code> <p>The input feature_map</p> required <p>Returns:</p> Name Type Description <code>TensorType</code> <code>TensorType</code> <p>The stacked gram matrices power-wise.</p> Source code in <code>oodeel/methods/gram.py</code> <pre><code>def _stat(self, feature_map: TensorType) -&gt; TensorType:\n\"\"\"Compute the correlation map (stat) for a given feature map. The values\n    for each power of gram matrix are contained in the same tensor\n\n    Args:\n        feature_map (TensorType): The input feature_map\n\n    Returns:\n        TensorType: The stacked gram matrices power-wise.\n    \"\"\"\n    fm_s = feature_map.shape\n    stat = []\n    for p in self.orders:\n        feature_map_p = feature_map**p\n        # construct the Gram matrix\n        if len(fm_s) == 2:\n            # build gram matrix for feature map of shape [dim_dense_layer, 1]\n            feature_map_p = self.op.einsum(\n                \"bi,bj-&gt;bij\", feature_map_p, feature_map_p\n            )\n        elif len(fm_s) &gt;= 3:\n            # flatten the feature map\n            if self.backend == \"tensorflow\":\n                feature_map_p = self.op.reshape(\n                    self.op.einsum(\"i...j-&gt;ij...\", feature_map_p),\n                    (fm_s[0], fm_s[-1], -1),\n                )\n            else:\n                # batch, channel, spatial\n                feature_map_p = self.op.reshape(\n                    feature_map_p, (fm_s[0], fm_s[1], -1)\n                )\n            # batch, channel, channel\n            feature_map_p = self.op.matmul(\n                feature_map_p, self.op.permute(feature_map_p, (0, 2, 1))\n            )\n        # normalize the Gram matrix\n        feature_map_p = self.op.sign(feature_map_p) * (\n            self.op.abs(feature_map_p) ** (1 / p)\n        )\n        # get the lower triangular part of the matrix\n        feature_map_p = self.op.tril(feature_map_p)\n        # directly sum row-wise (to limit computational burden) -&gt; batch, channel\n        feature_map_p = self.op.sum(feature_map_p, dim=2)\n        # stat.append(self.op.t(feature_map_p))\n        stat.append(feature_map_p)\n    # batch, n_orders, channel\n    stat = self.op.stack(stat, 1)\n    return stat\n</code></pre>"},{"location":"api/methods/#oodeel.methods.MLS","title":"<code>MLS</code>","text":"<p>         Bases: <code>OODBaseDetector</code></p> <p>Maximum Logit Scores method for OOD detection. \"Open-Set Recognition: a Good Closed-Set Classifier is All You Need?\" https://arxiv.org/abs/2110.06207, and Maximum Softmax Score \"A Baseline for Detecting Misclassified and Out-of-Distribution Examples in Neural Networks\" http://arxiv.org/abs/1610.02136</p> <p>Parameters:</p> Name Type Description Default <code>output_activation</code> <code>str</code> <p>activation function for the last layer. If \"linear\", the method is MLS and if \"softmax\", the method is MSS. Defaults to \"linear\".</p> <code>'linear'</code> <code>use_react</code> <code>bool</code> <p>if true, apply ReAct method by clipping penultimate activations under a threshold value.</p> <code>False</code> <code>react_quantile</code> <code>Optional[float]</code> <p>q value in the range [0, 1] used to compute the react clipping threshold defined as the q-th quantile penultimate layer activations. Defaults to 0.8.</p> <code>0.8</code> Source code in <code>oodeel/methods/mls.py</code> <pre><code>class MLS(OODBaseDetector):\n\"\"\"\n    Maximum Logit Scores method for OOD detection.\n    \"Open-Set Recognition: a Good Closed-Set Classifier is All You Need?\"\n    https://arxiv.org/abs/2110.06207,\n    and Maximum Softmax Score\n    \"A Baseline for Detecting Misclassified and Out-of-Distribution Examples\n    in Neural Networks\"\n    http://arxiv.org/abs/1610.02136\n\n    Args:\n        output_activation (str): activation function for the last layer. If \"linear\",\n            the method is MLS and if \"softmax\", the method is MSS.\n            Defaults to \"linear\".\n        use_react (bool): if true, apply ReAct method by clipping penultimate\n            activations under a threshold value.\n        react_quantile (Optional[float]): q value in the range [0, 1] used to compute\n            the react clipping threshold defined as the q-th quantile penultimate layer\n            activations. Defaults to 0.8.\n    \"\"\"\n\n    def __init__(\n        self,\n        output_activation: str = \"linear\",\n        use_react: bool = False,\n        use_scale: bool = False,\n        use_ash: bool = False,\n        react_quantile: float = 0.8,\n        scale_percentile: float = 0.85,\n        ash_percentile: float = 0.90,\n    ):\n        super().__init__(\n            use_react=use_react,\n            use_scale=use_scale,\n            use_ash=use_ash,\n            react_quantile=react_quantile,\n            scale_percentile=scale_percentile,\n            ash_percentile=ash_percentile,\n        )\n        self.output_activation = output_activation\n\n    def _score_tensor(self, inputs: TensorType) -&gt; Tuple[np.ndarray]:\n\"\"\"\n        Computes an OOD score for input samples \"inputs\" based on\n        the distance to nearest neighbors in the feature space of self.model\n\n        Args:\n            inputs: input samples to score\n\n        Returns:\n            Tuple[np.ndarray]: scores, logits\n        \"\"\"\n\n        _, logits = self.feature_extractor.predict_tensor(inputs)\n        if self.output_activation == \"softmax\":\n            logits = self.op.softmax(logits)\n        logits = self.op.convert_to_numpy(logits)\n        scores = -np.max(logits, axis=1)\n        return scores\n\n    def _fit_to_dataset(self, fit_dataset: DatasetType) -&gt; None:\n\"\"\"\n        Fits the OOD detector to fit_dataset.\n\n        Args:\n            fit_dataset: dataset to fit the OOD detector on\n        \"\"\"\n        pass\n\n    @property\n    def requires_to_fit_dataset(self) -&gt; bool:\n\"\"\"\n        Whether an OOD detector needs a `fit_dataset` argument in the fit function.\n\n        Returns:\n            bool: True if `fit_dataset` is required else False.\n        \"\"\"\n        return False\n\n    @property\n    def requires_internal_features(self) -&gt; bool:\n\"\"\"\n        Whether an OOD detector acts on internal model features.\n\n        Returns:\n            bool: True if the detector perform computations on an intermediate layer\n            else False.\n        \"\"\"\n        return False\n</code></pre>"},{"location":"api/methods/#oodeel.methods.mls.MLS.requires_internal_features","title":"<code>requires_internal_features: bool</code>  <code>property</code>","text":"<p>Whether an OOD detector acts on internal model features.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the detector perform computations on an intermediate layer</p> <code>bool</code> <p>else False.</p>"},{"location":"api/methods/#oodeel.methods.mls.MLS.requires_to_fit_dataset","title":"<code>requires_to_fit_dataset: bool</code>  <code>property</code>","text":"<p>Whether an OOD detector needs a <code>fit_dataset</code> argument in the fit function.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if <code>fit_dataset</code> is required else False.</p>"},{"location":"api/methods/#oodeel.methods.mls.MLS._fit_to_dataset","title":"<code>_fit_to_dataset(fit_dataset)</code>","text":"<p>Fits the OOD detector to fit_dataset.</p> <p>Parameters:</p> Name Type Description Default <code>fit_dataset</code> <code>DatasetType</code> <p>dataset to fit the OOD detector on</p> required Source code in <code>oodeel/methods/mls.py</code> <pre><code>def _fit_to_dataset(self, fit_dataset: DatasetType) -&gt; None:\n\"\"\"\n    Fits the OOD detector to fit_dataset.\n\n    Args:\n        fit_dataset: dataset to fit the OOD detector on\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/methods/#oodeel.methods.mls.MLS._score_tensor","title":"<code>_score_tensor(inputs)</code>","text":"<p>Computes an OOD score for input samples \"inputs\" based on the distance to nearest neighbors in the feature space of self.model</p> <p>Parameters:</p> Name Type Description Default <code>inputs</code> <code>TensorType</code> <p>input samples to score</p> required <p>Returns:</p> Type Description <code>Tuple[np.ndarray]</code> <p>Tuple[np.ndarray]: scores, logits</p> Source code in <code>oodeel/methods/mls.py</code> <pre><code>def _score_tensor(self, inputs: TensorType) -&gt; Tuple[np.ndarray]:\n\"\"\"\n    Computes an OOD score for input samples \"inputs\" based on\n    the distance to nearest neighbors in the feature space of self.model\n\n    Args:\n        inputs: input samples to score\n\n    Returns:\n        Tuple[np.ndarray]: scores, logits\n    \"\"\"\n\n    _, logits = self.feature_extractor.predict_tensor(inputs)\n    if self.output_activation == \"softmax\":\n        logits = self.op.softmax(logits)\n    logits = self.op.convert_to_numpy(logits)\n    scores = -np.max(logits, axis=1)\n    return scores\n</code></pre>"},{"location":"api/methods/#oodeel.methods.Mahalanobis","title":"<code>Mahalanobis</code>","text":"<p>         Bases: <code>OODBaseDetector</code></p> <p>\"A Simple Unified Framework for Detecting Out-of-Distribution Samples and Adversarial Attacks\" https://arxiv.org/abs/1807.03888</p> <p>Parameters:</p> Name Type Description Default <code>eps</code> <code>float</code> <p>magnitude for gradient based input perturbation. Defaults to 0.02.</p> <code>0.002</code> Source code in <code>oodeel/methods/mahalanobis.py</code> <pre><code>class Mahalanobis(OODBaseDetector):\n\"\"\"\n    \"A Simple Unified Framework for Detecting Out-of-Distribution Samples and\n    Adversarial Attacks\"\n    https://arxiv.org/abs/1807.03888\n\n    Args:\n        eps (float): magnitude for gradient based input perturbation.\n            Defaults to 0.02.\n    \"\"\"\n\n    def __init__(\n        self,\n        eps: float = 0.002,\n    ):\n        super(Mahalanobis, self).__init__()\n        self.eps = eps\n\n    def _fit_to_dataset(self, fit_dataset: DatasetType) -&gt; None:\n\"\"\"\n        Constructs the mean covariance matrix from ID data \"fit_dataset\", whose\n        pseudo-inverse will be used for mahalanobis distance computation.\n\n        Args:\n            fit_dataset (Union[TensorType, DatasetType]): input dataset (ID)\n        \"\"\"\n        # extract features and labels\n        features, infos = self.feature_extractor.predict(fit_dataset, detach=True)\n        labels = infos[\"labels\"]\n\n        # unique sorted classes\n        self._classes = np.sort(np.unique(self.op.convert_to_numpy(labels)))\n\n        # compute mus and covs\n        mus = dict()\n        mean_cov = None\n        for cls in self._classes:\n            indexes = self.op.equal(labels, cls)\n            _features_cls = self.op.flatten(features[0][indexes])\n            mus[cls] = self.op.mean(_features_cls, dim=0)\n            _zero_f_cls = _features_cls - mus[cls]\n            cov_cls = (\n                self.op.matmul(self.op.t(_zero_f_cls), _zero_f_cls)\n                / _zero_f_cls.shape[0]\n            )\n            if mean_cov is None:\n                mean_cov = (len(_features_cls) / len(features[0])) * cov_cls\n            else:\n                mean_cov += (len(_features_cls) / len(features[0])) * cov_cls\n\n        # pseudo-inverse of the mean covariance matrix\n        self._pinv_cov = self.op.pinv(mean_cov)\n        self._mus = mus\n\n    def _score_tensor(self, inputs: TensorType) -&gt; Tuple[np.ndarray]:\n\"\"\"\n        Computes an OOD score for input samples \"inputs\" based on the mahalanobis\n        distance with respect to the closest class-conditional Gaussian distribution.\n\n        Args:\n            inputs (TensorType): input samples\n\n        Returns:\n            Tuple[np.ndarray]: scores, logits\n        \"\"\"\n        # input preprocessing (perturbation)\n        if self.eps &gt; 0:\n            inputs_p = self._input_perturbation(inputs)\n        else:\n            inputs_p = inputs\n\n        # mahalanobis score on perturbed inputs\n        features_p, _ = self.feature_extractor.predict_tensor(inputs_p)\n        features_p = self.op.flatten(features_p[0])\n        gaussian_score_p = self._mahalanobis_score(features_p)\n\n        # take the highest score for each sample\n        gaussian_score_p = self.op.max(gaussian_score_p, dim=1)\n        return -self.op.convert_to_numpy(gaussian_score_p)\n\n    def _input_perturbation(self, inputs: TensorType) -&gt; TensorType:\n\"\"\"\n        Apply small perturbation on inputs to make the in- and out- distribution\n        samples more separable.\n        See original paper for more information (section 2.2)\n        https://arxiv.org/abs/1807.03888\n\n        Args:\n            inputs (TensorType): input samples\n\n        Returns:\n            TensorType: Perturbed inputs\n        \"\"\"\n\n        def __loss_fn(inputs: TensorType) -&gt; TensorType:\n\"\"\"\n            Loss function for the input perturbation.\n\n            Args:\n                inputs (TensorType): input samples\n\n            Returns:\n                TensorType: loss value\n            \"\"\"\n            # extract features\n            out_features, _ = self.feature_extractor.predict(inputs, detach=False)\n            out_features = self.op.flatten(out_features[0])\n            # get mahalanobis score for the class maximizing it\n            gaussian_score = self._mahalanobis_score(out_features)\n            log_probs_f = self.op.max(gaussian_score, dim=1)\n            return self.op.mean(-log_probs_f)\n\n        # compute gradient\n        gradient = self.op.gradient(__loss_fn, inputs)\n        gradient = self.op.sign(gradient)\n\n        inputs_p = inputs - self.eps * gradient\n        return inputs_p\n\n    def _mahalanobis_score(self, out_features: TensorType) -&gt; TensorType:\n\"\"\"\n        Mahalanobis distance-based confidence score. For each test sample, it computes\n        the log of the probability densities of some observations (assuming a\n        normal distribution) using the mahalanobis distance with respect to every\n        class-conditional distributions.\n\n        Args:\n            out_features (TensorType): test samples features\n\n        Returns:\n            TensorType: confidence scores (conditionally to each class)\n        \"\"\"\n        gaussian_scores = list()\n        # compute scores conditionally to each class\n        for cls in self._classes:\n            # center features wrt class-cond dist.\n            mu = self._mus[cls]\n            zero_f = out_features - mu\n            # gaussian log prob density (mahalanobis)\n            log_probs_f = -0.5 * self.op.diag(\n                self.op.matmul(\n                    self.op.matmul(zero_f, self._pinv_cov), self.op.t(zero_f)\n                )\n            )\n            gaussian_scores.append(self.op.reshape(log_probs_f, (-1, 1)))\n        # concatenate scores\n        gaussian_score = self.op.cat(gaussian_scores, 1)\n        return gaussian_score\n\n    @property\n    def requires_to_fit_dataset(self) -&gt; bool:\n\"\"\"\n        Whether an OOD detector needs a `fit_dataset` argument in the fit function.\n\n        Returns:\n            bool: True if `fit_dataset` is required else False.\n        \"\"\"\n        return True\n\n    @property\n    def requires_internal_features(self) -&gt; bool:\n\"\"\"\n        Whether an OOD detector acts on internal model features.\n\n        Returns:\n            bool: True if the detector perform computations on an intermediate layer\n            else False.\n        \"\"\"\n        return True\n</code></pre>"},{"location":"api/methods/#oodeel.methods.mahalanobis.Mahalanobis.requires_internal_features","title":"<code>requires_internal_features: bool</code>  <code>property</code>","text":"<p>Whether an OOD detector acts on internal model features.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the detector perform computations on an intermediate layer</p> <code>bool</code> <p>else False.</p>"},{"location":"api/methods/#oodeel.methods.mahalanobis.Mahalanobis.requires_to_fit_dataset","title":"<code>requires_to_fit_dataset: bool</code>  <code>property</code>","text":"<p>Whether an OOD detector needs a <code>fit_dataset</code> argument in the fit function.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if <code>fit_dataset</code> is required else False.</p>"},{"location":"api/methods/#oodeel.methods.mahalanobis.Mahalanobis._fit_to_dataset","title":"<code>_fit_to_dataset(fit_dataset)</code>","text":"<p>Constructs the mean covariance matrix from ID data \"fit_dataset\", whose pseudo-inverse will be used for mahalanobis distance computation.</p> <p>Parameters:</p> Name Type Description Default <code>fit_dataset</code> <code>Union[TensorType, DatasetType]</code> <p>input dataset (ID)</p> required Source code in <code>oodeel/methods/mahalanobis.py</code> <pre><code>def _fit_to_dataset(self, fit_dataset: DatasetType) -&gt; None:\n\"\"\"\n    Constructs the mean covariance matrix from ID data \"fit_dataset\", whose\n    pseudo-inverse will be used for mahalanobis distance computation.\n\n    Args:\n        fit_dataset (Union[TensorType, DatasetType]): input dataset (ID)\n    \"\"\"\n    # extract features and labels\n    features, infos = self.feature_extractor.predict(fit_dataset, detach=True)\n    labels = infos[\"labels\"]\n\n    # unique sorted classes\n    self._classes = np.sort(np.unique(self.op.convert_to_numpy(labels)))\n\n    # compute mus and covs\n    mus = dict()\n    mean_cov = None\n    for cls in self._classes:\n        indexes = self.op.equal(labels, cls)\n        _features_cls = self.op.flatten(features[0][indexes])\n        mus[cls] = self.op.mean(_features_cls, dim=0)\n        _zero_f_cls = _features_cls - mus[cls]\n        cov_cls = (\n            self.op.matmul(self.op.t(_zero_f_cls), _zero_f_cls)\n            / _zero_f_cls.shape[0]\n        )\n        if mean_cov is None:\n            mean_cov = (len(_features_cls) / len(features[0])) * cov_cls\n        else:\n            mean_cov += (len(_features_cls) / len(features[0])) * cov_cls\n\n    # pseudo-inverse of the mean covariance matrix\n    self._pinv_cov = self.op.pinv(mean_cov)\n    self._mus = mus\n</code></pre>"},{"location":"api/methods/#oodeel.methods.mahalanobis.Mahalanobis._input_perturbation","title":"<code>_input_perturbation(inputs)</code>","text":"<p>Apply small perturbation on inputs to make the in- and out- distribution samples more separable. See original paper for more information (section 2.2) https://arxiv.org/abs/1807.03888</p> <p>Parameters:</p> Name Type Description Default <code>inputs</code> <code>TensorType</code> <p>input samples</p> required <p>Returns:</p> Name Type Description <code>TensorType</code> <code>TensorType</code> <p>Perturbed inputs</p> Source code in <code>oodeel/methods/mahalanobis.py</code> <pre><code>def _input_perturbation(self, inputs: TensorType) -&gt; TensorType:\n\"\"\"\n    Apply small perturbation on inputs to make the in- and out- distribution\n    samples more separable.\n    See original paper for more information (section 2.2)\n    https://arxiv.org/abs/1807.03888\n\n    Args:\n        inputs (TensorType): input samples\n\n    Returns:\n        TensorType: Perturbed inputs\n    \"\"\"\n\n    def __loss_fn(inputs: TensorType) -&gt; TensorType:\n\"\"\"\n        Loss function for the input perturbation.\n\n        Args:\n            inputs (TensorType): input samples\n\n        Returns:\n            TensorType: loss value\n        \"\"\"\n        # extract features\n        out_features, _ = self.feature_extractor.predict(inputs, detach=False)\n        out_features = self.op.flatten(out_features[0])\n        # get mahalanobis score for the class maximizing it\n        gaussian_score = self._mahalanobis_score(out_features)\n        log_probs_f = self.op.max(gaussian_score, dim=1)\n        return self.op.mean(-log_probs_f)\n\n    # compute gradient\n    gradient = self.op.gradient(__loss_fn, inputs)\n    gradient = self.op.sign(gradient)\n\n    inputs_p = inputs - self.eps * gradient\n    return inputs_p\n</code></pre>"},{"location":"api/methods/#oodeel.methods.mahalanobis.Mahalanobis._mahalanobis_score","title":"<code>_mahalanobis_score(out_features)</code>","text":"<p>Mahalanobis distance-based confidence score. For each test sample, it computes the log of the probability densities of some observations (assuming a normal distribution) using the mahalanobis distance with respect to every class-conditional distributions.</p> <p>Parameters:</p> Name Type Description Default <code>out_features</code> <code>TensorType</code> <p>test samples features</p> required <p>Returns:</p> Name Type Description <code>TensorType</code> <code>TensorType</code> <p>confidence scores (conditionally to each class)</p> Source code in <code>oodeel/methods/mahalanobis.py</code> <pre><code>def _mahalanobis_score(self, out_features: TensorType) -&gt; TensorType:\n\"\"\"\n    Mahalanobis distance-based confidence score. For each test sample, it computes\n    the log of the probability densities of some observations (assuming a\n    normal distribution) using the mahalanobis distance with respect to every\n    class-conditional distributions.\n\n    Args:\n        out_features (TensorType): test samples features\n\n    Returns:\n        TensorType: confidence scores (conditionally to each class)\n    \"\"\"\n    gaussian_scores = list()\n    # compute scores conditionally to each class\n    for cls in self._classes:\n        # center features wrt class-cond dist.\n        mu = self._mus[cls]\n        zero_f = out_features - mu\n        # gaussian log prob density (mahalanobis)\n        log_probs_f = -0.5 * self.op.diag(\n            self.op.matmul(\n                self.op.matmul(zero_f, self._pinv_cov), self.op.t(zero_f)\n            )\n        )\n        gaussian_scores.append(self.op.reshape(log_probs_f, (-1, 1)))\n    # concatenate scores\n    gaussian_score = self.op.cat(gaussian_scores, 1)\n    return gaussian_score\n</code></pre>"},{"location":"api/methods/#oodeel.methods.mahalanobis.Mahalanobis._score_tensor","title":"<code>_score_tensor(inputs)</code>","text":"<p>Computes an OOD score for input samples \"inputs\" based on the mahalanobis distance with respect to the closest class-conditional Gaussian distribution.</p> <p>Parameters:</p> Name Type Description Default <code>inputs</code> <code>TensorType</code> <p>input samples</p> required <p>Returns:</p> Type Description <code>Tuple[np.ndarray]</code> <p>Tuple[np.ndarray]: scores, logits</p> Source code in <code>oodeel/methods/mahalanobis.py</code> <pre><code>def _score_tensor(self, inputs: TensorType) -&gt; Tuple[np.ndarray]:\n\"\"\"\n    Computes an OOD score for input samples \"inputs\" based on the mahalanobis\n    distance with respect to the closest class-conditional Gaussian distribution.\n\n    Args:\n        inputs (TensorType): input samples\n\n    Returns:\n        Tuple[np.ndarray]: scores, logits\n    \"\"\"\n    # input preprocessing (perturbation)\n    if self.eps &gt; 0:\n        inputs_p = self._input_perturbation(inputs)\n    else:\n        inputs_p = inputs\n\n    # mahalanobis score on perturbed inputs\n    features_p, _ = self.feature_extractor.predict_tensor(inputs_p)\n    features_p = self.op.flatten(features_p[0])\n    gaussian_score_p = self._mahalanobis_score(features_p)\n\n    # take the highest score for each sample\n    gaussian_score_p = self.op.max(gaussian_score_p, dim=1)\n    return -self.op.convert_to_numpy(gaussian_score_p)\n</code></pre>"},{"location":"api/methods/#oodeel.methods.ODIN","title":"<code>ODIN</code>","text":"<p>         Bases: <code>OODBaseDetector</code></p> <p>\"Enhancing The Reliability of Out-of-distribution Image Detection in Neural Networks\" http://arxiv.org/abs/1706.02690</p> <p>Parameters:</p> Name Type Description Default <code>temperature</code> <code>float</code> <p>Temperature parameter. Defaults to 1000.</p> <code>1000</code> <code>noise</code> <code>float</code> <p>Perturbation noise. Defaults to 0.014.</p> <code>0.014</code> <code>use_react</code> <code>bool</code> <p>if true, apply ReAct method by clipping penultimate activations under a threshold value.</p> <code>False</code> <code>react_quantile</code> <code>Optional[float]</code> <p>q value in the range [0, 1] used to compute the react clipping threshold defined as the q-th quantile penultimate layer activations. Defaults to 0.8.</p> <code>0.8</code> Source code in <code>oodeel/methods/odin.py</code> <pre><code>class ODIN(OODBaseDetector):\n\"\"\" \"Enhancing The Reliability of Out-of-distribution Image Detection\n    in Neural Networks\"\n    http://arxiv.org/abs/1706.02690\n\n    Args:\n        temperature (float, optional): Temperature parameter. Defaults to 1000.\n        noise (float, optional): Perturbation noise. Defaults to 0.014.\n        use_react (bool): if true, apply ReAct method by clipping penultimate\n            activations under a threshold value.\n        react_quantile (Optional[float]): q value in the range [0, 1] used to compute\n            the react clipping threshold defined as the q-th quantile penultimate layer\n            activations. Defaults to 0.8.\n    \"\"\"\n\n    def __init__(\n        self,\n        temperature: float = 1000,\n        noise: float = 0.014,\n        use_react: bool = False,\n        use_scale: bool = False,\n        use_ash: bool = False,\n        react_quantile: float = 0.8,\n        scale_percentile: float = 0.85,\n        ash_percentile: float = 0.90,\n    ):\n        self.temperature = temperature\n        super().__init__(\n            use_react=use_react,\n            use_scale=use_scale,\n            use_ash=use_ash,\n            react_quantile=react_quantile,\n            scale_percentile=scale_percentile,\n            ash_percentile=ash_percentile,\n        )\n        self.noise = noise\n\n    def _score_tensor(self, inputs: TensorType) -&gt; Tuple[np.ndarray]:\n\"\"\"\n        Computes an OOD score for input samples \"inputs\" based on\n        the distance to nearest neighbors in the feature space of self.model\n\n        Args:\n            inputs (TensorType): input samples to score\n\n        Returns:\n            Tuple[np.ndarray]: scores, logits\n        \"\"\"\n        if self.feature_extractor.backend == \"torch\":\n            inputs = inputs.to(self.feature_extractor._device)\n        x = self.input_perturbation(inputs)\n        _, logits = self.feature_extractor.predict_tensor(x)\n        logits_s = logits / self.temperature\n        probits = self.op.softmax(logits_s)\n        probits = self.op.convert_to_numpy(probits)\n        scores = -np.max(probits, axis=1)\n        return scores\n\n    def input_perturbation(self, inputs: TensorType) -&gt; TensorType:\n\"\"\"Apply a small perturbation over inputs to increase their softmax score.\n        See ODIN paper for more information (section 3):\n        http://arxiv.org/abs/1706.02690\n\n        Args:\n            inputs (TensorType): input samples to score\n\n        Returns:\n            TensorType: Perturbed inputs\n        \"\"\"\n        preds = self.feature_extractor.model(inputs)\n        outputs = self.op.argmax(preds, dim=1)\n        gradients = self.op.gradient(self._temperature_loss, inputs, outputs)\n        inputs_p = inputs - self.noise * self.op.sign(gradients)\n        return inputs_p\n\n    def _temperature_loss(self, inputs: TensorType, labels: TensorType) -&gt; TensorType:\n\"\"\"Compute the tempered cross-entropy loss.\n\n        Args:\n            inputs (TensorType): the inputs of the model.\n            labels (TensorType): the labels to fit on.\n\n        Returns:\n            TensorType: the cross-entropy loss.\n        \"\"\"\n        preds = self.feature_extractor.model(inputs) / self.temperature\n        loss = self.op.CrossEntropyLoss(reduction=\"sum\")(inputs=preds, targets=labels)\n        return loss\n\n    def _fit_to_dataset(self, fit_dataset: DatasetType) -&gt; None:\n\"\"\"\n        Fits the OOD detector to fit_dataset.\n\n        Args:\n            fit_dataset: dataset to fit the OOD detector on\n        \"\"\"\n        pass\n\n    @property\n    def requires_to_fit_dataset(self) -&gt; bool:\n\"\"\"\n        Whether an OOD detector needs a `fit_dataset` argument in the fit function.\n\n        Returns:\n            bool: True if `fit_dataset` is required else False.\n        \"\"\"\n        return False\n\n    @property\n    def requires_internal_features(self) -&gt; bool:\n\"\"\"\n        Whether an OOD detector acts on internal model features.\n\n        Returns:\n            bool: True if the detector perform computations on an intermediate layer\n            else False.\n        \"\"\"\n        return False\n</code></pre>"},{"location":"api/methods/#oodeel.methods.odin.ODIN.requires_internal_features","title":"<code>requires_internal_features: bool</code>  <code>property</code>","text":"<p>Whether an OOD detector acts on internal model features.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the detector perform computations on an intermediate layer</p> <code>bool</code> <p>else False.</p>"},{"location":"api/methods/#oodeel.methods.odin.ODIN.requires_to_fit_dataset","title":"<code>requires_to_fit_dataset: bool</code>  <code>property</code>","text":"<p>Whether an OOD detector needs a <code>fit_dataset</code> argument in the fit function.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if <code>fit_dataset</code> is required else False.</p>"},{"location":"api/methods/#oodeel.methods.odin.ODIN._fit_to_dataset","title":"<code>_fit_to_dataset(fit_dataset)</code>","text":"<p>Fits the OOD detector to fit_dataset.</p> <p>Parameters:</p> Name Type Description Default <code>fit_dataset</code> <code>DatasetType</code> <p>dataset to fit the OOD detector on</p> required Source code in <code>oodeel/methods/odin.py</code> <pre><code>def _fit_to_dataset(self, fit_dataset: DatasetType) -&gt; None:\n\"\"\"\n    Fits the OOD detector to fit_dataset.\n\n    Args:\n        fit_dataset: dataset to fit the OOD detector on\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/methods/#oodeel.methods.odin.ODIN._score_tensor","title":"<code>_score_tensor(inputs)</code>","text":"<p>Computes an OOD score for input samples \"inputs\" based on the distance to nearest neighbors in the feature space of self.model</p> <p>Parameters:</p> Name Type Description Default <code>inputs</code> <code>TensorType</code> <p>input samples to score</p> required <p>Returns:</p> Type Description <code>Tuple[np.ndarray]</code> <p>Tuple[np.ndarray]: scores, logits</p> Source code in <code>oodeel/methods/odin.py</code> <pre><code>def _score_tensor(self, inputs: TensorType) -&gt; Tuple[np.ndarray]:\n\"\"\"\n    Computes an OOD score for input samples \"inputs\" based on\n    the distance to nearest neighbors in the feature space of self.model\n\n    Args:\n        inputs (TensorType): input samples to score\n\n    Returns:\n        Tuple[np.ndarray]: scores, logits\n    \"\"\"\n    if self.feature_extractor.backend == \"torch\":\n        inputs = inputs.to(self.feature_extractor._device)\n    x = self.input_perturbation(inputs)\n    _, logits = self.feature_extractor.predict_tensor(x)\n    logits_s = logits / self.temperature\n    probits = self.op.softmax(logits_s)\n    probits = self.op.convert_to_numpy(probits)\n    scores = -np.max(probits, axis=1)\n    return scores\n</code></pre>"},{"location":"api/methods/#oodeel.methods.odin.ODIN._temperature_loss","title":"<code>_temperature_loss(inputs, labels)</code>","text":"<p>Compute the tempered cross-entropy loss.</p> <p>Parameters:</p> Name Type Description Default <code>inputs</code> <code>TensorType</code> <p>the inputs of the model.</p> required <code>labels</code> <code>TensorType</code> <p>the labels to fit on.</p> required <p>Returns:</p> Name Type Description <code>TensorType</code> <code>TensorType</code> <p>the cross-entropy loss.</p> Source code in <code>oodeel/methods/odin.py</code> <pre><code>def _temperature_loss(self, inputs: TensorType, labels: TensorType) -&gt; TensorType:\n\"\"\"Compute the tempered cross-entropy loss.\n\n    Args:\n        inputs (TensorType): the inputs of the model.\n        labels (TensorType): the labels to fit on.\n\n    Returns:\n        TensorType: the cross-entropy loss.\n    \"\"\"\n    preds = self.feature_extractor.model(inputs) / self.temperature\n    loss = self.op.CrossEntropyLoss(reduction=\"sum\")(inputs=preds, targets=labels)\n    return loss\n</code></pre>"},{"location":"api/methods/#oodeel.methods.odin.ODIN.input_perturbation","title":"<code>input_perturbation(inputs)</code>","text":"<p>Apply a small perturbation over inputs to increase their softmax score. See ODIN paper for more information (section 3): http://arxiv.org/abs/1706.02690</p> <p>Parameters:</p> Name Type Description Default <code>inputs</code> <code>TensorType</code> <p>input samples to score</p> required <p>Returns:</p> Name Type Description <code>TensorType</code> <code>TensorType</code> <p>Perturbed inputs</p> Source code in <code>oodeel/methods/odin.py</code> <pre><code>def input_perturbation(self, inputs: TensorType) -&gt; TensorType:\n\"\"\"Apply a small perturbation over inputs to increase their softmax score.\n    See ODIN paper for more information (section 3):\n    http://arxiv.org/abs/1706.02690\n\n    Args:\n        inputs (TensorType): input samples to score\n\n    Returns:\n        TensorType: Perturbed inputs\n    \"\"\"\n    preds = self.feature_extractor.model(inputs)\n    outputs = self.op.argmax(preds, dim=1)\n    gradients = self.op.gradient(self._temperature_loss, inputs, outputs)\n    inputs_p = inputs - self.noise * self.op.sign(gradients)\n    return inputs_p\n</code></pre>"},{"location":"api/methods/#oodeel.methods.RMDS","title":"<code>RMDS</code>","text":"<p>         Bases: <code>Mahalanobis</code></p> <p>\"A Simple Fix to Mahalanobis Distance for Improving Near-OOD Detection\" https://arxiv.org/abs/2106.09022</p> <p>Parameters:</p> Name Type Description Default <code>eps</code> <code>float</code> <p>magnitude for gradient based input perturbation. Defaults to 0.02.</p> <code>0.002</code> Source code in <code>oodeel/methods/rmds.py</code> <pre><code>class RMDS(Mahalanobis):\n\"\"\"\n    \"A Simple Fix to Mahalanobis Distance for Improving Near-OOD Detection\"\n    https://arxiv.org/abs/2106.09022\n\n    Args:\n        eps (float): magnitude for gradient based input perturbation.\n            Defaults to 0.02.\n    \"\"\"\n\n    def __init__(self, eps: float = 0.002):\n        super().__init__(eps=eps)\n\n    def _fit_to_dataset(self, fit_dataset: DatasetType) -&gt; None:\n\"\"\"\n        Constructs the per class means and the covariance matrix,\n        as well as the background mean and covariance matrix,\n        from ID data \"fit_dataset\".\n        The means and pseudo-inverses of the covariance matrices\n        will be used for RMDS score computation.\n\n        Args:\n            fit_dataset (Union[TensorType, DatasetType]): input dataset (ID)\n        \"\"\"\n        # means and pseudo-inverse of the mean convariance matrix from Mahalanobis\n        super()._fit_to_dataset(fit_dataset)\n\n        # extract features\n        features, _ = self.feature_extractor.predict(fit_dataset)\n\n        # compute background mu and cov\n        _features_bg = self.op.flatten(features[0])\n        mu_bg = self.op.mean(_features_bg, dim=0)\n        _zero_f_bg = _features_bg - mu_bg\n        cov_bg = self.op.matmul(self.op.t(_zero_f_bg), _zero_f_bg) / _zero_f_bg.shape[0]\n\n        # background mu and pseudo-inverse of the mean covariance matrices\n        self._mu_bg = mu_bg\n        self._pinv_cov_bg = self.op.pinv(cov_bg)\n\n    def _score_tensor(self, inputs: TensorType) -&gt; Tuple[np.ndarray]:\n\"\"\"\n        Computes an OOD score for input samples \"inputs\" based on the RMDS\n        distance with respect to the closest class-conditional Gaussian distribution,\n        and the background distribution.\n\n        Args:\n            inputs (TensorType): input samples\n\n        Returns:\n            Tuple[np.ndarray]: scores, logits\n        \"\"\"\n        # input preprocessing (perturbation)\n        if self.eps &gt; 0:\n            inputs_p = self._input_perturbation(inputs)\n        else:\n            inputs_p = inputs\n\n        # mahalanobis score on perturbed inputs\n        features_p, _ = self.feature_extractor.predict_tensor(inputs_p)\n        features_p = self.op.flatten(features_p[0])\n        gaussian_score_p = self._mahalanobis_score(features_p)\n\n        # background score on perturbed inputs\n        gaussian_score_bg = self._background_score(features_p)\n\n        # take the highest score for each sample\n        gaussian_score_corrected = self.op.max(\n            gaussian_score_p - gaussian_score_bg, dim=1\n        )\n        return -self.op.convert_to_numpy(gaussian_score_corrected)\n\n    def _background_score(self, out_features: TensorType) -&gt; TensorType:\n\"\"\"\n        Mahalanobis distance-based background score. For each test sample, it computes\n        the log of the probability densities of some observations (assuming a\n        normal distribution) using the mahalanobis distance with respect to the\n        background distribution.\n\n        Args:\n            out_features (TensorType): test samples features\n\n        Returns:\n            TensorType: confidence scores (with respect to the background distribution)\n        \"\"\"\n        zero_f = out_features - self._mu_bg\n        # gaussian log prob density (mahalanobis)\n        log_probs_f = -0.5 * self.op.diag(\n            self.op.matmul(self.op.matmul(zero_f, self._pinv_cov_bg), self.op.t(zero_f))\n        )\n        gaussian_score = self.op.reshape(log_probs_f, (-1, 1))\n        return gaussian_score\n</code></pre>"},{"location":"api/methods/#oodeel.methods.rmds.RMDS._background_score","title":"<code>_background_score(out_features)</code>","text":"<p>Mahalanobis distance-based background score. For each test sample, it computes the log of the probability densities of some observations (assuming a normal distribution) using the mahalanobis distance with respect to the background distribution.</p> <p>Parameters:</p> Name Type Description Default <code>out_features</code> <code>TensorType</code> <p>test samples features</p> required <p>Returns:</p> Name Type Description <code>TensorType</code> <code>TensorType</code> <p>confidence scores (with respect to the background distribution)</p> Source code in <code>oodeel/methods/rmds.py</code> <pre><code>def _background_score(self, out_features: TensorType) -&gt; TensorType:\n\"\"\"\n    Mahalanobis distance-based background score. For each test sample, it computes\n    the log of the probability densities of some observations (assuming a\n    normal distribution) using the mahalanobis distance with respect to the\n    background distribution.\n\n    Args:\n        out_features (TensorType): test samples features\n\n    Returns:\n        TensorType: confidence scores (with respect to the background distribution)\n    \"\"\"\n    zero_f = out_features - self._mu_bg\n    # gaussian log prob density (mahalanobis)\n    log_probs_f = -0.5 * self.op.diag(\n        self.op.matmul(self.op.matmul(zero_f, self._pinv_cov_bg), self.op.t(zero_f))\n    )\n    gaussian_score = self.op.reshape(log_probs_f, (-1, 1))\n    return gaussian_score\n</code></pre>"},{"location":"api/methods/#oodeel.methods.rmds.RMDS._fit_to_dataset","title":"<code>_fit_to_dataset(fit_dataset)</code>","text":"<p>Constructs the per class means and the covariance matrix, as well as the background mean and covariance matrix, from ID data \"fit_dataset\". The means and pseudo-inverses of the covariance matrices will be used for RMDS score computation.</p> <p>Parameters:</p> Name Type Description Default <code>fit_dataset</code> <code>Union[TensorType, DatasetType]</code> <p>input dataset (ID)</p> required Source code in <code>oodeel/methods/rmds.py</code> <pre><code>def _fit_to_dataset(self, fit_dataset: DatasetType) -&gt; None:\n\"\"\"\n    Constructs the per class means and the covariance matrix,\n    as well as the background mean and covariance matrix,\n    from ID data \"fit_dataset\".\n    The means and pseudo-inverses of the covariance matrices\n    will be used for RMDS score computation.\n\n    Args:\n        fit_dataset (Union[TensorType, DatasetType]): input dataset (ID)\n    \"\"\"\n    # means and pseudo-inverse of the mean convariance matrix from Mahalanobis\n    super()._fit_to_dataset(fit_dataset)\n\n    # extract features\n    features, _ = self.feature_extractor.predict(fit_dataset)\n\n    # compute background mu and cov\n    _features_bg = self.op.flatten(features[0])\n    mu_bg = self.op.mean(_features_bg, dim=0)\n    _zero_f_bg = _features_bg - mu_bg\n    cov_bg = self.op.matmul(self.op.t(_zero_f_bg), _zero_f_bg) / _zero_f_bg.shape[0]\n\n    # background mu and pseudo-inverse of the mean covariance matrices\n    self._mu_bg = mu_bg\n    self._pinv_cov_bg = self.op.pinv(cov_bg)\n</code></pre>"},{"location":"api/methods/#oodeel.methods.rmds.RMDS._score_tensor","title":"<code>_score_tensor(inputs)</code>","text":"<p>Computes an OOD score for input samples \"inputs\" based on the RMDS distance with respect to the closest class-conditional Gaussian distribution, and the background distribution.</p> <p>Parameters:</p> Name Type Description Default <code>inputs</code> <code>TensorType</code> <p>input samples</p> required <p>Returns:</p> Type Description <code>Tuple[np.ndarray]</code> <p>Tuple[np.ndarray]: scores, logits</p> Source code in <code>oodeel/methods/rmds.py</code> <pre><code>def _score_tensor(self, inputs: TensorType) -&gt; Tuple[np.ndarray]:\n\"\"\"\n    Computes an OOD score for input samples \"inputs\" based on the RMDS\n    distance with respect to the closest class-conditional Gaussian distribution,\n    and the background distribution.\n\n    Args:\n        inputs (TensorType): input samples\n\n    Returns:\n        Tuple[np.ndarray]: scores, logits\n    \"\"\"\n    # input preprocessing (perturbation)\n    if self.eps &gt; 0:\n        inputs_p = self._input_perturbation(inputs)\n    else:\n        inputs_p = inputs\n\n    # mahalanobis score on perturbed inputs\n    features_p, _ = self.feature_extractor.predict_tensor(inputs_p)\n    features_p = self.op.flatten(features_p[0])\n    gaussian_score_p = self._mahalanobis_score(features_p)\n\n    # background score on perturbed inputs\n    gaussian_score_bg = self._background_score(features_p)\n\n    # take the highest score for each sample\n    gaussian_score_corrected = self.op.max(\n        gaussian_score_p - gaussian_score_bg, dim=1\n    )\n    return -self.op.convert_to_numpy(gaussian_score_corrected)\n</code></pre>"},{"location":"api/methods/#oodeel.methods.SHE","title":"<code>SHE</code>","text":"<p>         Bases: <code>OODBaseDetector</code></p> <p>\"Out-of-Distribution Detection based on In-Distribution Data Patterns Memorization with Modern Hopfield Energy\" link</p> <p>This method first computes the mean of the internal layer representation of ID data for each ID class. This mean is seen as the average of the ID activation patterns as defined in the original paper. The method then returns the maximum value of the dot product between the internal layer representation of the input and the average patterns, which is a simplified version of Hopfield energy as defined in the original paper.</p> <p>Remarks: *   An input perturbation is applied in the same way as in Mahalanobis score *   The original paper only considers the penultimate layer of the neural network, while we aggregate the results of multiple layers after normalizing by the dimension of each vector (the activation vector for dense layers, and the average pooling of the feature map for convolutional layers).</p> <p>Parameters:</p> Name Type Description Default <code>eps</code> <code>float</code> <p>magnitude for gradient based input perturbation. Defaults to 0.0014.</p> <code>0.0014</code> Source code in <code>oodeel/methods/she.py</code> <pre><code>class SHE(OODBaseDetector):\n\"\"\"\n    \"Out-of-Distribution Detection based on In-Distribution Data Patterns Memorization\n    with Modern Hopfield Energy\"\n    [link](https://openreview.net/forum?id=KkazG4lgKL)\n\n    This method first computes the mean of the internal layer representation of ID data\n    for each ID class. This mean is seen as the average of the ID activation patterns\n    as defined in the original paper.\n    The method then returns the maximum value of the dot product between the internal\n    layer representation of the input and the average patterns, which is a simplified\n    version of Hopfield energy as defined in the original paper.\n\n    Remarks:\n    *   An input perturbation is applied in the same way as in Mahalanobis score\n    *   The original paper only considers the penultimate layer of the neural\n    network, while we aggregate the results of multiple layers after normalizing by\n    the dimension of each vector (the activation vector for dense layers, and the\n    average pooling of the feature map for convolutional layers).\n\n    Args:\n        eps (float): magnitude for gradient based input perturbation.\n            Defaults to 0.0014.\n    \"\"\"\n\n    def __init__(\n        self,\n        eps: float = 0.0014,\n    ):\n        super().__init__()\n        self.eps = eps\n        self.postproc_fns = None\n\n    def _postproc_feature_maps(self, feature_map):\n        if len(feature_map.shape) &gt; 2:\n            feature_map = self.op.avg_pool_2d(feature_map)\n        return self.op.flatten(feature_map)\n\n    def _fit_to_dataset(\n        self,\n        fit_dataset: Union[TensorType, DatasetType],\n    ) -&gt; None:\n\"\"\"\n        Compute the means of the input dataset in the activation space of the selected\n        layers. The means are computed for each class in the dataset.\n\n        Args:\n            fit_dataset (Union[TensorType, DatasetType]): input dataset (ID) to\n                construct the index with.\n            ood_dataset (Union[TensorType, DatasetType]): OOD dataset to tune the\n                aggregation coefficients.\n        \"\"\"\n        self.postproc_fns = [\n            self._postproc_feature_maps\n            for i in range(len(self.feature_extractor.feature_layers_id))\n        ]\n\n        features, infos = self.feature_extractor.predict(\n            fit_dataset, postproc_fns=self.postproc_fns\n        )\n\n        labels = infos[\"labels\"]\n        preds = self.op.argmax(infos[\"logits\"], dim=-1)\n        preds = self.op.convert_to_numpy(preds)\n\n        # unique sorted classes\n        self._classes = np.sort(np.unique(self.op.convert_to_numpy(labels)))\n        labels = self.op.convert_to_numpy(labels)\n\n        self._mus = list()\n        for feature in features:\n            mus_f = list()\n            for cls in self._classes:\n                indexes = np.equal(labels, cls) &amp; np.equal(preds, cls)\n                _features_cls = feature[indexes]\n                mus_f.append(\n                    self.op.unsqueeze(self.op.mean(_features_cls, dim=0), dim=0)\n                )\n            self._mus.append(self.op.permute(self.op.cat(mus_f), (1, 0)))\n\n    def _score_tensor(self, inputs: TensorType) -&gt; np.ndarray:\n\"\"\"\n        Computes an OOD score for input samples \"inputs\" based on\n        the aggregation of neural mean discrepancies from different layers.\n\n        Args:\n            inputs: input samples to score\n\n        Returns:\n            scores\n        \"\"\"\n\n        inputs_p = self._input_perturbation(inputs)\n        features, logits = self.feature_extractor.predict_tensor(\n            inputs_p, postproc_fns=self.postproc_fns\n        )\n\n        scores = self._get_she_output(features)\n\n        return -self.op.convert_to_numpy(scores)\n\n    def _get_she_output(self, features):\n        scores = None\n        for feature, mus_f in zip(features, self._mus):\n            she = self.op.matmul(self.op.squeeze(feature), mus_f) / feature.shape[1]\n            she = self.op.max(she, dim=1)\n            scores = she if scores is None else she + scores\n        return scores\n\n    def _input_perturbation(self, inputs: TensorType) -&gt; TensorType:\n\"\"\"\n        Apply small perturbation on inputs to make the in- and out- distribution\n        samples more separable.\n\n        Args:\n            inputs (TensorType): input samples\n\n        Returns:\n            TensorType: Perturbed inputs\n        \"\"\"\n\n        def __loss_fn(inputs: TensorType) -&gt; TensorType:\n\"\"\"\n            Loss function for the input perturbation.\n\n            Args:\n                inputs (TensorType): input samples\n\n            Returns:\n                TensorType: loss value\n            \"\"\"\n            # extract features\n            out_features, _ = self.feature_extractor.predict(\n                inputs, detach=False, postproc_fns=self.postproc_fns\n            )\n            # get mahalanobis score for the class maximizing it\n            she_score = self._get_she_output(out_features)\n            log_probs_f = self.op.log(she_score)\n            return self.op.mean(log_probs_f)\n\n        # compute gradient\n        gradient = self.op.gradient(__loss_fn, inputs)\n        gradient = self.op.sign(gradient)\n\n        inputs_p = inputs - self.eps * gradient\n        return inputs_p\n\n    @property\n    def requires_to_fit_dataset(self) -&gt; bool:\n\"\"\"\n        Whether an OOD detector needs a `fit_dataset` argument in the fit function.\n\n        Returns:\n            bool: True if `fit_dataset` is required else False.\n        \"\"\"\n        return True\n\n    @property\n    def requires_internal_features(self) -&gt; bool:\n\"\"\"\n        Whether an OOD detector acts on internal model features.\n\n        Returns:\n            bool: True if the detector perform computations on an intermediate layer\n            else False.\n        \"\"\"\n        return True\n</code></pre>"},{"location":"api/methods/#oodeel.methods.she.SHE.requires_internal_features","title":"<code>requires_internal_features: bool</code>  <code>property</code>","text":"<p>Whether an OOD detector acts on internal model features.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the detector perform computations on an intermediate layer</p> <code>bool</code> <p>else False.</p>"},{"location":"api/methods/#oodeel.methods.she.SHE.requires_to_fit_dataset","title":"<code>requires_to_fit_dataset: bool</code>  <code>property</code>","text":"<p>Whether an OOD detector needs a <code>fit_dataset</code> argument in the fit function.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if <code>fit_dataset</code> is required else False.</p>"},{"location":"api/methods/#oodeel.methods.she.SHE._fit_to_dataset","title":"<code>_fit_to_dataset(fit_dataset)</code>","text":"<p>Compute the means of the input dataset in the activation space of the selected layers. The means are computed for each class in the dataset.</p> <p>Parameters:</p> Name Type Description Default <code>fit_dataset</code> <code>Union[TensorType, DatasetType]</code> <p>input dataset (ID) to construct the index with.</p> required <code>ood_dataset</code> <code>Union[TensorType, DatasetType]</code> <p>OOD dataset to tune the aggregation coefficients.</p> required Source code in <code>oodeel/methods/she.py</code> <pre><code>def _fit_to_dataset(\n    self,\n    fit_dataset: Union[TensorType, DatasetType],\n) -&gt; None:\n\"\"\"\n    Compute the means of the input dataset in the activation space of the selected\n    layers. The means are computed for each class in the dataset.\n\n    Args:\n        fit_dataset (Union[TensorType, DatasetType]): input dataset (ID) to\n            construct the index with.\n        ood_dataset (Union[TensorType, DatasetType]): OOD dataset to tune the\n            aggregation coefficients.\n    \"\"\"\n    self.postproc_fns = [\n        self._postproc_feature_maps\n        for i in range(len(self.feature_extractor.feature_layers_id))\n    ]\n\n    features, infos = self.feature_extractor.predict(\n        fit_dataset, postproc_fns=self.postproc_fns\n    )\n\n    labels = infos[\"labels\"]\n    preds = self.op.argmax(infos[\"logits\"], dim=-1)\n    preds = self.op.convert_to_numpy(preds)\n\n    # unique sorted classes\n    self._classes = np.sort(np.unique(self.op.convert_to_numpy(labels)))\n    labels = self.op.convert_to_numpy(labels)\n\n    self._mus = list()\n    for feature in features:\n        mus_f = list()\n        for cls in self._classes:\n            indexes = np.equal(labels, cls) &amp; np.equal(preds, cls)\n            _features_cls = feature[indexes]\n            mus_f.append(\n                self.op.unsqueeze(self.op.mean(_features_cls, dim=0), dim=0)\n            )\n        self._mus.append(self.op.permute(self.op.cat(mus_f), (1, 0)))\n</code></pre>"},{"location":"api/methods/#oodeel.methods.she.SHE._input_perturbation","title":"<code>_input_perturbation(inputs)</code>","text":"<p>Apply small perturbation on inputs to make the in- and out- distribution samples more separable.</p> <p>Parameters:</p> Name Type Description Default <code>inputs</code> <code>TensorType</code> <p>input samples</p> required <p>Returns:</p> Name Type Description <code>TensorType</code> <code>TensorType</code> <p>Perturbed inputs</p> Source code in <code>oodeel/methods/she.py</code> <pre><code>def _input_perturbation(self, inputs: TensorType) -&gt; TensorType:\n\"\"\"\n    Apply small perturbation on inputs to make the in- and out- distribution\n    samples more separable.\n\n    Args:\n        inputs (TensorType): input samples\n\n    Returns:\n        TensorType: Perturbed inputs\n    \"\"\"\n\n    def __loss_fn(inputs: TensorType) -&gt; TensorType:\n\"\"\"\n        Loss function for the input perturbation.\n\n        Args:\n            inputs (TensorType): input samples\n\n        Returns:\n            TensorType: loss value\n        \"\"\"\n        # extract features\n        out_features, _ = self.feature_extractor.predict(\n            inputs, detach=False, postproc_fns=self.postproc_fns\n        )\n        # get mahalanobis score for the class maximizing it\n        she_score = self._get_she_output(out_features)\n        log_probs_f = self.op.log(she_score)\n        return self.op.mean(log_probs_f)\n\n    # compute gradient\n    gradient = self.op.gradient(__loss_fn, inputs)\n    gradient = self.op.sign(gradient)\n\n    inputs_p = inputs - self.eps * gradient\n    return inputs_p\n</code></pre>"},{"location":"api/methods/#oodeel.methods.she.SHE._score_tensor","title":"<code>_score_tensor(inputs)</code>","text":"<p>Computes an OOD score for input samples \"inputs\" based on the aggregation of neural mean discrepancies from different layers.</p> <p>Parameters:</p> Name Type Description Default <code>inputs</code> <code>TensorType</code> <p>input samples to score</p> required <p>Returns:</p> Type Description <code>np.ndarray</code> <p>scores</p> Source code in <code>oodeel/methods/she.py</code> <pre><code>def _score_tensor(self, inputs: TensorType) -&gt; np.ndarray:\n\"\"\"\n    Computes an OOD score for input samples \"inputs\" based on\n    the aggregation of neural mean discrepancies from different layers.\n\n    Args:\n        inputs: input samples to score\n\n    Returns:\n        scores\n    \"\"\"\n\n    inputs_p = self._input_perturbation(inputs)\n    features, logits = self.feature_extractor.predict_tensor(\n        inputs_p, postproc_fns=self.postproc_fns\n    )\n\n    scores = self._get_she_output(features)\n\n    return -self.op.convert_to_numpy(scores)\n</code></pre>"},{"location":"api/methods/#oodeel.methods.VIM","title":"<code>VIM</code>","text":"<p>         Bases: <code>OODBaseDetector</code></p> <p>Compute the Virtual Matching Logit (VIM) score. https://arxiv.org/abs/2203.10807</p> <p>This score combines the energy score with a PCA residual score.</p> <p>The energy score is the logarithm of the sum of exponential of logits. The PCA residual score is based on the projection on residual dimensions for principal component analysis.     Residual dimensions are the eigenvectors corresponding to the least eignevalues     (least variance).     Intuitively, this score method assumes that feature representations of ID data     occupy a low dimensional affine subspace $P+c$ of the feature space.     Specifically, the projection of ID data translated by $-c$ on the     orthognoal complement $P^{\\perp}$ is expected to have small norm.     It allows to detect points whose feature representation lie far from the     identified affine subspace, namely those points $x$ such that the     projection on $P^{\\perp}$ of $x-c$ has large norm.</p> <p>Parameters:</p> Name Type Description Default <code>princ_dims</code> <code>Union[int, float]</code> <p>number of principal dimensions of in distribution features to consider. If an int, must be less than the dimension of the feature space. If a float, it must be in [0,1), it represents the ratio of explained variance to consider to determine the number of principal components. Defaults to 0.99.</p> <code>0.99</code> <code>pca_origin</code> <code>str</code> <p>either \"pseudo\" for using $W^{-1}b$ where $W^{-1}$ is the pseudo inverse of the final linear layer applied to bias term (as in the VIM paper), or \"center\" for using the mean of the data in feature space. Defaults to \"pseudo\".</p> <code>'pseudo'</code> Source code in <code>oodeel/methods/vim.py</code> <pre><code>class VIM(OODBaseDetector):\n\"\"\"\n    Compute the Virtual Matching Logit (VIM) score.\n    https://arxiv.org/abs/2203.10807\n\n    This score combines the energy score with a PCA residual score.\n\n    The energy score is the logarithm of the sum of exponential of logits.\n    The PCA residual score is based on the projection on residual dimensions for\n    principal component analysis.\n        Residual dimensions are the eigenvectors corresponding to the least eignevalues\n        (least variance).\n        Intuitively, this score method assumes that feature representations of ID data\n        occupy a low dimensional affine subspace $P+c$ of the feature space.\n        Specifically, the projection of ID data translated by $-c$ on the\n        orthognoal complement $P^{\\\\perp}$ is expected to have small norm.\n        It allows to detect points whose feature representation lie far from the\n        identified affine subspace, namely those points $x$ such that the\n        projection on $P^{\\\\perp}$ of $x-c$ has large norm.\n\n    Args:\n        princ_dims (Union[int, float]): number of principal dimensions of in\n            distribution features to consider. If an int, must be less than the\n            dimension of the feature space.\n            If a float, it must be in [0,1), it represents the ratio of\n            explained variance to consider to determine the number of principal\n            components. Defaults to 0.99.\n        pca_origin (str): either \"pseudo\" for using $W^{-1}b$ where $W^{-1}$ is\n            the pseudo inverse of the final linear layer applied to bias term\n            (as in the VIM paper), or \"center\" for using the mean of the data in\n            feature space. Defaults to \"pseudo\".\n    \"\"\"\n\n    def __init__(\n        self,\n        princ_dims: Union[int, float] = 0.99,\n        pca_origin: str = \"pseudo\",\n    ):\n        super().__init__()\n        self._princ_dim = princ_dims\n        self.pca_origin = pca_origin\n\n    def _fit_to_dataset(self, fit_dataset: Union[TensorType, DatasetType]) -&gt; None:\n\"\"\"\n        Computes principal components of feature representations and store the residual\n        eigenvectors.\n        Computes a scaling factor constant :math:'\\alpha' such that the average scaled\n        residual score (on train) is equal to the average maximum logit score (MLS)\n        score.\n\n        Args:\n            fit_dataset: input dataset (ID) to construct the index with.\n        \"\"\"\n        # extract features from fit dataset\n        all_features_train, info = self.feature_extractor.predict(fit_dataset)\n        features_train = all_features_train[0]\n        logits_train = info[\"logits\"]\n        features_train = self.op.flatten(features_train)\n        self.feature_dim = features_train.shape[1]\n        logits_train = self.op.convert_to_numpy(logits_train)\n\n        # get distribution center for pca projection\n        if self.pca_origin == \"center\":\n            self.center = self.op.mean(features_train, dim=0)\n        elif self.pca_origin == \"pseudo\":\n            # W, b = self.feature_extractor.get_weights(\n            #    self.feature_extractor.feature_layers_id[0]\n            # )\n            W, b = self.feature_extractor.get_weights(-1)\n            W, b = self.op.from_numpy(W), self.op.from_numpy(b.reshape(-1, 1))\n            _W = self.op.t(W) if self.backend == \"tensorflow\" else W\n            self.center = -self.op.reshape(self.op.matmul(self.op.pinv(_W), b), (-1,))\n        else:\n            raise NotImplementedError(\n                'only \"center\" and \"pseudo\" are available for argument \"pca_origin\"'\n            )\n\n        # compute eigvalues and eigvectors of empirical covariance matrix\n        centered_features = features_train - self.center\n        emp_cov = (\n            self.op.matmul(self.op.t(centered_features), centered_features)\n            / centered_features.shape[0]\n        )\n        eig_vals, eigen_vectors = self.op.eigh(emp_cov)\n        self.eig_vals = self.op.convert_to_numpy(eig_vals)\n\n        # get number of residual dims for pca projection\n        if isinstance(self._princ_dim, int):\n            assert self._princ_dim &lt; self.feature_dim, (\n                f\"if 'princ_dims'(={self._princ_dim}) is an int, it must be less than \"\n                \"feature space dimension ={self.feature_dim})\"\n            )\n            self.res_dim = self.feature_dim - self._princ_dim\n            self._princ_dim = self._princ_dim\n        elif isinstance(self._princ_dim, float):\n            assert (\n                0 &lt;= self._princ_dim and self._princ_dim &lt; 1\n            ), f\"if 'princ_dims'(={self._princ_dim}) is a float, it must be in [0,1)\"\n            explained_variance = np.cumsum(\n                np.flip(self.eig_vals) / np.sum(self.eig_vals)\n            )\n            self._princ_dim = np.where(explained_variance &gt; self._princ_dim)[0][0]\n            self.res_dim = self.feature_dim - self._princ_dim\n\n        # projector on residual space\n        self.res = eigen_vectors[:, : self.res_dim]  # asc. order with eigh\n\n        # compute residual score on training data\n        train_residual_scores = self._compute_residual_score_tensor(features_train)\n        # compute MLS on training data\n        train_mls_scores = np.max(logits_train, axis=-1)\n        # compute scaling factor\n        self.alpha = np.mean(train_mls_scores) / np.mean(train_residual_scores)\n\n    def _compute_residual_score_tensor(self, features: TensorType) -&gt; np.ndarray:\n\"\"\"\n        Computes the norm of the residual projection in the feature space.\n\n        Args:\n            features: input samples to score\n\n        Returns:\n            np.ndarray: scores\n        \"\"\"\n        res_coordinates = self.op.matmul(features - self.center, self.res)\n        # taking the norm of the coordinates, which amounts to the norm of\n        # the projection since the eigenvectors form an orthornomal basis\n        res_norm = self.op.norm(res_coordinates, dim=-1)\n        return self.op.convert_to_numpy(res_norm)\n\n    def _score_tensor(self, inputs: TensorType) -&gt; Tuple[np.ndarray]:\n\"\"\"\n        Computes the VIM score for input samples \"inputs\" as the sum of the energy\n        score and a scaled (PCA) residual norm in the feature space.\n\n        Args:\n            inputs: input samples to score\n\n        Returns:\n            Tuple[np.ndarray]: scores, logits\n        \"\"\"\n        # extract features\n        features, logits = self.feature_extractor.predict_tensor(inputs)\n        features = self.op.flatten(features[0])\n        # vim score\n        res_scores = self._compute_residual_score_tensor(features)\n        logits = self.op.convert_to_numpy(logits)\n        energy_scores = logsumexp(logits, axis=-1)\n        scores = -self.alpha * res_scores + energy_scores\n        return -np.array(scores)\n\n    def plot_spectrum(self) -&gt; None:\n\"\"\"\n        Plot cumulated explained variance wrt the number of principal dimensions.\n        \"\"\"\n        cumul_explained_variance = np.cumsum(self.eig_vals)[::-1]\n        plt.plot(cumul_explained_variance / np.max(cumul_explained_variance))\n        plt.axvline(\n            x=self._princ_dim,\n            color=\"r\",\n            linestyle=\"--\",\n            label=f\"princ_dims = {self._princ_dim} \",\n        )\n        plt.legend()\n        plt.ylabel(\"Residual explained variance\")\n        plt.xlabel(\"Number of principal dimensions\")\n\n    @property\n    def requires_to_fit_dataset(self) -&gt; bool:\n\"\"\"\n        Whether an OOD detector needs a `fit_dataset` argument in the fit function.\n\n        Returns:\n            bool: True if `fit_dataset` is required else False.\n        \"\"\"\n        return True\n\n    @property\n    def requires_internal_features(self) -&gt; bool:\n\"\"\"\n        Whether an OOD detector acts on internal model features.\n\n        Returns:\n            bool: True if the detector perform computations on an intermediate layer\n            else False.\n        \"\"\"\n        return True\n</code></pre>"},{"location":"api/methods/#oodeel.methods.vim.VIM.requires_internal_features","title":"<code>requires_internal_features: bool</code>  <code>property</code>","text":"<p>Whether an OOD detector acts on internal model features.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the detector perform computations on an intermediate layer</p> <code>bool</code> <p>else False.</p>"},{"location":"api/methods/#oodeel.methods.vim.VIM.requires_to_fit_dataset","title":"<code>requires_to_fit_dataset: bool</code>  <code>property</code>","text":"<p>Whether an OOD detector needs a <code>fit_dataset</code> argument in the fit function.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if <code>fit_dataset</code> is required else False.</p>"},{"location":"api/methods/#oodeel.methods.vim.VIM._compute_residual_score_tensor","title":"<code>_compute_residual_score_tensor(features)</code>","text":"<p>Computes the norm of the residual projection in the feature space.</p> <p>Parameters:</p> Name Type Description Default <code>features</code> <code>TensorType</code> <p>input samples to score</p> required <p>Returns:</p> Type Description <code>np.ndarray</code> <p>np.ndarray: scores</p> Source code in <code>oodeel/methods/vim.py</code> <pre><code>def _compute_residual_score_tensor(self, features: TensorType) -&gt; np.ndarray:\n\"\"\"\n    Computes the norm of the residual projection in the feature space.\n\n    Args:\n        features: input samples to score\n\n    Returns:\n        np.ndarray: scores\n    \"\"\"\n    res_coordinates = self.op.matmul(features - self.center, self.res)\n    # taking the norm of the coordinates, which amounts to the norm of\n    # the projection since the eigenvectors form an orthornomal basis\n    res_norm = self.op.norm(res_coordinates, dim=-1)\n    return self.op.convert_to_numpy(res_norm)\n</code></pre>"},{"location":"api/methods/#oodeel.methods.vim.VIM._fit_to_dataset","title":"<code>_fit_to_dataset(fit_dataset)</code>","text":"<p>Computes principal components of feature representations and store the residual eigenvectors. Computes a scaling factor constant :math:'\u0007lpha' such that the average scaled residual score (on train) is equal to the average maximum logit score (MLS) score.</p> <p>Parameters:</p> Name Type Description Default <code>fit_dataset</code> <code>Union[TensorType, DatasetType]</code> <p>input dataset (ID) to construct the index with.</p> required Source code in <code>oodeel/methods/vim.py</code> <pre><code>def _fit_to_dataset(self, fit_dataset: Union[TensorType, DatasetType]) -&gt; None:\n\"\"\"\n    Computes principal components of feature representations and store the residual\n    eigenvectors.\n    Computes a scaling factor constant :math:'\\alpha' such that the average scaled\n    residual score (on train) is equal to the average maximum logit score (MLS)\n    score.\n\n    Args:\n        fit_dataset: input dataset (ID) to construct the index with.\n    \"\"\"\n    # extract features from fit dataset\n    all_features_train, info = self.feature_extractor.predict(fit_dataset)\n    features_train = all_features_train[0]\n    logits_train = info[\"logits\"]\n    features_train = self.op.flatten(features_train)\n    self.feature_dim = features_train.shape[1]\n    logits_train = self.op.convert_to_numpy(logits_train)\n\n    # get distribution center for pca projection\n    if self.pca_origin == \"center\":\n        self.center = self.op.mean(features_train, dim=0)\n    elif self.pca_origin == \"pseudo\":\n        # W, b = self.feature_extractor.get_weights(\n        #    self.feature_extractor.feature_layers_id[0]\n        # )\n        W, b = self.feature_extractor.get_weights(-1)\n        W, b = self.op.from_numpy(W), self.op.from_numpy(b.reshape(-1, 1))\n        _W = self.op.t(W) if self.backend == \"tensorflow\" else W\n        self.center = -self.op.reshape(self.op.matmul(self.op.pinv(_W), b), (-1,))\n    else:\n        raise NotImplementedError(\n            'only \"center\" and \"pseudo\" are available for argument \"pca_origin\"'\n        )\n\n    # compute eigvalues and eigvectors of empirical covariance matrix\n    centered_features = features_train - self.center\n    emp_cov = (\n        self.op.matmul(self.op.t(centered_features), centered_features)\n        / centered_features.shape[0]\n    )\n    eig_vals, eigen_vectors = self.op.eigh(emp_cov)\n    self.eig_vals = self.op.convert_to_numpy(eig_vals)\n\n    # get number of residual dims for pca projection\n    if isinstance(self._princ_dim, int):\n        assert self._princ_dim &lt; self.feature_dim, (\n            f\"if 'princ_dims'(={self._princ_dim}) is an int, it must be less than \"\n            \"feature space dimension ={self.feature_dim})\"\n        )\n        self.res_dim = self.feature_dim - self._princ_dim\n        self._princ_dim = self._princ_dim\n    elif isinstance(self._princ_dim, float):\n        assert (\n            0 &lt;= self._princ_dim and self._princ_dim &lt; 1\n        ), f\"if 'princ_dims'(={self._princ_dim}) is a float, it must be in [0,1)\"\n        explained_variance = np.cumsum(\n            np.flip(self.eig_vals) / np.sum(self.eig_vals)\n        )\n        self._princ_dim = np.where(explained_variance &gt; self._princ_dim)[0][0]\n        self.res_dim = self.feature_dim - self._princ_dim\n\n    # projector on residual space\n    self.res = eigen_vectors[:, : self.res_dim]  # asc. order with eigh\n\n    # compute residual score on training data\n    train_residual_scores = self._compute_residual_score_tensor(features_train)\n    # compute MLS on training data\n    train_mls_scores = np.max(logits_train, axis=-1)\n    # compute scaling factor\n    self.alpha = np.mean(train_mls_scores) / np.mean(train_residual_scores)\n</code></pre>"},{"location":"api/methods/#oodeel.methods.vim.VIM._score_tensor","title":"<code>_score_tensor(inputs)</code>","text":"<p>Computes the VIM score for input samples \"inputs\" as the sum of the energy score and a scaled (PCA) residual norm in the feature space.</p> <p>Parameters:</p> Name Type Description Default <code>inputs</code> <code>TensorType</code> <p>input samples to score</p> required <p>Returns:</p> Type Description <code>Tuple[np.ndarray]</code> <p>Tuple[np.ndarray]: scores, logits</p> Source code in <code>oodeel/methods/vim.py</code> <pre><code>def _score_tensor(self, inputs: TensorType) -&gt; Tuple[np.ndarray]:\n\"\"\"\n    Computes the VIM score for input samples \"inputs\" as the sum of the energy\n    score and a scaled (PCA) residual norm in the feature space.\n\n    Args:\n        inputs: input samples to score\n\n    Returns:\n        Tuple[np.ndarray]: scores, logits\n    \"\"\"\n    # extract features\n    features, logits = self.feature_extractor.predict_tensor(inputs)\n    features = self.op.flatten(features[0])\n    # vim score\n    res_scores = self._compute_residual_score_tensor(features)\n    logits = self.op.convert_to_numpy(logits)\n    energy_scores = logsumexp(logits, axis=-1)\n    scores = -self.alpha * res_scores + energy_scores\n    return -np.array(scores)\n</code></pre>"},{"location":"api/methods/#oodeel.methods.vim.VIM.plot_spectrum","title":"<code>plot_spectrum()</code>","text":"<p>Plot cumulated explained variance wrt the number of principal dimensions.</p> Source code in <code>oodeel/methods/vim.py</code> <pre><code>def plot_spectrum(self) -&gt; None:\n\"\"\"\n    Plot cumulated explained variance wrt the number of principal dimensions.\n    \"\"\"\n    cumul_explained_variance = np.cumsum(self.eig_vals)[::-1]\n    plt.plot(cumul_explained_variance / np.max(cumul_explained_variance))\n    plt.axvline(\n        x=self._princ_dim,\n        color=\"r\",\n        linestyle=\"--\",\n        label=f\"princ_dims = {self._princ_dim} \",\n    )\n    plt.legend()\n    plt.ylabel(\"Residual explained variance\")\n    plt.xlabel(\"Number of principal dimensions\")\n</code></pre>"},{"location":"api/metrics/","title":"Metrics","text":""},{"location":"api/metrics/#oodeel.eval.metrics.bench_metrics","title":"<code>bench_metrics(scores, labels=None, in_value=0, out_value=1, metrics=['auroc', 'fpr95tpr'], threshold=None, step=4)</code>","text":"<p>Compute various common metrics from the OOD detector scores: AUROC, FPR95TPR (or any other similar metric relative to confusion matrix), Detection accuracy and sklearn.metric metrics</p> <p>Parameters:</p> Name Type Description Default <code>scores</code> <code>Union[np.ndarray, Tuple[np.ndarray, np.ndarray]]</code> <p>scores output of the OOD detector to evaluate. If a tuple is provided, the first array is considered in-distribution scores, and the second is considered out-of-distribution scores.</p> required <code>labels</code> <code>Optional[np.ndarray]</code> <p>labels denoting oodness. When scores is a tuple, this argument and the following in_value and out_value are not used. If scores is a np.ndarray, labels are required with in_value and out_value if different from their default values. Defaults to None.</p> <code>None</code> <code>in_value</code> <code>Optional[int]</code> <p>ood label value for in-distribution data. Defaults to 0.</p> <code>0</code> <code>out_value</code> <code>Optional[int]</code> <p>ood label value for out-of-distribution data. Defaults to 1.</p> <code>1</code> <code>metrics</code> <code>Optional[List[str]]</code> <p>list of metrics to compute. Can pass any metric name from sklearn.metric or among \"detect_acc\" and \"\" where  and  are in [\"fpr\", \"tpr\", \"fnr\", \"tnr\"] and  is an integer between 1 and 99. Defaults to [\"auroc\", \"fpr95tpr\"]. <code>['auroc', 'fpr95tpr']</code> <code>threshold</code> <code>Optional[float]</code> <p>Threshold to use when using threshold-dependent metrics. Defaults to None.</p> <code>None</code> <code>step</code> <code>Optional[int]</code> <p>integration step (wrt percentile). Only used for auroc and fpr95tpr. Defaults to 4.</p> <code>4</code> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>Dictionnary of metrics</p> Source code in <code>oodeel/eval/metrics.py</code> <pre><code>def bench_metrics(\n    scores: Union[np.ndarray, tuple],\n    labels: Optional[np.ndarray] = None,\n    in_value: Optional[int] = 0,\n    out_value: Optional[int] = 1,\n    metrics: Optional[list] = [\"auroc\", \"fpr95tpr\"],\n    threshold: Optional[float] = None,\n    step: Optional[int] = 4,\n) -&gt; dict:\n\"\"\"Compute various common metrics from the OOD detector scores:\n    AUROC, FPR95TPR (or any other similar metric relative to confusion matrix),\n    Detection accuracy and sklearn.metric metrics\n\n    Args:\n        scores (Union[np.ndarray, Tuple[np.ndarray, np.ndarray]]): scores output of\n            the OOD detector to evaluate. If a tuple is provided,\n            the first array is considered in-distribution scores, and the second\n            is considered out-of-distribution scores.\n        labels (Optional[np.ndarray], optional): labels denoting oodness. When scores is\n            a tuple, this argument and the following in_value and out_value are not\n            used. If scores is a np.ndarray, labels are required with in_value and\n            out_value if different from their default values.\n            Defaults to None.\n        in_value (Optional[int], optional): ood label value for in-distribution data.\n            Defaults to 0.\n        out_value (Optional[int], optional): ood label value for out-of-distribution\n            data. Defaults to 1.\n        metrics (Optional[List[str]], optional): list of metrics to compute. Can pass\n            any metric name from sklearn.metric or among \"detect_acc\" and\n            \"&lt;aaa&gt;&lt;XX&gt;&lt;bbb&gt;\" where &lt;aaa&gt; and &lt;bbb&gt; are in [\"fpr\", \"tpr\", \"fnr\", \"tnr\"]\n            and &lt;XX&gt; is an integer between 1 and 99. Defaults to [\"auroc\", \"fpr95tpr\"].\n        threshold (Optional[float], optional): Threshold to use when using\n            threshold-dependent metrics. Defaults to None.\n        step (Optional[int], optional): integration step (wrt percentile).\n            Only used for auroc and fpr95tpr. Defaults to 4.\n\n    Returns:\n        dict: Dictionnary of metrics\n    \"\"\"\n    metrics_dict = {}\n\n    if isinstance(scores, np.ndarray):\n        assert labels is not None, (\n            \"Provide labels with scores, or provide a tuple of in-distribution \"\n            \"and out-of-distribution scores arrays\"\n        )\n        labels = np.copy(labels)  # to avoid mutable np.array to be modified\n        labels[labels == in_value] = 0\n        labels[labels == out_value] = 1\n    elif isinstance(scores, tuple):\n        scores_in, scores_out = scores\n        scores = np.concatenate([scores_in, scores_out])\n        labels = np.concatenate([scores_in * 0, scores_out * 0 + 1])\n\n    fpr, tpr, fnr, tnr, acc = get_curve(scores, labels, step)\n\n    for metric in metrics:\n        if isinstance(metric, str):\n            if metric == \"auroc\":\n                if np.__version__ &gt;= \"2.0.0\":\n                    auroc = -np.trapezoid(1.0 - fpr, tpr)\n                else:\n                    auroc = -np.trapz(1.0 - fpr, tpr)\n                metrics_dict[\"auroc\"] = auroc\n\n            elif metric == \"detect_acc\":\n                metrics_dict[\"detect_acc\"] = np.max(acc)\n\n            # compute &lt;aaa&gt;&lt;XX&gt;&lt;bbb&gt; metrics (check docstring for more info)\n            elif (\n                re.search(r\"^(fpr|tpr|fnr|tnr)(\\d{1,2})(fpr|tpr|fnr|tnr)$\", metric)\n                is not None\n            ):\n                count_1_str, thr, count_2_str = re.match(\n                    pattern=r\"^(fpr|tpr|fnr|tnr)(\\d{1,2})(fpr|tpr|fnr|tnr)$\",\n                    string=metric,\n                ).groups()\n                thr = int(thr)\n                count_1, count_2 = locals()[count_1_str], locals()[count_2_str]\n                for i, c2 in enumerate(count_2):\n                    if (count_2_str in [\"fpr\", \"tpr\"] and c2 &lt; thr / 100) or (\n                        count_2_str in [\"tnr\", \"fnr\"] and c2 &gt; thr / 100\n                    ):\n                        ind = i\n                        break\n                metrics_dict[metric] = count_1[ind]\n\n        elif metric.__name__ in sklearn.metrics.__all__:\n            if metric.__name__[:3] == \"roc\":\n                metrics_dict[metric.__name__] = metric(labels, scores)\n            else:\n                if threshold is None:\n                    print(\n                        f\"No threshold is specified for metric {metric.__name__}, \"\n                        \"skipping\"\n                    )\n                else:\n                    oodness = [1 if x &gt; threshold else 0 for x in scores]\n                    metrics_dict[metric.__name__] = metric(labels, oodness)\n\n        else:\n            print(f\"Metric {metric.__name__} not implemented, skipping\")\n\n    return metrics_dict\n</code></pre>"},{"location":"api/metrics/#oodeel.eval.metrics.ftpn","title":"<code>ftpn(scores, labels, threshold)</code>","text":"<p>Computes the number of     * true positives,     * false positives,     * true negatives,     * false negatives, for a given threshold</p> <p>Parameters:</p> Name Type Description Default <code>scores</code> <code>np.ndarray</code> <p>scores output of the OOD detector to evaluate</p> required <code>labels</code> <code>np.ndarray</code> <p>1 if ood else 0</p> required <code>threshold</code> <code>float</code> <p>threshold to use to consider scores as in-distribution or out-of-distribution</p> required <p>Returns:</p> Type Description <code>tuple</code> <p>Tuple[float]: The four metrics</p> Source code in <code>oodeel/eval/metrics.py</code> <pre><code>def ftpn(scores: np.ndarray, labels: np.ndarray, threshold: float) -&gt; tuple:\n\"\"\"Computes the number of\n        * true positives,\n        * false positives,\n        * true negatives,\n        * false negatives,\n    for a given threshold\n\n    Args:\n        scores (np.ndarray): scores output of the OOD detector to evaluate\n        labels (np.ndarray): 1 if ood else 0\n        threshold (float): threshold to use to consider scores\n            as in-distribution or out-of-distribution\n\n    Returns:\n        Tuple[float]: The four metrics\n    \"\"\"\n    pos = np.where(scores &gt;= threshold)\n    neg = np.where(scores &lt; threshold)\n    n_pos = len(pos[0])\n    n_neg = len(neg[0])\n\n    tp = np.sum(labels[pos])\n    fp = n_pos - tp\n    fn = np.sum(labels[neg])\n    tn = n_neg - fn\n\n    return fp, tp, fn, tn\n</code></pre>"},{"location":"api/metrics/#oodeel.eval.metrics.get_curve","title":"<code>get_curve(scores, labels, step=4, return_raw=False)</code>","text":"<p>Computes the     * true positive rate: TP / (TP + FN),     * false positive rate: FP / (FP + TN),     * true negative rate: TN / (FP + TN),     * false negative rate: FN / (TP + FN),     * accuracy: (TN + TP) / (TP + FP + TN + FN), for different threshold values. The values are uniformly distributed among the percentiles, with a step = 4 / scores.shape[0]</p> <p>Parameters:</p> Name Type Description Default <code>scores</code> <code>np.ndarray</code> <p>scores output of the OOD detector to evaluate</p> required <code>labels</code> <code>np.ndarray</code> <p>1 if ood else 0</p> required <code>step</code> <code>Optional[int]</code> <p>integration step (wrt percentile). Defaults to 4.</p> <code>4</code> <code>return_raw</code> <code>Optional[bool]</code> <p>To return all the curves or only the rate curves. Defaults to False.</p> <code>False</code> <p>Returns:</p> Type Description <code>Union[Tuple[tuple, tuple], tuple]</code> <p>Union[Tuple[Tuple[np.ndarray], Tuple[np.ndarray]], Tuple[np.ndarray]]: curves</p> Source code in <code>oodeel/eval/metrics.py</code> <pre><code>def get_curve(\n    scores: np.ndarray,\n    labels: np.ndarray,\n    step: Optional[int] = 4,\n    return_raw: Optional[bool] = False,\n) -&gt; Union[Tuple[tuple, tuple], tuple]:\n\"\"\"Computes the\n        * true positive rate: TP / (TP + FN),\n        * false positive rate: FP / (FP + TN),\n        * true negative rate: TN / (FP + TN),\n        * false negative rate: FN / (TP + FN),\n        * accuracy: (TN + TP) / (TP + FP + TN + FN),\n    for different threshold values. The values are uniformly\n    distributed among the percentiles, with a step = 4 / scores.shape[0]\n\n    Args:\n        scores (np.ndarray): scores output of the OOD detector to evaluate\n        labels (np.ndarray): 1 if ood else 0\n        step (Optional[int], optional): integration step (wrt percentile).\n            Defaults to 4.\n        return_raw (Optional[bool], optional): To return all the curves\n            or only the rate curves. Defaults to False.\n\n    Returns:\n        Union[Tuple[Tuple[np.ndarray], Tuple[np.ndarray]], Tuple[np.ndarray]]: curves\n    \"\"\"\n    tpc = np.array([])\n    fpc = np.array([])\n    tnc = np.array([])\n    fnc = np.array([])\n    thresholds = np.sort(scores)\n    for i in range(1, len(scores), step):\n        fp, tp, fn, tn = ftpn(scores, labels, thresholds[i])\n        tpc = np.append(tpc, tp)\n        fpc = np.append(fpc, fp)\n        tnc = np.append(tnc, tn)\n        fnc = np.append(fnc, fn)\n\n    fpr = np.concatenate([[1.0], fpc / (fpc + tnc), [0.0]])\n    tpr = np.concatenate([[1.0], tpc / (tpc + fnc), [0.0]])\n    tnr = np.concatenate([[0.0], tnc / (fpc + tnc), [1.0]])\n    fnr = np.concatenate([[0.0], fnc / (tpc + fnc), [1.0]])\n    acc = (tnc + tpc) / (tpc + fpc + tnc + fnc)\n\n    if return_raw:\n        return (fpc, tpc, fnc, tnc), (fpr, tpr, fnr, tnr, acc)\n    else:\n        return fpr, tpr, fnr, tnr, acc\n</code></pre>"},{"location":"api/ooddataset/","title":"OOD dataset","text":""},{"location":"api/ooddataset/#oodeel.datasets.ooddataset.OODDataset","title":"<code>OODDataset</code>","text":"<p>         Bases: <code>object</code></p> <p>Class for managing loading and processing of datasets that are to be used for OOD detection. The class encapsulates a dataset like object augmented with OOD related information, and then returns a dataset like object that is suited for scoring or training with the .prepare method.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>Union[DatasetType, tuple, dict, str]</code> <p>The dataset to load. Can be loaded from tensorflow or torch datasets catalog when the str matches one of the datasets. Defaults to Union[DatasetType, tuple, dict, str].</p> required <code>backend</code> <code>str</code> <p>Whether the dataset is to be used for tensorflow  or torch models. Defaults to \"tensorflow\". Alternative: \"torch\".</p> <code>'tensorflow'</code> <code>keys</code> <code>list</code> <p>keys to use for dataset elems. Default to None</p> <code>None</code> <code>load_kwargs</code> <code>dict</code> <p>Additional loading kwargs when loading from tensorflow_datasets catalog. Defaults to {}.</p> <code>{}</code> <code>load_from_tensorflow_datasets</code> <code>bool</code> <p>In the case where if the backend is torch but the user still wants to import from tensorflow_datasets catalog. In that case, tf.Tensor will not be loaded in VRAM and converted as torch.Tensors on the fly. Defaults to False.</p> <code>False</code> <code>input_key</code> <code>str</code> <p>The key of the element/item to consider as the model input tensor. If None, taken as the first key. Defaults to None.</p> <code>None</code> Source code in <code>oodeel/datasets/ooddataset.py</code> <pre><code>class OODDataset(object):\n\"\"\"Class for managing loading and processing of datasets that are to be used for\n    OOD detection. The class encapsulates a dataset like object augmented with OOD\n    related information, and then returns a dataset like object that is suited for\n    scoring or training with the .prepare method.\n\n    Args:\n        dataset_id (Union[DatasetType, tuple, dict, str]): The dataset to load.\n            Can be loaded from tensorflow or torch datasets catalog when the str matches\n            one of the datasets. Defaults to Union[DatasetType, tuple, dict, str].\n        backend (str, optional): Whether the dataset is to be used for tensorflow\n             or torch models. Defaults to \"tensorflow\". Alternative: \"torch\".\n        keys (list, optional): keys to use for dataset elems. Default to None\n        load_kwargs (dict, optional): Additional loading kwargs when loading from\n            tensorflow_datasets catalog. Defaults to {}.\n        load_from_tensorflow_datasets (bool, optional): In the case where if the backend\n            is torch but the user still wants to import from tensorflow_datasets\n            catalog. In that case, tf.Tensor will not be loaded in VRAM and converted as\n            torch.Tensors on the fly. Defaults to False.\n        input_key (str, optional): The key of the element/item to consider as the\n            model input tensor. If None, taken as the first key. Defaults to None.\n    \"\"\"\n\n    def __init__(\n        self,\n        dataset_id: Union[DatasetType, tuple, dict, str],\n        backend: str = \"tensorflow\",\n        keys: Optional[list] = None,\n        load_kwargs: dict = {},\n        load_from_tensorflow_datasets: bool = False,\n        input_key: Optional[str] = None,\n    ):\n        self.backend = backend\n        self.load_from_tensorflow_datasets = load_from_tensorflow_datasets\n\n        # The length of the dataset is kept as attribute to avoid redundant\n        # iterations over self.data\n        self.length = None\n\n        # Set the load parameters for tfds / torchvision\n        if backend == \"tensorflow\":\n            load_kwargs[\"as_supervised\"] = False\n        # Set the channel order depending on the backend\n        if self.backend == \"torch\":\n            if load_from_tensorflow_datasets:\n                from .tf_data_handler import TFDataHandler\n                import tensorflow as tf\n\n                tf.config.set_visible_devices([], \"GPU\")\n                self._data_handler = TFDataHandler()\n                load_kwargs[\"as_supervised\"] = False\n            else:\n                from .torch_data_handler import TorchDataHandler\n\n                self._data_handler = TorchDataHandler()\n            self.channel_order = \"channels_first\"\n        else:\n            from .tf_data_handler import TFDataHandler\n\n            self._data_handler = TFDataHandler()\n            self.channel_order = \"channels_last\"\n\n        self.load_params = load_kwargs\n        # Load the dataset depending on the type of dataset_id\n        self.data = self._data_handler.load_dataset(dataset_id, keys, load_kwargs)\n\n        # Get the length of the elements/items in the dataset\n        self.len_item = self._data_handler.get_item_length(self.data)\n        if self.has_ood_label:\n            self.len_item -= 1\n\n        # Get the key of the tensor to feed the model with\n        if input_key is None:\n            self.input_key = self._data_handler.get_ds_feature_keys(self.data)[0]\n        else:\n            self.input_key = input_key\n\n    def __len__(self) -&gt; int:\n\"\"\"get the length of the dataset.\n\n        Returns:\n            int: length of the dataset\n        \"\"\"\n        if self.length is None:\n            self.length = self._data_handler.get_dataset_length(self.data)\n        return self.length\n\n    @property\n    def has_ood_label(self) -&gt; bool:\n\"\"\"Check if the dataset has an out-of-distribution label.\n\n        Returns:\n            bool: True if data handler has a \"ood_label\" feature key.\n        \"\"\"\n        return self._data_handler.has_feature_key(self.data, \"ood_label\")\n\n    def get_ood_labels(\n        self,\n    ) -&gt; np.ndarray:\n\"\"\"Get ood_labels from self.data if any\n\n        Returns:\n            np.ndarray: array of labels\n        \"\"\"\n        assert self._data_handler.has_feature_key(\n            self.data, \"ood_label\"\n        ), \"The data has no ood_labels\"\n        labels = self._data_handler.get_feature_from_ds(self.data, \"ood_label\")\n        return labels\n\n    def add_out_data(\n        self,\n        out_dataset: Union[\"OODDataset\", DatasetType],\n        in_value: int = 0,\n        out_value: int = 1,\n        resize: Optional[bool] = False,\n        shape: Optional[Tuple[int]] = None,\n    ) -&gt; \"OODDataset\":\n\"\"\"Concatenate two OODDatasets. Useful for scoring on multiple datasets, or\n        training with added out-of-distribution data.\n\n        Args:\n            out_dataset (Union[OODDataset, DatasetType]): dataset of\n                out-of-distribution data\n            in_value (int): ood label value for in-distribution data. Defaults to 0\n            out_value (int): ood label value for out-of-distribution data. Defaults to 1\n            resize (Optional[bool], optional):toggles if input tensors of the\n                datasets have to be resized to have the same shape. Defaults to False.\n            shape (Optional[Tuple[int]], optional):shape to use for resizing input\n                tensors. If None, the tensors are resized with the shape of the\n                in_dataset input tensors. Defaults to None.\n\n        Returns:\n            OODDataset: a Dataset object with the concatenated data\n        \"\"\"\n\n        # Creating an OODDataset object from out_dataset if necessary and make sure\n        # the two OODDatasets have compatible parameters\n        if isinstance(out_dataset, type(self)):\n            out_dataset = out_dataset.data\n        else:\n            out_dataset = OODDataset(out_dataset, backend=self.backend).data\n\n        # Assign the correct ood_label to self.data, depending on out_as_in\n        self.data = self._data_handler.assign_feature_value(\n            self.data, \"ood_label\", in_value\n        )\n        out_dataset = self._data_handler.assign_feature_value(\n            out_dataset, \"ood_label\", out_value\n        )\n\n        # Merge the two underlying Datasets\n        merge_kwargs = (\n            {\"channel_order\": self.channel_order}\n            if self.backend == \"tensorflow\"\n            else {}\n        )\n        data = self._data_handler.merge(\n            self.data,\n            out_dataset,\n            resize=resize,\n            shape=shape,\n            **merge_kwargs,\n        )\n\n        # Create a new OODDataset from the merged Dataset\n        output_ds = OODDataset(\n            dataset_id=data,\n            backend=self.backend,\n        )\n\n        return output_ds\n\n    def split_by_class(\n        self,\n        in_labels: Optional[Union[np.ndarray, list]] = None,\n        out_labels: Optional[Union[np.ndarray, list]] = None,\n    ) -&gt; Optional[Tuple[\"OODDataset\"]]:\n\"\"\"Filter the dataset by assigning ood labels depending on labels\n        value (typically, class id).\n\n        Args:\n            in_labels (Optional[Union[np.ndarray, list]], optional): set of labels\n                to be considered as in-distribution. Defaults to None.\n            out_labels (Optional[Union[np.ndarray, list]], optional): set of labels\n                to be considered as out-of-distribution. Defaults to None.\n\n        Returns:\n            Optional[Tuple[OODDataset]]: Tuple of in-distribution and\n                out-of-distribution OODDatasets\n        \"\"\"\n        # Make sure the dataset has labels\n        assert (in_labels is not None) or (\n            out_labels is not None\n        ), \"specify labels to filter with\"\n        assert self.len_item &gt;= 2, \"the dataset has no labels\"\n\n        # Filter the dataset depending on in_labels and out_labels given\n        if (out_labels is not None) and (in_labels is not None):\n            in_data = self._data_handler.filter_by_feature_value(\n                self.data, \"label\", in_labels\n            )\n            out_data = self._data_handler.filter_by_feature_value(\n                self.data, \"label\", out_labels\n            )\n\n        if out_labels is None:\n            in_data = self._data_handler.filter_by_feature_value(\n                self.data, \"label\", in_labels\n            )\n            out_data = self._data_handler.filter_by_feature_value(\n                self.data, \"label\", in_labels, excluded=True\n            )\n\n        elif in_labels is None:\n            in_data = self._data_handler.filter_by_feature_value(\n                self.data, \"label\", out_labels, excluded=True\n            )\n            out_data = self._data_handler.filter_by_feature_value(\n                self.data, \"label\", out_labels\n            )\n\n        # Return the filtered OODDatasets\n        return (\n            OODDataset(in_data, backend=self.backend),\n            OODDataset(out_data, backend=self.backend),\n        )\n\n    def prepare(\n        self,\n        batch_size: int = 128,\n        preprocess_fn: Optional[Callable] = None,\n        augment_fn: Optional[Callable] = None,\n        with_ood_labels: bool = False,\n        with_labels: bool = True,\n        shuffle: bool = False,\n        **kwargs_prepare,\n    ) -&gt; DatasetType:\n\"\"\"Prepare self.data for scoring or training\n\n        Args:\n            batch_size (int, optional): Batch_size of the returned dataset like object.\n                Defaults to 128.\n            preprocess_fn (Callable, optional): Preprocessing function to apply to\n                the dataset. Defaults to None.\n            augment_fn (Callable, optional): Augment function to be used (when the\n                returned dataset is to be used for training). Defaults to None.\n            with_ood_labels (bool, optional): To return the dataset with ood_labels\n                or not. Defaults to True.\n            with_labels (bool, optional): To return the dataset with labels or not.\n                Defaults to True.\n            shuffle (bool, optional): To shuffle the returned dataset or not.\n                Defaults to False.\n            kwargs_prepare (dict): Additional parameters to be passed to the\n                data_handler.prepare_for_training method.\n\n\n        Returns:\n            DatasetType: prepared dataset\n        \"\"\"\n        # Check if the dataset has at least one of label and ood_label\n        assert (\n            with_ood_labels or with_labels\n        ), \"The dataset must have at least one of label and ood_label\"\n\n        # Check if the dataset has ood_labels when asked to return with_ood_labels\n        if with_ood_labels:\n            assert (\n                self.has_ood_label\n            ), \"Please assign ood labels before preparing with ood_labels\"\n\n        dataset_to_prepare = self.data\n\n        # Making the dataset channel first if the backend is torch\n        if self.backend == \"torch\" and self.load_from_tensorflow_datasets:\n            dataset_to_prepare = self._data_handler.make_channel_first(\n                self.input_key, dataset_to_prepare\n            )\n\n        # # Select the keys to be returned\n        keys = [self.input_key, \"label\", \"ood_label\"]\n        if not with_labels:\n            keys.remove(\"label\")\n        if not with_ood_labels:\n            keys.remove(\"ood_label\")\n\n        # Prepare the dataset for training or scoring\n        dataset = self._data_handler.prepare_for_training(\n            dataset=dataset_to_prepare,\n            batch_size=batch_size,\n            shuffle=shuffle,\n            preprocess_fn=preprocess_fn,\n            augment_fn=augment_fn,\n            output_keys=keys,\n            **kwargs_prepare,\n        )\n\n        return dataset\n</code></pre>"},{"location":"api/ooddataset/#oodeel.datasets.ooddataset.OODDataset.has_ood_label","title":"<code>has_ood_label: bool</code>  <code>property</code>","text":"<p>Check if the dataset has an out-of-distribution label.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if data handler has a \"ood_label\" feature key.</p>"},{"location":"api/ooddataset/#oodeel.datasets.ooddataset.OODDataset.__init__","title":"<code>__init__(dataset_id, backend='tensorflow', keys=None, load_kwargs={}, load_from_tensorflow_datasets=False, input_key=None)</code>","text":"Source code in <code>oodeel/datasets/ooddataset.py</code> <pre><code>def __init__(\n    self,\n    dataset_id: Union[DatasetType, tuple, dict, str],\n    backend: str = \"tensorflow\",\n    keys: Optional[list] = None,\n    load_kwargs: dict = {},\n    load_from_tensorflow_datasets: bool = False,\n    input_key: Optional[str] = None,\n):\n    self.backend = backend\n    self.load_from_tensorflow_datasets = load_from_tensorflow_datasets\n\n    # The length of the dataset is kept as attribute to avoid redundant\n    # iterations over self.data\n    self.length = None\n\n    # Set the load parameters for tfds / torchvision\n    if backend == \"tensorflow\":\n        load_kwargs[\"as_supervised\"] = False\n    # Set the channel order depending on the backend\n    if self.backend == \"torch\":\n        if load_from_tensorflow_datasets:\n            from .tf_data_handler import TFDataHandler\n            import tensorflow as tf\n\n            tf.config.set_visible_devices([], \"GPU\")\n            self._data_handler = TFDataHandler()\n            load_kwargs[\"as_supervised\"] = False\n        else:\n            from .torch_data_handler import TorchDataHandler\n\n            self._data_handler = TorchDataHandler()\n        self.channel_order = \"channels_first\"\n    else:\n        from .tf_data_handler import TFDataHandler\n\n        self._data_handler = TFDataHandler()\n        self.channel_order = \"channels_last\"\n\n    self.load_params = load_kwargs\n    # Load the dataset depending on the type of dataset_id\n    self.data = self._data_handler.load_dataset(dataset_id, keys, load_kwargs)\n\n    # Get the length of the elements/items in the dataset\n    self.len_item = self._data_handler.get_item_length(self.data)\n    if self.has_ood_label:\n        self.len_item -= 1\n\n    # Get the key of the tensor to feed the model with\n    if input_key is None:\n        self.input_key = self._data_handler.get_ds_feature_keys(self.data)[0]\n    else:\n        self.input_key = input_key\n</code></pre>"},{"location":"api/ooddataset/#oodeel.datasets.ooddataset.OODDataset.__len__","title":"<code>__len__()</code>","text":"<p>get the length of the dataset.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>length of the dataset</p> Source code in <code>oodeel/datasets/ooddataset.py</code> <pre><code>def __len__(self) -&gt; int:\n\"\"\"get the length of the dataset.\n\n    Returns:\n        int: length of the dataset\n    \"\"\"\n    if self.length is None:\n        self.length = self._data_handler.get_dataset_length(self.data)\n    return self.length\n</code></pre>"},{"location":"api/ooddataset/#oodeel.datasets.ooddataset.OODDataset.add_out_data","title":"<code>add_out_data(out_dataset, in_value=0, out_value=1, resize=False, shape=None)</code>","text":"<p>Concatenate two OODDatasets. Useful for scoring on multiple datasets, or training with added out-of-distribution data.</p> <p>Parameters:</p> Name Type Description Default <code>out_dataset</code> <code>Union[OODDataset, DatasetType]</code> <p>dataset of out-of-distribution data</p> required <code>in_value</code> <code>int</code> <p>ood label value for in-distribution data. Defaults to 0</p> <code>0</code> <code>out_value</code> <code>int</code> <p>ood label value for out-of-distribution data. Defaults to 1</p> <code>1</code> <code>resize</code> <code>Optional[bool]</code> <p>toggles if input tensors of the datasets have to be resized to have the same shape. Defaults to False.</p> <code>False</code> <code>shape</code> <code>Optional[Tuple[int]]</code> <p>shape to use for resizing input tensors. If None, the tensors are resized with the shape of the in_dataset input tensors. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>OODDataset</code> <code>OODDataset</code> <p>a Dataset object with the concatenated data</p> Source code in <code>oodeel/datasets/ooddataset.py</code> <pre><code>def add_out_data(\n    self,\n    out_dataset: Union[\"OODDataset\", DatasetType],\n    in_value: int = 0,\n    out_value: int = 1,\n    resize: Optional[bool] = False,\n    shape: Optional[Tuple[int]] = None,\n) -&gt; \"OODDataset\":\n\"\"\"Concatenate two OODDatasets. Useful for scoring on multiple datasets, or\n    training with added out-of-distribution data.\n\n    Args:\n        out_dataset (Union[OODDataset, DatasetType]): dataset of\n            out-of-distribution data\n        in_value (int): ood label value for in-distribution data. Defaults to 0\n        out_value (int): ood label value for out-of-distribution data. Defaults to 1\n        resize (Optional[bool], optional):toggles if input tensors of the\n            datasets have to be resized to have the same shape. Defaults to False.\n        shape (Optional[Tuple[int]], optional):shape to use for resizing input\n            tensors. If None, the tensors are resized with the shape of the\n            in_dataset input tensors. Defaults to None.\n\n    Returns:\n        OODDataset: a Dataset object with the concatenated data\n    \"\"\"\n\n    # Creating an OODDataset object from out_dataset if necessary and make sure\n    # the two OODDatasets have compatible parameters\n    if isinstance(out_dataset, type(self)):\n        out_dataset = out_dataset.data\n    else:\n        out_dataset = OODDataset(out_dataset, backend=self.backend).data\n\n    # Assign the correct ood_label to self.data, depending on out_as_in\n    self.data = self._data_handler.assign_feature_value(\n        self.data, \"ood_label\", in_value\n    )\n    out_dataset = self._data_handler.assign_feature_value(\n        out_dataset, \"ood_label\", out_value\n    )\n\n    # Merge the two underlying Datasets\n    merge_kwargs = (\n        {\"channel_order\": self.channel_order}\n        if self.backend == \"tensorflow\"\n        else {}\n    )\n    data = self._data_handler.merge(\n        self.data,\n        out_dataset,\n        resize=resize,\n        shape=shape,\n        **merge_kwargs,\n    )\n\n    # Create a new OODDataset from the merged Dataset\n    output_ds = OODDataset(\n        dataset_id=data,\n        backend=self.backend,\n    )\n\n    return output_ds\n</code></pre>"},{"location":"api/ooddataset/#oodeel.datasets.ooddataset.OODDataset.get_ood_labels","title":"<code>get_ood_labels()</code>","text":"<p>Get ood_labels from self.data if any</p> <p>Returns:</p> Type Description <code>np.ndarray</code> <p>np.ndarray: array of labels</p> Source code in <code>oodeel/datasets/ooddataset.py</code> <pre><code>def get_ood_labels(\n    self,\n) -&gt; np.ndarray:\n\"\"\"Get ood_labels from self.data if any\n\n    Returns:\n        np.ndarray: array of labels\n    \"\"\"\n    assert self._data_handler.has_feature_key(\n        self.data, \"ood_label\"\n    ), \"The data has no ood_labels\"\n    labels = self._data_handler.get_feature_from_ds(self.data, \"ood_label\")\n    return labels\n</code></pre>"},{"location":"api/ooddataset/#oodeel.datasets.ooddataset.OODDataset.prepare","title":"<code>prepare(batch_size=128, preprocess_fn=None, augment_fn=None, with_ood_labels=False, with_labels=True, shuffle=False, **kwargs_prepare)</code>","text":"<p>Prepare self.data for scoring or training</p> <p>Parameters:</p> Name Type Description Default <code>batch_size</code> <code>int</code> <p>Batch_size of the returned dataset like object. Defaults to 128.</p> <code>128</code> <code>preprocess_fn</code> <code>Callable</code> <p>Preprocessing function to apply to the dataset. Defaults to None.</p> <code>None</code> <code>augment_fn</code> <code>Callable</code> <p>Augment function to be used (when the returned dataset is to be used for training). Defaults to None.</p> <code>None</code> <code>with_ood_labels</code> <code>bool</code> <p>To return the dataset with ood_labels or not. Defaults to True.</p> <code>False</code> <code>with_labels</code> <code>bool</code> <p>To return the dataset with labels or not. Defaults to True.</p> <code>True</code> <code>shuffle</code> <code>bool</code> <p>To shuffle the returned dataset or not. Defaults to False.</p> <code>False</code> <code>kwargs_prepare</code> <code>dict</code> <p>Additional parameters to be passed to the data_handler.prepare_for_training method.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>DatasetType</code> <code>DatasetType</code> <p>prepared dataset</p> Source code in <code>oodeel/datasets/ooddataset.py</code> <pre><code>def prepare(\n    self,\n    batch_size: int = 128,\n    preprocess_fn: Optional[Callable] = None,\n    augment_fn: Optional[Callable] = None,\n    with_ood_labels: bool = False,\n    with_labels: bool = True,\n    shuffle: bool = False,\n    **kwargs_prepare,\n) -&gt; DatasetType:\n\"\"\"Prepare self.data for scoring or training\n\n    Args:\n        batch_size (int, optional): Batch_size of the returned dataset like object.\n            Defaults to 128.\n        preprocess_fn (Callable, optional): Preprocessing function to apply to\n            the dataset. Defaults to None.\n        augment_fn (Callable, optional): Augment function to be used (when the\n            returned dataset is to be used for training). Defaults to None.\n        with_ood_labels (bool, optional): To return the dataset with ood_labels\n            or not. Defaults to True.\n        with_labels (bool, optional): To return the dataset with labels or not.\n            Defaults to True.\n        shuffle (bool, optional): To shuffle the returned dataset or not.\n            Defaults to False.\n        kwargs_prepare (dict): Additional parameters to be passed to the\n            data_handler.prepare_for_training method.\n\n\n    Returns:\n        DatasetType: prepared dataset\n    \"\"\"\n    # Check if the dataset has at least one of label and ood_label\n    assert (\n        with_ood_labels or with_labels\n    ), \"The dataset must have at least one of label and ood_label\"\n\n    # Check if the dataset has ood_labels when asked to return with_ood_labels\n    if with_ood_labels:\n        assert (\n            self.has_ood_label\n        ), \"Please assign ood labels before preparing with ood_labels\"\n\n    dataset_to_prepare = self.data\n\n    # Making the dataset channel first if the backend is torch\n    if self.backend == \"torch\" and self.load_from_tensorflow_datasets:\n        dataset_to_prepare = self._data_handler.make_channel_first(\n            self.input_key, dataset_to_prepare\n        )\n\n    # # Select the keys to be returned\n    keys = [self.input_key, \"label\", \"ood_label\"]\n    if not with_labels:\n        keys.remove(\"label\")\n    if not with_ood_labels:\n        keys.remove(\"ood_label\")\n\n    # Prepare the dataset for training or scoring\n    dataset = self._data_handler.prepare_for_training(\n        dataset=dataset_to_prepare,\n        batch_size=batch_size,\n        shuffle=shuffle,\n        preprocess_fn=preprocess_fn,\n        augment_fn=augment_fn,\n        output_keys=keys,\n        **kwargs_prepare,\n    )\n\n    return dataset\n</code></pre>"},{"location":"api/ooddataset/#oodeel.datasets.ooddataset.OODDataset.split_by_class","title":"<code>split_by_class(in_labels=None, out_labels=None)</code>","text":"<p>Filter the dataset by assigning ood labels depending on labels value (typically, class id).</p> <p>Parameters:</p> Name Type Description Default <code>in_labels</code> <code>Optional[Union[np.ndarray, list]]</code> <p>set of labels to be considered as in-distribution. Defaults to None.</p> <code>None</code> <code>out_labels</code> <code>Optional[Union[np.ndarray, list]]</code> <p>set of labels to be considered as out-of-distribution. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>Optional[Tuple[OODDataset]]</code> <p>Optional[Tuple[OODDataset]]: Tuple of in-distribution and out-of-distribution OODDatasets</p> Source code in <code>oodeel/datasets/ooddataset.py</code> <pre><code>def split_by_class(\n    self,\n    in_labels: Optional[Union[np.ndarray, list]] = None,\n    out_labels: Optional[Union[np.ndarray, list]] = None,\n) -&gt; Optional[Tuple[\"OODDataset\"]]:\n\"\"\"Filter the dataset by assigning ood labels depending on labels\n    value (typically, class id).\n\n    Args:\n        in_labels (Optional[Union[np.ndarray, list]], optional): set of labels\n            to be considered as in-distribution. Defaults to None.\n        out_labels (Optional[Union[np.ndarray, list]], optional): set of labels\n            to be considered as out-of-distribution. Defaults to None.\n\n    Returns:\n        Optional[Tuple[OODDataset]]: Tuple of in-distribution and\n            out-of-distribution OODDatasets\n    \"\"\"\n    # Make sure the dataset has labels\n    assert (in_labels is not None) or (\n        out_labels is not None\n    ), \"specify labels to filter with\"\n    assert self.len_item &gt;= 2, \"the dataset has no labels\"\n\n    # Filter the dataset depending on in_labels and out_labels given\n    if (out_labels is not None) and (in_labels is not None):\n        in_data = self._data_handler.filter_by_feature_value(\n            self.data, \"label\", in_labels\n        )\n        out_data = self._data_handler.filter_by_feature_value(\n            self.data, \"label\", out_labels\n        )\n\n    if out_labels is None:\n        in_data = self._data_handler.filter_by_feature_value(\n            self.data, \"label\", in_labels\n        )\n        out_data = self._data_handler.filter_by_feature_value(\n            self.data, \"label\", in_labels, excluded=True\n        )\n\n    elif in_labels is None:\n        in_data = self._data_handler.filter_by_feature_value(\n            self.data, \"label\", out_labels, excluded=True\n        )\n        out_data = self._data_handler.filter_by_feature_value(\n            self.data, \"label\", out_labels\n        )\n\n    # Return the filtered OODDatasets\n    return (\n        OODDataset(in_data, backend=self.backend),\n        OODDataset(out_data, backend=self.backend),\n    )\n</code></pre>"},{"location":"api/operators/","title":"Operators","text":""},{"location":"api/operators/#oodeel.utils.tf_operator.TFOperator","title":"<code>TFOperator</code>","text":"<p>         Bases: <code>Operator</code></p> <p>Class to handle tensorflow operations with a unified API</p> Source code in <code>oodeel/utils/tf_operator.py</code> <pre><code>class TFOperator(Operator):\n\"\"\"Class to handle tensorflow operations with a unified API\"\"\"\n\n    @staticmethod\n    def softmax(tensor: TensorType) -&gt; tf.Tensor:\n\"\"\"Softmax function along the last dimension\"\"\"\n        return tf.keras.activations.softmax(tensor, axis=-1)\n\n    @staticmethod\n    def argmax(tensor: TensorType, dim: Optional[int] = None) -&gt; tf.Tensor:\n\"\"\"Argmax function\"\"\"\n        if dim is None:\n            return tf.argmax(tf.reshape(tensor, [-1]))\n        return tf.argmax(tensor, axis=dim)\n\n    @staticmethod\n    def max(\n        tensor: TensorType, dim: Optional[int] = None, keepdim: bool = False\n    ) -&gt; tf.Tensor:\n\"\"\"Max function\"\"\"\n        return tf.reduce_max(tensor, axis=dim, keepdims=keepdim)\n\n    @staticmethod\n    def min(\n        tensor: TensorType, dim: Optional[int] = None, keepdim: bool = False\n    ) -&gt; tf.Tensor:\n\"\"\"Min function\"\"\"\n        return tf.reduce_min(tensor, axis=dim, keepdims=keepdim)\n\n    @staticmethod\n    def one_hot(tensor: TensorType, num_classes: int) -&gt; tf.Tensor:\n\"\"\"One hot function\"\"\"\n        return tf.one_hot(tensor, num_classes)\n\n    @staticmethod\n    def sign(tensor: TensorType) -&gt; tf.Tensor:\n\"\"\"Sign function\"\"\"\n        return tf.sign(tensor)\n\n    @staticmethod\n    def CrossEntropyLoss(reduction: str = \"mean\"):\n\"\"\"Cross Entropy Loss from logits\"\"\"\n\n        tf_reduction = {\"mean\": \"sum_over_batch_size\", \"sum\": \"sum\"}[reduction]\n\n        def sanitized_ce_loss(inputs, targets):\n            return tf.keras.losses.SparseCategoricalCrossentropy(\n                from_logits=True, reduction=tf_reduction\n            )(targets, inputs)\n\n        return sanitized_ce_loss\n\n    @staticmethod\n    def norm(tensor: TensorType, dim: Optional[int] = None) -&gt; tf.Tensor:\n\"\"\"Tensor Norm\"\"\"\n        return tf.norm(tensor, axis=dim)\n\n    @staticmethod\n    @tf.function\n    def matmul(tensor_1: TensorType, tensor_2: TensorType) -&gt; tf.Tensor:\n\"\"\"Matmul operation\"\"\"\n        return tf.matmul(tensor_1, tensor_2)\n\n    @staticmethod\n    def convert_to_numpy(tensor: TensorType) -&gt; np.ndarray:\n\"\"\"Convert tensor into a np.ndarray\"\"\"\n        return tensor.numpy()\n\n    @staticmethod\n    def gradient(func: Callable, inputs: tf.Tensor, *args, **kwargs) -&gt; tf.Tensor:\n\"\"\"Compute gradients for a batch of samples.\n\n        Args:\n            func (Callable): Function used for computing gradient. Must be built with\n                tensorflow differentiable operations only, and return a scalar.\n            inputs (tf.Tensor): Input tensor wrt which the gradients are computed\n            *args: Additional Args for func.\n            **kwargs: Additional Kwargs for func.\n\n        Returns:\n            tf.Tensor: Gradients computed, with the same shape as the inputs.\n        \"\"\"\n        with tf.GradientTape(watch_accessed_variables=False) as tape:\n            tape.watch(inputs)\n            outputs = func(inputs, *args, **kwargs)\n        return tape.gradient(outputs, inputs)\n\n    @staticmethod\n    def stack(tensors: List[TensorType], dim: int = 0) -&gt; tf.Tensor:\n        \"Stack tensors along a new dimension\"\n        return tf.stack(tensors, dim)\n\n    @staticmethod\n    def cat(tensors: List[TensorType], dim: int = 0) -&gt; tf.Tensor:\n        \"Concatenate tensors in a given dimension\"\n        return tf.concat(tensors, dim)\n\n    @staticmethod\n    def mean(tensor: TensorType, dim: Optional[int] = None) -&gt; tf.Tensor:\n        \"Mean function\"\n        return tf.reduce_mean(tensor, dim)\n\n    @staticmethod\n    def flatten(tensor: TensorType) -&gt; tf.Tensor:\n        \"Flatten to 2D tensor of shape (tensor.shape[0], -1)\"\n        # Flatten the features to 2D (n_batch, n_features)\n        return tf.reshape(tensor, shape=[tf.shape(tensor)[0], -1])\n\n    @staticmethod\n    def from_numpy(arr: np.ndarray) -&gt; tf.Tensor:\n        \"Convert a NumPy array to a tensor\"\n        # TODO change dtype\n        return tf.convert_to_tensor(arr)\n\n    @staticmethod\n    def t(tensor: TensorType) -&gt; tf.Tensor:\n        \"Transpose function for tensor of rank 2\"\n        return tf.transpose(tensor)\n\n    @staticmethod\n    def permute(tensor: TensorType, dims) -&gt; tf.Tensor:\n        \"Transpose function for tensor of rank 2\"\n        return tf.transpose(tensor, dims)\n\n    @staticmethod\n    def diag(tensor: TensorType) -&gt; tf.Tensor:\n        \"Diagonal function: return the diagonal of a 2D tensor\"\n        return tf.linalg.diag_part(tensor)\n\n    @staticmethod\n    def reshape(tensor: TensorType, shape: List[int]) -&gt; tf.Tensor:\n        \"Reshape function\"\n        return tf.reshape(tensor, shape)\n\n    @staticmethod\n    def equal(tensor: TensorType, other: Union[TensorType, int, float]) -&gt; tf.Tensor:\n        \"Computes element-wise equality\"\n        return tf.math.equal(tensor, other)\n\n    @staticmethod\n    def pinv(tensor: TensorType) -&gt; tf.Tensor:\n        \"Computes the pseudoinverse (Moore-Penrose inverse) of a matrix.\"\n        return tf.linalg.pinv(tensor)\n\n    @staticmethod\n    def eigh(tensor: TensorType) -&gt; tf.Tensor:\n        \"Computes the eigen decomposition of a self-adjoint matrix.\"\n        eigval, eigvec = tf.linalg.eigh(tensor)\n        return eigval, eigvec\n\n    @staticmethod\n    def quantile(tensor: TensorType, q: float, dim: int = None) -&gt; tf.Tensor:\n        \"Computes the quantile of a tensor's components. q in (0,1)\"\n        q = tfp.stats.percentile(tensor, q * 100, axis=dim)\n        return float(q) if dim is None else q\n\n    @staticmethod\n    def relu(tensor: TensorType) -&gt; tf.Tensor:\n        \"Apply relu to a tensor\"\n        return tf.nn.relu(tensor)\n\n    @staticmethod\n    def einsum(equation: str, *tensors: TensorType) -&gt; tf.Tensor:\n        \"Computes the einsum between tensors following equation\"\n        return tf.einsum(equation, *tensors)\n\n    @staticmethod\n    def tril(tensor: TensorType, diagonal: int = 0) -&gt; tf.Tensor:\n        \"Set the upper triangle of the matrix formed by the last two dimensions of\"\n        \"tensor to zero\"\n        return tf.experimental.numpy.tril(tensor, k=diagonal)\n\n    @staticmethod\n    def sum(tensor: TensorType, dim: Union[tuple, list, int] = None) -&gt; tf.Tensor:\n        \"sum along dim\"\n        return tf.reduce_sum(tensor, axis=dim)\n\n    @staticmethod\n    def unsqueeze(tensor: TensorType, dim: int) -&gt; tf.Tensor:\n        \"expand_dim along dim\"\n        return tf.expand_dims(tensor, dim)\n\n    @staticmethod\n    def squeeze(tensor: TensorType, dim: int = None) -&gt; tf.Tensor:\n        \"expand_dim along dim\"\n        return tf.squeeze(tensor, dim)\n\n    @staticmethod\n    def abs(tensor: TensorType) -&gt; tf.Tensor:\n        \"compute absolute value\"\n        return tf.abs(tensor)\n\n    @staticmethod\n    def where(\n        condition: TensorType,\n        input: Union[TensorType, float],\n        other: Union[TensorType, float],\n    ) -&gt; tf.Tensor:\n        \"Applies where function to condition\"\n        return tf.where(condition, input, other)\n\n    @staticmethod\n    def percentile(x, q):\n        return tfp.stats.percentile(x, q)\n\n    @staticmethod\n    def avg_pool_2d(tensor: TensorType) -&gt; tf.Tensor:\n\"\"\"Perform avg pool in 2d as in torch.nn.functional.adaptive_avg_pool2d\"\"\"\n        return tf.reduce_mean(tensor, axis=(-3, -2))\n\n    @staticmethod\n    def log(tensor: TensorType) -&gt; tf.Tensor:\n\"\"\"Perform log\"\"\"\n        return tf.math.log(tensor)\n</code></pre>"},{"location":"api/operators/#oodeel.utils.tf_operator.TFOperator.CrossEntropyLoss","title":"<code>CrossEntropyLoss(reduction='mean')</code>  <code>staticmethod</code>","text":"<p>Cross Entropy Loss from logits</p> Source code in <code>oodeel/utils/tf_operator.py</code> <pre><code>@staticmethod\ndef CrossEntropyLoss(reduction: str = \"mean\"):\n\"\"\"Cross Entropy Loss from logits\"\"\"\n\n    tf_reduction = {\"mean\": \"sum_over_batch_size\", \"sum\": \"sum\"}[reduction]\n\n    def sanitized_ce_loss(inputs, targets):\n        return tf.keras.losses.SparseCategoricalCrossentropy(\n            from_logits=True, reduction=tf_reduction\n        )(targets, inputs)\n\n    return sanitized_ce_loss\n</code></pre>"},{"location":"api/operators/#oodeel.utils.tf_operator.TFOperator.abs","title":"<code>abs(tensor)</code>  <code>staticmethod</code>","text":"<p>compute absolute value</p> Source code in <code>oodeel/utils/tf_operator.py</code> <pre><code>@staticmethod\ndef abs(tensor: TensorType) -&gt; tf.Tensor:\n    \"compute absolute value\"\n    return tf.abs(tensor)\n</code></pre>"},{"location":"api/operators/#oodeel.utils.tf_operator.TFOperator.argmax","title":"<code>argmax(tensor, dim=None)</code>  <code>staticmethod</code>","text":"<p>Argmax function</p> Source code in <code>oodeel/utils/tf_operator.py</code> <pre><code>@staticmethod\ndef argmax(tensor: TensorType, dim: Optional[int] = None) -&gt; tf.Tensor:\n\"\"\"Argmax function\"\"\"\n    if dim is None:\n        return tf.argmax(tf.reshape(tensor, [-1]))\n    return tf.argmax(tensor, axis=dim)\n</code></pre>"},{"location":"api/operators/#oodeel.utils.tf_operator.TFOperator.avg_pool_2d","title":"<code>avg_pool_2d(tensor)</code>  <code>staticmethod</code>","text":"<p>Perform avg pool in 2d as in torch.nn.functional.adaptive_avg_pool2d</p> Source code in <code>oodeel/utils/tf_operator.py</code> <pre><code>@staticmethod\ndef avg_pool_2d(tensor: TensorType) -&gt; tf.Tensor:\n\"\"\"Perform avg pool in 2d as in torch.nn.functional.adaptive_avg_pool2d\"\"\"\n    return tf.reduce_mean(tensor, axis=(-3, -2))\n</code></pre>"},{"location":"api/operators/#oodeel.utils.tf_operator.TFOperator.cat","title":"<code>cat(tensors, dim=0)</code>  <code>staticmethod</code>","text":"<p>Concatenate tensors in a given dimension</p> Source code in <code>oodeel/utils/tf_operator.py</code> <pre><code>@staticmethod\ndef cat(tensors: List[TensorType], dim: int = 0) -&gt; tf.Tensor:\n    \"Concatenate tensors in a given dimension\"\n    return tf.concat(tensors, dim)\n</code></pre>"},{"location":"api/operators/#oodeel.utils.tf_operator.TFOperator.convert_to_numpy","title":"<code>convert_to_numpy(tensor)</code>  <code>staticmethod</code>","text":"<p>Convert tensor into a np.ndarray</p> Source code in <code>oodeel/utils/tf_operator.py</code> <pre><code>@staticmethod\ndef convert_to_numpy(tensor: TensorType) -&gt; np.ndarray:\n\"\"\"Convert tensor into a np.ndarray\"\"\"\n    return tensor.numpy()\n</code></pre>"},{"location":"api/operators/#oodeel.utils.tf_operator.TFOperator.diag","title":"<code>diag(tensor)</code>  <code>staticmethod</code>","text":"<p>Diagonal function: return the diagonal of a 2D tensor</p> Source code in <code>oodeel/utils/tf_operator.py</code> <pre><code>@staticmethod\ndef diag(tensor: TensorType) -&gt; tf.Tensor:\n    \"Diagonal function: return the diagonal of a 2D tensor\"\n    return tf.linalg.diag_part(tensor)\n</code></pre>"},{"location":"api/operators/#oodeel.utils.tf_operator.TFOperator.eigh","title":"<code>eigh(tensor)</code>  <code>staticmethod</code>","text":"<p>Computes the eigen decomposition of a self-adjoint matrix.</p> Source code in <code>oodeel/utils/tf_operator.py</code> <pre><code>@staticmethod\ndef eigh(tensor: TensorType) -&gt; tf.Tensor:\n    \"Computes the eigen decomposition of a self-adjoint matrix.\"\n    eigval, eigvec = tf.linalg.eigh(tensor)\n    return eigval, eigvec\n</code></pre>"},{"location":"api/operators/#oodeel.utils.tf_operator.TFOperator.einsum","title":"<code>einsum(equation, *tensors)</code>  <code>staticmethod</code>","text":"<p>Computes the einsum between tensors following equation</p> Source code in <code>oodeel/utils/tf_operator.py</code> <pre><code>@staticmethod\ndef einsum(equation: str, *tensors: TensorType) -&gt; tf.Tensor:\n    \"Computes the einsum between tensors following equation\"\n    return tf.einsum(equation, *tensors)\n</code></pre>"},{"location":"api/operators/#oodeel.utils.tf_operator.TFOperator.equal","title":"<code>equal(tensor, other)</code>  <code>staticmethod</code>","text":"<p>Computes element-wise equality</p> Source code in <code>oodeel/utils/tf_operator.py</code> <pre><code>@staticmethod\ndef equal(tensor: TensorType, other: Union[TensorType, int, float]) -&gt; tf.Tensor:\n    \"Computes element-wise equality\"\n    return tf.math.equal(tensor, other)\n</code></pre>"},{"location":"api/operators/#oodeel.utils.tf_operator.TFOperator.flatten","title":"<code>flatten(tensor)</code>  <code>staticmethod</code>","text":"<p>Flatten to 2D tensor of shape (tensor.shape[0], -1)</p> Source code in <code>oodeel/utils/tf_operator.py</code> <pre><code>@staticmethod\ndef flatten(tensor: TensorType) -&gt; tf.Tensor:\n    \"Flatten to 2D tensor of shape (tensor.shape[0], -1)\"\n    # Flatten the features to 2D (n_batch, n_features)\n    return tf.reshape(tensor, shape=[tf.shape(tensor)[0], -1])\n</code></pre>"},{"location":"api/operators/#oodeel.utils.tf_operator.TFOperator.from_numpy","title":"<code>from_numpy(arr)</code>  <code>staticmethod</code>","text":"<p>Convert a NumPy array to a tensor</p> Source code in <code>oodeel/utils/tf_operator.py</code> <pre><code>@staticmethod\ndef from_numpy(arr: np.ndarray) -&gt; tf.Tensor:\n    \"Convert a NumPy array to a tensor\"\n    # TODO change dtype\n    return tf.convert_to_tensor(arr)\n</code></pre>"},{"location":"api/operators/#oodeel.utils.tf_operator.TFOperator.gradient","title":"<code>gradient(func, inputs, *args, **kwargs)</code>  <code>staticmethod</code>","text":"<p>Compute gradients for a batch of samples.</p> <p>Parameters:</p> Name Type Description Default <code>func</code> <code>Callable</code> <p>Function used for computing gradient. Must be built with tensorflow differentiable operations only, and return a scalar.</p> required <code>inputs</code> <code>tf.Tensor</code> <p>Input tensor wrt which the gradients are computed</p> required <code>*args</code> <p>Additional Args for func.</p> <code>()</code> <code>**kwargs</code> <p>Additional Kwargs for func.</p> <code>{}</code> <p>Returns:</p> Type Description <code>tf.Tensor</code> <p>tf.Tensor: Gradients computed, with the same shape as the inputs.</p> Source code in <code>oodeel/utils/tf_operator.py</code> <pre><code>@staticmethod\ndef gradient(func: Callable, inputs: tf.Tensor, *args, **kwargs) -&gt; tf.Tensor:\n\"\"\"Compute gradients for a batch of samples.\n\n    Args:\n        func (Callable): Function used for computing gradient. Must be built with\n            tensorflow differentiable operations only, and return a scalar.\n        inputs (tf.Tensor): Input tensor wrt which the gradients are computed\n        *args: Additional Args for func.\n        **kwargs: Additional Kwargs for func.\n\n    Returns:\n        tf.Tensor: Gradients computed, with the same shape as the inputs.\n    \"\"\"\n    with tf.GradientTape(watch_accessed_variables=False) as tape:\n        tape.watch(inputs)\n        outputs = func(inputs, *args, **kwargs)\n    return tape.gradient(outputs, inputs)\n</code></pre>"},{"location":"api/operators/#oodeel.utils.tf_operator.TFOperator.log","title":"<code>log(tensor)</code>  <code>staticmethod</code>","text":"<p>Perform log</p> Source code in <code>oodeel/utils/tf_operator.py</code> <pre><code>@staticmethod\ndef log(tensor: TensorType) -&gt; tf.Tensor:\n\"\"\"Perform log\"\"\"\n    return tf.math.log(tensor)\n</code></pre>"},{"location":"api/operators/#oodeel.utils.tf_operator.TFOperator.matmul","title":"<code>matmul(tensor_1, tensor_2)</code>  <code>staticmethod</code>","text":"<p>Matmul operation</p> Source code in <code>oodeel/utils/tf_operator.py</code> <pre><code>@staticmethod\n@tf.function\ndef matmul(tensor_1: TensorType, tensor_2: TensorType) -&gt; tf.Tensor:\n\"\"\"Matmul operation\"\"\"\n    return tf.matmul(tensor_1, tensor_2)\n</code></pre>"},{"location":"api/operators/#oodeel.utils.tf_operator.TFOperator.max","title":"<code>max(tensor, dim=None, keepdim=False)</code>  <code>staticmethod</code>","text":"<p>Max function</p> Source code in <code>oodeel/utils/tf_operator.py</code> <pre><code>@staticmethod\ndef max(\n    tensor: TensorType, dim: Optional[int] = None, keepdim: bool = False\n) -&gt; tf.Tensor:\n\"\"\"Max function\"\"\"\n    return tf.reduce_max(tensor, axis=dim, keepdims=keepdim)\n</code></pre>"},{"location":"api/operators/#oodeel.utils.tf_operator.TFOperator.mean","title":"<code>mean(tensor, dim=None)</code>  <code>staticmethod</code>","text":"<p>Mean function</p> Source code in <code>oodeel/utils/tf_operator.py</code> <pre><code>@staticmethod\ndef mean(tensor: TensorType, dim: Optional[int] = None) -&gt; tf.Tensor:\n    \"Mean function\"\n    return tf.reduce_mean(tensor, dim)\n</code></pre>"},{"location":"api/operators/#oodeel.utils.tf_operator.TFOperator.min","title":"<code>min(tensor, dim=None, keepdim=False)</code>  <code>staticmethod</code>","text":"<p>Min function</p> Source code in <code>oodeel/utils/tf_operator.py</code> <pre><code>@staticmethod\ndef min(\n    tensor: TensorType, dim: Optional[int] = None, keepdim: bool = False\n) -&gt; tf.Tensor:\n\"\"\"Min function\"\"\"\n    return tf.reduce_min(tensor, axis=dim, keepdims=keepdim)\n</code></pre>"},{"location":"api/operators/#oodeel.utils.tf_operator.TFOperator.norm","title":"<code>norm(tensor, dim=None)</code>  <code>staticmethod</code>","text":"<p>Tensor Norm</p> Source code in <code>oodeel/utils/tf_operator.py</code> <pre><code>@staticmethod\ndef norm(tensor: TensorType, dim: Optional[int] = None) -&gt; tf.Tensor:\n\"\"\"Tensor Norm\"\"\"\n    return tf.norm(tensor, axis=dim)\n</code></pre>"},{"location":"api/operators/#oodeel.utils.tf_operator.TFOperator.one_hot","title":"<code>one_hot(tensor, num_classes)</code>  <code>staticmethod</code>","text":"<p>One hot function</p> Source code in <code>oodeel/utils/tf_operator.py</code> <pre><code>@staticmethod\ndef one_hot(tensor: TensorType, num_classes: int) -&gt; tf.Tensor:\n\"\"\"One hot function\"\"\"\n    return tf.one_hot(tensor, num_classes)\n</code></pre>"},{"location":"api/operators/#oodeel.utils.tf_operator.TFOperator.permute","title":"<code>permute(tensor, dims)</code>  <code>staticmethod</code>","text":"<p>Transpose function for tensor of rank 2</p> Source code in <code>oodeel/utils/tf_operator.py</code> <pre><code>@staticmethod\ndef permute(tensor: TensorType, dims) -&gt; tf.Tensor:\n    \"Transpose function for tensor of rank 2\"\n    return tf.transpose(tensor, dims)\n</code></pre>"},{"location":"api/operators/#oodeel.utils.tf_operator.TFOperator.pinv","title":"<code>pinv(tensor)</code>  <code>staticmethod</code>","text":"<p>Computes the pseudoinverse (Moore-Penrose inverse) of a matrix.</p> Source code in <code>oodeel/utils/tf_operator.py</code> <pre><code>@staticmethod\ndef pinv(tensor: TensorType) -&gt; tf.Tensor:\n    \"Computes the pseudoinverse (Moore-Penrose inverse) of a matrix.\"\n    return tf.linalg.pinv(tensor)\n</code></pre>"},{"location":"api/operators/#oodeel.utils.tf_operator.TFOperator.quantile","title":"<code>quantile(tensor, q, dim=None)</code>  <code>staticmethod</code>","text":"<p>Computes the quantile of a tensor's components. q in (0,1)</p> Source code in <code>oodeel/utils/tf_operator.py</code> <pre><code>@staticmethod\ndef quantile(tensor: TensorType, q: float, dim: int = None) -&gt; tf.Tensor:\n    \"Computes the quantile of a tensor's components. q in (0,1)\"\n    q = tfp.stats.percentile(tensor, q * 100, axis=dim)\n    return float(q) if dim is None else q\n</code></pre>"},{"location":"api/operators/#oodeel.utils.tf_operator.TFOperator.relu","title":"<code>relu(tensor)</code>  <code>staticmethod</code>","text":"<p>Apply relu to a tensor</p> Source code in <code>oodeel/utils/tf_operator.py</code> <pre><code>@staticmethod\ndef relu(tensor: TensorType) -&gt; tf.Tensor:\n    \"Apply relu to a tensor\"\n    return tf.nn.relu(tensor)\n</code></pre>"},{"location":"api/operators/#oodeel.utils.tf_operator.TFOperator.reshape","title":"<code>reshape(tensor, shape)</code>  <code>staticmethod</code>","text":"<p>Reshape function</p> Source code in <code>oodeel/utils/tf_operator.py</code> <pre><code>@staticmethod\ndef reshape(tensor: TensorType, shape: List[int]) -&gt; tf.Tensor:\n    \"Reshape function\"\n    return tf.reshape(tensor, shape)\n</code></pre>"},{"location":"api/operators/#oodeel.utils.tf_operator.TFOperator.sign","title":"<code>sign(tensor)</code>  <code>staticmethod</code>","text":"<p>Sign function</p> Source code in <code>oodeel/utils/tf_operator.py</code> <pre><code>@staticmethod\ndef sign(tensor: TensorType) -&gt; tf.Tensor:\n\"\"\"Sign function\"\"\"\n    return tf.sign(tensor)\n</code></pre>"},{"location":"api/operators/#oodeel.utils.tf_operator.TFOperator.softmax","title":"<code>softmax(tensor)</code>  <code>staticmethod</code>","text":"<p>Softmax function along the last dimension</p> Source code in <code>oodeel/utils/tf_operator.py</code> <pre><code>@staticmethod\ndef softmax(tensor: TensorType) -&gt; tf.Tensor:\n\"\"\"Softmax function along the last dimension\"\"\"\n    return tf.keras.activations.softmax(tensor, axis=-1)\n</code></pre>"},{"location":"api/operators/#oodeel.utils.tf_operator.TFOperator.squeeze","title":"<code>squeeze(tensor, dim=None)</code>  <code>staticmethod</code>","text":"<p>expand_dim along dim</p> Source code in <code>oodeel/utils/tf_operator.py</code> <pre><code>@staticmethod\ndef squeeze(tensor: TensorType, dim: int = None) -&gt; tf.Tensor:\n    \"expand_dim along dim\"\n    return tf.squeeze(tensor, dim)\n</code></pre>"},{"location":"api/operators/#oodeel.utils.tf_operator.TFOperator.stack","title":"<code>stack(tensors, dim=0)</code>  <code>staticmethod</code>","text":"<p>Stack tensors along a new dimension</p> Source code in <code>oodeel/utils/tf_operator.py</code> <pre><code>@staticmethod\ndef stack(tensors: List[TensorType], dim: int = 0) -&gt; tf.Tensor:\n    \"Stack tensors along a new dimension\"\n    return tf.stack(tensors, dim)\n</code></pre>"},{"location":"api/operators/#oodeel.utils.tf_operator.TFOperator.sum","title":"<code>sum(tensor, dim=None)</code>  <code>staticmethod</code>","text":"<p>sum along dim</p> Source code in <code>oodeel/utils/tf_operator.py</code> <pre><code>@staticmethod\ndef sum(tensor: TensorType, dim: Union[tuple, list, int] = None) -&gt; tf.Tensor:\n    \"sum along dim\"\n    return tf.reduce_sum(tensor, axis=dim)\n</code></pre>"},{"location":"api/operators/#oodeel.utils.tf_operator.TFOperator.t","title":"<code>t(tensor)</code>  <code>staticmethod</code>","text":"<p>Transpose function for tensor of rank 2</p> Source code in <code>oodeel/utils/tf_operator.py</code> <pre><code>@staticmethod\ndef t(tensor: TensorType) -&gt; tf.Tensor:\n    \"Transpose function for tensor of rank 2\"\n    return tf.transpose(tensor)\n</code></pre>"},{"location":"api/operators/#oodeel.utils.tf_operator.TFOperator.tril","title":"<code>tril(tensor, diagonal=0)</code>  <code>staticmethod</code>","text":"<p>Set the upper triangle of the matrix formed by the last two dimensions of</p> Source code in <code>oodeel/utils/tf_operator.py</code> <pre><code>@staticmethod\ndef tril(tensor: TensorType, diagonal: int = 0) -&gt; tf.Tensor:\n    \"Set the upper triangle of the matrix formed by the last two dimensions of\"\n    \"tensor to zero\"\n    return tf.experimental.numpy.tril(tensor, k=diagonal)\n</code></pre>"},{"location":"api/operators/#oodeel.utils.tf_operator.TFOperator.unsqueeze","title":"<code>unsqueeze(tensor, dim)</code>  <code>staticmethod</code>","text":"<p>expand_dim along dim</p> Source code in <code>oodeel/utils/tf_operator.py</code> <pre><code>@staticmethod\ndef unsqueeze(tensor: TensorType, dim: int) -&gt; tf.Tensor:\n    \"expand_dim along dim\"\n    return tf.expand_dims(tensor, dim)\n</code></pre>"},{"location":"api/operators/#oodeel.utils.tf_operator.TFOperator.where","title":"<code>where(condition, input, other)</code>  <code>staticmethod</code>","text":"<p>Applies where function to condition</p> Source code in <code>oodeel/utils/tf_operator.py</code> <pre><code>@staticmethod\ndef where(\n    condition: TensorType,\n    input: Union[TensorType, float],\n    other: Union[TensorType, float],\n) -&gt; tf.Tensor:\n    \"Applies where function to condition\"\n    return tf.where(condition, input, other)\n</code></pre>"},{"location":"api/operators/#oodeel.utils.tf_operator.sanitize_input","title":"<code>sanitize_input(tensor_arg_func)</code>","text":"<p>ensures the decorated function receives a tf.Tensor</p> Source code in <code>oodeel/utils/tf_operator.py</code> <pre><code>def sanitize_input(tensor_arg_func: Callable):\n\"\"\"ensures the decorated function receives a tf.Tensor\"\"\"\n\n    def wrapper(obj, tensor, *args, **kwargs):\n        if isinstance(tensor, tf.Tensor):\n            pass\n        elif is_from(tensor, \"torch\"):\n            tensor = tf.convert_to_tensor(tensor.numpy())\n        else:\n            tensor = tf.convert_to_tensor(tensor)\n\n        return tensor_arg_func(obj, tensor, *args, **kwargs)\n\n    return wrapper\n</code></pre>"},{"location":"api/operators/#oodeel.utils.torch_operator.TorchOperator","title":"<code>TorchOperator</code>","text":"<p>         Bases: <code>Operator</code></p> <p>Class to handle torch operations with a unified API</p> Source code in <code>oodeel/utils/torch_operator.py</code> <pre><code>class TorchOperator(Operator):\n\"\"\"Class to handle torch operations with a unified API\"\"\"\n\n    def __init__(self, model: Optional[torch.nn.Module] = None):\n        if model is not None:\n            self._device = next(model.parameters()).device\n        else:\n            self._device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n    @staticmethod\n    def softmax(tensor: TensorType) -&gt; torch.Tensor:\n\"\"\"Softmax function along the last dimension\"\"\"\n        return torch.nn.functional.softmax(tensor, dim=-1)\n\n    @staticmethod\n    def argmax(tensor: TensorType, dim: Optional[int] = None) -&gt; torch.Tensor:\n\"\"\"Argmax function\"\"\"\n        return torch.argmax(tensor, dim=dim)\n\n    @staticmethod\n    def max(\n        tensor: TensorType, dim: Optional[int] = None, keepdim: Optional[bool] = False\n    ) -&gt; torch.Tensor:\n\"\"\"Max function\"\"\"\n        if dim is None:\n            return torch.max(tensor)\n        else:\n            return torch.max(tensor, dim, keepdim=keepdim)[0]\n\n    @staticmethod\n    def min(\n        tensor: TensorType, dim: Optional[int] = None, keepdim: bool = False\n    ) -&gt; torch.Tensor:\n\"\"\"Min function\"\"\"\n        if dim is None:\n            return torch.min(tensor)\n        else:\n            return torch.min(tensor, dim, keepdim=keepdim)[0]\n\n    @staticmethod\n    def one_hot(tensor: TensorType, num_classes: int) -&gt; torch.Tensor:\n\"\"\"One hot function\"\"\"\n        return torch.nn.functional.one_hot(tensor, num_classes)\n\n    @staticmethod\n    def sign(tensor: TensorType) -&gt; torch.Tensor:\n\"\"\"Sign function\"\"\"\n        return torch.sign(tensor)\n\n    @staticmethod\n    def CrossEntropyLoss(reduction: str = \"mean\"):\n\"\"\"Cross Entropy Loss from logits\"\"\"\n\n        def sanitized_ce_loss(inputs, targets):\n            return torch.nn.CrossEntropyLoss(reduction=reduction)(inputs, targets)\n\n        return sanitized_ce_loss\n\n    @staticmethod\n    def norm(tensor: TensorType, dim: Optional[int] = None) -&gt; torch.Tensor:\n\"\"\"Tensor Norm\"\"\"\n        return torch.norm(tensor, dim=dim)\n\n    @staticmethod\n    def matmul(tensor_1: TensorType, tensor_2: TensorType) -&gt; torch.Tensor:\n\"\"\"Matmul operation\"\"\"\n        return torch.matmul(tensor_1, tensor_2)\n\n    @staticmethod\n    def convert_from_tensorflow(tensor: TensorType) -&gt; torch.Tensor:\n\"\"\"Convert a tensorflow tensor into a torch tensor\n\n        Used when using a pytorch model on a dataset loaded from tensorflow datasets\n        \"\"\"\n        return torch.Tensor(tensor.numpy())\n\n    @staticmethod\n    def convert_to_numpy(tensor: TensorType) -&gt; np.ndarray:\n\"\"\"Convert tensor into a np.ndarray\"\"\"\n        if tensor.device != \"cpu\":\n            tensor = tensor.to(\"cpu\")\n        return tensor.detach().numpy()\n\n    @staticmethod\n    def gradient(func: Callable, inputs: torch.Tensor, *args, **kwargs) -&gt; torch.Tensor:\n\"\"\"Compute gradients for a batch of samples.\n\n        Args:\n            func (Callable): Function used for computing gradient. Must be built with\n                torch differentiable operations only, and return a scalar.\n            inputs (torch.Tensor): Input tensor wrt which the gradients are computed\n            *args: Additional Args for func.\n            **kwargs: Additional Kwargs for func.\n\n        Returns:\n            torch.Tensor: Gradients computed, with the same shape as the inputs.\n        \"\"\"\n        inputs.requires_grad_(True)\n        outputs = func(inputs, *args, **kwargs)\n        gradients = torch.autograd.grad(outputs, inputs)\n        inputs.requires_grad_(False)\n        return gradients[0]\n\n    @staticmethod\n    def stack(tensors: List[TensorType], dim: int = 0) -&gt; torch.Tensor:\n        \"Stack tensors along a new dimension\"\n        return torch.stack(tensors, dim)\n\n    @staticmethod\n    def cat(tensors: List[TensorType], dim: int = 0) -&gt; torch.Tensor:\n        \"Concatenate tensors in a given dimension\"\n        return torch.cat(tensors, dim)\n\n    @staticmethod\n    def mean(tensor: TensorType, dim: Optional[int] = None) -&gt; torch.Tensor:\n        \"Mean function\"\n        if dim is None:\n            return torch.mean(tensor)\n        else:\n            return torch.mean(tensor, dim)\n\n    @staticmethod\n    def flatten(tensor: TensorType) -&gt; torch.Tensor:\n        \"Flatten function\"\n        # Flatten the features to 2D (n_batch, n_features)\n        return tensor.view(tensor.size(0), -1)\n\n    def from_numpy(self, arr: np.ndarray) -&gt; torch.Tensor:\n        \"Convert a NumPy array to a tensor\"\n        # TODO change dtype\n        return torch.tensor(arr).to(self._device)\n\n    @staticmethod\n    def t(tensor: TensorType) -&gt; torch.Tensor:\n        \"Transpose function for tensor of rank 2\"\n        return tensor.t()\n\n    @staticmethod\n    def permute(tensor: TensorType, dims) -&gt; torch.Tensor:\n        \"Transpose function for tensor of rank 2\"\n        return torch.permute(tensor, dims)\n\n    @staticmethod\n    def diag(tensor: TensorType) -&gt; torch.Tensor:\n        \"Diagonal function: return the diagonal of a 2D tensor\"\n        return tensor.diag()\n\n    @staticmethod\n    def reshape(tensor: TensorType, shape: List[int]) -&gt; torch.Tensor:\n        \"Reshape function\"\n        return tensor.view(*shape)\n\n    @staticmethod\n    def equal(tensor: TensorType, other: Union[TensorType, int, float]) -&gt; torch.Tensor:\n        \"Computes element-wise equality\"\n        return torch.eq(tensor, other)\n\n    @staticmethod\n    def pinv(tensor: TensorType) -&gt; torch.Tensor:\n        \"Computes the pseudoinverse (Moore-Penrose inverse) of a matrix.\"\n        return torch.linalg.pinv(tensor)\n\n    @staticmethod\n    def eigh(tensor: TensorType) -&gt; torch.Tensor:\n        \"Computes the eigen decomposition of a self-adjoint matrix.\"\n        eigval, eigvec = torch.linalg.eigh(tensor)\n        return eigval, eigvec\n\n    @staticmethod\n    def quantile(tensor: TensorType, q: float, dim: int = None) -&gt; torch.Tensor:\n        \"Computes the quantile of a tensor's components. q in (0,1)\"\n        if dim is None:\n            # keep the 16 millions first elements (see torch.quantile issue:\n            # https://github.com/pytorch/pytorch/issues/64947)\n            tensor_flatten = tensor.view(-1)[:16_000_000]\n            return torch.quantile(tensor_flatten, q).item()\n        else:\n            return torch.quantile(tensor, q, dim)\n\n    @staticmethod\n    def relu(tensor: TensorType) -&gt; torch.Tensor:\n        \"Apply relu to a tensor\"\n        return torch.nn.functional.relu(tensor)\n\n    @staticmethod\n    def einsum(equation: str, *tensors: TensorType) -&gt; torch.Tensor:\n        \"Computes the einsum between tensors following equation\"\n        return torch.einsum(equation, *tensors)\n\n    @staticmethod\n    def tril(tensor: TensorType, diagonal: int = 0) -&gt; torch.Tensor:\n        \"Set the upper triangle of the matrix formed by the last two dimensions of\"\n        \"tensor to zero\"\n        return torch.tril(tensor, diagonal)\n\n    @staticmethod\n    def sum(tensor: TensorType, dim: Union[tuple, list, int] = None) -&gt; torch.Tensor:\n        \"sum along dim\"\n        return torch.sum(tensor, dim)\n\n    @staticmethod\n    def unsqueeze(tensor: TensorType, dim: int) -&gt; torch.Tensor:\n        \"unsqueeze along dim\"\n        return torch.unsqueeze(tensor, dim)\n\n    @staticmethod\n    def squeeze(tensor: TensorType, dim: int = None) -&gt; torch.Tensor:\n        \"squeeze along dim\"\n\n        if dim is None:\n            return torch.squeeze(tensor)\n\n        return torch.squeeze(tensor, dim)\n\n    @staticmethod\n    def abs(tensor: TensorType) -&gt; torch.Tensor:\n        \"compute absolute value\"\n        return torch.abs(tensor)\n\n    @staticmethod\n    def where(\n        condition: TensorType,\n        input: Union[TensorType, float],\n        other: Union[TensorType, float],\n    ) -&gt; torch.Tensor:\n        \"Applies where function , to condition\"\n        return torch.where(condition, input, other)\n\n    @staticmethod\n    def avg_pool_2d(tensor: TensorType) -&gt; torch.Tensor:\n\"\"\"Perform avg pool in 2d as in torch.nn.functional.adaptive_avg_pool2d\"\"\"\n        return torch.mean(tensor, dim=(-2, -1))\n\n    @staticmethod\n    def log(tensor: TensorType) -&gt; torch.Tensor:\n\"\"\"Perform log\"\"\"\n        return torch.log(tensor)\n</code></pre>"},{"location":"api/operators/#oodeel.utils.torch_operator.TorchOperator.CrossEntropyLoss","title":"<code>CrossEntropyLoss(reduction='mean')</code>  <code>staticmethod</code>","text":"<p>Cross Entropy Loss from logits</p> Source code in <code>oodeel/utils/torch_operator.py</code> <pre><code>@staticmethod\ndef CrossEntropyLoss(reduction: str = \"mean\"):\n\"\"\"Cross Entropy Loss from logits\"\"\"\n\n    def sanitized_ce_loss(inputs, targets):\n        return torch.nn.CrossEntropyLoss(reduction=reduction)(inputs, targets)\n\n    return sanitized_ce_loss\n</code></pre>"},{"location":"api/operators/#oodeel.utils.torch_operator.TorchOperator.abs","title":"<code>abs(tensor)</code>  <code>staticmethod</code>","text":"<p>compute absolute value</p> Source code in <code>oodeel/utils/torch_operator.py</code> <pre><code>@staticmethod\ndef abs(tensor: TensorType) -&gt; torch.Tensor:\n    \"compute absolute value\"\n    return torch.abs(tensor)\n</code></pre>"},{"location":"api/operators/#oodeel.utils.torch_operator.TorchOperator.argmax","title":"<code>argmax(tensor, dim=None)</code>  <code>staticmethod</code>","text":"<p>Argmax function</p> Source code in <code>oodeel/utils/torch_operator.py</code> <pre><code>@staticmethod\ndef argmax(tensor: TensorType, dim: Optional[int] = None) -&gt; torch.Tensor:\n\"\"\"Argmax function\"\"\"\n    return torch.argmax(tensor, dim=dim)\n</code></pre>"},{"location":"api/operators/#oodeel.utils.torch_operator.TorchOperator.avg_pool_2d","title":"<code>avg_pool_2d(tensor)</code>  <code>staticmethod</code>","text":"<p>Perform avg pool in 2d as in torch.nn.functional.adaptive_avg_pool2d</p> Source code in <code>oodeel/utils/torch_operator.py</code> <pre><code>@staticmethod\ndef avg_pool_2d(tensor: TensorType) -&gt; torch.Tensor:\n\"\"\"Perform avg pool in 2d as in torch.nn.functional.adaptive_avg_pool2d\"\"\"\n    return torch.mean(tensor, dim=(-2, -1))\n</code></pre>"},{"location":"api/operators/#oodeel.utils.torch_operator.TorchOperator.cat","title":"<code>cat(tensors, dim=0)</code>  <code>staticmethod</code>","text":"<p>Concatenate tensors in a given dimension</p> Source code in <code>oodeel/utils/torch_operator.py</code> <pre><code>@staticmethod\ndef cat(tensors: List[TensorType], dim: int = 0) -&gt; torch.Tensor:\n    \"Concatenate tensors in a given dimension\"\n    return torch.cat(tensors, dim)\n</code></pre>"},{"location":"api/operators/#oodeel.utils.torch_operator.TorchOperator.convert_from_tensorflow","title":"<code>convert_from_tensorflow(tensor)</code>  <code>staticmethod</code>","text":"<p>Convert a tensorflow tensor into a torch tensor</p> <p>Used when using a pytorch model on a dataset loaded from tensorflow datasets</p> Source code in <code>oodeel/utils/torch_operator.py</code> <pre><code>@staticmethod\ndef convert_from_tensorflow(tensor: TensorType) -&gt; torch.Tensor:\n\"\"\"Convert a tensorflow tensor into a torch tensor\n\n    Used when using a pytorch model on a dataset loaded from tensorflow datasets\n    \"\"\"\n    return torch.Tensor(tensor.numpy())\n</code></pre>"},{"location":"api/operators/#oodeel.utils.torch_operator.TorchOperator.convert_to_numpy","title":"<code>convert_to_numpy(tensor)</code>  <code>staticmethod</code>","text":"<p>Convert tensor into a np.ndarray</p> Source code in <code>oodeel/utils/torch_operator.py</code> <pre><code>@staticmethod\ndef convert_to_numpy(tensor: TensorType) -&gt; np.ndarray:\n\"\"\"Convert tensor into a np.ndarray\"\"\"\n    if tensor.device != \"cpu\":\n        tensor = tensor.to(\"cpu\")\n    return tensor.detach().numpy()\n</code></pre>"},{"location":"api/operators/#oodeel.utils.torch_operator.TorchOperator.diag","title":"<code>diag(tensor)</code>  <code>staticmethod</code>","text":"<p>Diagonal function: return the diagonal of a 2D tensor</p> Source code in <code>oodeel/utils/torch_operator.py</code> <pre><code>@staticmethod\ndef diag(tensor: TensorType) -&gt; torch.Tensor:\n    \"Diagonal function: return the diagonal of a 2D tensor\"\n    return tensor.diag()\n</code></pre>"},{"location":"api/operators/#oodeel.utils.torch_operator.TorchOperator.eigh","title":"<code>eigh(tensor)</code>  <code>staticmethod</code>","text":"<p>Computes the eigen decomposition of a self-adjoint matrix.</p> Source code in <code>oodeel/utils/torch_operator.py</code> <pre><code>@staticmethod\ndef eigh(tensor: TensorType) -&gt; torch.Tensor:\n    \"Computes the eigen decomposition of a self-adjoint matrix.\"\n    eigval, eigvec = torch.linalg.eigh(tensor)\n    return eigval, eigvec\n</code></pre>"},{"location":"api/operators/#oodeel.utils.torch_operator.TorchOperator.einsum","title":"<code>einsum(equation, *tensors)</code>  <code>staticmethod</code>","text":"<p>Computes the einsum between tensors following equation</p> Source code in <code>oodeel/utils/torch_operator.py</code> <pre><code>@staticmethod\ndef einsum(equation: str, *tensors: TensorType) -&gt; torch.Tensor:\n    \"Computes the einsum between tensors following equation\"\n    return torch.einsum(equation, *tensors)\n</code></pre>"},{"location":"api/operators/#oodeel.utils.torch_operator.TorchOperator.equal","title":"<code>equal(tensor, other)</code>  <code>staticmethod</code>","text":"<p>Computes element-wise equality</p> Source code in <code>oodeel/utils/torch_operator.py</code> <pre><code>@staticmethod\ndef equal(tensor: TensorType, other: Union[TensorType, int, float]) -&gt; torch.Tensor:\n    \"Computes element-wise equality\"\n    return torch.eq(tensor, other)\n</code></pre>"},{"location":"api/operators/#oodeel.utils.torch_operator.TorchOperator.flatten","title":"<code>flatten(tensor)</code>  <code>staticmethod</code>","text":"<p>Flatten function</p> Source code in <code>oodeel/utils/torch_operator.py</code> <pre><code>@staticmethod\ndef flatten(tensor: TensorType) -&gt; torch.Tensor:\n    \"Flatten function\"\n    # Flatten the features to 2D (n_batch, n_features)\n    return tensor.view(tensor.size(0), -1)\n</code></pre>"},{"location":"api/operators/#oodeel.utils.torch_operator.TorchOperator.from_numpy","title":"<code>from_numpy(arr)</code>","text":"<p>Convert a NumPy array to a tensor</p> Source code in <code>oodeel/utils/torch_operator.py</code> <pre><code>def from_numpy(self, arr: np.ndarray) -&gt; torch.Tensor:\n    \"Convert a NumPy array to a tensor\"\n    # TODO change dtype\n    return torch.tensor(arr).to(self._device)\n</code></pre>"},{"location":"api/operators/#oodeel.utils.torch_operator.TorchOperator.gradient","title":"<code>gradient(func, inputs, *args, **kwargs)</code>  <code>staticmethod</code>","text":"<p>Compute gradients for a batch of samples.</p> <p>Parameters:</p> Name Type Description Default <code>func</code> <code>Callable</code> <p>Function used for computing gradient. Must be built with torch differentiable operations only, and return a scalar.</p> required <code>inputs</code> <code>torch.Tensor</code> <p>Input tensor wrt which the gradients are computed</p> required <code>*args</code> <p>Additional Args for func.</p> <code>()</code> <code>**kwargs</code> <p>Additional Kwargs for func.</p> <code>{}</code> <p>Returns:</p> Type Description <code>torch.Tensor</code> <p>torch.Tensor: Gradients computed, with the same shape as the inputs.</p> Source code in <code>oodeel/utils/torch_operator.py</code> <pre><code>@staticmethod\ndef gradient(func: Callable, inputs: torch.Tensor, *args, **kwargs) -&gt; torch.Tensor:\n\"\"\"Compute gradients for a batch of samples.\n\n    Args:\n        func (Callable): Function used for computing gradient. Must be built with\n            torch differentiable operations only, and return a scalar.\n        inputs (torch.Tensor): Input tensor wrt which the gradients are computed\n        *args: Additional Args for func.\n        **kwargs: Additional Kwargs for func.\n\n    Returns:\n        torch.Tensor: Gradients computed, with the same shape as the inputs.\n    \"\"\"\n    inputs.requires_grad_(True)\n    outputs = func(inputs, *args, **kwargs)\n    gradients = torch.autograd.grad(outputs, inputs)\n    inputs.requires_grad_(False)\n    return gradients[0]\n</code></pre>"},{"location":"api/operators/#oodeel.utils.torch_operator.TorchOperator.log","title":"<code>log(tensor)</code>  <code>staticmethod</code>","text":"<p>Perform log</p> Source code in <code>oodeel/utils/torch_operator.py</code> <pre><code>@staticmethod\ndef log(tensor: TensorType) -&gt; torch.Tensor:\n\"\"\"Perform log\"\"\"\n    return torch.log(tensor)\n</code></pre>"},{"location":"api/operators/#oodeel.utils.torch_operator.TorchOperator.matmul","title":"<code>matmul(tensor_1, tensor_2)</code>  <code>staticmethod</code>","text":"<p>Matmul operation</p> Source code in <code>oodeel/utils/torch_operator.py</code> <pre><code>@staticmethod\ndef matmul(tensor_1: TensorType, tensor_2: TensorType) -&gt; torch.Tensor:\n\"\"\"Matmul operation\"\"\"\n    return torch.matmul(tensor_1, tensor_2)\n</code></pre>"},{"location":"api/operators/#oodeel.utils.torch_operator.TorchOperator.max","title":"<code>max(tensor, dim=None, keepdim=False)</code>  <code>staticmethod</code>","text":"<p>Max function</p> Source code in <code>oodeel/utils/torch_operator.py</code> <pre><code>@staticmethod\ndef max(\n    tensor: TensorType, dim: Optional[int] = None, keepdim: Optional[bool] = False\n) -&gt; torch.Tensor:\n\"\"\"Max function\"\"\"\n    if dim is None:\n        return torch.max(tensor)\n    else:\n        return torch.max(tensor, dim, keepdim=keepdim)[0]\n</code></pre>"},{"location":"api/operators/#oodeel.utils.torch_operator.TorchOperator.mean","title":"<code>mean(tensor, dim=None)</code>  <code>staticmethod</code>","text":"<p>Mean function</p> Source code in <code>oodeel/utils/torch_operator.py</code> <pre><code>@staticmethod\ndef mean(tensor: TensorType, dim: Optional[int] = None) -&gt; torch.Tensor:\n    \"Mean function\"\n    if dim is None:\n        return torch.mean(tensor)\n    else:\n        return torch.mean(tensor, dim)\n</code></pre>"},{"location":"api/operators/#oodeel.utils.torch_operator.TorchOperator.min","title":"<code>min(tensor, dim=None, keepdim=False)</code>  <code>staticmethod</code>","text":"<p>Min function</p> Source code in <code>oodeel/utils/torch_operator.py</code> <pre><code>@staticmethod\ndef min(\n    tensor: TensorType, dim: Optional[int] = None, keepdim: bool = False\n) -&gt; torch.Tensor:\n\"\"\"Min function\"\"\"\n    if dim is None:\n        return torch.min(tensor)\n    else:\n        return torch.min(tensor, dim, keepdim=keepdim)[0]\n</code></pre>"},{"location":"api/operators/#oodeel.utils.torch_operator.TorchOperator.norm","title":"<code>norm(tensor, dim=None)</code>  <code>staticmethod</code>","text":"<p>Tensor Norm</p> Source code in <code>oodeel/utils/torch_operator.py</code> <pre><code>@staticmethod\ndef norm(tensor: TensorType, dim: Optional[int] = None) -&gt; torch.Tensor:\n\"\"\"Tensor Norm\"\"\"\n    return torch.norm(tensor, dim=dim)\n</code></pre>"},{"location":"api/operators/#oodeel.utils.torch_operator.TorchOperator.one_hot","title":"<code>one_hot(tensor, num_classes)</code>  <code>staticmethod</code>","text":"<p>One hot function</p> Source code in <code>oodeel/utils/torch_operator.py</code> <pre><code>@staticmethod\ndef one_hot(tensor: TensorType, num_classes: int) -&gt; torch.Tensor:\n\"\"\"One hot function\"\"\"\n    return torch.nn.functional.one_hot(tensor, num_classes)\n</code></pre>"},{"location":"api/operators/#oodeel.utils.torch_operator.TorchOperator.permute","title":"<code>permute(tensor, dims)</code>  <code>staticmethod</code>","text":"<p>Transpose function for tensor of rank 2</p> Source code in <code>oodeel/utils/torch_operator.py</code> <pre><code>@staticmethod\ndef permute(tensor: TensorType, dims) -&gt; torch.Tensor:\n    \"Transpose function for tensor of rank 2\"\n    return torch.permute(tensor, dims)\n</code></pre>"},{"location":"api/operators/#oodeel.utils.torch_operator.TorchOperator.pinv","title":"<code>pinv(tensor)</code>  <code>staticmethod</code>","text":"<p>Computes the pseudoinverse (Moore-Penrose inverse) of a matrix.</p> Source code in <code>oodeel/utils/torch_operator.py</code> <pre><code>@staticmethod\ndef pinv(tensor: TensorType) -&gt; torch.Tensor:\n    \"Computes the pseudoinverse (Moore-Penrose inverse) of a matrix.\"\n    return torch.linalg.pinv(tensor)\n</code></pre>"},{"location":"api/operators/#oodeel.utils.torch_operator.TorchOperator.quantile","title":"<code>quantile(tensor, q, dim=None)</code>  <code>staticmethod</code>","text":"<p>Computes the quantile of a tensor's components. q in (0,1)</p> Source code in <code>oodeel/utils/torch_operator.py</code> <pre><code>@staticmethod\ndef quantile(tensor: TensorType, q: float, dim: int = None) -&gt; torch.Tensor:\n    \"Computes the quantile of a tensor's components. q in (0,1)\"\n    if dim is None:\n        # keep the 16 millions first elements (see torch.quantile issue:\n        # https://github.com/pytorch/pytorch/issues/64947)\n        tensor_flatten = tensor.view(-1)[:16_000_000]\n        return torch.quantile(tensor_flatten, q).item()\n    else:\n        return torch.quantile(tensor, q, dim)\n</code></pre>"},{"location":"api/operators/#oodeel.utils.torch_operator.TorchOperator.relu","title":"<code>relu(tensor)</code>  <code>staticmethod</code>","text":"<p>Apply relu to a tensor</p> Source code in <code>oodeel/utils/torch_operator.py</code> <pre><code>@staticmethod\ndef relu(tensor: TensorType) -&gt; torch.Tensor:\n    \"Apply relu to a tensor\"\n    return torch.nn.functional.relu(tensor)\n</code></pre>"},{"location":"api/operators/#oodeel.utils.torch_operator.TorchOperator.reshape","title":"<code>reshape(tensor, shape)</code>  <code>staticmethod</code>","text":"<p>Reshape function</p> Source code in <code>oodeel/utils/torch_operator.py</code> <pre><code>@staticmethod\ndef reshape(tensor: TensorType, shape: List[int]) -&gt; torch.Tensor:\n    \"Reshape function\"\n    return tensor.view(*shape)\n</code></pre>"},{"location":"api/operators/#oodeel.utils.torch_operator.TorchOperator.sign","title":"<code>sign(tensor)</code>  <code>staticmethod</code>","text":"<p>Sign function</p> Source code in <code>oodeel/utils/torch_operator.py</code> <pre><code>@staticmethod\ndef sign(tensor: TensorType) -&gt; torch.Tensor:\n\"\"\"Sign function\"\"\"\n    return torch.sign(tensor)\n</code></pre>"},{"location":"api/operators/#oodeel.utils.torch_operator.TorchOperator.softmax","title":"<code>softmax(tensor)</code>  <code>staticmethod</code>","text":"<p>Softmax function along the last dimension</p> Source code in <code>oodeel/utils/torch_operator.py</code> <pre><code>@staticmethod\ndef softmax(tensor: TensorType) -&gt; torch.Tensor:\n\"\"\"Softmax function along the last dimension\"\"\"\n    return torch.nn.functional.softmax(tensor, dim=-1)\n</code></pre>"},{"location":"api/operators/#oodeel.utils.torch_operator.TorchOperator.squeeze","title":"<code>squeeze(tensor, dim=None)</code>  <code>staticmethod</code>","text":"<p>squeeze along dim</p> Source code in <code>oodeel/utils/torch_operator.py</code> <pre><code>@staticmethod\ndef squeeze(tensor: TensorType, dim: int = None) -&gt; torch.Tensor:\n    \"squeeze along dim\"\n\n    if dim is None:\n        return torch.squeeze(tensor)\n\n    return torch.squeeze(tensor, dim)\n</code></pre>"},{"location":"api/operators/#oodeel.utils.torch_operator.TorchOperator.stack","title":"<code>stack(tensors, dim=0)</code>  <code>staticmethod</code>","text":"<p>Stack tensors along a new dimension</p> Source code in <code>oodeel/utils/torch_operator.py</code> <pre><code>@staticmethod\ndef stack(tensors: List[TensorType], dim: int = 0) -&gt; torch.Tensor:\n    \"Stack tensors along a new dimension\"\n    return torch.stack(tensors, dim)\n</code></pre>"},{"location":"api/operators/#oodeel.utils.torch_operator.TorchOperator.sum","title":"<code>sum(tensor, dim=None)</code>  <code>staticmethod</code>","text":"<p>sum along dim</p> Source code in <code>oodeel/utils/torch_operator.py</code> <pre><code>@staticmethod\ndef sum(tensor: TensorType, dim: Union[tuple, list, int] = None) -&gt; torch.Tensor:\n    \"sum along dim\"\n    return torch.sum(tensor, dim)\n</code></pre>"},{"location":"api/operators/#oodeel.utils.torch_operator.TorchOperator.t","title":"<code>t(tensor)</code>  <code>staticmethod</code>","text":"<p>Transpose function for tensor of rank 2</p> Source code in <code>oodeel/utils/torch_operator.py</code> <pre><code>@staticmethod\ndef t(tensor: TensorType) -&gt; torch.Tensor:\n    \"Transpose function for tensor of rank 2\"\n    return tensor.t()\n</code></pre>"},{"location":"api/operators/#oodeel.utils.torch_operator.TorchOperator.tril","title":"<code>tril(tensor, diagonal=0)</code>  <code>staticmethod</code>","text":"<p>Set the upper triangle of the matrix formed by the last two dimensions of</p> Source code in <code>oodeel/utils/torch_operator.py</code> <pre><code>@staticmethod\ndef tril(tensor: TensorType, diagonal: int = 0) -&gt; torch.Tensor:\n    \"Set the upper triangle of the matrix formed by the last two dimensions of\"\n    \"tensor to zero\"\n    return torch.tril(tensor, diagonal)\n</code></pre>"},{"location":"api/operators/#oodeel.utils.torch_operator.TorchOperator.unsqueeze","title":"<code>unsqueeze(tensor, dim)</code>  <code>staticmethod</code>","text":"<p>unsqueeze along dim</p> Source code in <code>oodeel/utils/torch_operator.py</code> <pre><code>@staticmethod\ndef unsqueeze(tensor: TensorType, dim: int) -&gt; torch.Tensor:\n    \"unsqueeze along dim\"\n    return torch.unsqueeze(tensor, dim)\n</code></pre>"},{"location":"api/operators/#oodeel.utils.torch_operator.TorchOperator.where","title":"<code>where(condition, input, other)</code>  <code>staticmethod</code>","text":"<p>Applies where function , to condition</p> Source code in <code>oodeel/utils/torch_operator.py</code> <pre><code>@staticmethod\ndef where(\n    condition: TensorType,\n    input: Union[TensorType, float],\n    other: Union[TensorType, float],\n) -&gt; torch.Tensor:\n    \"Applies where function , to condition\"\n    return torch.where(condition, input, other)\n</code></pre>"},{"location":"api/operators/#oodeel.utils.torch_operator.sanitize_input","title":"<code>sanitize_input(tensor_arg_func)</code>","text":"<p>ensures the decorated function receives a torch.Tensor</p> Source code in <code>oodeel/utils/torch_operator.py</code> <pre><code>def sanitize_input(tensor_arg_func: Callable):\n\"\"\"ensures the decorated function receives a torch.Tensor\"\"\"\n\n    def wrapper(obj, tensor, *args, **kwargs):\n        if isinstance(tensor, torch.Tensor):\n            pass\n        elif is_from(tensor, \"tensorflow\"):\n            tensor = torch.Tensor(tensor.numpy())\n        else:\n            tensor = torch.Tensor(tensor)\n\n        return tensor_arg_func(obj, tensor, *args, **kwargs)\n\n    return wrapper\n</code></pre>"},{"location":"api/plots/","title":"Plots","text":""},{"location":"api/plots/#oodeel.eval.plots.features.plot_2D_features","title":"<code>plot_2D_features(model, in_dataset, output_layer_id, out_dataset=None, proj_method='TSNE', max_samples=4000, title=None, **proj_kwargs)</code>","text":"<p>Visualize ID and OOD features of a model on a 2D plan using dimensionality reduction methods and matplotlib scatter function. Different projection methods are available: TSNE, PCA.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Callable</code> <p>Torch or Keras model.</p> required <code>in_dataset</code> <code>DatasetType</code> <p>In-distribution dataset (torch dataloader or tf dataset) that will be projected on the model feature space.</p> required <code>output_layer_id</code> <code>Union[int, str]</code> <p>Identifier for the layer to inspect.</p> required <code>out_dataset</code> <code>DatasetType</code> <p>Out-of-distribution dataset (torch dataloader or tf dataset) that will be projected on the model feature space if not equal to None. Defaults to None.</p> <code>None</code> <code>proj_method</code> <code>str</code> <p>Projection method for 2d dimensionality reduction. Defaults to \"TSNE\", alternative: \"PCA\".</p> <code>'TSNE'</code> <code>max_samples</code> <code>int</code> <p>Max samples to display on the scatter plot. Defaults to 4000.</p> <code>4000</code> <code>title</code> <code>str</code> <p>Custom figure title. Defaults to None.</p> <code>None</code> Source code in <code>oodeel/eval/plots/features.py</code> <pre><code>def plot_2D_features(\n    model: Callable,\n    in_dataset: DatasetType,\n    output_layer_id: Union[int, str],\n    out_dataset: DatasetType = None,\n    proj_method: str = \"TSNE\",\n    max_samples: int = 4000,\n    title: str = None,\n    **proj_kwargs,\n):\n\"\"\"Visualize ID and OOD features of a model on a 2D plan using dimensionality\n    reduction methods and matplotlib scatter function. Different projection methods are\n    available: TSNE, PCA.\n\n    Args:\n        model (Callable): Torch or Keras model.\n        in_dataset (DatasetType): In-distribution dataset (torch dataloader or tf\n            dataset) that will be projected on the model feature space.\n        output_layer_id (Union[int, str]): Identifier for the layer to inspect.\n        out_dataset (DatasetType, optional): Out-of-distribution dataset (torch\n            dataloader or tf dataset) that will be projected on the model feature space\n            if not equal to None. Defaults to None.\n        proj_method (str, optional): Projection method for 2d dimensionality reduction.\n            Defaults to \"TSNE\", alternative: \"PCA\".\n        max_samples (int, optional): Max samples to display on the scatter plot.\n            Defaults to 4000.\n        title (str, optional): Custom figure title. Defaults to None.\n    \"\"\"\n\n    _plot_features(\n        model=model,\n        in_dataset=in_dataset,\n        output_layer_id=output_layer_id,\n        out_dataset=out_dataset,\n        proj_method=proj_method,\n        max_samples=max_samples,\n        title=title,\n        n_components=2,\n        **proj_kwargs,\n    )\n</code></pre>"},{"location":"api/plots/#oodeel.eval.plots.features.plot_3D_features","title":"<code>plot_3D_features(model, in_dataset, output_layer_id, out_dataset=None, proj_method='TSNE', max_samples=4000, title=None, **proj_kwargs)</code>","text":"<p>Visualize ID and OOD features of a model on a 3D space using dimensionality reduction methods and matplotlib scatter function. Different projection methods are available: TSNE, PCA.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Callable</code> <p>Torch or Keras model.</p> required <code>in_dataset</code> <code>DatasetType</code> <p>In-distribution dataset (torch dataloader or tf dataset) that will be projected on the model feature space.</p> required <code>output_layer_id</code> <code>Union[int, str]</code> <p>Identifier for the layer to inspect.</p> required <code>out_dataset</code> <code>DatasetType</code> <p>Out-of-distribution dataset (torch dataloader or tf dataset) that will be projected on the model feature space if not equal to None. Defaults to None.</p> <code>None</code> <code>proj_method</code> <code>str</code> <p>Projection method for 2d dimensionality reduction. Defaults to \"TSNE\", alternative: \"PCA\".</p> <code>'TSNE'</code> <code>max_samples</code> <code>int</code> <p>Max samples to display on the scatter plot. Defaults to 4000.</p> <code>4000</code> <code>title</code> <code>str</code> <p>Custom figure title. Defaults to None.</p> <code>None</code> Source code in <code>oodeel/eval/plots/features.py</code> <pre><code>def plot_3D_features(\n    model: Callable,\n    in_dataset: DatasetType,\n    output_layer_id: Union[int, str],\n    out_dataset: DatasetType = None,\n    proj_method: str = \"TSNE\",\n    max_samples: int = 4000,\n    title: str = None,\n    **proj_kwargs,\n):\n\"\"\"Visualize ID and OOD features of a model on a 3D space using dimensionality\n    reduction methods and matplotlib scatter function. Different projection methods are\n    available: TSNE, PCA.\n\n    Args:\n        model (Callable): Torch or Keras model.\n        in_dataset (DatasetType): In-distribution dataset (torch dataloader or tf\n            dataset) that will be projected on the model feature space.\n        output_layer_id (Union[int, str]): Identifier for the layer to inspect.\n        out_dataset (DatasetType, optional): Out-of-distribution dataset (torch\n            dataloader or tf dataset) that will be projected on the model feature space\n            if not equal to None. Defaults to None.\n        proj_method (str, optional): Projection method for 2d dimensionality reduction.\n            Defaults to \"TSNE\", alternative: \"PCA\".\n        max_samples (int, optional): Max samples to display on the scatter plot.\n            Defaults to 4000.\n        title (str, optional): Custom figure title. Defaults to None.\n    \"\"\"\n    _plot_features(\n        model=model,\n        in_dataset=in_dataset,\n        output_layer_id=output_layer_id,\n        out_dataset=out_dataset,\n        proj_method=proj_method,\n        max_samples=max_samples,\n        title=title,\n        n_components=3,\n        **proj_kwargs,\n    )\n</code></pre>"},{"location":"api/plots/#oodeel.eval.plots.metrics.plot_ood_scores","title":"<code>plot_ood_scores(scores_in, scores_out, log_scale=False, title=None)</code>","text":"<p>Plot histograms of OOD detection scores for ID and OOD distribution, using matplotlib and seaborn.</p> <p>Parameters:</p> Name Type Description Default <code>scores_in</code> <code>np.ndarray</code> <p>OOD detection scores for ID data.</p> required <code>scores_out</code> <code>np.ndarray</code> <p>OOD detection scores for OOD data.</p> required <code>log_scale</code> <code>bool</code> <p>If True, apply a log scale on x axis. Defaults to False.</p> <code>False</code> <code>title</code> <code>str</code> <p>Custom figure title. If None a default one is provided. Defaults to None.</p> <code>None</code> Source code in <code>oodeel/eval/plots/metrics.py</code> <pre><code>def plot_ood_scores(\n    scores_in: np.ndarray,\n    scores_out: np.ndarray,\n    log_scale: bool = False,\n    title: str = None,\n):\n\"\"\"Plot histograms of OOD detection scores for ID and OOD distribution, using\n    matplotlib and seaborn.\n\n    Args:\n        scores_in (np.ndarray): OOD detection scores for ID data.\n        scores_out (np.ndarray): OOD detection scores for OOD data.\n        log_scale (bool, optional): If True, apply a log scale on x axis. Defaults to\n            False.\n        title (str, optional): Custom figure title. If None a default one is provided.\n            Defaults to None.\n    \"\"\"\n    title = title or \"Histograms of OOD detection scores\"\n    ax1 = sns.histplot(\n        data=scores_in,\n        alpha=0.5,\n        label=\"ID data\",\n        stat=\"density\",\n        log_scale=log_scale,\n        kde=True,\n    )\n    ax2 = sns.histplot(\n        data=scores_out,\n        alpha=0.5,\n        label=\"OOD data\",\n        stat=\"density\",\n        log_scale=log_scale,\n        kde=True,\n    )\n    ymax = max(ax1.get_ylim()[1], ax2.get_ylim()[1])\n    threshold = np.percentile(scores_out, q=5.0)\n    plt.vlines(\n        x=[threshold],\n        ymin=0,\n        ymax=ymax,\n        colors=[\"red\"],\n        linestyles=[\"dashed\"],\n        alpha=0.7,\n        label=\"TPR=95%\",\n    )\n    plt.xlabel(\"OOD score\")\n    plt.legend()\n    plt.title(title, weight=\"bold\").set_fontsize(11)\n</code></pre>"},{"location":"api/plots/#oodeel.eval.plots.metrics.plot_roc_curve","title":"<code>plot_roc_curve(scores_in, scores_out, title=None)</code>","text":"<p>Plot ROC curve for OOD detection task, using matplotlib and seaborn.</p> <p>Parameters:</p> Name Type Description Default <code>scores_in</code> <code>np.ndarray</code> <p>OOD detection scores for ID data.</p> required <code>scores_out</code> <code>np.ndarray</code> <p>OOD detection scores for OOD data.</p> required <code>title</code> <code>str</code> <p>Custom figure title. If None a default one is provided. Defaults to None.</p> <code>None</code> Source code in <code>oodeel/eval/plots/metrics.py</code> <pre><code>def plot_roc_curve(scores_in: np.ndarray, scores_out: np.ndarray, title: str = None):\n\"\"\"Plot ROC curve for OOD detection task, using matplotlib and seaborn.\n\n    Args:\n        scores_in (np.ndarray): OOD detection scores for ID data.\n        scores_out (np.ndarray): OOD detection scores for OOD data.\n        title (str, optional): Custom figure title. If None a default one is provided.\n            Defaults to None.\n    \"\"\"\n    # compute auroc\n    metrics = bench_metrics(\n        (scores_in, scores_out),\n        metrics=[\"auroc\", \"fpr95tpr\"],\n    )\n    auroc, fpr95tpr = metrics[\"auroc\"], metrics[\"fpr95tpr\"]\n\n    # roc\n    fpr, tpr, _, _, _ = get_curve(\n        scores=np.concatenate([scores_in, scores_out]),\n        labels=np.concatenate([scores_in * 0 + 0, scores_out * 0 + 1]),\n    )\n\n    # plot roc\n    title = title or \"ROC curve (AuC = {:.3f})\".format(auroc)\n    plt.plot(fpr, tpr)\n    plt.fill_between(fpr, tpr, np.zeros_like(tpr), alpha=0.5)\n    plt.plot([fpr95tpr, fpr95tpr, 0], [0, 0.95, 0.95], \"--\", color=\"red\", alpha=0.7)\n    plt.scatter([fpr95tpr], [0.95], marker=\"o\", alpha=0.7, color=\"red\", label=\"TPR=95%\")\n    plt.xlabel(\"FPR\")\n    plt.ylabel(\"TPR\")\n    plt.xlim([-0.01, 1.01])\n    plt.ylim([-0.01, 1.01])\n    plt.legend()\n    plt.title(title, weight=\"bold\").set_fontsize(11)\n</code></pre>"},{"location":"api/plots/#oodeel.eval.plots.plotly.plotly_3D_features","title":"<code>plotly_3D_features(model, in_dataset, output_layer_id, out_dataset=None, proj_method='TSNE', max_samples=4000, title=None, **proj_kwargs)</code>","text":"<p>Visualize ID and OOD features of a model on a 3D space using dimensionality reduction methods and matplotlib scatter function. Different projection methods are available: TSNE, PCA. This function requires the package plotly to be installed to run an interactive 3D scatter plot.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Callable</code> <p>Torch or Keras model.</p> required <code>in_dataset</code> <code>DatasetType</code> <p>In-distribution dataset (torch dataloader or tf dataset) that will be projected on the model feature space.</p> required <code>output_layer_id</code> <code>Union[int, str]</code> <p>Identifier for the layer to inspect.</p> required <code>out_dataset</code> <code>DatasetType</code> <p>Out-of-distribution dataset (torch dataloader or tf dataset) that will be projected on the model feature space if not equal to None. Defaults to None.</p> <code>None</code> <code>proj_method</code> <code>str</code> <p>Projection method for 2d dimensionality reduction. Defaults to \"TSNE\", alternative: \"PCA\".</p> <code>'TSNE'</code> <code>max_samples</code> <code>int</code> <p>Max samples to display on the scatter plot. Defaults to 4000.</p> <code>4000</code> <code>title</code> <code>str</code> <p>Custom figure title. Defaults to None.</p> <code>None</code> Source code in <code>oodeel/eval/plots/plotly.py</code> <pre><code>def plotly_3D_features(\n    model: Callable,\n    in_dataset: DatasetType,\n    output_layer_id: Union[int, str],\n    out_dataset: DatasetType = None,\n    proj_method: str = \"TSNE\",\n    max_samples: int = 4000,\n    title: str = None,\n    **proj_kwargs,\n):\n\"\"\"Visualize ID and OOD features of a model on a 3D space using dimensionality\n    reduction methods and matplotlib scatter function. Different projection methods are\n    available: TSNE, PCA. This function requires the package plotly to be installed to\n    run an interactive 3D scatter plot.\n\n    Args:\n        model (Callable): Torch or Keras model.\n        in_dataset (DatasetType): In-distribution dataset (torch dataloader or tf\n            dataset) that will be projected on the model feature space.\n        output_layer_id (Union[int, str]): Identifier for the layer to inspect.\n        out_dataset (DatasetType, optional): Out-of-distribution dataset (torch\n            dataloader or tf dataset) that will be projected on the model feature space\n            if not equal to None. Defaults to None.\n        proj_method (str, optional): Projection method for 2d dimensionality reduction.\n            Defaults to \"TSNE\", alternative: \"PCA\".\n        max_samples (int, optional): Max samples to display on the scatter plot.\n            Defaults to 4000.\n        title (str, optional): Custom figure title. Defaults to None.\n    \"\"\"\n    max_samples = max_samples if out_dataset is None else max_samples // 2\n\n    # feature extractor\n    _, _, op, FeatureExtractorClass = import_backend_specific_stuff(model)\n    feature_extractor = FeatureExtractorClass(model, [output_layer_id])\n\n    # === extract id features ===\n    # features\n    in_features, _ = feature_extractor.predict(in_dataset)\n    in_features = op.convert_to_numpy(op.flatten(in_features[0]))[:max_samples]\n\n    # labels\n    in_labels = []\n    for _, batch_y in in_dataset:\n        in_labels.append(op.convert_to_numpy(batch_y))\n    in_labels = np.concatenate(in_labels)[:max_samples]\n    in_labels = list(map(lambda x: f\"class {x}\", in_labels))\n\n    # === extract ood features ===\n    if out_dataset is not None:\n        # features\n        out_features, _ = feature_extractor.predict(out_dataset)\n        out_features = op.convert_to_numpy(op.flatten(out_features[0]))[:max_samples]\n\n        # labels\n        out_labels = np.array([\"unknown\"] * len(out_features))\n\n        # concatenate id and ood items\n        features = np.concatenate([out_features, in_features])\n        labels = np.concatenate([out_labels, in_labels])\n        data_type = np.array([\"OOD\"] * len(out_labels) + [\"ID\"] * len(in_labels))\n        points_size = np.array([1] * len(out_labels) + [3] * len(in_labels))\n    else:\n        features = in_features\n        labels = in_labels\n        data_type = np.array([\"ID\"] * len(in_labels))\n        points_size = np.array([3] * len(in_labels))\n\n    # === project on 3d space using tsne or pca ===\n    proj_class = PROJ_DICT[proj_method][\"class\"]\n    p_kwargs = PROJ_DICT[proj_method][\"default_kwargs\"]\n    p_kwargs.update(proj_kwargs)\n    projector = proj_class(\n        n_components=3,\n        **p_kwargs,\n    )\n    features_proj = projector.fit_transform(features)\n\n    # === plot 3d features ===\n    features_dim = features.shape[1]\n    method_str = PROJ_DICT[proj_method][\"name\"]\n    title = (\n        title\n        or f\"{method_str} 3D projection\\n\"\n        + f\"[layer {output_layer_id}, dim: {features_dim}]\"\n    )\n\n    x, y, z = features_proj.T\n    df = pd.DataFrame(\n        {\n            \"dim 1\": x,\n            \"dim 2\": y,\n            \"dim 3\": z,\n            \"class\": labels,\n            \"data type\": data_type,\n            \"size\": points_size,\n        }\n    )\n\n    # 3D projection\n    fig = px.scatter_3d(\n        data_frame=df,\n        x=\"dim 1\",\n        y=\"dim 2\",\n        z=\"dim 3\",\n        color=\"class\",\n        symbol=\"data type\",\n        size=\"size\",\n        opacity=1,\n        category_orders={\"class\": np.unique(df[\"class\"])},\n        symbol_map={\"OOD\": \"circle\", \"ID\": \"diamond\"},\n    )\n\n    fig.update_layout(\n        title={\"text\": title, \"y\": 0.9, \"x\": 0.5, \"xanchor\": \"center\", \"yanchor\": \"top\"}\n    )\n    fig.show()\n</code></pre>"},{"location":"api/tf_datahandler/","title":"TFDataHandler","text":""},{"location":"api/tf_datahandler/#oodeel.datasets.tf_data_handler.TFDataHandler","title":"<code>TFDataHandler</code>","text":"<p>         Bases: <code>DataHandler</code></p> <p>Class to manage tf.data.Dataset. The aim is to provide a simple interface for working with tf.data.Datasets and manage them without having to use tensorflow syntax.</p> Source code in <code>oodeel/datasets/tf_data_handler.py</code> <pre><code>class TFDataHandler(DataHandler):\n\"\"\"\n    Class to manage tf.data.Dataset. The aim is to provide a simple interface for\n    working with tf.data.Datasets and manage them without having to use\n    tensorflow syntax.\n    \"\"\"\n\n    @classmethod\n    def load_dataset(\n        cls,\n        dataset_id: Union[tf.data.Dataset, ItemType, str],\n        keys: Optional[list] = None,\n        load_kwargs: dict = {},\n    ) -&gt; tf.data.Dataset:\n\"\"\"Load dataset from different manners, ensuring to return a dict based\n        tf.data.Dataset.\n\n        Args:\n            dataset_id (Any): dataset identification\n            keys (list, optional): Features keys. If None, assigned as \"input_i\"\n                for i-th feature. Defaults to None.\n            load_kwargs (dict, optional): Additional args for loading from\n                tensorflow_datasets. Defaults to {}.\n\n        Returns:\n            tf.data.Dataset: A dict based tf.data.Dataset\n        \"\"\"\n        if isinstance(dataset_id, get_args(ItemType)):\n            dataset = cls.load_dataset_from_arrays(dataset_id, keys)\n        elif isinstance(dataset_id, tf.data.Dataset):\n            dataset = cls.load_custom_dataset(dataset_id, keys)\n        elif isinstance(dataset_id, str):\n            dataset = cls.load_from_tensorflow_datasets(dataset_id, load_kwargs)\n        return dataset\n\n    @staticmethod\n    def load_dataset_from_arrays(\n        dataset_id: ItemType, keys: Optional[list] = None\n    ) -&gt; tf.data.Dataset:\n\"\"\"Load a tf.data.Dataset from a np.ndarray, a tf.Tensor or a tuple/dict\n        of np.ndarrays/td.Tensors.\n\n        Args:\n            dataset_id (ItemType): numpy array(s) to load.\n            keys (list, optional): Features keys. If None, assigned as \"input_i\"\n                for i-th feature. Defaults to None.\n\n        Returns:\n            tf.data.Dataset\n        \"\"\"\n        # If dataset_id is a numpy array, convert it to a dict\n        if isinstance(dataset_id, get_args(TensorType)):\n            dataset_dict = {\"input\": dataset_id}\n\n        # If dataset_id is a tuple, convert it to a dict\n        elif isinstance(dataset_id, tuple):\n            len_elem = len(dataset_id)\n            if keys is None:\n                if len_elem == 2:\n                    dataset_dict = {\"input\": dataset_id[0], \"label\": dataset_id[1]}\n                else:\n                    dataset_dict = {\n                        f\"input_{i}\": dataset_id[i] for i in range(len_elem - 1)\n                    }\n                    dataset_dict[\"label\"] = dataset_id[-1]\n                print(\n                    'Loading tf.data.Dataset with elems as dicts, assigning \"input_i\" '\n                    'key to the i-th tuple dimension and \"label\" key to the last '\n                    \"tuple dimension.\"\n                )\n            else:\n                assert (\n                    len(keys) == len_elem\n                ), \"Number of keys mismatch with the number of features\"\n                dataset_dict = {keys[i]: dataset_id[i] for i in range(len_elem)}\n\n        elif isinstance(dataset_id, dict):\n            if keys is not None:\n                len_elem = len(dataset_id)\n                assert (\n                    len(keys) == len_elem\n                ), \"Number of keys mismatch with the number of features\"\n                original_keys = list(dataset_id.keys())\n                dataset_dict = {\n                    keys[i]: dataset_id[original_keys[i]] for i in range(len_elem)\n                }\n\n        dataset = tf.data.Dataset.from_tensor_slices(dataset_dict)\n        return dataset\n\n    @classmethod\n    def load_custom_dataset(\n        cls, dataset_id: tf.data.Dataset, keys: Optional[list] = None\n    ) -&gt; tf.data.Dataset:\n\"\"\"Load a custom Dataset by ensuring it has the correct format (dict-based)\n\n        Args:\n            dataset_id (tf.data.Dataset): tf.data.Dataset\n            keys (list, optional): Features keys. If None, assigned as \"input_i\"\n                for i-th feature. Defaults to None.\n\n        Returns:\n            tf.data.Dataset\n        \"\"\"\n        # If dataset_id is a tuple based tf.data.dataset, convert it to a dict\n        if not isinstance(dataset_id.element_spec, dict):\n            len_elem = len(dataset_id.element_spec)\n            if keys is None:\n                print(\n                    \"Feature name not found, assigning 'input_i' \"\n                    \"key to the i-th tensor and 'label' key to the last\"\n                )\n                if len_elem == 2:\n                    keys = [\"input\", \"label\"]\n                else:\n                    keys = [f\"input_{i}\" for i in range(len_elem)]\n                    keys[-1] = \"label\"\n            else:\n                assert (\n                    len(keys) == len_elem\n                ), \"Number of keys mismatch with the number of features\"\n\n            dataset_id = cls.tuple_to_dict(dataset_id, keys)\n\n        dataset = dataset_id\n        return dataset\n\n    @staticmethod\n    def load_from_tensorflow_datasets(\n        dataset_id: str,\n        load_kwargs: dict = {},\n    ) -&gt; tf.data.Dataset:\n\"\"\"Load a tf.data.Dataset from the tensorflow_datasets catalog\n\n        Args:\n            dataset_id (str): Identifier of the dataset\n            load_kwargs (dict, optional): Loading kwargs to add to tfds.load().\n                Defaults to {}.\n\n        Returns:\n            tf.data.Dataset\n        \"\"\"\n        assert (\n            dataset_id in tfds.list_builders()\n        ), \"Dataset not available on tensorflow datasets catalog\"\n        dataset = tfds.load(dataset_id, **load_kwargs)\n        return dataset\n\n    @staticmethod\n    @dict_only_ds\n    def dict_to_tuple(\n        dataset: tf.data.Dataset, keys: Optional[list] = None\n    ) -&gt; tf.data.Dataset:\n\"\"\"Turn a dict based tf.data.Dataset to a tuple based tf.data.Dataset\n\n        Args:\n            dataset (tf.data.Dataset): Dict based tf.data.Dataset\n            keys (list, optional): Features to use for the tuples based\n                tf.data.Dataset. If None, takes all the features. Defaults to None.\n\n        Returns:\n            tf.data.Dataset\n        \"\"\"\n        if keys is None:\n            keys = list(dataset.element_spec.keys())\n        dataset = dataset.map(lambda x: tuple(x[k] for k in keys))\n        return dataset\n\n    @staticmethod\n    def tuple_to_dict(dataset: tf.data.Dataset, keys: list) -&gt; tf.data.Dataset:\n\"\"\"Turn a tuple based tf.data.Dataset to a dict based tf.data.Dataset\n\n        Args:\n            dataset (tf.data.Dataset): Tuple based tf.data.Dataset\n            keys (list): Keys to use for the dict based tf.data.Dataset\n\n        Returns:\n            tf.data.Dataset\n        \"\"\"\n        assert isinstance(\n            dataset.element_spec, tuple\n        ), \"dataset elements must be tuples\"\n        len_elem = len(dataset.element_spec)\n        assert len_elem == len(\n            keys\n        ), \"The number of keys must be equal to the number of tuple elements\"\n\n        def tuple_to_dict(*inputs):\n            return {keys[i]: inputs[i] for i in range(len_elem)}\n\n        dataset = dataset.map(tuple_to_dict)\n        return dataset\n\n    @staticmethod\n    def assign_feature_value(\n        dataset: tf.data.Dataset, feature_key: str, value: int\n    ) -&gt; tf.data.Dataset:\n\"\"\"Assign a value to a feature for every sample in a tf.data.Dataset\n\n        Args:\n            dataset (tf.data.Dataset): tf.data.Dataset to assign the value to\n            feature_key (str): Feature to assign the value to\n            value (int): Value to assign\n\n        Returns:\n            tf.data.Dataset\n        \"\"\"\n        assert isinstance(dataset.element_spec, dict), \"dataset elements must be dicts\"\n\n        def assign_value_to_feature(x):\n            x[feature_key] = value\n            return x\n\n        dataset = dataset.map(assign_value_to_feature)\n        return dataset\n\n    @staticmethod\n    @dict_only_ds\n    def get_feature_from_ds(dataset: tf.data.Dataset, feature_key: str) -&gt; np.ndarray:\n\"\"\"Get a feature from a tf.data.Dataset\n\n        !!! note\n            This function can be a bit time consuming since it needs to iterate\n            over the whole dataset.\n\n        Args:\n            dataset (tf.data.Dataset): tf.data.Dataset to get the feature from\n            feature_key (str): Feature value to get\n\n        Returns:\n            np.ndarray: Feature values for dataset\n        \"\"\"\n        features = dataset.map(lambda x: x[feature_key])\n        features = list(features.as_numpy_iterator())\n        features = np.array(features)\n        return features\n\n    @staticmethod\n    @dict_only_ds\n    def get_ds_feature_keys(dataset: tf.data.Dataset) -&gt; list:\n\"\"\"Get the feature keys of a tf.data.Dataset\n\n        Args:\n            dataset (tf.data.Dataset): tf.data.Dataset to get the feature keys from\n\n        Returns:\n            list: List of feature keys\n        \"\"\"\n        return list(dataset.element_spec.keys())\n\n    @staticmethod\n    def has_feature_key(dataset: tf.data.Dataset, key: str) -&gt; bool:\n\"\"\"Check if a tf.data.Dataset has a feature denoted by key\n\n        Args:\n            dataset (tf.data.Dataset): tf.data.Dataset to check\n            key (str): Key to check\n\n        Returns:\n            bool: If the tf.data.Dataset has a feature denoted by key\n        \"\"\"\n        assert isinstance(dataset.element_spec, dict), \"dataset elements must be dicts\"\n        return True if (key in dataset.element_spec.keys()) else False\n\n    @staticmethod\n    def map_ds(\n        dataset: tf.data.Dataset,\n        map_fn: Callable,\n        num_parallel_calls: Optional[int] = None,\n    ) -&gt; tf.data.Dataset:\n\"\"\"Map a function to a tf.data.Dataset\n\n        Args:\n            dataset (tf.data.Dataset): tf.data.Dataset to map the function to\n            map_fn (Callable): Function to map\n            num_parallel_calls (Optional[int], optional): Number of parallel processes\n                to use. Defaults to None.\n\n        Returns:\n            tf.data.Dataset: Maped dataset\n        \"\"\"\n        if num_parallel_calls is None:\n            num_parallel_calls = tf.data.experimental.AUTOTUNE\n        dataset = dataset.map(map_fn, num_parallel_calls=num_parallel_calls)\n        return dataset\n\n    @staticmethod\n    @dict_only_ds\n    def filter_by_feature_value(\n        dataset: tf.data.Dataset,\n        feature_key: str,\n        values: list,\n        excluded: bool = False,\n    ) -&gt; tf.data.Dataset:\n\"\"\"Filter a tf.data.Dataset by checking the value of a feature is in 'values'\n\n        Args:\n            dataset (tf.data.Dataset): tf.data.Dataset to filter\n            feature_key (str): Feature name to check the value\n            values (list): Feature_key values to keep (if excluded is False)\n                or to exclude\n            excluded (bool, optional): To keep (False) or exclude (True) the samples\n                with Feature_key value included in Values. Defaults to False.\n\n        Returns:\n            tf.data.Dataset: Filtered dataset\n        \"\"\"\n        # If the labels are one-hot encoded, prepare a function to get the label as int\n        if len(dataset.element_spec[feature_key].shape) &gt; 0:\n\n            def get_label_int(elem):\n                return int(tf.argmax(elem[feature_key]))\n\n        else:\n\n            def get_label_int(elem):\n                return elem[feature_key]\n\n        def filter_fn(elem):\n            value = get_label_int(elem)\n            if excluded:\n                return not tf.reduce_any(tf.equal(value, values))\n            else:\n                return tf.reduce_any(tf.equal(value, values))\n\n        dataset_to_filter = dataset\n        dataset_to_filter = dataset_to_filter.filter(filter_fn)\n        return dataset_to_filter\n\n    @classmethod\n    def prepare_for_training(\n        cls,\n        dataset: tf.data.Dataset,\n        batch_size: int,\n        shuffle: bool = False,\n        preprocess_fn: Optional[Callable] = None,\n        augment_fn: Optional[Callable] = None,\n        output_keys: Optional[list] = None,\n        dict_based_fns: bool = False,\n        shuffle_buffer_size: Optional[int] = None,\n        prefetch_buffer_size: Optional[int] = None,\n        drop_remainder: Optional[bool] = False,\n    ) -&gt; tf.data.Dataset:\n\"\"\"Prepare a tf.data.Dataset for training\n\n        Args:\n            dataset (tf.data.Dataset): tf.data.Dataset to prepare\n            batch_size (int): Batch size\n            shuffle (bool, optional): To shuffle the returned dataset or not.\n                Defaults to False.\n            preprocess_fn (Callable, optional): Preprocessing function to apply to\\\n                the dataset. Defaults to None.\n            augment_fn (Callable, optional): Augment function to be used (when the\\\n                returned dataset is to be used for training). Defaults to None.\n            output_keys (list, optional): List of keys corresponding to the features\n                that will be returned. Keep all features if None. Defaults to None.\n            dict_based_fns (bool, optional): If the augment and preprocess functions are\n                dict based or not. Defaults to False.\n            shuffle_buffer_size (int, optional): Size of the shuffle buffer. If None,\n                taken as the number of samples in the dataset. Defaults to None.\n            prefetch_buffer_size (Optional[int], optional): Buffer size for prefetch.\n                If None, automatically chose using tf.data.experimental.AUTOTUNE.\n                Defaults to None.\n            drop_remainder (Optional[bool], optional): To drop the last batch when\n                its size is lower than batch_size. Defaults to False.\n\n        Returns:\n            tf.data.Dataset: Prepared dataset\n        \"\"\"\n        # dict based to tuple based\n        output_keys = output_keys or cls.get_ds_feature_keys(dataset)\n        if not dict_based_fns:\n            dataset = cls.dict_to_tuple(dataset, output_keys)\n\n        # preprocess + DA\n        if preprocess_fn is not None:\n            dataset = cls.map_ds(dataset, preprocess_fn)\n        if augment_fn is not None:\n            dataset = cls.map_ds(dataset, augment_fn)\n\n        if dict_based_fns:\n            dataset = cls.dict_to_tuple(dataset, output_keys)\n\n        dataset = dataset.cache()\n\n        # shuffle\n        if shuffle:\n            num_samples = cls.get_dataset_length(dataset)\n            shuffle_buffer_size = (\n                num_samples if shuffle_buffer_size is None else shuffle_buffer_size\n            )\n            dataset = dataset.shuffle(shuffle_buffer_size)\n        # batch\n        dataset = dataset.batch(batch_size, drop_remainder=drop_remainder)\n        # prefetch\n        if prefetch_buffer_size is not None:\n            prefetch_buffer_size = tf.data.experimental.AUTOTUNE\n        dataset = dataset.prefetch(prefetch_buffer_size)\n        return dataset\n\n    @staticmethod\n    def make_channel_first(input_key: str, dataset: tf.data.Dataset) -&gt; tf.data.Dataset:\n\"\"\"Make a tf.data.Dataset channel first. Make sure that the dataset is not\n            already Channel first. If so, the tensor will have the format\n            (batch_size, x_size, channel, y_size).\n\n        Args:\n            input_key (str): input key of the dict-based tf.data.Dataset\n            dataset (tf.data.Dataset): tf.data.Dataset to make channel first\n\n        Returns:\n            tf.data.Dataset: Channel first dataset\n        \"\"\"\n\n        def channel_first(x):\n            x[input_key] = tf.transpose(x[input_key], perm=[2, 0, 1])\n            return x\n\n        dataset = dataset.map(channel_first)\n        return dataset\n\n    @classmethod\n    def merge(\n        cls,\n        id_dataset: tf.data.Dataset,\n        ood_dataset: tf.data.Dataset,\n        resize: Optional[bool] = False,\n        shape: Optional[Tuple[int]] = None,\n        channel_order: Optional[str] = \"channels_last\",\n    ) -&gt; tf.data.Dataset:\n\"\"\"Merge two tf.data.Datasets\n\n        Args:\n            id_dataset (tf.data.Dataset): dataset of in-distribution data\n            ood_dataset (tf.data.Dataset): dataset of out-of-distribution data\n            resize (Optional[bool], optional): toggles if input tensors of the\n                datasets have to be resized to have the same shape. Defaults to True.\n            shape (Optional[Tuple[int]], optional): shape to use for resizing input\n                tensors. If None, the tensors are resized with the shape of the\n                id_dataset input tensors. Defaults to None.\n            channel_order (Optional[str], optional): channel order of the input\n\n        Returns:\n            tf.data.Dataset: merged dataset\n        \"\"\"\n        len_elem_id = cls.get_item_length(id_dataset)\n        len_elem_ood = cls.get_item_length(ood_dataset)\n        assert (\n            len_elem_id == len_elem_ood\n        ), \"incompatible dataset elements (different elem dict length)\"\n\n        # If a desired shape is given, triggers the resize\n        if shape is not None:\n            resize = True\n\n        id_elem_spec = id_dataset.element_spec\n        ood_elem_spec = ood_dataset.element_spec\n        assert isinstance(id_elem_spec, dict), \"dataset elements must be dicts\"\n        assert isinstance(ood_elem_spec, dict), \"dataset elements must be dicts\"\n\n        input_key_id = list(id_elem_spec.keys())[0]\n        input_key_ood = list(ood_elem_spec.keys())[0]\n        shape_id = id_dataset.element_spec[input_key_id].shape\n        shape_ood = ood_dataset.element_spec[input_key_ood].shape\n\n        # If the shape of the two datasets are different, triggers the resize\n        if shape_id != shape_ood:\n            resize = True\n\n            if shape is None:\n                print(\n                    \"Resizing the first item of elem (usually the image)\",\n                    \" with the shape of id_dataset\",\n                )\n                if channel_order == \"channels_first\":\n                    shape = shape_id[1:]\n                else:\n                    shape = shape_id[:2]\n\n        if resize:\n\n            def reshape_im_id(elem):\n                elem[input_key_id] = tf.image.resize(elem[input_key_id], shape)\n                return elem\n\n            def reshape_im_ood(elem):\n                elem[input_key_ood] = tf.image.resize(elem[input_key_ood], shape)\n                return elem\n\n            id_dataset = id_dataset.map(reshape_im_id)\n            ood_dataset = ood_dataset.map(reshape_im_ood)\n\n        merged_dataset = id_dataset.concatenate(ood_dataset)\n        return merged_dataset\n\n    @staticmethod\n    def get_item_length(dataset: tf.data.Dataset) -&gt; int:\n\"\"\"Get the length of a dataset element. If an element is a tensor, the length is\n        one and if it is a sequence (list or tuple), it is len(elem).\n\n        Args:\n            dataset (tf.data.Dataset): Dataset to process\n\n        Returns:\n            int: length of the dataset elems\n        \"\"\"\n        if isinstance(dataset.element_spec, (tuple, list, dict)):\n            return len(dataset.element_spec)\n        return 1\n\n    @staticmethod\n    def get_dataset_length(dataset: tf.data.Dataset) -&gt; int:\n\"\"\"Get the length of a dataset. Try to access it with len(), and if not\n        available, with a reduce op.\n\n        Args:\n            dataset (tf.data.Dataset): Dataset to process\n\n        Returns:\n            int: _description_\n        \"\"\"\n        try:\n            return len(dataset)\n        except TypeError:\n            cardinality = dataset.reduce(0, lambda x, _: x + 1)\n            return int(cardinality)\n\n    @staticmethod\n    def get_feature_shape(\n        dataset: tf.data.Dataset, feature_key: Union[str, int]\n    ) -&gt; tuple:\n\"\"\"Get the shape of a feature of dataset identified by feature_key\n\n        Args:\n            dataset (tf.data.Dataset): a tf.data.dataset\n            feature_key (Union[str, int]): The identifier of the feature\n\n        Returns:\n            tuple: the shape of feature_id\n        \"\"\"\n        return tuple(dataset.element_spec[feature_key].shape)\n\n    @staticmethod\n    def get_input_from_dataset_item(elem: ItemType) -&gt; TensorType:\n\"\"\"Get the tensor that is to be feed as input to a model from a dataset element.\n\n        Args:\n            elem (ItemType): dataset element to extract input from\n\n        Returns:\n            TensorType: Input tensor\n        \"\"\"\n        if isinstance(elem, (tuple, list)):\n            tensor = elem[0]\n        elif isinstance(elem, dict):\n            tensor = elem[list(elem.keys())[0]]\n        else:\n            tensor = elem\n        return tensor\n\n    @staticmethod\n    def get_label_from_dataset_item(item: ItemType):\n\"\"\"Retrieve label tensor from item as a tuple/list. Label must be at index 1\n        in the item tuple. If one-hot encoded, labels are converted to single value.\n\n        Args:\n            elem (ItemType): dataset element to extract label from\n\n        Returns:\n            Any: Label tensor\n        \"\"\"\n        label = item[1]  # labels must be at index 1 in the item tuple\n        # If labels are one-hot encoded, take the argmax\n        if tf.rank(label) &gt; 1 and label.shape[1] &gt; 1:\n            label = tf.reshape(label, shape=[label.shape[0], -1])\n            label = tf.argmax(label, axis=1)\n        # If labels are in two dimensions, squeeze them\n        if len(label.shape) &gt; 1:\n            label = tf.reshape(label, [label.shape[0]])\n        return label\n\n    @staticmethod\n    def get_feature(\n        dataset: tf.data.Dataset, feature_key: Union[str, int]\n    ) -&gt; tf.data.Dataset:\n\"\"\"Extract a feature from a dataset\n\n        Args:\n            dataset (tf.data.Dataset): Dataset to extract the feature from\n            feature_key (Union[str, int]): feature to extract\n\n        Returns:\n            tf.data.Dataset: dataset built with the extracted feature only\n        \"\"\"\n\n        def _get_feature_elem(elem):\n            return elem[feature_key]\n\n        return dataset.map(_get_feature_elem)\n</code></pre>"},{"location":"api/tf_datahandler/#oodeel.datasets.tf_data_handler.TFDataHandler.assign_feature_value","title":"<code>assign_feature_value(dataset, feature_key, value)</code>  <code>staticmethod</code>","text":"<p>Assign a value to a feature for every sample in a tf.data.Dataset</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>tf.data.Dataset</code> <p>tf.data.Dataset to assign the value to</p> required <code>feature_key</code> <code>str</code> <p>Feature to assign the value to</p> required <code>value</code> <code>int</code> <p>Value to assign</p> required <p>Returns:</p> Type Description <code>tf.data.Dataset</code> <p>tf.data.Dataset</p> Source code in <code>oodeel/datasets/tf_data_handler.py</code> <pre><code>@staticmethod\ndef assign_feature_value(\n    dataset: tf.data.Dataset, feature_key: str, value: int\n) -&gt; tf.data.Dataset:\n\"\"\"Assign a value to a feature for every sample in a tf.data.Dataset\n\n    Args:\n        dataset (tf.data.Dataset): tf.data.Dataset to assign the value to\n        feature_key (str): Feature to assign the value to\n        value (int): Value to assign\n\n    Returns:\n        tf.data.Dataset\n    \"\"\"\n    assert isinstance(dataset.element_spec, dict), \"dataset elements must be dicts\"\n\n    def assign_value_to_feature(x):\n        x[feature_key] = value\n        return x\n\n    dataset = dataset.map(assign_value_to_feature)\n    return dataset\n</code></pre>"},{"location":"api/tf_datahandler/#oodeel.datasets.tf_data_handler.TFDataHandler.dict_to_tuple","title":"<code>dict_to_tuple(dataset, keys=None)</code>  <code>staticmethod</code>","text":"<p>Turn a dict based tf.data.Dataset to a tuple based tf.data.Dataset</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>tf.data.Dataset</code> <p>Dict based tf.data.Dataset</p> required <code>keys</code> <code>list</code> <p>Features to use for the tuples based tf.data.Dataset. If None, takes all the features. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>tf.data.Dataset</code> <p>tf.data.Dataset</p> Source code in <code>oodeel/datasets/tf_data_handler.py</code> <pre><code>@staticmethod\n@dict_only_ds\ndef dict_to_tuple(\n    dataset: tf.data.Dataset, keys: Optional[list] = None\n) -&gt; tf.data.Dataset:\n\"\"\"Turn a dict based tf.data.Dataset to a tuple based tf.data.Dataset\n\n    Args:\n        dataset (tf.data.Dataset): Dict based tf.data.Dataset\n        keys (list, optional): Features to use for the tuples based\n            tf.data.Dataset. If None, takes all the features. Defaults to None.\n\n    Returns:\n        tf.data.Dataset\n    \"\"\"\n    if keys is None:\n        keys = list(dataset.element_spec.keys())\n    dataset = dataset.map(lambda x: tuple(x[k] for k in keys))\n    return dataset\n</code></pre>"},{"location":"api/tf_datahandler/#oodeel.datasets.tf_data_handler.TFDataHandler.filter_by_feature_value","title":"<code>filter_by_feature_value(dataset, feature_key, values, excluded=False)</code>  <code>staticmethod</code>","text":"<p>Filter a tf.data.Dataset by checking the value of a feature is in 'values'</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>tf.data.Dataset</code> <p>tf.data.Dataset to filter</p> required <code>feature_key</code> <code>str</code> <p>Feature name to check the value</p> required <code>values</code> <code>list</code> <p>Feature_key values to keep (if excluded is False) or to exclude</p> required <code>excluded</code> <code>bool</code> <p>To keep (False) or exclude (True) the samples with Feature_key value included in Values. Defaults to False.</p> <code>False</code> <p>Returns:</p> Type Description <code>tf.data.Dataset</code> <p>tf.data.Dataset: Filtered dataset</p> Source code in <code>oodeel/datasets/tf_data_handler.py</code> <pre><code>@staticmethod\n@dict_only_ds\ndef filter_by_feature_value(\n    dataset: tf.data.Dataset,\n    feature_key: str,\n    values: list,\n    excluded: bool = False,\n) -&gt; tf.data.Dataset:\n\"\"\"Filter a tf.data.Dataset by checking the value of a feature is in 'values'\n\n    Args:\n        dataset (tf.data.Dataset): tf.data.Dataset to filter\n        feature_key (str): Feature name to check the value\n        values (list): Feature_key values to keep (if excluded is False)\n            or to exclude\n        excluded (bool, optional): To keep (False) or exclude (True) the samples\n            with Feature_key value included in Values. Defaults to False.\n\n    Returns:\n        tf.data.Dataset: Filtered dataset\n    \"\"\"\n    # If the labels are one-hot encoded, prepare a function to get the label as int\n    if len(dataset.element_spec[feature_key].shape) &gt; 0:\n\n        def get_label_int(elem):\n            return int(tf.argmax(elem[feature_key]))\n\n    else:\n\n        def get_label_int(elem):\n            return elem[feature_key]\n\n    def filter_fn(elem):\n        value = get_label_int(elem)\n        if excluded:\n            return not tf.reduce_any(tf.equal(value, values))\n        else:\n            return tf.reduce_any(tf.equal(value, values))\n\n    dataset_to_filter = dataset\n    dataset_to_filter = dataset_to_filter.filter(filter_fn)\n    return dataset_to_filter\n</code></pre>"},{"location":"api/tf_datahandler/#oodeel.datasets.tf_data_handler.TFDataHandler.get_dataset_length","title":"<code>get_dataset_length(dataset)</code>  <code>staticmethod</code>","text":"<p>Get the length of a dataset. Try to access it with len(), and if not available, with a reduce op.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>tf.data.Dataset</code> <p>Dataset to process</p> required <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>description</p> Source code in <code>oodeel/datasets/tf_data_handler.py</code> <pre><code>@staticmethod\ndef get_dataset_length(dataset: tf.data.Dataset) -&gt; int:\n\"\"\"Get the length of a dataset. Try to access it with len(), and if not\n    available, with a reduce op.\n\n    Args:\n        dataset (tf.data.Dataset): Dataset to process\n\n    Returns:\n        int: _description_\n    \"\"\"\n    try:\n        return len(dataset)\n    except TypeError:\n        cardinality = dataset.reduce(0, lambda x, _: x + 1)\n        return int(cardinality)\n</code></pre>"},{"location":"api/tf_datahandler/#oodeel.datasets.tf_data_handler.TFDataHandler.get_ds_feature_keys","title":"<code>get_ds_feature_keys(dataset)</code>  <code>staticmethod</code>","text":"<p>Get the feature keys of a tf.data.Dataset</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>tf.data.Dataset</code> <p>tf.data.Dataset to get the feature keys from</p> required <p>Returns:</p> Name Type Description <code>list</code> <code>list</code> <p>List of feature keys</p> Source code in <code>oodeel/datasets/tf_data_handler.py</code> <pre><code>@staticmethod\n@dict_only_ds\ndef get_ds_feature_keys(dataset: tf.data.Dataset) -&gt; list:\n\"\"\"Get the feature keys of a tf.data.Dataset\n\n    Args:\n        dataset (tf.data.Dataset): tf.data.Dataset to get the feature keys from\n\n    Returns:\n        list: List of feature keys\n    \"\"\"\n    return list(dataset.element_spec.keys())\n</code></pre>"},{"location":"api/tf_datahandler/#oodeel.datasets.tf_data_handler.TFDataHandler.get_feature","title":"<code>get_feature(dataset, feature_key)</code>  <code>staticmethod</code>","text":"<p>Extract a feature from a dataset</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>tf.data.Dataset</code> <p>Dataset to extract the feature from</p> required <code>feature_key</code> <code>Union[str, int]</code> <p>feature to extract</p> required <p>Returns:</p> Type Description <code>tf.data.Dataset</code> <p>tf.data.Dataset: dataset built with the extracted feature only</p> Source code in <code>oodeel/datasets/tf_data_handler.py</code> <pre><code>@staticmethod\ndef get_feature(\n    dataset: tf.data.Dataset, feature_key: Union[str, int]\n) -&gt; tf.data.Dataset:\n\"\"\"Extract a feature from a dataset\n\n    Args:\n        dataset (tf.data.Dataset): Dataset to extract the feature from\n        feature_key (Union[str, int]): feature to extract\n\n    Returns:\n        tf.data.Dataset: dataset built with the extracted feature only\n    \"\"\"\n\n    def _get_feature_elem(elem):\n        return elem[feature_key]\n\n    return dataset.map(_get_feature_elem)\n</code></pre>"},{"location":"api/tf_datahandler/#oodeel.datasets.tf_data_handler.TFDataHandler.get_feature_from_ds","title":"<code>get_feature_from_ds(dataset, feature_key)</code>  <code>staticmethod</code>","text":"<p>Get a feature from a tf.data.Dataset</p> <p>Note</p> <p>This function can be a bit time consuming since it needs to iterate over the whole dataset.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>tf.data.Dataset</code> <p>tf.data.Dataset to get the feature from</p> required <code>feature_key</code> <code>str</code> <p>Feature value to get</p> required <p>Returns:</p> Type Description <code>np.ndarray</code> <p>np.ndarray: Feature values for dataset</p> Source code in <code>oodeel/datasets/tf_data_handler.py</code> <pre><code>@staticmethod\n@dict_only_ds\ndef get_feature_from_ds(dataset: tf.data.Dataset, feature_key: str) -&gt; np.ndarray:\n\"\"\"Get a feature from a tf.data.Dataset\n\n    !!! note\n        This function can be a bit time consuming since it needs to iterate\n        over the whole dataset.\n\n    Args:\n        dataset (tf.data.Dataset): tf.data.Dataset to get the feature from\n        feature_key (str): Feature value to get\n\n    Returns:\n        np.ndarray: Feature values for dataset\n    \"\"\"\n    features = dataset.map(lambda x: x[feature_key])\n    features = list(features.as_numpy_iterator())\n    features = np.array(features)\n    return features\n</code></pre>"},{"location":"api/tf_datahandler/#oodeel.datasets.tf_data_handler.TFDataHandler.get_feature_shape","title":"<code>get_feature_shape(dataset, feature_key)</code>  <code>staticmethod</code>","text":"<p>Get the shape of a feature of dataset identified by feature_key</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>tf.data.Dataset</code> <p>a tf.data.dataset</p> required <code>feature_key</code> <code>Union[str, int]</code> <p>The identifier of the feature</p> required <p>Returns:</p> Name Type Description <code>tuple</code> <code>tuple</code> <p>the shape of feature_id</p> Source code in <code>oodeel/datasets/tf_data_handler.py</code> <pre><code>@staticmethod\ndef get_feature_shape(\n    dataset: tf.data.Dataset, feature_key: Union[str, int]\n) -&gt; tuple:\n\"\"\"Get the shape of a feature of dataset identified by feature_key\n\n    Args:\n        dataset (tf.data.Dataset): a tf.data.dataset\n        feature_key (Union[str, int]): The identifier of the feature\n\n    Returns:\n        tuple: the shape of feature_id\n    \"\"\"\n    return tuple(dataset.element_spec[feature_key].shape)\n</code></pre>"},{"location":"api/tf_datahandler/#oodeel.datasets.tf_data_handler.TFDataHandler.get_input_from_dataset_item","title":"<code>get_input_from_dataset_item(elem)</code>  <code>staticmethod</code>","text":"<p>Get the tensor that is to be feed as input to a model from a dataset element.</p> <p>Parameters:</p> Name Type Description Default <code>elem</code> <code>ItemType</code> <p>dataset element to extract input from</p> required <p>Returns:</p> Name Type Description <code>TensorType</code> <code>TensorType</code> <p>Input tensor</p> Source code in <code>oodeel/datasets/tf_data_handler.py</code> <pre><code>@staticmethod\ndef get_input_from_dataset_item(elem: ItemType) -&gt; TensorType:\n\"\"\"Get the tensor that is to be feed as input to a model from a dataset element.\n\n    Args:\n        elem (ItemType): dataset element to extract input from\n\n    Returns:\n        TensorType: Input tensor\n    \"\"\"\n    if isinstance(elem, (tuple, list)):\n        tensor = elem[0]\n    elif isinstance(elem, dict):\n        tensor = elem[list(elem.keys())[0]]\n    else:\n        tensor = elem\n    return tensor\n</code></pre>"},{"location":"api/tf_datahandler/#oodeel.datasets.tf_data_handler.TFDataHandler.get_item_length","title":"<code>get_item_length(dataset)</code>  <code>staticmethod</code>","text":"<p>Get the length of a dataset element. If an element is a tensor, the length is one and if it is a sequence (list or tuple), it is len(elem).</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>tf.data.Dataset</code> <p>Dataset to process</p> required <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>length of the dataset elems</p> Source code in <code>oodeel/datasets/tf_data_handler.py</code> <pre><code>@staticmethod\ndef get_item_length(dataset: tf.data.Dataset) -&gt; int:\n\"\"\"Get the length of a dataset element. If an element is a tensor, the length is\n    one and if it is a sequence (list or tuple), it is len(elem).\n\n    Args:\n        dataset (tf.data.Dataset): Dataset to process\n\n    Returns:\n        int: length of the dataset elems\n    \"\"\"\n    if isinstance(dataset.element_spec, (tuple, list, dict)):\n        return len(dataset.element_spec)\n    return 1\n</code></pre>"},{"location":"api/tf_datahandler/#oodeel.datasets.tf_data_handler.TFDataHandler.get_label_from_dataset_item","title":"<code>get_label_from_dataset_item(item)</code>  <code>staticmethod</code>","text":"<p>Retrieve label tensor from item as a tuple/list. Label must be at index 1 in the item tuple. If one-hot encoded, labels are converted to single value.</p> <p>Parameters:</p> Name Type Description Default <code>elem</code> <code>ItemType</code> <p>dataset element to extract label from</p> required <p>Returns:</p> Name Type Description <code>Any</code> <p>Label tensor</p> Source code in <code>oodeel/datasets/tf_data_handler.py</code> <pre><code>@staticmethod\ndef get_label_from_dataset_item(item: ItemType):\n\"\"\"Retrieve label tensor from item as a tuple/list. Label must be at index 1\n    in the item tuple. If one-hot encoded, labels are converted to single value.\n\n    Args:\n        elem (ItemType): dataset element to extract label from\n\n    Returns:\n        Any: Label tensor\n    \"\"\"\n    label = item[1]  # labels must be at index 1 in the item tuple\n    # If labels are one-hot encoded, take the argmax\n    if tf.rank(label) &gt; 1 and label.shape[1] &gt; 1:\n        label = tf.reshape(label, shape=[label.shape[0], -1])\n        label = tf.argmax(label, axis=1)\n    # If labels are in two dimensions, squeeze them\n    if len(label.shape) &gt; 1:\n        label = tf.reshape(label, [label.shape[0]])\n    return label\n</code></pre>"},{"location":"api/tf_datahandler/#oodeel.datasets.tf_data_handler.TFDataHandler.has_feature_key","title":"<code>has_feature_key(dataset, key)</code>  <code>staticmethod</code>","text":"<p>Check if a tf.data.Dataset has a feature denoted by key</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>tf.data.Dataset</code> <p>tf.data.Dataset to check</p> required <code>key</code> <code>str</code> <p>Key to check</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>If the tf.data.Dataset has a feature denoted by key</p> Source code in <code>oodeel/datasets/tf_data_handler.py</code> <pre><code>@staticmethod\ndef has_feature_key(dataset: tf.data.Dataset, key: str) -&gt; bool:\n\"\"\"Check if a tf.data.Dataset has a feature denoted by key\n\n    Args:\n        dataset (tf.data.Dataset): tf.data.Dataset to check\n        key (str): Key to check\n\n    Returns:\n        bool: If the tf.data.Dataset has a feature denoted by key\n    \"\"\"\n    assert isinstance(dataset.element_spec, dict), \"dataset elements must be dicts\"\n    return True if (key in dataset.element_spec.keys()) else False\n</code></pre>"},{"location":"api/tf_datahandler/#oodeel.datasets.tf_data_handler.TFDataHandler.load_custom_dataset","title":"<code>load_custom_dataset(dataset_id, keys=None)</code>  <code>classmethod</code>","text":"<p>Load a custom Dataset by ensuring it has the correct format (dict-based)</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>tf.data.Dataset</code> <p>tf.data.Dataset</p> required <code>keys</code> <code>list</code> <p>Features keys. If None, assigned as \"input_i\" for i-th feature. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>tf.data.Dataset</code> <p>tf.data.Dataset</p> Source code in <code>oodeel/datasets/tf_data_handler.py</code> <pre><code>@classmethod\ndef load_custom_dataset(\n    cls, dataset_id: tf.data.Dataset, keys: Optional[list] = None\n) -&gt; tf.data.Dataset:\n\"\"\"Load a custom Dataset by ensuring it has the correct format (dict-based)\n\n    Args:\n        dataset_id (tf.data.Dataset): tf.data.Dataset\n        keys (list, optional): Features keys. If None, assigned as \"input_i\"\n            for i-th feature. Defaults to None.\n\n    Returns:\n        tf.data.Dataset\n    \"\"\"\n    # If dataset_id is a tuple based tf.data.dataset, convert it to a dict\n    if not isinstance(dataset_id.element_spec, dict):\n        len_elem = len(dataset_id.element_spec)\n        if keys is None:\n            print(\n                \"Feature name not found, assigning 'input_i' \"\n                \"key to the i-th tensor and 'label' key to the last\"\n            )\n            if len_elem == 2:\n                keys = [\"input\", \"label\"]\n            else:\n                keys = [f\"input_{i}\" for i in range(len_elem)]\n                keys[-1] = \"label\"\n        else:\n            assert (\n                len(keys) == len_elem\n            ), \"Number of keys mismatch with the number of features\"\n\n        dataset_id = cls.tuple_to_dict(dataset_id, keys)\n\n    dataset = dataset_id\n    return dataset\n</code></pre>"},{"location":"api/tf_datahandler/#oodeel.datasets.tf_data_handler.TFDataHandler.load_dataset","title":"<code>load_dataset(dataset_id, keys=None, load_kwargs={})</code>  <code>classmethod</code>","text":"<p>Load dataset from different manners, ensuring to return a dict based tf.data.Dataset.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>Any</code> <p>dataset identification</p> required <code>keys</code> <code>list</code> <p>Features keys. If None, assigned as \"input_i\" for i-th feature. Defaults to None.</p> <code>None</code> <code>load_kwargs</code> <code>dict</code> <p>Additional args for loading from tensorflow_datasets. Defaults to {}.</p> <code>{}</code> <p>Returns:</p> Type Description <code>tf.data.Dataset</code> <p>tf.data.Dataset: A dict based tf.data.Dataset</p> Source code in <code>oodeel/datasets/tf_data_handler.py</code> <pre><code>@classmethod\ndef load_dataset(\n    cls,\n    dataset_id: Union[tf.data.Dataset, ItemType, str],\n    keys: Optional[list] = None,\n    load_kwargs: dict = {},\n) -&gt; tf.data.Dataset:\n\"\"\"Load dataset from different manners, ensuring to return a dict based\n    tf.data.Dataset.\n\n    Args:\n        dataset_id (Any): dataset identification\n        keys (list, optional): Features keys. If None, assigned as \"input_i\"\n            for i-th feature. Defaults to None.\n        load_kwargs (dict, optional): Additional args for loading from\n            tensorflow_datasets. Defaults to {}.\n\n    Returns:\n        tf.data.Dataset: A dict based tf.data.Dataset\n    \"\"\"\n    if isinstance(dataset_id, get_args(ItemType)):\n        dataset = cls.load_dataset_from_arrays(dataset_id, keys)\n    elif isinstance(dataset_id, tf.data.Dataset):\n        dataset = cls.load_custom_dataset(dataset_id, keys)\n    elif isinstance(dataset_id, str):\n        dataset = cls.load_from_tensorflow_datasets(dataset_id, load_kwargs)\n    return dataset\n</code></pre>"},{"location":"api/tf_datahandler/#oodeel.datasets.tf_data_handler.TFDataHandler.load_dataset_from_arrays","title":"<code>load_dataset_from_arrays(dataset_id, keys=None)</code>  <code>staticmethod</code>","text":"<p>Load a tf.data.Dataset from a np.ndarray, a tf.Tensor or a tuple/dict of np.ndarrays/td.Tensors.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>ItemType</code> <p>numpy array(s) to load.</p> required <code>keys</code> <code>list</code> <p>Features keys. If None, assigned as \"input_i\" for i-th feature. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>tf.data.Dataset</code> <p>tf.data.Dataset</p> Source code in <code>oodeel/datasets/tf_data_handler.py</code> <pre><code>@staticmethod\ndef load_dataset_from_arrays(\n    dataset_id: ItemType, keys: Optional[list] = None\n) -&gt; tf.data.Dataset:\n\"\"\"Load a tf.data.Dataset from a np.ndarray, a tf.Tensor or a tuple/dict\n    of np.ndarrays/td.Tensors.\n\n    Args:\n        dataset_id (ItemType): numpy array(s) to load.\n        keys (list, optional): Features keys. If None, assigned as \"input_i\"\n            for i-th feature. Defaults to None.\n\n    Returns:\n        tf.data.Dataset\n    \"\"\"\n    # If dataset_id is a numpy array, convert it to a dict\n    if isinstance(dataset_id, get_args(TensorType)):\n        dataset_dict = {\"input\": dataset_id}\n\n    # If dataset_id is a tuple, convert it to a dict\n    elif isinstance(dataset_id, tuple):\n        len_elem = len(dataset_id)\n        if keys is None:\n            if len_elem == 2:\n                dataset_dict = {\"input\": dataset_id[0], \"label\": dataset_id[1]}\n            else:\n                dataset_dict = {\n                    f\"input_{i}\": dataset_id[i] for i in range(len_elem - 1)\n                }\n                dataset_dict[\"label\"] = dataset_id[-1]\n            print(\n                'Loading tf.data.Dataset with elems as dicts, assigning \"input_i\" '\n                'key to the i-th tuple dimension and \"label\" key to the last '\n                \"tuple dimension.\"\n            )\n        else:\n            assert (\n                len(keys) == len_elem\n            ), \"Number of keys mismatch with the number of features\"\n            dataset_dict = {keys[i]: dataset_id[i] for i in range(len_elem)}\n\n    elif isinstance(dataset_id, dict):\n        if keys is not None:\n            len_elem = len(dataset_id)\n            assert (\n                len(keys) == len_elem\n            ), \"Number of keys mismatch with the number of features\"\n            original_keys = list(dataset_id.keys())\n            dataset_dict = {\n                keys[i]: dataset_id[original_keys[i]] for i in range(len_elem)\n            }\n\n    dataset = tf.data.Dataset.from_tensor_slices(dataset_dict)\n    return dataset\n</code></pre>"},{"location":"api/tf_datahandler/#oodeel.datasets.tf_data_handler.TFDataHandler.load_from_tensorflow_datasets","title":"<code>load_from_tensorflow_datasets(dataset_id, load_kwargs={})</code>  <code>staticmethod</code>","text":"<p>Load a tf.data.Dataset from the tensorflow_datasets catalog</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>str</code> <p>Identifier of the dataset</p> required <code>load_kwargs</code> <code>dict</code> <p>Loading kwargs to add to tfds.load(). Defaults to {}.</p> <code>{}</code> <p>Returns:</p> Type Description <code>tf.data.Dataset</code> <p>tf.data.Dataset</p> Source code in <code>oodeel/datasets/tf_data_handler.py</code> <pre><code>@staticmethod\ndef load_from_tensorflow_datasets(\n    dataset_id: str,\n    load_kwargs: dict = {},\n) -&gt; tf.data.Dataset:\n\"\"\"Load a tf.data.Dataset from the tensorflow_datasets catalog\n\n    Args:\n        dataset_id (str): Identifier of the dataset\n        load_kwargs (dict, optional): Loading kwargs to add to tfds.load().\n            Defaults to {}.\n\n    Returns:\n        tf.data.Dataset\n    \"\"\"\n    assert (\n        dataset_id in tfds.list_builders()\n    ), \"Dataset not available on tensorflow datasets catalog\"\n    dataset = tfds.load(dataset_id, **load_kwargs)\n    return dataset\n</code></pre>"},{"location":"api/tf_datahandler/#oodeel.datasets.tf_data_handler.TFDataHandler.make_channel_first","title":"<code>make_channel_first(input_key, dataset)</code>  <code>staticmethod</code>","text":"<p>Make a tf.data.Dataset channel first. Make sure that the dataset is not     already Channel first. If so, the tensor will have the format     (batch_size, x_size, channel, y_size).</p> <p>Parameters:</p> Name Type Description Default <code>input_key</code> <code>str</code> <p>input key of the dict-based tf.data.Dataset</p> required <code>dataset</code> <code>tf.data.Dataset</code> <p>tf.data.Dataset to make channel first</p> required <p>Returns:</p> Type Description <code>tf.data.Dataset</code> <p>tf.data.Dataset: Channel first dataset</p> Source code in <code>oodeel/datasets/tf_data_handler.py</code> <pre><code>@staticmethod\ndef make_channel_first(input_key: str, dataset: tf.data.Dataset) -&gt; tf.data.Dataset:\n\"\"\"Make a tf.data.Dataset channel first. Make sure that the dataset is not\n        already Channel first. If so, the tensor will have the format\n        (batch_size, x_size, channel, y_size).\n\n    Args:\n        input_key (str): input key of the dict-based tf.data.Dataset\n        dataset (tf.data.Dataset): tf.data.Dataset to make channel first\n\n    Returns:\n        tf.data.Dataset: Channel first dataset\n    \"\"\"\n\n    def channel_first(x):\n        x[input_key] = tf.transpose(x[input_key], perm=[2, 0, 1])\n        return x\n\n    dataset = dataset.map(channel_first)\n    return dataset\n</code></pre>"},{"location":"api/tf_datahandler/#oodeel.datasets.tf_data_handler.TFDataHandler.map_ds","title":"<code>map_ds(dataset, map_fn, num_parallel_calls=None)</code>  <code>staticmethod</code>","text":"<p>Map a function to a tf.data.Dataset</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>tf.data.Dataset</code> <p>tf.data.Dataset to map the function to</p> required <code>map_fn</code> <code>Callable</code> <p>Function to map</p> required <code>num_parallel_calls</code> <code>Optional[int]</code> <p>Number of parallel processes to use. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>tf.data.Dataset</code> <p>tf.data.Dataset: Maped dataset</p> Source code in <code>oodeel/datasets/tf_data_handler.py</code> <pre><code>@staticmethod\ndef map_ds(\n    dataset: tf.data.Dataset,\n    map_fn: Callable,\n    num_parallel_calls: Optional[int] = None,\n) -&gt; tf.data.Dataset:\n\"\"\"Map a function to a tf.data.Dataset\n\n    Args:\n        dataset (tf.data.Dataset): tf.data.Dataset to map the function to\n        map_fn (Callable): Function to map\n        num_parallel_calls (Optional[int], optional): Number of parallel processes\n            to use. Defaults to None.\n\n    Returns:\n        tf.data.Dataset: Maped dataset\n    \"\"\"\n    if num_parallel_calls is None:\n        num_parallel_calls = tf.data.experimental.AUTOTUNE\n    dataset = dataset.map(map_fn, num_parallel_calls=num_parallel_calls)\n    return dataset\n</code></pre>"},{"location":"api/tf_datahandler/#oodeel.datasets.tf_data_handler.TFDataHandler.merge","title":"<code>merge(id_dataset, ood_dataset, resize=False, shape=None, channel_order='channels_last')</code>  <code>classmethod</code>","text":"<p>Merge two tf.data.Datasets</p> <p>Parameters:</p> Name Type Description Default <code>id_dataset</code> <code>tf.data.Dataset</code> <p>dataset of in-distribution data</p> required <code>ood_dataset</code> <code>tf.data.Dataset</code> <p>dataset of out-of-distribution data</p> required <code>resize</code> <code>Optional[bool]</code> <p>toggles if input tensors of the datasets have to be resized to have the same shape. Defaults to True.</p> <code>False</code> <code>shape</code> <code>Optional[Tuple[int]]</code> <p>shape to use for resizing input tensors. If None, the tensors are resized with the shape of the id_dataset input tensors. Defaults to None.</p> <code>None</code> <code>channel_order</code> <code>Optional[str]</code> <p>channel order of the input</p> <code>'channels_last'</code> <p>Returns:</p> Type Description <code>tf.data.Dataset</code> <p>tf.data.Dataset: merged dataset</p> Source code in <code>oodeel/datasets/tf_data_handler.py</code> <pre><code>@classmethod\ndef merge(\n    cls,\n    id_dataset: tf.data.Dataset,\n    ood_dataset: tf.data.Dataset,\n    resize: Optional[bool] = False,\n    shape: Optional[Tuple[int]] = None,\n    channel_order: Optional[str] = \"channels_last\",\n) -&gt; tf.data.Dataset:\n\"\"\"Merge two tf.data.Datasets\n\n    Args:\n        id_dataset (tf.data.Dataset): dataset of in-distribution data\n        ood_dataset (tf.data.Dataset): dataset of out-of-distribution data\n        resize (Optional[bool], optional): toggles if input tensors of the\n            datasets have to be resized to have the same shape. Defaults to True.\n        shape (Optional[Tuple[int]], optional): shape to use for resizing input\n            tensors. If None, the tensors are resized with the shape of the\n            id_dataset input tensors. Defaults to None.\n        channel_order (Optional[str], optional): channel order of the input\n\n    Returns:\n        tf.data.Dataset: merged dataset\n    \"\"\"\n    len_elem_id = cls.get_item_length(id_dataset)\n    len_elem_ood = cls.get_item_length(ood_dataset)\n    assert (\n        len_elem_id == len_elem_ood\n    ), \"incompatible dataset elements (different elem dict length)\"\n\n    # If a desired shape is given, triggers the resize\n    if shape is not None:\n        resize = True\n\n    id_elem_spec = id_dataset.element_spec\n    ood_elem_spec = ood_dataset.element_spec\n    assert isinstance(id_elem_spec, dict), \"dataset elements must be dicts\"\n    assert isinstance(ood_elem_spec, dict), \"dataset elements must be dicts\"\n\n    input_key_id = list(id_elem_spec.keys())[0]\n    input_key_ood = list(ood_elem_spec.keys())[0]\n    shape_id = id_dataset.element_spec[input_key_id].shape\n    shape_ood = ood_dataset.element_spec[input_key_ood].shape\n\n    # If the shape of the two datasets are different, triggers the resize\n    if shape_id != shape_ood:\n        resize = True\n\n        if shape is None:\n            print(\n                \"Resizing the first item of elem (usually the image)\",\n                \" with the shape of id_dataset\",\n            )\n            if channel_order == \"channels_first\":\n                shape = shape_id[1:]\n            else:\n                shape = shape_id[:2]\n\n    if resize:\n\n        def reshape_im_id(elem):\n            elem[input_key_id] = tf.image.resize(elem[input_key_id], shape)\n            return elem\n\n        def reshape_im_ood(elem):\n            elem[input_key_ood] = tf.image.resize(elem[input_key_ood], shape)\n            return elem\n\n        id_dataset = id_dataset.map(reshape_im_id)\n        ood_dataset = ood_dataset.map(reshape_im_ood)\n\n    merged_dataset = id_dataset.concatenate(ood_dataset)\n    return merged_dataset\n</code></pre>"},{"location":"api/tf_datahandler/#oodeel.datasets.tf_data_handler.TFDataHandler.prepare_for_training","title":"<code>prepare_for_training(dataset, batch_size, shuffle=False, preprocess_fn=None, augment_fn=None, output_keys=None, dict_based_fns=False, shuffle_buffer_size=None, prefetch_buffer_size=None, drop_remainder=False)</code>  <code>classmethod</code>","text":"<p>Prepare a tf.data.Dataset for training</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>tf.data.Dataset</code> <p>tf.data.Dataset to prepare</p> required <code>batch_size</code> <code>int</code> <p>Batch size</p> required <code>shuffle</code> <code>bool</code> <p>To shuffle the returned dataset or not. Defaults to False.</p> <code>False</code> <code>preprocess_fn</code> <code>Callable</code> <p>Preprocessing function to apply to                the dataset. Defaults to None.</p> <code>None</code> <code>augment_fn</code> <code>Callable</code> <p>Augment function to be used (when the                returned dataset is to be used for training). Defaults to None.</p> <code>None</code> <code>output_keys</code> <code>list</code> <p>List of keys corresponding to the features that will be returned. Keep all features if None. Defaults to None.</p> <code>None</code> <code>dict_based_fns</code> <code>bool</code> <p>If the augment and preprocess functions are dict based or not. Defaults to False.</p> <code>False</code> <code>shuffle_buffer_size</code> <code>int</code> <p>Size of the shuffle buffer. If None, taken as the number of samples in the dataset. Defaults to None.</p> <code>None</code> <code>prefetch_buffer_size</code> <code>Optional[int]</code> <p>Buffer size for prefetch. If None, automatically chose using tf.data.experimental.AUTOTUNE. Defaults to None.</p> <code>None</code> <code>drop_remainder</code> <code>Optional[bool]</code> <p>To drop the last batch when its size is lower than batch_size. Defaults to False.</p> <code>False</code> <p>Returns:</p> Type Description <code>tf.data.Dataset</code> <p>tf.data.Dataset: Prepared dataset</p> Source code in <code>oodeel/datasets/tf_data_handler.py</code> <pre><code>@classmethod\ndef prepare_for_training(\n    cls,\n    dataset: tf.data.Dataset,\n    batch_size: int,\n    shuffle: bool = False,\n    preprocess_fn: Optional[Callable] = None,\n    augment_fn: Optional[Callable] = None,\n    output_keys: Optional[list] = None,\n    dict_based_fns: bool = False,\n    shuffle_buffer_size: Optional[int] = None,\n    prefetch_buffer_size: Optional[int] = None,\n    drop_remainder: Optional[bool] = False,\n) -&gt; tf.data.Dataset:\n\"\"\"Prepare a tf.data.Dataset for training\n\n    Args:\n        dataset (tf.data.Dataset): tf.data.Dataset to prepare\n        batch_size (int): Batch size\n        shuffle (bool, optional): To shuffle the returned dataset or not.\n            Defaults to False.\n        preprocess_fn (Callable, optional): Preprocessing function to apply to\\\n            the dataset. Defaults to None.\n        augment_fn (Callable, optional): Augment function to be used (when the\\\n            returned dataset is to be used for training). Defaults to None.\n        output_keys (list, optional): List of keys corresponding to the features\n            that will be returned. Keep all features if None. Defaults to None.\n        dict_based_fns (bool, optional): If the augment and preprocess functions are\n            dict based or not. Defaults to False.\n        shuffle_buffer_size (int, optional): Size of the shuffle buffer. If None,\n            taken as the number of samples in the dataset. Defaults to None.\n        prefetch_buffer_size (Optional[int], optional): Buffer size for prefetch.\n            If None, automatically chose using tf.data.experimental.AUTOTUNE.\n            Defaults to None.\n        drop_remainder (Optional[bool], optional): To drop the last batch when\n            its size is lower than batch_size. Defaults to False.\n\n    Returns:\n        tf.data.Dataset: Prepared dataset\n    \"\"\"\n    # dict based to tuple based\n    output_keys = output_keys or cls.get_ds_feature_keys(dataset)\n    if not dict_based_fns:\n        dataset = cls.dict_to_tuple(dataset, output_keys)\n\n    # preprocess + DA\n    if preprocess_fn is not None:\n        dataset = cls.map_ds(dataset, preprocess_fn)\n    if augment_fn is not None:\n        dataset = cls.map_ds(dataset, augment_fn)\n\n    if dict_based_fns:\n        dataset = cls.dict_to_tuple(dataset, output_keys)\n\n    dataset = dataset.cache()\n\n    # shuffle\n    if shuffle:\n        num_samples = cls.get_dataset_length(dataset)\n        shuffle_buffer_size = (\n            num_samples if shuffle_buffer_size is None else shuffle_buffer_size\n        )\n        dataset = dataset.shuffle(shuffle_buffer_size)\n    # batch\n    dataset = dataset.batch(batch_size, drop_remainder=drop_remainder)\n    # prefetch\n    if prefetch_buffer_size is not None:\n        prefetch_buffer_size = tf.data.experimental.AUTOTUNE\n    dataset = dataset.prefetch(prefetch_buffer_size)\n    return dataset\n</code></pre>"},{"location":"api/tf_datahandler/#oodeel.datasets.tf_data_handler.TFDataHandler.tuple_to_dict","title":"<code>tuple_to_dict(dataset, keys)</code>  <code>staticmethod</code>","text":"<p>Turn a tuple based tf.data.Dataset to a dict based tf.data.Dataset</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>tf.data.Dataset</code> <p>Tuple based tf.data.Dataset</p> required <code>keys</code> <code>list</code> <p>Keys to use for the dict based tf.data.Dataset</p> required <p>Returns:</p> Type Description <code>tf.data.Dataset</code> <p>tf.data.Dataset</p> Source code in <code>oodeel/datasets/tf_data_handler.py</code> <pre><code>@staticmethod\ndef tuple_to_dict(dataset: tf.data.Dataset, keys: list) -&gt; tf.data.Dataset:\n\"\"\"Turn a tuple based tf.data.Dataset to a dict based tf.data.Dataset\n\n    Args:\n        dataset (tf.data.Dataset): Tuple based tf.data.Dataset\n        keys (list): Keys to use for the dict based tf.data.Dataset\n\n    Returns:\n        tf.data.Dataset\n    \"\"\"\n    assert isinstance(\n        dataset.element_spec, tuple\n    ), \"dataset elements must be tuples\"\n    len_elem = len(dataset.element_spec)\n    assert len_elem == len(\n        keys\n    ), \"The number of keys must be equal to the number of tuple elements\"\n\n    def tuple_to_dict(*inputs):\n        return {keys[i]: inputs[i] for i in range(len_elem)}\n\n    dataset = dataset.map(tuple_to_dict)\n    return dataset\n</code></pre>"},{"location":"api/tf_datahandler/#oodeel.datasets.tf_data_handler.dict_only_ds","title":"<code>dict_only_ds(ds_handling_method)</code>","text":"<p>Decorator to ensure that the dataset is a dict dataset and that the input key matches one of the feature keys. The signature of decorated functions must be function(dataset, args, *kwargs) with feature_key either in kwargs or args[0] when relevant.</p> <p>Parameters:</p> Name Type Description Default <code>ds_handling_method</code> <code>Callable</code> <p>method to decorate</p> required <p>Returns:</p> Type Description <code>Callable</code> <p>decorated method</p> Source code in <code>oodeel/datasets/tf_data_handler.py</code> <pre><code>def dict_only_ds(ds_handling_method: Callable) -&gt; Callable:\n\"\"\"Decorator to ensure that the dataset is a dict dataset and that the input key\n    matches one of the feature keys. The signature of decorated functions\n    must be function(dataset, *args, **kwargs) with feature_key either in kwargs or\n    args[0] when relevant.\n\n\n    Args:\n        ds_handling_method: method to decorate\n\n    Returns:\n        decorated method\n    \"\"\"\n\n    def wrapper(dataset: tf.data.Dataset, *args, **kwargs):\n        assert isinstance(dataset.element_spec, dict), \"dataset elements must be dicts\"\n\n        if \"feature_key\" in kwargs.keys():\n            feature_key = kwargs[\"feature_key\"]\n        elif len(args) &gt; 0:\n            feature_key = args[0]\n\n        # If feature_key is provided, check that it is in the dataset feature keys\n        if (len(args) &gt; 0) or (\"feature_key\" in kwargs):\n            if isinstance(feature_key, str):\n                feature_key = [feature_key]\n            for key in feature_key:\n                assert (\n                    key in dataset.element_spec.keys()\n                ), f\"The input dataset has no feature names {key}\"\n        return ds_handling_method(dataset, *args, **kwargs)\n\n    return wrapper\n</code></pre>"},{"location":"api/tf_operator/","title":"TFOperator","text":""},{"location":"api/tf_operator/#oodeel.utils.tf_operator.TFOperator","title":"<code>TFOperator</code>","text":"<p>         Bases: <code>Operator</code></p> <p>Class to handle tensorflow operations with a unified API</p> Source code in <code>oodeel/utils/tf_operator.py</code> <pre><code>class TFOperator(Operator):\n\"\"\"Class to handle tensorflow operations with a unified API\"\"\"\n\n    @staticmethod\n    def softmax(tensor: TensorType) -&gt; tf.Tensor:\n\"\"\"Softmax function along the last dimension\"\"\"\n        return tf.keras.activations.softmax(tensor, axis=-1)\n\n    @staticmethod\n    def argmax(tensor: TensorType, dim: Optional[int] = None) -&gt; tf.Tensor:\n\"\"\"Argmax function\"\"\"\n        if dim is None:\n            return tf.argmax(tf.reshape(tensor, [-1]))\n        return tf.argmax(tensor, axis=dim)\n\n    @staticmethod\n    def max(\n        tensor: TensorType, dim: Optional[int] = None, keepdim: bool = False\n    ) -&gt; tf.Tensor:\n\"\"\"Max function\"\"\"\n        return tf.reduce_max(tensor, axis=dim, keepdims=keepdim)\n\n    @staticmethod\n    def min(\n        tensor: TensorType, dim: Optional[int] = None, keepdim: bool = False\n    ) -&gt; tf.Tensor:\n\"\"\"Min function\"\"\"\n        return tf.reduce_min(tensor, axis=dim, keepdims=keepdim)\n\n    @staticmethod\n    def one_hot(tensor: TensorType, num_classes: int) -&gt; tf.Tensor:\n\"\"\"One hot function\"\"\"\n        return tf.one_hot(tensor, num_classes)\n\n    @staticmethod\n    def sign(tensor: TensorType) -&gt; tf.Tensor:\n\"\"\"Sign function\"\"\"\n        return tf.sign(tensor)\n\n    @staticmethod\n    def CrossEntropyLoss(reduction: str = \"mean\"):\n\"\"\"Cross Entropy Loss from logits\"\"\"\n\n        tf_reduction = {\"mean\": \"sum_over_batch_size\", \"sum\": \"sum\"}[reduction]\n\n        def sanitized_ce_loss(inputs, targets):\n            return tf.keras.losses.SparseCategoricalCrossentropy(\n                from_logits=True, reduction=tf_reduction\n            )(targets, inputs)\n\n        return sanitized_ce_loss\n\n    @staticmethod\n    def norm(tensor: TensorType, dim: Optional[int] = None) -&gt; tf.Tensor:\n\"\"\"Tensor Norm\"\"\"\n        return tf.norm(tensor, axis=dim)\n\n    @staticmethod\n    @tf.function\n    def matmul(tensor_1: TensorType, tensor_2: TensorType) -&gt; tf.Tensor:\n\"\"\"Matmul operation\"\"\"\n        return tf.matmul(tensor_1, tensor_2)\n\n    @staticmethod\n    def convert_to_numpy(tensor: TensorType) -&gt; np.ndarray:\n\"\"\"Convert tensor into a np.ndarray\"\"\"\n        return tensor.numpy()\n\n    @staticmethod\n    def gradient(func: Callable, inputs: tf.Tensor, *args, **kwargs) -&gt; tf.Tensor:\n\"\"\"Compute gradients for a batch of samples.\n\n        Args:\n            func (Callable): Function used for computing gradient. Must be built with\n                tensorflow differentiable operations only, and return a scalar.\n            inputs (tf.Tensor): Input tensor wrt which the gradients are computed\n            *args: Additional Args for func.\n            **kwargs: Additional Kwargs for func.\n\n        Returns:\n            tf.Tensor: Gradients computed, with the same shape as the inputs.\n        \"\"\"\n        with tf.GradientTape(watch_accessed_variables=False) as tape:\n            tape.watch(inputs)\n            outputs = func(inputs, *args, **kwargs)\n        return tape.gradient(outputs, inputs)\n\n    @staticmethod\n    def stack(tensors: List[TensorType], dim: int = 0) -&gt; tf.Tensor:\n        \"Stack tensors along a new dimension\"\n        return tf.stack(tensors, dim)\n\n    @staticmethod\n    def cat(tensors: List[TensorType], dim: int = 0) -&gt; tf.Tensor:\n        \"Concatenate tensors in a given dimension\"\n        return tf.concat(tensors, dim)\n\n    @staticmethod\n    def mean(tensor: TensorType, dim: Optional[int] = None) -&gt; tf.Tensor:\n        \"Mean function\"\n        return tf.reduce_mean(tensor, dim)\n\n    @staticmethod\n    def flatten(tensor: TensorType) -&gt; tf.Tensor:\n        \"Flatten to 2D tensor of shape (tensor.shape[0], -1)\"\n        # Flatten the features to 2D (n_batch, n_features)\n        return tf.reshape(tensor, shape=[tf.shape(tensor)[0], -1])\n\n    @staticmethod\n    def from_numpy(arr: np.ndarray) -&gt; tf.Tensor:\n        \"Convert a NumPy array to a tensor\"\n        # TODO change dtype\n        return tf.convert_to_tensor(arr)\n\n    @staticmethod\n    def t(tensor: TensorType) -&gt; tf.Tensor:\n        \"Transpose function for tensor of rank 2\"\n        return tf.transpose(tensor)\n\n    @staticmethod\n    def permute(tensor: TensorType, dims) -&gt; tf.Tensor:\n        \"Transpose function for tensor of rank 2\"\n        return tf.transpose(tensor, dims)\n\n    @staticmethod\n    def diag(tensor: TensorType) -&gt; tf.Tensor:\n        \"Diagonal function: return the diagonal of a 2D tensor\"\n        return tf.linalg.diag_part(tensor)\n\n    @staticmethod\n    def reshape(tensor: TensorType, shape: List[int]) -&gt; tf.Tensor:\n        \"Reshape function\"\n        return tf.reshape(tensor, shape)\n\n    @staticmethod\n    def equal(tensor: TensorType, other: Union[TensorType, int, float]) -&gt; tf.Tensor:\n        \"Computes element-wise equality\"\n        return tf.math.equal(tensor, other)\n\n    @staticmethod\n    def pinv(tensor: TensorType) -&gt; tf.Tensor:\n        \"Computes the pseudoinverse (Moore-Penrose inverse) of a matrix.\"\n        return tf.linalg.pinv(tensor)\n\n    @staticmethod\n    def eigh(tensor: TensorType) -&gt; tf.Tensor:\n        \"Computes the eigen decomposition of a self-adjoint matrix.\"\n        eigval, eigvec = tf.linalg.eigh(tensor)\n        return eigval, eigvec\n\n    @staticmethod\n    def quantile(tensor: TensorType, q: float, dim: int = None) -&gt; tf.Tensor:\n        \"Computes the quantile of a tensor's components. q in (0,1)\"\n        q = tfp.stats.percentile(tensor, q * 100, axis=dim)\n        return float(q) if dim is None else q\n\n    @staticmethod\n    def relu(tensor: TensorType) -&gt; tf.Tensor:\n        \"Apply relu to a tensor\"\n        return tf.nn.relu(tensor)\n\n    @staticmethod\n    def einsum(equation: str, *tensors: TensorType) -&gt; tf.Tensor:\n        \"Computes the einsum between tensors following equation\"\n        return tf.einsum(equation, *tensors)\n\n    @staticmethod\n    def tril(tensor: TensorType, diagonal: int = 0) -&gt; tf.Tensor:\n        \"Set the upper triangle of the matrix formed by the last two dimensions of\"\n        \"tensor to zero\"\n        return tf.experimental.numpy.tril(tensor, k=diagonal)\n\n    @staticmethod\n    def sum(tensor: TensorType, dim: Union[tuple, list, int] = None) -&gt; tf.Tensor:\n        \"sum along dim\"\n        return tf.reduce_sum(tensor, axis=dim)\n\n    @staticmethod\n    def unsqueeze(tensor: TensorType, dim: int) -&gt; tf.Tensor:\n        \"expand_dim along dim\"\n        return tf.expand_dims(tensor, dim)\n\n    @staticmethod\n    def squeeze(tensor: TensorType, dim: int = None) -&gt; tf.Tensor:\n        \"expand_dim along dim\"\n        return tf.squeeze(tensor, dim)\n\n    @staticmethod\n    def abs(tensor: TensorType) -&gt; tf.Tensor:\n        \"compute absolute value\"\n        return tf.abs(tensor)\n\n    @staticmethod\n    def where(\n        condition: TensorType,\n        input: Union[TensorType, float],\n        other: Union[TensorType, float],\n    ) -&gt; tf.Tensor:\n        \"Applies where function to condition\"\n        return tf.where(condition, input, other)\n\n    @staticmethod\n    def percentile(x, q):\n        return tfp.stats.percentile(x, q)\n\n    @staticmethod\n    def avg_pool_2d(tensor: TensorType) -&gt; tf.Tensor:\n\"\"\"Perform avg pool in 2d as in torch.nn.functional.adaptive_avg_pool2d\"\"\"\n        return tf.reduce_mean(tensor, axis=(-3, -2))\n\n    @staticmethod\n    def log(tensor: TensorType) -&gt; tf.Tensor:\n\"\"\"Perform log\"\"\"\n        return tf.math.log(tensor)\n</code></pre>"},{"location":"api/tf_operator/#oodeel.utils.tf_operator.TFOperator.CrossEntropyLoss","title":"<code>CrossEntropyLoss(reduction='mean')</code>  <code>staticmethod</code>","text":"<p>Cross Entropy Loss from logits</p> Source code in <code>oodeel/utils/tf_operator.py</code> <pre><code>@staticmethod\ndef CrossEntropyLoss(reduction: str = \"mean\"):\n\"\"\"Cross Entropy Loss from logits\"\"\"\n\n    tf_reduction = {\"mean\": \"sum_over_batch_size\", \"sum\": \"sum\"}[reduction]\n\n    def sanitized_ce_loss(inputs, targets):\n        return tf.keras.losses.SparseCategoricalCrossentropy(\n            from_logits=True, reduction=tf_reduction\n        )(targets, inputs)\n\n    return sanitized_ce_loss\n</code></pre>"},{"location":"api/tf_operator/#oodeel.utils.tf_operator.TFOperator.abs","title":"<code>abs(tensor)</code>  <code>staticmethod</code>","text":"<p>compute absolute value</p> Source code in <code>oodeel/utils/tf_operator.py</code> <pre><code>@staticmethod\ndef abs(tensor: TensorType) -&gt; tf.Tensor:\n    \"compute absolute value\"\n    return tf.abs(tensor)\n</code></pre>"},{"location":"api/tf_operator/#oodeel.utils.tf_operator.TFOperator.argmax","title":"<code>argmax(tensor, dim=None)</code>  <code>staticmethod</code>","text":"<p>Argmax function</p> Source code in <code>oodeel/utils/tf_operator.py</code> <pre><code>@staticmethod\ndef argmax(tensor: TensorType, dim: Optional[int] = None) -&gt; tf.Tensor:\n\"\"\"Argmax function\"\"\"\n    if dim is None:\n        return tf.argmax(tf.reshape(tensor, [-1]))\n    return tf.argmax(tensor, axis=dim)\n</code></pre>"},{"location":"api/tf_operator/#oodeel.utils.tf_operator.TFOperator.avg_pool_2d","title":"<code>avg_pool_2d(tensor)</code>  <code>staticmethod</code>","text":"<p>Perform avg pool in 2d as in torch.nn.functional.adaptive_avg_pool2d</p> Source code in <code>oodeel/utils/tf_operator.py</code> <pre><code>@staticmethod\ndef avg_pool_2d(tensor: TensorType) -&gt; tf.Tensor:\n\"\"\"Perform avg pool in 2d as in torch.nn.functional.adaptive_avg_pool2d\"\"\"\n    return tf.reduce_mean(tensor, axis=(-3, -2))\n</code></pre>"},{"location":"api/tf_operator/#oodeel.utils.tf_operator.TFOperator.cat","title":"<code>cat(tensors, dim=0)</code>  <code>staticmethod</code>","text":"<p>Concatenate tensors in a given dimension</p> Source code in <code>oodeel/utils/tf_operator.py</code> <pre><code>@staticmethod\ndef cat(tensors: List[TensorType], dim: int = 0) -&gt; tf.Tensor:\n    \"Concatenate tensors in a given dimension\"\n    return tf.concat(tensors, dim)\n</code></pre>"},{"location":"api/tf_operator/#oodeel.utils.tf_operator.TFOperator.convert_to_numpy","title":"<code>convert_to_numpy(tensor)</code>  <code>staticmethod</code>","text":"<p>Convert tensor into a np.ndarray</p> Source code in <code>oodeel/utils/tf_operator.py</code> <pre><code>@staticmethod\ndef convert_to_numpy(tensor: TensorType) -&gt; np.ndarray:\n\"\"\"Convert tensor into a np.ndarray\"\"\"\n    return tensor.numpy()\n</code></pre>"},{"location":"api/tf_operator/#oodeel.utils.tf_operator.TFOperator.diag","title":"<code>diag(tensor)</code>  <code>staticmethod</code>","text":"<p>Diagonal function: return the diagonal of a 2D tensor</p> Source code in <code>oodeel/utils/tf_operator.py</code> <pre><code>@staticmethod\ndef diag(tensor: TensorType) -&gt; tf.Tensor:\n    \"Diagonal function: return the diagonal of a 2D tensor\"\n    return tf.linalg.diag_part(tensor)\n</code></pre>"},{"location":"api/tf_operator/#oodeel.utils.tf_operator.TFOperator.eigh","title":"<code>eigh(tensor)</code>  <code>staticmethod</code>","text":"<p>Computes the eigen decomposition of a self-adjoint matrix.</p> Source code in <code>oodeel/utils/tf_operator.py</code> <pre><code>@staticmethod\ndef eigh(tensor: TensorType) -&gt; tf.Tensor:\n    \"Computes the eigen decomposition of a self-adjoint matrix.\"\n    eigval, eigvec = tf.linalg.eigh(tensor)\n    return eigval, eigvec\n</code></pre>"},{"location":"api/tf_operator/#oodeel.utils.tf_operator.TFOperator.einsum","title":"<code>einsum(equation, *tensors)</code>  <code>staticmethod</code>","text":"<p>Computes the einsum between tensors following equation</p> Source code in <code>oodeel/utils/tf_operator.py</code> <pre><code>@staticmethod\ndef einsum(equation: str, *tensors: TensorType) -&gt; tf.Tensor:\n    \"Computes the einsum between tensors following equation\"\n    return tf.einsum(equation, *tensors)\n</code></pre>"},{"location":"api/tf_operator/#oodeel.utils.tf_operator.TFOperator.equal","title":"<code>equal(tensor, other)</code>  <code>staticmethod</code>","text":"<p>Computes element-wise equality</p> Source code in <code>oodeel/utils/tf_operator.py</code> <pre><code>@staticmethod\ndef equal(tensor: TensorType, other: Union[TensorType, int, float]) -&gt; tf.Tensor:\n    \"Computes element-wise equality\"\n    return tf.math.equal(tensor, other)\n</code></pre>"},{"location":"api/tf_operator/#oodeel.utils.tf_operator.TFOperator.flatten","title":"<code>flatten(tensor)</code>  <code>staticmethod</code>","text":"<p>Flatten to 2D tensor of shape (tensor.shape[0], -1)</p> Source code in <code>oodeel/utils/tf_operator.py</code> <pre><code>@staticmethod\ndef flatten(tensor: TensorType) -&gt; tf.Tensor:\n    \"Flatten to 2D tensor of shape (tensor.shape[0], -1)\"\n    # Flatten the features to 2D (n_batch, n_features)\n    return tf.reshape(tensor, shape=[tf.shape(tensor)[0], -1])\n</code></pre>"},{"location":"api/tf_operator/#oodeel.utils.tf_operator.TFOperator.from_numpy","title":"<code>from_numpy(arr)</code>  <code>staticmethod</code>","text":"<p>Convert a NumPy array to a tensor</p> Source code in <code>oodeel/utils/tf_operator.py</code> <pre><code>@staticmethod\ndef from_numpy(arr: np.ndarray) -&gt; tf.Tensor:\n    \"Convert a NumPy array to a tensor\"\n    # TODO change dtype\n    return tf.convert_to_tensor(arr)\n</code></pre>"},{"location":"api/tf_operator/#oodeel.utils.tf_operator.TFOperator.gradient","title":"<code>gradient(func, inputs, *args, **kwargs)</code>  <code>staticmethod</code>","text":"<p>Compute gradients for a batch of samples.</p> <p>Parameters:</p> Name Type Description Default <code>func</code> <code>Callable</code> <p>Function used for computing gradient. Must be built with tensorflow differentiable operations only, and return a scalar.</p> required <code>inputs</code> <code>tf.Tensor</code> <p>Input tensor wrt which the gradients are computed</p> required <code>*args</code> <p>Additional Args for func.</p> <code>()</code> <code>**kwargs</code> <p>Additional Kwargs for func.</p> <code>{}</code> <p>Returns:</p> Type Description <code>tf.Tensor</code> <p>tf.Tensor: Gradients computed, with the same shape as the inputs.</p> Source code in <code>oodeel/utils/tf_operator.py</code> <pre><code>@staticmethod\ndef gradient(func: Callable, inputs: tf.Tensor, *args, **kwargs) -&gt; tf.Tensor:\n\"\"\"Compute gradients for a batch of samples.\n\n    Args:\n        func (Callable): Function used for computing gradient. Must be built with\n            tensorflow differentiable operations only, and return a scalar.\n        inputs (tf.Tensor): Input tensor wrt which the gradients are computed\n        *args: Additional Args for func.\n        **kwargs: Additional Kwargs for func.\n\n    Returns:\n        tf.Tensor: Gradients computed, with the same shape as the inputs.\n    \"\"\"\n    with tf.GradientTape(watch_accessed_variables=False) as tape:\n        tape.watch(inputs)\n        outputs = func(inputs, *args, **kwargs)\n    return tape.gradient(outputs, inputs)\n</code></pre>"},{"location":"api/tf_operator/#oodeel.utils.tf_operator.TFOperator.log","title":"<code>log(tensor)</code>  <code>staticmethod</code>","text":"<p>Perform log</p> Source code in <code>oodeel/utils/tf_operator.py</code> <pre><code>@staticmethod\ndef log(tensor: TensorType) -&gt; tf.Tensor:\n\"\"\"Perform log\"\"\"\n    return tf.math.log(tensor)\n</code></pre>"},{"location":"api/tf_operator/#oodeel.utils.tf_operator.TFOperator.matmul","title":"<code>matmul(tensor_1, tensor_2)</code>  <code>staticmethod</code>","text":"<p>Matmul operation</p> Source code in <code>oodeel/utils/tf_operator.py</code> <pre><code>@staticmethod\n@tf.function\ndef matmul(tensor_1: TensorType, tensor_2: TensorType) -&gt; tf.Tensor:\n\"\"\"Matmul operation\"\"\"\n    return tf.matmul(tensor_1, tensor_2)\n</code></pre>"},{"location":"api/tf_operator/#oodeel.utils.tf_operator.TFOperator.max","title":"<code>max(tensor, dim=None, keepdim=False)</code>  <code>staticmethod</code>","text":"<p>Max function</p> Source code in <code>oodeel/utils/tf_operator.py</code> <pre><code>@staticmethod\ndef max(\n    tensor: TensorType, dim: Optional[int] = None, keepdim: bool = False\n) -&gt; tf.Tensor:\n\"\"\"Max function\"\"\"\n    return tf.reduce_max(tensor, axis=dim, keepdims=keepdim)\n</code></pre>"},{"location":"api/tf_operator/#oodeel.utils.tf_operator.TFOperator.mean","title":"<code>mean(tensor, dim=None)</code>  <code>staticmethod</code>","text":"<p>Mean function</p> Source code in <code>oodeel/utils/tf_operator.py</code> <pre><code>@staticmethod\ndef mean(tensor: TensorType, dim: Optional[int] = None) -&gt; tf.Tensor:\n    \"Mean function\"\n    return tf.reduce_mean(tensor, dim)\n</code></pre>"},{"location":"api/tf_operator/#oodeel.utils.tf_operator.TFOperator.min","title":"<code>min(tensor, dim=None, keepdim=False)</code>  <code>staticmethod</code>","text":"<p>Min function</p> Source code in <code>oodeel/utils/tf_operator.py</code> <pre><code>@staticmethod\ndef min(\n    tensor: TensorType, dim: Optional[int] = None, keepdim: bool = False\n) -&gt; tf.Tensor:\n\"\"\"Min function\"\"\"\n    return tf.reduce_min(tensor, axis=dim, keepdims=keepdim)\n</code></pre>"},{"location":"api/tf_operator/#oodeel.utils.tf_operator.TFOperator.norm","title":"<code>norm(tensor, dim=None)</code>  <code>staticmethod</code>","text":"<p>Tensor Norm</p> Source code in <code>oodeel/utils/tf_operator.py</code> <pre><code>@staticmethod\ndef norm(tensor: TensorType, dim: Optional[int] = None) -&gt; tf.Tensor:\n\"\"\"Tensor Norm\"\"\"\n    return tf.norm(tensor, axis=dim)\n</code></pre>"},{"location":"api/tf_operator/#oodeel.utils.tf_operator.TFOperator.one_hot","title":"<code>one_hot(tensor, num_classes)</code>  <code>staticmethod</code>","text":"<p>One hot function</p> Source code in <code>oodeel/utils/tf_operator.py</code> <pre><code>@staticmethod\ndef one_hot(tensor: TensorType, num_classes: int) -&gt; tf.Tensor:\n\"\"\"One hot function\"\"\"\n    return tf.one_hot(tensor, num_classes)\n</code></pre>"},{"location":"api/tf_operator/#oodeel.utils.tf_operator.TFOperator.permute","title":"<code>permute(tensor, dims)</code>  <code>staticmethod</code>","text":"<p>Transpose function for tensor of rank 2</p> Source code in <code>oodeel/utils/tf_operator.py</code> <pre><code>@staticmethod\ndef permute(tensor: TensorType, dims) -&gt; tf.Tensor:\n    \"Transpose function for tensor of rank 2\"\n    return tf.transpose(tensor, dims)\n</code></pre>"},{"location":"api/tf_operator/#oodeel.utils.tf_operator.TFOperator.pinv","title":"<code>pinv(tensor)</code>  <code>staticmethod</code>","text":"<p>Computes the pseudoinverse (Moore-Penrose inverse) of a matrix.</p> Source code in <code>oodeel/utils/tf_operator.py</code> <pre><code>@staticmethod\ndef pinv(tensor: TensorType) -&gt; tf.Tensor:\n    \"Computes the pseudoinverse (Moore-Penrose inverse) of a matrix.\"\n    return tf.linalg.pinv(tensor)\n</code></pre>"},{"location":"api/tf_operator/#oodeel.utils.tf_operator.TFOperator.quantile","title":"<code>quantile(tensor, q, dim=None)</code>  <code>staticmethod</code>","text":"<p>Computes the quantile of a tensor's components. q in (0,1)</p> Source code in <code>oodeel/utils/tf_operator.py</code> <pre><code>@staticmethod\ndef quantile(tensor: TensorType, q: float, dim: int = None) -&gt; tf.Tensor:\n    \"Computes the quantile of a tensor's components. q in (0,1)\"\n    q = tfp.stats.percentile(tensor, q * 100, axis=dim)\n    return float(q) if dim is None else q\n</code></pre>"},{"location":"api/tf_operator/#oodeel.utils.tf_operator.TFOperator.relu","title":"<code>relu(tensor)</code>  <code>staticmethod</code>","text":"<p>Apply relu to a tensor</p> Source code in <code>oodeel/utils/tf_operator.py</code> <pre><code>@staticmethod\ndef relu(tensor: TensorType) -&gt; tf.Tensor:\n    \"Apply relu to a tensor\"\n    return tf.nn.relu(tensor)\n</code></pre>"},{"location":"api/tf_operator/#oodeel.utils.tf_operator.TFOperator.reshape","title":"<code>reshape(tensor, shape)</code>  <code>staticmethod</code>","text":"<p>Reshape function</p> Source code in <code>oodeel/utils/tf_operator.py</code> <pre><code>@staticmethod\ndef reshape(tensor: TensorType, shape: List[int]) -&gt; tf.Tensor:\n    \"Reshape function\"\n    return tf.reshape(tensor, shape)\n</code></pre>"},{"location":"api/tf_operator/#oodeel.utils.tf_operator.TFOperator.sign","title":"<code>sign(tensor)</code>  <code>staticmethod</code>","text":"<p>Sign function</p> Source code in <code>oodeel/utils/tf_operator.py</code> <pre><code>@staticmethod\ndef sign(tensor: TensorType) -&gt; tf.Tensor:\n\"\"\"Sign function\"\"\"\n    return tf.sign(tensor)\n</code></pre>"},{"location":"api/tf_operator/#oodeel.utils.tf_operator.TFOperator.softmax","title":"<code>softmax(tensor)</code>  <code>staticmethod</code>","text":"<p>Softmax function along the last dimension</p> Source code in <code>oodeel/utils/tf_operator.py</code> <pre><code>@staticmethod\ndef softmax(tensor: TensorType) -&gt; tf.Tensor:\n\"\"\"Softmax function along the last dimension\"\"\"\n    return tf.keras.activations.softmax(tensor, axis=-1)\n</code></pre>"},{"location":"api/tf_operator/#oodeel.utils.tf_operator.TFOperator.squeeze","title":"<code>squeeze(tensor, dim=None)</code>  <code>staticmethod</code>","text":"<p>expand_dim along dim</p> Source code in <code>oodeel/utils/tf_operator.py</code> <pre><code>@staticmethod\ndef squeeze(tensor: TensorType, dim: int = None) -&gt; tf.Tensor:\n    \"expand_dim along dim\"\n    return tf.squeeze(tensor, dim)\n</code></pre>"},{"location":"api/tf_operator/#oodeel.utils.tf_operator.TFOperator.stack","title":"<code>stack(tensors, dim=0)</code>  <code>staticmethod</code>","text":"<p>Stack tensors along a new dimension</p> Source code in <code>oodeel/utils/tf_operator.py</code> <pre><code>@staticmethod\ndef stack(tensors: List[TensorType], dim: int = 0) -&gt; tf.Tensor:\n    \"Stack tensors along a new dimension\"\n    return tf.stack(tensors, dim)\n</code></pre>"},{"location":"api/tf_operator/#oodeel.utils.tf_operator.TFOperator.sum","title":"<code>sum(tensor, dim=None)</code>  <code>staticmethod</code>","text":"<p>sum along dim</p> Source code in <code>oodeel/utils/tf_operator.py</code> <pre><code>@staticmethod\ndef sum(tensor: TensorType, dim: Union[tuple, list, int] = None) -&gt; tf.Tensor:\n    \"sum along dim\"\n    return tf.reduce_sum(tensor, axis=dim)\n</code></pre>"},{"location":"api/tf_operator/#oodeel.utils.tf_operator.TFOperator.t","title":"<code>t(tensor)</code>  <code>staticmethod</code>","text":"<p>Transpose function for tensor of rank 2</p> Source code in <code>oodeel/utils/tf_operator.py</code> <pre><code>@staticmethod\ndef t(tensor: TensorType) -&gt; tf.Tensor:\n    \"Transpose function for tensor of rank 2\"\n    return tf.transpose(tensor)\n</code></pre>"},{"location":"api/tf_operator/#oodeel.utils.tf_operator.TFOperator.tril","title":"<code>tril(tensor, diagonal=0)</code>  <code>staticmethod</code>","text":"<p>Set the upper triangle of the matrix formed by the last two dimensions of</p> Source code in <code>oodeel/utils/tf_operator.py</code> <pre><code>@staticmethod\ndef tril(tensor: TensorType, diagonal: int = 0) -&gt; tf.Tensor:\n    \"Set the upper triangle of the matrix formed by the last two dimensions of\"\n    \"tensor to zero\"\n    return tf.experimental.numpy.tril(tensor, k=diagonal)\n</code></pre>"},{"location":"api/tf_operator/#oodeel.utils.tf_operator.TFOperator.unsqueeze","title":"<code>unsqueeze(tensor, dim)</code>  <code>staticmethod</code>","text":"<p>expand_dim along dim</p> Source code in <code>oodeel/utils/tf_operator.py</code> <pre><code>@staticmethod\ndef unsqueeze(tensor: TensorType, dim: int) -&gt; tf.Tensor:\n    \"expand_dim along dim\"\n    return tf.expand_dims(tensor, dim)\n</code></pre>"},{"location":"api/tf_operator/#oodeel.utils.tf_operator.TFOperator.where","title":"<code>where(condition, input, other)</code>  <code>staticmethod</code>","text":"<p>Applies where function to condition</p> Source code in <code>oodeel/utils/tf_operator.py</code> <pre><code>@staticmethod\ndef where(\n    condition: TensorType,\n    input: Union[TensorType, float],\n    other: Union[TensorType, float],\n) -&gt; tf.Tensor:\n    \"Applies where function to condition\"\n    return tf.where(condition, input, other)\n</code></pre>"},{"location":"api/tf_operator/#oodeel.utils.tf_operator.sanitize_input","title":"<code>sanitize_input(tensor_arg_func)</code>","text":"<p>ensures the decorated function receives a tf.Tensor</p> Source code in <code>oodeel/utils/tf_operator.py</code> <pre><code>def sanitize_input(tensor_arg_func: Callable):\n\"\"\"ensures the decorated function receives a tf.Tensor\"\"\"\n\n    def wrapper(obj, tensor, *args, **kwargs):\n        if isinstance(tensor, tf.Tensor):\n            pass\n        elif is_from(tensor, \"torch\"):\n            tensor = tf.convert_to_tensor(tensor.numpy())\n        else:\n            tensor = tf.convert_to_tensor(tensor)\n\n        return tensor_arg_func(obj, tensor, *args, **kwargs)\n\n    return wrapper\n</code></pre>"},{"location":"api/torch_datahandler/","title":"TorchDataHandler","text":""},{"location":"api/torch_datahandler/#oodeel.datasets.torch_data_handler.DictDataset","title":"<code>DictDataset</code>","text":"<p>         Bases: <code>Dataset</code></p> <p>Dictionary pytorch dataset</p> <p>Wrapper to output a dictionary of tensors at the getitem call of a dataset. Some mapping, filtering and concatenation methods are implemented to imitate tensorflow datasets features.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>Dataset</code> <p>Dataset to wrap.</p> required <code>output_keys</code> <code>output_keys[str]</code> <p>Keys describing the output tensors.</p> <code>['input', 'label']</code> Source code in <code>oodeel/datasets/torch_data_handler.py</code> <pre><code>class DictDataset(Dataset):\nr\"\"\"Dictionary pytorch dataset\n\n    Wrapper to output a dictionary of tensors at the __getitem__ call of a dataset.\n    Some mapping, filtering and concatenation methods are implemented to imitate\n    tensorflow datasets features.\n\n    Args:\n        dataset (Dataset): Dataset to wrap.\n        output_keys (output_keys[str]): Keys describing the output tensors.\n    \"\"\"\n\n    def __init__(\n        self, dataset: Dataset, output_keys: List[str] = [\"input\", \"label\"]\n    ) -&gt; None:\n        self._dataset = dataset\n        self._raw_output_keys = output_keys\n        self.map_fns = []\n        self._check_init_args()\n\n    @property\n    def output_keys(self) -&gt; list:\n\"\"\"Get the list of keys in a dict-based item from the dataset.\n\n        Returns:\n            list: feature keys of the dataset.\n        \"\"\"\n        dummy_item = self[0]\n        return list(dummy_item.keys())\n\n    @property\n    def output_shapes(self) -&gt; list:\n\"\"\"Get a list of the tensor shapes in an item from the dataset.\n\n        Returns:\n            list: tensor shapes of an dataset item.\n        \"\"\"\n        dummy_item = self[0]\n        return [dummy_item[key].shape for key in self.output_keys]\n\n    def _check_init_args(self) -&gt; None:\n\"\"\"Check validity of dataset and output keys provided at init\"\"\"\n        dummy_item = self._dataset[0]\n        assert isinstance(\n            dummy_item, (tuple, dict, list, torch.Tensor)\n        ), \"Dataset to be wrapped needs to return tuple, list or dict of tensors\"\n        if isinstance(dummy_item, torch.Tensor):\n            dummy_item = [dummy_item]\n        assert len(dummy_item) == len(\n            self._raw_output_keys\n        ), \"Length mismatch between dataset item and provided keys\"\n\n    def __getitem__(self, index: int) -&gt; dict:\n\"\"\"Return a dictionary of tensors corresponding to a specfic index.\n\n        Args:\n            index (int): the index of the item to retrieve.\n\n        Returns:\n            dict: tensors for the item at the specific index.\n        \"\"\"\n        item = self._dataset[index]\n\n        # convert item to a list / tuple of tensors\n        if isinstance(item, torch.Tensor):\n            tensors = [item]\n        elif isinstance(item, dict):\n            tensors = list(item.values())\n        else:\n            tensors = item\n\n        # build output dictionary\n        output_dict = {\n            key: tensor for (key, tensor) in zip(self._raw_output_keys, tensors)\n        }\n\n        # apply map functions\n        for map_fn in self.map_fns:\n            output_dict = map_fn(output_dict)\n        return output_dict\n\n    def map(self, map_fn: Callable, inplace: bool = False) -&gt; \"DictDataset\":\n\"\"\"Map the dataset\n\n        Args:\n            map_fn (Callable): map function f: dict -&gt; dict\n            inplace (bool): if False, applies the mapping on a copied version of\\\n                the dataset. Defaults to False.\n\n        Return:\n            DictDataset: Mapped dataset\n        \"\"\"\n        dataset = self if inplace else copy.deepcopy(self)\n        dataset.map_fns.append(map_fn)\n        return dataset\n\n    def filter(self, filter_fn: Callable, inplace: bool = False) -&gt; \"DictDataset\":\n\"\"\"Filter the dataset\n\n        Args:\n            filter_fn (Callable): filter function f: dict -&gt; bool\n            inplace (bool): if False, applies the filtering on a copied version of\\\n                the dataset. Defaults to False.\n\n        Returns:\n            DictDataset: Filtered dataset\n        \"\"\"\n        indices = [i for i in range(len(self)) if filter_fn(self[i])]\n        dataset = self if inplace else copy.deepcopy(self)\n        dataset._dataset = Subset(self._dataset, indices)\n        return dataset\n\n    def concatenate(\n        self, other_dataset: Dataset, inplace: bool = False\n    ) -&gt; \"DictDataset\":\n\"\"\"Concatenate with another dataset\n\n        Args:\n            other_dataset (DictDataset): Dataset to concatenate with\n            inplace (bool): if False, applies the filtering on a copied version of\\\n                the dataset. Defaults to False.\n\n        Returns:\n            DictDataset: Concatenated dataset\n        \"\"\"\n        assert isinstance(\n            other_dataset, DictDataset\n        ), \"Second dataset should be an instance of DictDataset\"\n        assert (\n            self.output_keys == other_dataset.output_keys\n        ), \"Incompatible dataset elements (different dict keys)\"\n        if inplace:\n            dataset_copy = copy.deepcopy(self)\n            self._raw_output_keys = self.output_keys\n            self.map_fns = []\n            self._dataset = ConcatDataset([dataset_copy, other_dataset])\n            dataset = self\n        else:\n            dataset = DictDataset(\n                ConcatDataset([self, other_dataset]), self.output_keys\n            )\n        return dataset\n\n    def __len__(self) -&gt; int:\n\"\"\"Return the length of the dataset, i.e. the number of items.\n\n        Returns:\n            int: length of the dataset.\n        \"\"\"\n        return len(self._dataset)\n</code></pre>"},{"location":"api/torch_datahandler/#oodeel.datasets.torch_data_handler.DictDataset.output_keys","title":"<code>output_keys: list</code>  <code>property</code>","text":"<p>Get the list of keys in a dict-based item from the dataset.</p> <p>Returns:</p> Name Type Description <code>list</code> <code>list</code> <p>feature keys of the dataset.</p>"},{"location":"api/torch_datahandler/#oodeel.datasets.torch_data_handler.DictDataset.output_shapes","title":"<code>output_shapes: list</code>  <code>property</code>","text":"<p>Get a list of the tensor shapes in an item from the dataset.</p> <p>Returns:</p> Name Type Description <code>list</code> <code>list</code> <p>tensor shapes of an dataset item.</p>"},{"location":"api/torch_datahandler/#oodeel.datasets.torch_data_handler.DictDataset.__getitem__","title":"<code>__getitem__(index)</code>","text":"<p>Return a dictionary of tensors corresponding to a specfic index.</p> <p>Parameters:</p> Name Type Description Default <code>index</code> <code>int</code> <p>the index of the item to retrieve.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>tensors for the item at the specific index.</p> Source code in <code>oodeel/datasets/torch_data_handler.py</code> <pre><code>def __getitem__(self, index: int) -&gt; dict:\n\"\"\"Return a dictionary of tensors corresponding to a specfic index.\n\n    Args:\n        index (int): the index of the item to retrieve.\n\n    Returns:\n        dict: tensors for the item at the specific index.\n    \"\"\"\n    item = self._dataset[index]\n\n    # convert item to a list / tuple of tensors\n    if isinstance(item, torch.Tensor):\n        tensors = [item]\n    elif isinstance(item, dict):\n        tensors = list(item.values())\n    else:\n        tensors = item\n\n    # build output dictionary\n    output_dict = {\n        key: tensor for (key, tensor) in zip(self._raw_output_keys, tensors)\n    }\n\n    # apply map functions\n    for map_fn in self.map_fns:\n        output_dict = map_fn(output_dict)\n    return output_dict\n</code></pre>"},{"location":"api/torch_datahandler/#oodeel.datasets.torch_data_handler.DictDataset.__len__","title":"<code>__len__()</code>","text":"<p>Return the length of the dataset, i.e. the number of items.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>length of the dataset.</p> Source code in <code>oodeel/datasets/torch_data_handler.py</code> <pre><code>def __len__(self) -&gt; int:\n\"\"\"Return the length of the dataset, i.e. the number of items.\n\n    Returns:\n        int: length of the dataset.\n    \"\"\"\n    return len(self._dataset)\n</code></pre>"},{"location":"api/torch_datahandler/#oodeel.datasets.torch_data_handler.DictDataset.concatenate","title":"<code>concatenate(other_dataset, inplace=False)</code>","text":"<p>Concatenate with another dataset</p> <p>Parameters:</p> Name Type Description Default <code>other_dataset</code> <code>DictDataset</code> <p>Dataset to concatenate with</p> required <code>inplace</code> <code>bool</code> <p>if False, applies the filtering on a copied version of                the dataset. Defaults to False.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>DictDataset</code> <code>DictDataset</code> <p>Concatenated dataset</p> Source code in <code>oodeel/datasets/torch_data_handler.py</code> <pre><code>def concatenate(\n    self, other_dataset: Dataset, inplace: bool = False\n) -&gt; \"DictDataset\":\n\"\"\"Concatenate with another dataset\n\n    Args:\n        other_dataset (DictDataset): Dataset to concatenate with\n        inplace (bool): if False, applies the filtering on a copied version of\\\n            the dataset. Defaults to False.\n\n    Returns:\n        DictDataset: Concatenated dataset\n    \"\"\"\n    assert isinstance(\n        other_dataset, DictDataset\n    ), \"Second dataset should be an instance of DictDataset\"\n    assert (\n        self.output_keys == other_dataset.output_keys\n    ), \"Incompatible dataset elements (different dict keys)\"\n    if inplace:\n        dataset_copy = copy.deepcopy(self)\n        self._raw_output_keys = self.output_keys\n        self.map_fns = []\n        self._dataset = ConcatDataset([dataset_copy, other_dataset])\n        dataset = self\n    else:\n        dataset = DictDataset(\n            ConcatDataset([self, other_dataset]), self.output_keys\n        )\n    return dataset\n</code></pre>"},{"location":"api/torch_datahandler/#oodeel.datasets.torch_data_handler.DictDataset.filter","title":"<code>filter(filter_fn, inplace=False)</code>","text":"<p>Filter the dataset</p> <p>Parameters:</p> Name Type Description Default <code>filter_fn</code> <code>Callable</code> <p>filter function f: dict -&gt; bool</p> required <code>inplace</code> <code>bool</code> <p>if False, applies the filtering on a copied version of                the dataset. Defaults to False.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>DictDataset</code> <code>DictDataset</code> <p>Filtered dataset</p> Source code in <code>oodeel/datasets/torch_data_handler.py</code> <pre><code>def filter(self, filter_fn: Callable, inplace: bool = False) -&gt; \"DictDataset\":\n\"\"\"Filter the dataset\n\n    Args:\n        filter_fn (Callable): filter function f: dict -&gt; bool\n        inplace (bool): if False, applies the filtering on a copied version of\\\n            the dataset. Defaults to False.\n\n    Returns:\n        DictDataset: Filtered dataset\n    \"\"\"\n    indices = [i for i in range(len(self)) if filter_fn(self[i])]\n    dataset = self if inplace else copy.deepcopy(self)\n    dataset._dataset = Subset(self._dataset, indices)\n    return dataset\n</code></pre>"},{"location":"api/torch_datahandler/#oodeel.datasets.torch_data_handler.DictDataset.map","title":"<code>map(map_fn, inplace=False)</code>","text":"<p>Map the dataset</p> <p>Parameters:</p> Name Type Description Default <code>map_fn</code> <code>Callable</code> <p>map function f: dict -&gt; dict</p> required <code>inplace</code> <code>bool</code> <p>if False, applies the mapping on a copied version of                the dataset. Defaults to False.</p> <code>False</code> Return <p>DictDataset: Mapped dataset</p> Source code in <code>oodeel/datasets/torch_data_handler.py</code> <pre><code>def map(self, map_fn: Callable, inplace: bool = False) -&gt; \"DictDataset\":\n\"\"\"Map the dataset\n\n    Args:\n        map_fn (Callable): map function f: dict -&gt; dict\n        inplace (bool): if False, applies the mapping on a copied version of\\\n            the dataset. Defaults to False.\n\n    Return:\n        DictDataset: Mapped dataset\n    \"\"\"\n    dataset = self if inplace else copy.deepcopy(self)\n    dataset.map_fns.append(map_fn)\n    return dataset\n</code></pre>"},{"location":"api/torch_datahandler/#oodeel.datasets.torch_data_handler.TorchDataHandler","title":"<code>TorchDataHandler</code>","text":"<p>         Bases: <code>DataHandler</code></p> <p>Class to manage torch DictDataset. The aim is to provide a simple interface for working with torch datasets and manage them without having to use torch syntax.</p> Source code in <code>oodeel/datasets/torch_data_handler.py</code> <pre><code>class TorchDataHandler(DataHandler):\n\"\"\"\n    Class to manage torch DictDataset. The aim is to provide a simple interface\n    for working with torch datasets and manage them without having to use\n    torch syntax.\n    \"\"\"\n\n    @staticmethod\n    def _default_target_transform(y: Any) -&gt; torch.Tensor:\n\"\"\"Format int or float item target as a torch tensor\n\n        Args:\n            y (Any): dataset item target\n\n        Returns:\n            torch.Tensor: target as a torch.Tensor\n        \"\"\"\n        return torch.tensor(y) if isinstance(y, (float, int)) else y\n\n    DEFAULT_TRANSFORM = torchvision.transforms.PILToTensor()\n    DEFAULT_TARGET_TRANSFORM = _default_target_transform.__func__\n\n    @classmethod\n    def load_dataset(\n        cls,\n        dataset_id: Union[Dataset, ItemType, str],\n        keys: Optional[list] = None,\n        load_kwargs: dict = {},\n    ) -&gt; DictDataset:\n\"\"\"Load dataset from different manners\n\n        Args:\n            dataset_id (Union[Dataset, ItemType, str]): dataset identification\n            keys (list, optional): Features keys. If None, assigned as \"input_i\"\n                for i-th feature. Defaults to None.\n            load_kwargs (dict, optional): Additional loading kwargs. Defaults to {}.\n\n        Returns:\n            DictDataset: dataset\n        \"\"\"\n        if isinstance(dataset_id, str):\n            assert \"root\" in load_kwargs.keys()\n            dataset = cls.load_from_torchvision(dataset_id, **load_kwargs)\n        elif isinstance(dataset_id, Dataset):\n            dataset = cls.load_custom_dataset(dataset_id, keys)\n        elif isinstance(dataset_id, get_args(ItemType)):\n            dataset = cls.load_dataset_from_arrays(dataset_id, keys)\n        return dataset\n\n    @staticmethod\n    def load_dataset_from_arrays(\n        dataset_id: ItemType,\n        keys: Optional[list] = None,\n    ) -&gt; DictDataset:\n\"\"\"Load a torch.utils.data.Dataset from an array or a tuple/dict of arrays.\n\n        Args:\n            dataset_id (ItemType):\n                numpy / torch array(s) to load.\n            keys (list, optional): Features keys. If None, assigned as \"input_i\"\n                for i-th feature. Defaults to None.\n\n        Returns:\n            DictDataset: dataset\n        \"\"\"\n        # If dataset_id is an array\n        if isinstance(dataset_id, get_args(TensorType)):\n            tensors = tuple(to_torch(dataset_id))\n            output_keys = keys or [\"input\"]\n\n        # If dataset_id is a tuple of arrays\n        elif isinstance(dataset_id, tuple):\n            len_elem = len(dataset_id)\n            output_keys = keys\n            if output_keys is None:\n                if len_elem == 2:\n                    output_keys = [\"input\", \"label\"]\n                else:\n                    output_keys = [f\"input_{i}\" for i in range(len_elem - 1)] + [\n                        \"label\"\n                    ]\n                    print(\n                        \"Loading torch.utils.data.Dataset with elems as dicts, \"\n                        'assigning \"input_i\" key to the i-th tuple dimension and'\n                        ' \"label\" key to the last tuple dimension.'\n                    )\n            assert len(output_keys) == len(dataset_id)\n            tensors = tuple(to_torch(array) for array in dataset_id)\n\n        # If dataset_id is a dictionary of arrays\n        elif isinstance(dataset_id, dict):\n            output_keys = keys or list(dataset_id.keys())\n            assert len(output_keys) == len(dataset_id)\n            tensors = tuple(to_torch(array) for array in dataset_id.values())\n\n        # create torch dictionary dataset from tensors tuple and keys\n        dataset = DictDataset(TensorDataset(*tensors), output_keys)\n        return dataset\n\n    @staticmethod\n    def load_custom_dataset(\n        dataset_id: Dataset, keys: Optional[list] = None\n    ) -&gt; DictDataset:\n\"\"\"Load a custom Dataset by ensuring it has the correct format (dict-based)\n\n        Args:\n            dataset_id (Dataset): Dataset\n            keys (list, optional): Keys to use for features if dataset_id is\n                tuple based. Defaults to None.\n\n        Returns:\n            DictDataset\n        \"\"\"\n        # If dataset_id is a tuple based Dataset, convert it to a DictDataset\n        dummy_item = dataset_id[0]\n        if not isinstance(dummy_item, dict):\n            assert isinstance(\n                dummy_item, (Tuple, torch.Tensor)\n            ), \"Custom dataset should be either dictionary based or tuple based\"\n            output_keys = keys\n            if output_keys is None:\n                len_elem = len(dummy_item)\n                if len_elem == 2:\n                    output_keys = [\"input\", \"label\"]\n                else:\n                    output_keys = [f\"input_{i}\" for i in range(len_elem - 1)] + [\n                        \"label\"\n                    ]\n                    print(\n                        \"Feature name not found, assigning 'input_i' \"\n                        \"key to the i-th tensor and 'label' key to the last\"\n                    )\n            dataset_id = DictDataset(dataset_id, output_keys)\n\n        dataset = dataset_id\n        return dataset\n\n    @classmethod\n    def load_from_torchvision(\n        cls,\n        dataset_id: str,\n        root: str,\n        transform: Callable = DEFAULT_TRANSFORM,\n        target_transform: Callable = DEFAULT_TARGET_TRANSFORM,\n        download: bool = False,\n        **load_kwargs,\n    ) -&gt; DictDataset:\n\"\"\"Load a Dataset from the torchvision datasets catalog\n\n        Args:\n            dataset_id (str): Identifier of the dataset\n            root (str): Root directory of dataset\n            transform (Callable, optional): Transform function to apply to the input.\n                Defaults to DEFAULT_TRANSFORM.\n            target_transform (Callable, optional): Transform function to apply\n                to the target. Defaults to DEFAULT_TARGET_TRANSFORM.\n            download (bool):  If true, downloads the dataset from the internet and puts\n                it in root directory. If dataset is already downloaded, it is not\n                downloaded again. Defaults to False.\n            load_kwargs (dict): Loading kwargs to add to the initialization\n                of dataset.\n\n        Returns:\n            DictDataset: dataset\n        \"\"\"\n        assert (\n            dataset_id in torchvision.datasets.__all__\n        ), \"Dataset not available on torchvision datasets catalog\"\n        dataset = getattr(torchvision.datasets, dataset_id)(\n            root=root,\n            download=download,\n            transform=transform,\n            target_transform=target_transform,\n            **load_kwargs,\n        )\n        return cls.load_custom_dataset(dataset)\n\n    @staticmethod\n    def assign_feature_value(\n        dataset: DictDataset, feature_key: str, value: int\n    ) -&gt; DictDataset:\n\"\"\"Assign a value to a feature for every sample in a DictDataset\n\n        Args:\n            dataset (DictDataset): DictDataset to assign the value to\n            feature_key (str): Feature to assign the value to\n            value (int): Value to assign\n\n        Returns:\n            DictDataset\n        \"\"\"\n        assert isinstance(\n            dataset, DictDataset\n        ), \"Dataset must be an instance of DictDataset\"\n\n        def assign_value_to_feature(x):\n            x[feature_key] = torch.tensor(value)\n            return x\n\n        dataset = dataset.map(assign_value_to_feature)\n        return dataset\n\n    @staticmethod\n    @dict_only_ds\n    def get_feature_from_ds(dataset: DictDataset, feature_key: str) -&gt; np.ndarray:\n\"\"\"Get a feature from a DictDataset\n\n        !!! note\n            This function can be a bit time consuming since it needs to iterate\n            over the whole dataset.\n\n        Args:\n            dataset (DictDataset): Dataset to get the feature from\n            feature_key (str): Feature value to get\n\n        Returns:\n            np.ndarray: Feature values for dataset\n        \"\"\"\n\n        features = dataset.map(lambda x: x[feature_key])\n        features = np.stack([f.numpy() for f in features])\n        return features\n\n    @staticmethod\n    @dict_only_ds\n    def get_ds_feature_keys(dataset: DictDataset) -&gt; list:\n\"\"\"Get the feature keys of a DictDataset\n\n        Args:\n            dataset (DictDataset): Dataset to get the feature keys from\n\n        Returns:\n            list: List of feature keys\n        \"\"\"\n        return dataset.output_keys\n\n    @staticmethod\n    def has_feature_key(dataset: DictDataset, key: str) -&gt; bool:\n\"\"\"Check if a DictDataset has a feature denoted by key\n\n        Args:\n            dataset (DictDataset): Dataset to check\n            key (str): Key to check\n\n        Returns:\n            bool: If the dataset has a feature denoted by key\n        \"\"\"\n        assert isinstance(\n            dataset, DictDataset\n        ), \"Dataset must be an instance of DictDataset\"\n\n        return key in dataset.output_keys\n\n    @staticmethod\n    def map_ds(\n        dataset: DictDataset,\n        map_fn: Callable,\n    ) -&gt; DictDataset:\n\"\"\"Map a function to a DictDataset\n\n        Args:\n            dataset (DictDataset): Dataset to map the function to\n            map_fn (Callable): Function to map\n\n        Returns:\n            DictDataset: Mapped dataset\n        \"\"\"\n        return dataset.map(map_fn)\n\n    @staticmethod\n    @dict_only_ds\n    def filter_by_feature_value(\n        dataset: DictDataset,\n        feature_key: str,\n        values: list,\n        excluded: bool = False,\n    ) -&gt; DictDataset:\n\"\"\"Filter the dataset by checking the value of a feature is in `values`\n\n        !!! note\n            This function can be a bit of time consuming since it needs to iterate\n            over the whole dataset.\n\n        Args:\n            dataset (DictDataset): Dataset to filter\n            feature_key (str): Feature name to check the value\n            values (list): Feature_key values to keep\n            excluded (bool, optional): To keep (False) or exclude (True) the samples\n                with Feature_key value included in Values. Defaults to False.\n\n        Returns:\n            DictDataset: Filtered dataset\n        \"\"\"\n\n        if len(dataset[0][feature_key].shape) &gt; 0:\n            value_dim = dataset[0][feature_key].shape[-1]\n            values = [\n                F.one_hot(torch.tensor(value).long(), value_dim) for value in values\n            ]\n\n        def filter_fn(x):\n            keep = any([torch.all(x[feature_key] == v) for v in values])\n            return keep if not excluded else not keep\n\n        filtered_dataset = dataset.filter(filter_fn)\n        return filtered_dataset\n\n    @classmethod\n    def prepare_for_training(\n        cls,\n        dataset: DictDataset,\n        batch_size: int,\n        shuffle: bool = False,\n        preprocess_fn: Optional[Callable] = None,\n        augment_fn: Optional[Callable] = None,\n        output_keys: Optional[list] = None,\n        dict_based_fns: bool = False,\n        shuffle_buffer_size: Optional[int] = None,\n        num_workers: int = 8,\n    ) -&gt; DataLoader:\n\"\"\"Prepare a DataLoader for training\n\n        Args:\n            dataset (DictDataset): Dataset to prepare\n            batch_size (int): Batch size\n            shuffle (bool): Wether to shuffle the dataloader or not\n            preprocess_fn (Callable, optional): Preprocessing function to apply to\n                the dataset. Defaults to None.\n            augment_fn (Callable, optional): Augment function to be used (when the\n                returned dataset is to be used for training). Defaults to None.\n            output_keys (list): List of keys corresponding to the features that will be\n                returned. Keep all features if None. Defaults to None.\n            dict_based_fns (bool): Whether to use preprocess and DA functions as dict\n                based (if True) or as tuple based (if False). Defaults to False.\n            shuffle_buffer_size (int, optional): Size of the shuffle buffer. Not used\n                in torch because we only rely on Map-Style datasets. Still as argument\n                for API consistency. Defaults to None.\n            num_workers (int, optional): Number of workers to use for the dataloader.\n\n        Returns:\n            DataLoader: dataloader\n        \"\"\"\n        output_keys = output_keys or cls.get_ds_feature_keys(dataset)\n\n        def collate_fn(batch: List[dict]):\n            if dict_based_fns:\n                # preprocess + DA: List[dict] -&gt; List[dict]\n                preprocess_func = preprocess_fn or (lambda x: x)\n                augment_func = augment_fn or (lambda x: x)\n                batch = [augment_func(preprocess_func(d)) for d in batch]\n                # to tuple of batchs\n                return tuple(\n                    default_collate([d[key] for d in batch]) for key in output_keys\n                )\n            else:\n                # preprocess + DA: List[dict] -&gt; List[tuple]\n                preprocess_func = preprocess_fn or (lambda *x: x)\n                augment_func = augment_fn or (lambda *x: x)\n                batch = [\n                    augment_func(\n                        *preprocess_func(*tuple(d[key] for key in output_keys))\n                    )\n                    for d in batch\n                ]\n                # to tuple of batchs\n                return default_collate(batch)\n\n        loader = DataLoader(\n            dataset,\n            batch_size=batch_size,\n            shuffle=shuffle,\n            collate_fn=collate_fn,\n            num_workers=num_workers,\n        )\n        return loader\n\n    @staticmethod\n    def merge(\n        id_dataset: DictDataset,\n        ood_dataset: DictDataset,\n        resize: Optional[bool] = False,\n        shape: Optional[Tuple[int]] = None,\n    ) -&gt; DictDataset:\n\"\"\"Merge two instances of DictDataset\n\n        Args:\n            id_dataset (DictDataset): dataset of in-distribution data\n            ood_dataset (DictDataset): dataset of out-of-distribution data\n            resize (Optional[bool], optional): toggles if input tensors of the\n                datasets have to be resized to have the same shape. Defaults to True.\n            shape (Optional[Tuple[int]], optional): shape to use for resizing input\n                tensors. If None, the tensors are resized with the shape of the\n                id_dataset input tensors. Defaults to None.\n\n        Returns:\n            DictDataset: merged dataset\n        \"\"\"\n        # If a desired shape is given, triggers the resize\n        if shape is not None:\n            resize = True\n\n        # If the shape of the two datasets are different, triggers the resize\n        if id_dataset.output_shapes[0] != ood_dataset.output_shapes[0]:\n            resize = True\n            if shape is None:\n                print(\n                    \"Resizing the first item of elem (usually the image)\",\n                    \" with the shape of id_dataset\",\n                )\n                shape = id_dataset.output_shapes[0][1:]\n\n        if resize:\n            resize_fn = torchvision.transforms.Resize(shape)\n\n            def reshape_fn(item_dict):\n                item_dict[\"input\"] = resize_fn(item_dict[\"input\"])\n                return item_dict\n\n            id_dataset = id_dataset.map(reshape_fn)\n            ood_dataset = ood_dataset.map(reshape_fn)\n\n        merged_dataset = id_dataset.concatenate(ood_dataset)\n        return merged_dataset\n\n    @staticmethod\n    def get_item_length(dataset: Dataset) -&gt; int:\n\"\"\"Number of elements in a dataset item\n\n        Args:\n            dataset (DictDataset): Dataset\n\n        Returns:\n            int: Item length\n        \"\"\"\n        return len(dataset[0])\n\n    @staticmethod\n    def get_dataset_length(dataset: Dataset) -&gt; int:\n\"\"\"Number of items in a dataset\n\n        Args:\n            dataset (DictDataset): Dataset\n\n        Returns:\n            int: Dataset length\n        \"\"\"\n        return len(dataset)\n\n    @staticmethod\n    def get_feature_shape(dataset: Dataset, feature_key: Union[str, int]) -&gt; tuple:\n\"\"\"Get the shape of a feature of dataset identified by feature_key\n\n        Args:\n            dataset (Dataset): a Dataset\n            feature_key (Union[str, int]): The identifier of the feature\n\n        Returns:\n            tuple: the shape of feature_id\n        \"\"\"\n        return tuple(dataset[0][feature_key].shape)\n\n    @staticmethod\n    def get_input_from_dataset_item(elem: ItemType) -&gt; Any:\n\"\"\"Get the tensor that is to be feed as input to a model from a dataset element.\n\n        Args:\n            elem (ItemType): dataset element to extract input from\n\n        Returns:\n            Any: Input tensor\n        \"\"\"\n        if isinstance(elem, (tuple, list)):\n            tensor = elem[0]\n        elif isinstance(elem, dict):\n            tensor = elem[list(elem.keys())[0]]\n        else:\n            tensor = elem\n        return tensor\n\n    @staticmethod\n    def get_label_from_dataset_item(item: ItemType):\n\"\"\"Retrieve label tensor from item as a tuple/list. Label must be at index 1\n        in the item tuple. If one-hot encoded, labels are converted to single value.\n\n        Args:\n            elem (ItemType): dataset element to extract label from\n\n        Returns:\n            Any: Label tensor\n        \"\"\"\n        label = item[1]  # labels must be at index 1 in the batch tuple\n        # If labels are one-hot encoded, take the argmax\n        if len(label.shape) &gt; 1 and label.shape[1] &gt; 1:\n            label = label.view(label.size(0), -1)\n            label = torch.argmax(label, dim=1)\n        # If labels are in two dimensions, squeeze them\n        if len(label.shape) &gt; 1:\n            label = label.view([label.shape[0]])\n        return label\n\n    @staticmethod\n    def get_feature(dataset: DictDataset, feature_key: Union[str, int]) -&gt; DictDataset:\n\"\"\"Extract a feature from a dataset\n\n        Args:\n            dataset (tf.data.Dataset): Dataset to extract the feature from\n            feature_key (Union[str, int]): feature to extract\n\n        Returns:\n            tf.data.Dataset: dataset built with the extracted feature only\n        \"\"\"\n\n        def _get_feature_item(item):\n            return item[feature_key]\n\n        return dataset.map(_get_feature_item)\n</code></pre>"},{"location":"api/torch_datahandler/#oodeel.datasets.torch_data_handler.TorchDataHandler.assign_feature_value","title":"<code>assign_feature_value(dataset, feature_key, value)</code>  <code>staticmethod</code>","text":"<p>Assign a value to a feature for every sample in a DictDataset</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>DictDataset</code> <p>DictDataset to assign the value to</p> required <code>feature_key</code> <code>str</code> <p>Feature to assign the value to</p> required <code>value</code> <code>int</code> <p>Value to assign</p> required <p>Returns:</p> Type Description <code>DictDataset</code> <p>DictDataset</p> Source code in <code>oodeel/datasets/torch_data_handler.py</code> <pre><code>@staticmethod\ndef assign_feature_value(\n    dataset: DictDataset, feature_key: str, value: int\n) -&gt; DictDataset:\n\"\"\"Assign a value to a feature for every sample in a DictDataset\n\n    Args:\n        dataset (DictDataset): DictDataset to assign the value to\n        feature_key (str): Feature to assign the value to\n        value (int): Value to assign\n\n    Returns:\n        DictDataset\n    \"\"\"\n    assert isinstance(\n        dataset, DictDataset\n    ), \"Dataset must be an instance of DictDataset\"\n\n    def assign_value_to_feature(x):\n        x[feature_key] = torch.tensor(value)\n        return x\n\n    dataset = dataset.map(assign_value_to_feature)\n    return dataset\n</code></pre>"},{"location":"api/torch_datahandler/#oodeel.datasets.torch_data_handler.TorchDataHandler.filter_by_feature_value","title":"<code>filter_by_feature_value(dataset, feature_key, values, excluded=False)</code>  <code>staticmethod</code>","text":"<p>Filter the dataset by checking the value of a feature is in <code>values</code></p> <p>Note</p> <p>This function can be a bit of time consuming since it needs to iterate over the whole dataset.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>DictDataset</code> <p>Dataset to filter</p> required <code>feature_key</code> <code>str</code> <p>Feature name to check the value</p> required <code>values</code> <code>list</code> <p>Feature_key values to keep</p> required <code>excluded</code> <code>bool</code> <p>To keep (False) or exclude (True) the samples with Feature_key value included in Values. Defaults to False.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>DictDataset</code> <code>DictDataset</code> <p>Filtered dataset</p> Source code in <code>oodeel/datasets/torch_data_handler.py</code> <pre><code>@staticmethod\n@dict_only_ds\ndef filter_by_feature_value(\n    dataset: DictDataset,\n    feature_key: str,\n    values: list,\n    excluded: bool = False,\n) -&gt; DictDataset:\n\"\"\"Filter the dataset by checking the value of a feature is in `values`\n\n    !!! note\n        This function can be a bit of time consuming since it needs to iterate\n        over the whole dataset.\n\n    Args:\n        dataset (DictDataset): Dataset to filter\n        feature_key (str): Feature name to check the value\n        values (list): Feature_key values to keep\n        excluded (bool, optional): To keep (False) or exclude (True) the samples\n            with Feature_key value included in Values. Defaults to False.\n\n    Returns:\n        DictDataset: Filtered dataset\n    \"\"\"\n\n    if len(dataset[0][feature_key].shape) &gt; 0:\n        value_dim = dataset[0][feature_key].shape[-1]\n        values = [\n            F.one_hot(torch.tensor(value).long(), value_dim) for value in values\n        ]\n\n    def filter_fn(x):\n        keep = any([torch.all(x[feature_key] == v) for v in values])\n        return keep if not excluded else not keep\n\n    filtered_dataset = dataset.filter(filter_fn)\n    return filtered_dataset\n</code></pre>"},{"location":"api/torch_datahandler/#oodeel.datasets.torch_data_handler.TorchDataHandler.get_dataset_length","title":"<code>get_dataset_length(dataset)</code>  <code>staticmethod</code>","text":"<p>Number of items in a dataset</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>DictDataset</code> <p>Dataset</p> required <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>Dataset length</p> Source code in <code>oodeel/datasets/torch_data_handler.py</code> <pre><code>@staticmethod\ndef get_dataset_length(dataset: Dataset) -&gt; int:\n\"\"\"Number of items in a dataset\n\n    Args:\n        dataset (DictDataset): Dataset\n\n    Returns:\n        int: Dataset length\n    \"\"\"\n    return len(dataset)\n</code></pre>"},{"location":"api/torch_datahandler/#oodeel.datasets.torch_data_handler.TorchDataHandler.get_ds_feature_keys","title":"<code>get_ds_feature_keys(dataset)</code>  <code>staticmethod</code>","text":"<p>Get the feature keys of a DictDataset</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>DictDataset</code> <p>Dataset to get the feature keys from</p> required <p>Returns:</p> Name Type Description <code>list</code> <code>list</code> <p>List of feature keys</p> Source code in <code>oodeel/datasets/torch_data_handler.py</code> <pre><code>@staticmethod\n@dict_only_ds\ndef get_ds_feature_keys(dataset: DictDataset) -&gt; list:\n\"\"\"Get the feature keys of a DictDataset\n\n    Args:\n        dataset (DictDataset): Dataset to get the feature keys from\n\n    Returns:\n        list: List of feature keys\n    \"\"\"\n    return dataset.output_keys\n</code></pre>"},{"location":"api/torch_datahandler/#oodeel.datasets.torch_data_handler.TorchDataHandler.get_feature","title":"<code>get_feature(dataset, feature_key)</code>  <code>staticmethod</code>","text":"<p>Extract a feature from a dataset</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>tf.data.Dataset</code> <p>Dataset to extract the feature from</p> required <code>feature_key</code> <code>Union[str, int]</code> <p>feature to extract</p> required <p>Returns:</p> Type Description <code>DictDataset</code> <p>tf.data.Dataset: dataset built with the extracted feature only</p> Source code in <code>oodeel/datasets/torch_data_handler.py</code> <pre><code>@staticmethod\ndef get_feature(dataset: DictDataset, feature_key: Union[str, int]) -&gt; DictDataset:\n\"\"\"Extract a feature from a dataset\n\n    Args:\n        dataset (tf.data.Dataset): Dataset to extract the feature from\n        feature_key (Union[str, int]): feature to extract\n\n    Returns:\n        tf.data.Dataset: dataset built with the extracted feature only\n    \"\"\"\n\n    def _get_feature_item(item):\n        return item[feature_key]\n\n    return dataset.map(_get_feature_item)\n</code></pre>"},{"location":"api/torch_datahandler/#oodeel.datasets.torch_data_handler.TorchDataHandler.get_feature_from_ds","title":"<code>get_feature_from_ds(dataset, feature_key)</code>  <code>staticmethod</code>","text":"<p>Get a feature from a DictDataset</p> <p>Note</p> <p>This function can be a bit time consuming since it needs to iterate over the whole dataset.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>DictDataset</code> <p>Dataset to get the feature from</p> required <code>feature_key</code> <code>str</code> <p>Feature value to get</p> required <p>Returns:</p> Type Description <code>np.ndarray</code> <p>np.ndarray: Feature values for dataset</p> Source code in <code>oodeel/datasets/torch_data_handler.py</code> <pre><code>@staticmethod\n@dict_only_ds\ndef get_feature_from_ds(dataset: DictDataset, feature_key: str) -&gt; np.ndarray:\n\"\"\"Get a feature from a DictDataset\n\n    !!! note\n        This function can be a bit time consuming since it needs to iterate\n        over the whole dataset.\n\n    Args:\n        dataset (DictDataset): Dataset to get the feature from\n        feature_key (str): Feature value to get\n\n    Returns:\n        np.ndarray: Feature values for dataset\n    \"\"\"\n\n    features = dataset.map(lambda x: x[feature_key])\n    features = np.stack([f.numpy() for f in features])\n    return features\n</code></pre>"},{"location":"api/torch_datahandler/#oodeel.datasets.torch_data_handler.TorchDataHandler.get_feature_shape","title":"<code>get_feature_shape(dataset, feature_key)</code>  <code>staticmethod</code>","text":"<p>Get the shape of a feature of dataset identified by feature_key</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>Dataset</code> <p>a Dataset</p> required <code>feature_key</code> <code>Union[str, int]</code> <p>The identifier of the feature</p> required <p>Returns:</p> Name Type Description <code>tuple</code> <code>tuple</code> <p>the shape of feature_id</p> Source code in <code>oodeel/datasets/torch_data_handler.py</code> <pre><code>@staticmethod\ndef get_feature_shape(dataset: Dataset, feature_key: Union[str, int]) -&gt; tuple:\n\"\"\"Get the shape of a feature of dataset identified by feature_key\n\n    Args:\n        dataset (Dataset): a Dataset\n        feature_key (Union[str, int]): The identifier of the feature\n\n    Returns:\n        tuple: the shape of feature_id\n    \"\"\"\n    return tuple(dataset[0][feature_key].shape)\n</code></pre>"},{"location":"api/torch_datahandler/#oodeel.datasets.torch_data_handler.TorchDataHandler.get_input_from_dataset_item","title":"<code>get_input_from_dataset_item(elem)</code>  <code>staticmethod</code>","text":"<p>Get the tensor that is to be feed as input to a model from a dataset element.</p> <p>Parameters:</p> Name Type Description Default <code>elem</code> <code>ItemType</code> <p>dataset element to extract input from</p> required <p>Returns:</p> Name Type Description <code>Any</code> <code>Any</code> <p>Input tensor</p> Source code in <code>oodeel/datasets/torch_data_handler.py</code> <pre><code>@staticmethod\ndef get_input_from_dataset_item(elem: ItemType) -&gt; Any:\n\"\"\"Get the tensor that is to be feed as input to a model from a dataset element.\n\n    Args:\n        elem (ItemType): dataset element to extract input from\n\n    Returns:\n        Any: Input tensor\n    \"\"\"\n    if isinstance(elem, (tuple, list)):\n        tensor = elem[0]\n    elif isinstance(elem, dict):\n        tensor = elem[list(elem.keys())[0]]\n    else:\n        tensor = elem\n    return tensor\n</code></pre>"},{"location":"api/torch_datahandler/#oodeel.datasets.torch_data_handler.TorchDataHandler.get_item_length","title":"<code>get_item_length(dataset)</code>  <code>staticmethod</code>","text":"<p>Number of elements in a dataset item</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>DictDataset</code> <p>Dataset</p> required <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>Item length</p> Source code in <code>oodeel/datasets/torch_data_handler.py</code> <pre><code>@staticmethod\ndef get_item_length(dataset: Dataset) -&gt; int:\n\"\"\"Number of elements in a dataset item\n\n    Args:\n        dataset (DictDataset): Dataset\n\n    Returns:\n        int: Item length\n    \"\"\"\n    return len(dataset[0])\n</code></pre>"},{"location":"api/torch_datahandler/#oodeel.datasets.torch_data_handler.TorchDataHandler.get_label_from_dataset_item","title":"<code>get_label_from_dataset_item(item)</code>  <code>staticmethod</code>","text":"<p>Retrieve label tensor from item as a tuple/list. Label must be at index 1 in the item tuple. If one-hot encoded, labels are converted to single value.</p> <p>Parameters:</p> Name Type Description Default <code>elem</code> <code>ItemType</code> <p>dataset element to extract label from</p> required <p>Returns:</p> Name Type Description <code>Any</code> <p>Label tensor</p> Source code in <code>oodeel/datasets/torch_data_handler.py</code> <pre><code>@staticmethod\ndef get_label_from_dataset_item(item: ItemType):\n\"\"\"Retrieve label tensor from item as a tuple/list. Label must be at index 1\n    in the item tuple. If one-hot encoded, labels are converted to single value.\n\n    Args:\n        elem (ItemType): dataset element to extract label from\n\n    Returns:\n        Any: Label tensor\n    \"\"\"\n    label = item[1]  # labels must be at index 1 in the batch tuple\n    # If labels are one-hot encoded, take the argmax\n    if len(label.shape) &gt; 1 and label.shape[1] &gt; 1:\n        label = label.view(label.size(0), -1)\n        label = torch.argmax(label, dim=1)\n    # If labels are in two dimensions, squeeze them\n    if len(label.shape) &gt; 1:\n        label = label.view([label.shape[0]])\n    return label\n</code></pre>"},{"location":"api/torch_datahandler/#oodeel.datasets.torch_data_handler.TorchDataHandler.has_feature_key","title":"<code>has_feature_key(dataset, key)</code>  <code>staticmethod</code>","text":"<p>Check if a DictDataset has a feature denoted by key</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>DictDataset</code> <p>Dataset to check</p> required <code>key</code> <code>str</code> <p>Key to check</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>If the dataset has a feature denoted by key</p> Source code in <code>oodeel/datasets/torch_data_handler.py</code> <pre><code>@staticmethod\ndef has_feature_key(dataset: DictDataset, key: str) -&gt; bool:\n\"\"\"Check if a DictDataset has a feature denoted by key\n\n    Args:\n        dataset (DictDataset): Dataset to check\n        key (str): Key to check\n\n    Returns:\n        bool: If the dataset has a feature denoted by key\n    \"\"\"\n    assert isinstance(\n        dataset, DictDataset\n    ), \"Dataset must be an instance of DictDataset\"\n\n    return key in dataset.output_keys\n</code></pre>"},{"location":"api/torch_datahandler/#oodeel.datasets.torch_data_handler.TorchDataHandler.load_custom_dataset","title":"<code>load_custom_dataset(dataset_id, keys=None)</code>  <code>staticmethod</code>","text":"<p>Load a custom Dataset by ensuring it has the correct format (dict-based)</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>Dataset</code> <p>Dataset</p> required <code>keys</code> <code>list</code> <p>Keys to use for features if dataset_id is tuple based. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>DictDataset</code> <p>DictDataset</p> Source code in <code>oodeel/datasets/torch_data_handler.py</code> <pre><code>@staticmethod\ndef load_custom_dataset(\n    dataset_id: Dataset, keys: Optional[list] = None\n) -&gt; DictDataset:\n\"\"\"Load a custom Dataset by ensuring it has the correct format (dict-based)\n\n    Args:\n        dataset_id (Dataset): Dataset\n        keys (list, optional): Keys to use for features if dataset_id is\n            tuple based. Defaults to None.\n\n    Returns:\n        DictDataset\n    \"\"\"\n    # If dataset_id is a tuple based Dataset, convert it to a DictDataset\n    dummy_item = dataset_id[0]\n    if not isinstance(dummy_item, dict):\n        assert isinstance(\n            dummy_item, (Tuple, torch.Tensor)\n        ), \"Custom dataset should be either dictionary based or tuple based\"\n        output_keys = keys\n        if output_keys is None:\n            len_elem = len(dummy_item)\n            if len_elem == 2:\n                output_keys = [\"input\", \"label\"]\n            else:\n                output_keys = [f\"input_{i}\" for i in range(len_elem - 1)] + [\n                    \"label\"\n                ]\n                print(\n                    \"Feature name not found, assigning 'input_i' \"\n                    \"key to the i-th tensor and 'label' key to the last\"\n                )\n        dataset_id = DictDataset(dataset_id, output_keys)\n\n    dataset = dataset_id\n    return dataset\n</code></pre>"},{"location":"api/torch_datahandler/#oodeel.datasets.torch_data_handler.TorchDataHandler.load_dataset","title":"<code>load_dataset(dataset_id, keys=None, load_kwargs={})</code>  <code>classmethod</code>","text":"<p>Load dataset from different manners</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>Union[Dataset, ItemType, str]</code> <p>dataset identification</p> required <code>keys</code> <code>list</code> <p>Features keys. If None, assigned as \"input_i\" for i-th feature. Defaults to None.</p> <code>None</code> <code>load_kwargs</code> <code>dict</code> <p>Additional loading kwargs. Defaults to {}.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>DictDataset</code> <code>DictDataset</code> <p>dataset</p> Source code in <code>oodeel/datasets/torch_data_handler.py</code> <pre><code>@classmethod\ndef load_dataset(\n    cls,\n    dataset_id: Union[Dataset, ItemType, str],\n    keys: Optional[list] = None,\n    load_kwargs: dict = {},\n) -&gt; DictDataset:\n\"\"\"Load dataset from different manners\n\n    Args:\n        dataset_id (Union[Dataset, ItemType, str]): dataset identification\n        keys (list, optional): Features keys. If None, assigned as \"input_i\"\n            for i-th feature. Defaults to None.\n        load_kwargs (dict, optional): Additional loading kwargs. Defaults to {}.\n\n    Returns:\n        DictDataset: dataset\n    \"\"\"\n    if isinstance(dataset_id, str):\n        assert \"root\" in load_kwargs.keys()\n        dataset = cls.load_from_torchvision(dataset_id, **load_kwargs)\n    elif isinstance(dataset_id, Dataset):\n        dataset = cls.load_custom_dataset(dataset_id, keys)\n    elif isinstance(dataset_id, get_args(ItemType)):\n        dataset = cls.load_dataset_from_arrays(dataset_id, keys)\n    return dataset\n</code></pre>"},{"location":"api/torch_datahandler/#oodeel.datasets.torch_data_handler.TorchDataHandler.load_dataset_from_arrays","title":"<code>load_dataset_from_arrays(dataset_id, keys=None)</code>  <code>staticmethod</code>","text":"<p>Load a torch.utils.data.Dataset from an array or a tuple/dict of arrays.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>ItemType</code> <p>numpy / torch array(s) to load.</p> required <code>keys</code> <code>list</code> <p>Features keys. If None, assigned as \"input_i\" for i-th feature. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>DictDataset</code> <code>DictDataset</code> <p>dataset</p> Source code in <code>oodeel/datasets/torch_data_handler.py</code> <pre><code>@staticmethod\ndef load_dataset_from_arrays(\n    dataset_id: ItemType,\n    keys: Optional[list] = None,\n) -&gt; DictDataset:\n\"\"\"Load a torch.utils.data.Dataset from an array or a tuple/dict of arrays.\n\n    Args:\n        dataset_id (ItemType):\n            numpy / torch array(s) to load.\n        keys (list, optional): Features keys. If None, assigned as \"input_i\"\n            for i-th feature. Defaults to None.\n\n    Returns:\n        DictDataset: dataset\n    \"\"\"\n    # If dataset_id is an array\n    if isinstance(dataset_id, get_args(TensorType)):\n        tensors = tuple(to_torch(dataset_id))\n        output_keys = keys or [\"input\"]\n\n    # If dataset_id is a tuple of arrays\n    elif isinstance(dataset_id, tuple):\n        len_elem = len(dataset_id)\n        output_keys = keys\n        if output_keys is None:\n            if len_elem == 2:\n                output_keys = [\"input\", \"label\"]\n            else:\n                output_keys = [f\"input_{i}\" for i in range(len_elem - 1)] + [\n                    \"label\"\n                ]\n                print(\n                    \"Loading torch.utils.data.Dataset with elems as dicts, \"\n                    'assigning \"input_i\" key to the i-th tuple dimension and'\n                    ' \"label\" key to the last tuple dimension.'\n                )\n        assert len(output_keys) == len(dataset_id)\n        tensors = tuple(to_torch(array) for array in dataset_id)\n\n    # If dataset_id is a dictionary of arrays\n    elif isinstance(dataset_id, dict):\n        output_keys = keys or list(dataset_id.keys())\n        assert len(output_keys) == len(dataset_id)\n        tensors = tuple(to_torch(array) for array in dataset_id.values())\n\n    # create torch dictionary dataset from tensors tuple and keys\n    dataset = DictDataset(TensorDataset(*tensors), output_keys)\n    return dataset\n</code></pre>"},{"location":"api/torch_datahandler/#oodeel.datasets.torch_data_handler.TorchDataHandler.load_from_torchvision","title":"<code>load_from_torchvision(dataset_id, root, transform=DEFAULT_TRANSFORM, target_transform=DEFAULT_TARGET_TRANSFORM, download=False, **load_kwargs)</code>  <code>classmethod</code>","text":"<p>Load a Dataset from the torchvision datasets catalog</p> <p>Parameters:</p> Name Type Description Default <code>dataset_id</code> <code>str</code> <p>Identifier of the dataset</p> required <code>root</code> <code>str</code> <p>Root directory of dataset</p> required <code>transform</code> <code>Callable</code> <p>Transform function to apply to the input. Defaults to DEFAULT_TRANSFORM.</p> <code>DEFAULT_TRANSFORM</code> <code>target_transform</code> <code>Callable</code> <p>Transform function to apply to the target. Defaults to DEFAULT_TARGET_TRANSFORM.</p> <code>DEFAULT_TARGET_TRANSFORM</code> <code>download</code> <code>bool</code> <p>If true, downloads the dataset from the internet and puts it in root directory. If dataset is already downloaded, it is not downloaded again. Defaults to False.</p> <code>False</code> <code>load_kwargs</code> <code>dict</code> <p>Loading kwargs to add to the initialization of dataset.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>DictDataset</code> <code>DictDataset</code> <p>dataset</p> Source code in <code>oodeel/datasets/torch_data_handler.py</code> <pre><code>@classmethod\ndef load_from_torchvision(\n    cls,\n    dataset_id: str,\n    root: str,\n    transform: Callable = DEFAULT_TRANSFORM,\n    target_transform: Callable = DEFAULT_TARGET_TRANSFORM,\n    download: bool = False,\n    **load_kwargs,\n) -&gt; DictDataset:\n\"\"\"Load a Dataset from the torchvision datasets catalog\n\n    Args:\n        dataset_id (str): Identifier of the dataset\n        root (str): Root directory of dataset\n        transform (Callable, optional): Transform function to apply to the input.\n            Defaults to DEFAULT_TRANSFORM.\n        target_transform (Callable, optional): Transform function to apply\n            to the target. Defaults to DEFAULT_TARGET_TRANSFORM.\n        download (bool):  If true, downloads the dataset from the internet and puts\n            it in root directory. If dataset is already downloaded, it is not\n            downloaded again. Defaults to False.\n        load_kwargs (dict): Loading kwargs to add to the initialization\n            of dataset.\n\n    Returns:\n        DictDataset: dataset\n    \"\"\"\n    assert (\n        dataset_id in torchvision.datasets.__all__\n    ), \"Dataset not available on torchvision datasets catalog\"\n    dataset = getattr(torchvision.datasets, dataset_id)(\n        root=root,\n        download=download,\n        transform=transform,\n        target_transform=target_transform,\n        **load_kwargs,\n    )\n    return cls.load_custom_dataset(dataset)\n</code></pre>"},{"location":"api/torch_datahandler/#oodeel.datasets.torch_data_handler.TorchDataHandler.map_ds","title":"<code>map_ds(dataset, map_fn)</code>  <code>staticmethod</code>","text":"<p>Map a function to a DictDataset</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>DictDataset</code> <p>Dataset to map the function to</p> required <code>map_fn</code> <code>Callable</code> <p>Function to map</p> required <p>Returns:</p> Name Type Description <code>DictDataset</code> <code>DictDataset</code> <p>Mapped dataset</p> Source code in <code>oodeel/datasets/torch_data_handler.py</code> <pre><code>@staticmethod\ndef map_ds(\n    dataset: DictDataset,\n    map_fn: Callable,\n) -&gt; DictDataset:\n\"\"\"Map a function to a DictDataset\n\n    Args:\n        dataset (DictDataset): Dataset to map the function to\n        map_fn (Callable): Function to map\n\n    Returns:\n        DictDataset: Mapped dataset\n    \"\"\"\n    return dataset.map(map_fn)\n</code></pre>"},{"location":"api/torch_datahandler/#oodeel.datasets.torch_data_handler.TorchDataHandler.merge","title":"<code>merge(id_dataset, ood_dataset, resize=False, shape=None)</code>  <code>staticmethod</code>","text":"<p>Merge two instances of DictDataset</p> <p>Parameters:</p> Name Type Description Default <code>id_dataset</code> <code>DictDataset</code> <p>dataset of in-distribution data</p> required <code>ood_dataset</code> <code>DictDataset</code> <p>dataset of out-of-distribution data</p> required <code>resize</code> <code>Optional[bool]</code> <p>toggles if input tensors of the datasets have to be resized to have the same shape. Defaults to True.</p> <code>False</code> <code>shape</code> <code>Optional[Tuple[int]]</code> <p>shape to use for resizing input tensors. If None, the tensors are resized with the shape of the id_dataset input tensors. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>DictDataset</code> <code>DictDataset</code> <p>merged dataset</p> Source code in <code>oodeel/datasets/torch_data_handler.py</code> <pre><code>@staticmethod\ndef merge(\n    id_dataset: DictDataset,\n    ood_dataset: DictDataset,\n    resize: Optional[bool] = False,\n    shape: Optional[Tuple[int]] = None,\n) -&gt; DictDataset:\n\"\"\"Merge two instances of DictDataset\n\n    Args:\n        id_dataset (DictDataset): dataset of in-distribution data\n        ood_dataset (DictDataset): dataset of out-of-distribution data\n        resize (Optional[bool], optional): toggles if input tensors of the\n            datasets have to be resized to have the same shape. Defaults to True.\n        shape (Optional[Tuple[int]], optional): shape to use for resizing input\n            tensors. If None, the tensors are resized with the shape of the\n            id_dataset input tensors. Defaults to None.\n\n    Returns:\n        DictDataset: merged dataset\n    \"\"\"\n    # If a desired shape is given, triggers the resize\n    if shape is not None:\n        resize = True\n\n    # If the shape of the two datasets are different, triggers the resize\n    if id_dataset.output_shapes[0] != ood_dataset.output_shapes[0]:\n        resize = True\n        if shape is None:\n            print(\n                \"Resizing the first item of elem (usually the image)\",\n                \" with the shape of id_dataset\",\n            )\n            shape = id_dataset.output_shapes[0][1:]\n\n    if resize:\n        resize_fn = torchvision.transforms.Resize(shape)\n\n        def reshape_fn(item_dict):\n            item_dict[\"input\"] = resize_fn(item_dict[\"input\"])\n            return item_dict\n\n        id_dataset = id_dataset.map(reshape_fn)\n        ood_dataset = ood_dataset.map(reshape_fn)\n\n    merged_dataset = id_dataset.concatenate(ood_dataset)\n    return merged_dataset\n</code></pre>"},{"location":"api/torch_datahandler/#oodeel.datasets.torch_data_handler.TorchDataHandler.prepare_for_training","title":"<code>prepare_for_training(dataset, batch_size, shuffle=False, preprocess_fn=None, augment_fn=None, output_keys=None, dict_based_fns=False, shuffle_buffer_size=None, num_workers=8)</code>  <code>classmethod</code>","text":"<p>Prepare a DataLoader for training</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>DictDataset</code> <p>Dataset to prepare</p> required <code>batch_size</code> <code>int</code> <p>Batch size</p> required <code>shuffle</code> <code>bool</code> <p>Wether to shuffle the dataloader or not</p> <code>False</code> <code>preprocess_fn</code> <code>Callable</code> <p>Preprocessing function to apply to the dataset. Defaults to None.</p> <code>None</code> <code>augment_fn</code> <code>Callable</code> <p>Augment function to be used (when the returned dataset is to be used for training). Defaults to None.</p> <code>None</code> <code>output_keys</code> <code>list</code> <p>List of keys corresponding to the features that will be returned. Keep all features if None. Defaults to None.</p> <code>None</code> <code>dict_based_fns</code> <code>bool</code> <p>Whether to use preprocess and DA functions as dict based (if True) or as tuple based (if False). Defaults to False.</p> <code>False</code> <code>shuffle_buffer_size</code> <code>int</code> <p>Size of the shuffle buffer. Not used in torch because we only rely on Map-Style datasets. Still as argument for API consistency. Defaults to None.</p> <code>None</code> <code>num_workers</code> <code>int</code> <p>Number of workers to use for the dataloader.</p> <code>8</code> <p>Returns:</p> Name Type Description <code>DataLoader</code> <code>DataLoader</code> <p>dataloader</p> Source code in <code>oodeel/datasets/torch_data_handler.py</code> <pre><code>@classmethod\ndef prepare_for_training(\n    cls,\n    dataset: DictDataset,\n    batch_size: int,\n    shuffle: bool = False,\n    preprocess_fn: Optional[Callable] = None,\n    augment_fn: Optional[Callable] = None,\n    output_keys: Optional[list] = None,\n    dict_based_fns: bool = False,\n    shuffle_buffer_size: Optional[int] = None,\n    num_workers: int = 8,\n) -&gt; DataLoader:\n\"\"\"Prepare a DataLoader for training\n\n    Args:\n        dataset (DictDataset): Dataset to prepare\n        batch_size (int): Batch size\n        shuffle (bool): Wether to shuffle the dataloader or not\n        preprocess_fn (Callable, optional): Preprocessing function to apply to\n            the dataset. Defaults to None.\n        augment_fn (Callable, optional): Augment function to be used (when the\n            returned dataset is to be used for training). Defaults to None.\n        output_keys (list): List of keys corresponding to the features that will be\n            returned. Keep all features if None. Defaults to None.\n        dict_based_fns (bool): Whether to use preprocess and DA functions as dict\n            based (if True) or as tuple based (if False). Defaults to False.\n        shuffle_buffer_size (int, optional): Size of the shuffle buffer. Not used\n            in torch because we only rely on Map-Style datasets. Still as argument\n            for API consistency. Defaults to None.\n        num_workers (int, optional): Number of workers to use for the dataloader.\n\n    Returns:\n        DataLoader: dataloader\n    \"\"\"\n    output_keys = output_keys or cls.get_ds_feature_keys(dataset)\n\n    def collate_fn(batch: List[dict]):\n        if dict_based_fns:\n            # preprocess + DA: List[dict] -&gt; List[dict]\n            preprocess_func = preprocess_fn or (lambda x: x)\n            augment_func = augment_fn or (lambda x: x)\n            batch = [augment_func(preprocess_func(d)) for d in batch]\n            # to tuple of batchs\n            return tuple(\n                default_collate([d[key] for d in batch]) for key in output_keys\n            )\n        else:\n            # preprocess + DA: List[dict] -&gt; List[tuple]\n            preprocess_func = preprocess_fn or (lambda *x: x)\n            augment_func = augment_fn or (lambda *x: x)\n            batch = [\n                augment_func(\n                    *preprocess_func(*tuple(d[key] for key in output_keys))\n                )\n                for d in batch\n            ]\n            # to tuple of batchs\n            return default_collate(batch)\n\n    loader = DataLoader(\n        dataset,\n        batch_size=batch_size,\n        shuffle=shuffle,\n        collate_fn=collate_fn,\n        num_workers=num_workers,\n    )\n    return loader\n</code></pre>"},{"location":"api/torch_datahandler/#oodeel.datasets.torch_data_handler.dict_only_ds","title":"<code>dict_only_ds(ds_handling_method)</code>","text":"<p>Decorator to ensure that the dataset is a dict dataset and that the input key matches one of the feature keys. The signature of decorated functions must be function(dataset, args, *kwargs) with feature_key either in kwargs or args[0] when relevant.</p> <p>Parameters:</p> Name Type Description Default <code>ds_handling_method</code> <code>Callable</code> <p>method to decorate</p> required <p>Returns:</p> Type Description <code>Callable</code> <p>decorated method</p> Source code in <code>oodeel/datasets/torch_data_handler.py</code> <pre><code>def dict_only_ds(ds_handling_method: Callable) -&gt; Callable:\n\"\"\"Decorator to ensure that the dataset is a dict dataset and that the input key\n    matches one of the feature keys. The signature of decorated functions\n    must be function(dataset, *args, **kwargs) with feature_key either in kwargs or\n    args[0] when relevant.\n\n\n    Args:\n        ds_handling_method: method to decorate\n\n    Returns:\n        decorated method\n    \"\"\"\n\n    def wrapper(dataset: Dataset, *args, **kwargs):\n        assert isinstance(\n            dataset, DictDataset\n        ), \"Dataset must be an instance of DictDataset\"\n\n        if \"feature_key\" in kwargs:\n            feature_key = kwargs[\"feature_key\"]\n        elif len(args) &gt; 0:\n            feature_key = args[0]\n\n        # If feature_key is provided, check that it is in the dataset feature keys\n        if (len(args) &gt; 0) or (\"feature_key\" in kwargs):\n            if isinstance(feature_key, str):\n                feature_key = [feature_key]\n            for key in feature_key:\n                assert (\n                    key in dataset.output_keys\n                ), f\"The input dataset has no feature names {key}\"\n        return ds_handling_method(dataset, *args, **kwargs)\n\n    return wrapper\n</code></pre>"},{"location":"api/torch_datahandler/#oodeel.datasets.torch_data_handler.to_torch","title":"<code>to_torch(array)</code>","text":"<p>Convert an array into a torch Tensor</p> <p>Parameters:</p> Name Type Description Default <code>array</code> <code>TensorType</code> <p>array to convert</p> required <p>Returns:</p> Type Description <code>torch.Tensor</code> <p>torch.Tensor: converted array</p> Source code in <code>oodeel/datasets/torch_data_handler.py</code> <pre><code>def to_torch(array: TensorType) -&gt; torch.Tensor:\n\"\"\"Convert an array into a torch Tensor\n\n    Args:\n        array (TensorType): array to convert\n\n    Returns:\n        torch.Tensor: converted array\n    \"\"\"\n    if isinstance(array, np.ndarray):\n        return torch.Tensor(array)\n    elif isinstance(array, torch.Tensor):\n        return array\n    else:\n        raise TypeError(\"Input array must be of numpy or torch type\")\n</code></pre>"},{"location":"api/torch_feature_extractor/","title":"TorchFeatureExtractor","text":""},{"location":"api/torch_feature_extractor/#oodeel.extractor.torch_feature_extractor.TorchFeatureExtractor","title":"<code>TorchFeatureExtractor</code>","text":"<p>         Bases: <code>FeatureExtractor</code></p> <p>Feature extractor based on \"model\" to construct a feature space on which OOD detection is performed. The features can be the output activation values of internal model layers, or the output of the model (softmax/logits).</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>nn.Module</code> <p>model to extract the features from</p> required <code>feature_layers_id</code> <code>List[Union[int, str]]</code> <p>list of str or int that identify features to output. If int, the rank of the layer in the layer list If str, the name of the layer. Defaults to [].</p> <code>[]</code> <code>input_layer_id</code> <code>Optional[Union[int, str]]</code> <p>input layer of the feature extractor (to avoid useless forwards when working on the feature space without finetuning the bottom of the model). Defaults to None.</p> <code>None</code> <code>react_threshold</code> <code>Optional[float]</code> <p>if not None, penultimate layer activations are clipped under this threshold value (useful for ReAct). Defaults to None.</p> <code>None</code> <code>scale_percentile</code> <code>Optional[float]</code> <p>if not None, the features are scaled following the method of Xu et al., ICLR 2024. Defaults to None.</p> <code>None</code> <code>ash_percentile</code> <code>Optional[float]</code> <p>if not None, the features are scaled following the method of Djurisic et al., ICLR 2023.</p> <code>None</code> Source code in <code>oodeel/extractor/torch_feature_extractor.py</code> <pre><code>class TorchFeatureExtractor(FeatureExtractor):\n\"\"\"\n    Feature extractor based on \"model\" to construct a feature space\n    on which OOD detection is performed. The features can be the output\n    activation values of internal model layers,\n    or the output of the model (softmax/logits).\n\n    Args:\n        model: model to extract the features from\n        feature_layers_id: list of str or int that identify features to output.\n            If int, the rank of the layer in the layer list\n            If str, the name of the layer. Defaults to [].\n        input_layer_id: input layer of the feature extractor (to avoid useless forwards\n            when working on the feature space without finetuning the bottom of\n            the model).\n            Defaults to None.\n        react_threshold: if not None, penultimate layer activations are clipped under\n            this threshold value (useful for ReAct). Defaults to None.\n        scale_percentile: if not None, the features are scaled\n            following the method of Xu et al., ICLR 2024.\n            Defaults to None.\n        ash_percentile: if not None, the features are scaled following\n            the method of Djurisic et al., ICLR 2023.\n\n    \"\"\"\n\n    def __init__(\n        self,\n        model: nn.Module,\n        feature_layers_id: List[Union[int, str]] = [],\n        input_layer_id: Optional[Union[int, str]] = None,\n        react_threshold: Optional[float] = None,\n        scale_percentile: Optional[float] = None,\n        ash_percentile: Optional[float] = None,\n    ):\n        model = model.eval()\n        super().__init__(\n            model=model,\n            feature_layers_id=feature_layers_id,\n            input_layer_id=input_layer_id,\n            react_threshold=react_threshold,\n            scale_percentile=scale_percentile,\n            ash_percentile=ash_percentile,\n        )\n        self._device = next(model.parameters()).device\n        self._features = {layer: torch.empty(0) for layer in self._hook_layers_id}\n        self._last_logits = None\n        self.backend = \"torch\"\n\n    @property\n    def _hook_layers_id(self):\n        return self.feature_layers_id + [-1]\n\n    def _get_features_hook(self, layer_id: Union[str, int]) -&gt; Callable:\n\"\"\"\n        Hook that stores features corresponding to a specific layer\n        in a class dictionary.\n\n        Args:\n            layer_id (Union[str, int]): layer identifier\n\n        Returns:\n            Callable: hook function\n        \"\"\"\n\n        def hook(_, __, output):\n            if isinstance(output, torch.Tensor):\n                self._features[layer_id] = output\n            else:\n                raise NotImplementedError\n\n        return hook\n\n    @staticmethod\n    def find_layer(\n        model: nn.Module,\n        layer_id: Union[str, int],\n        index_offset: int = 0,\n        return_id: bool = False,\n    ) -&gt; Union[nn.Module, Tuple[nn.Module, str]]:\n\"\"\"Find a layer in a model either by his name or by his index.\n\n        Args:\n            model (nn.Module): model whose identified layer will be returned\n            layer_id (Union[str, int]): layer identifier\n            index_offset (int): index offset to find layers located before (negative\n                offset) or after (positive offset) the identified layer\n            return_id (bool): if True, the layer will be returned with its id\n\n        Returns:\n            Union[nn.Module, Tuple[nn.Module, str]]: the corresponding layer and its id\n                if return_id is True.\n        \"\"\"\n        if isinstance(layer_id, int):\n            layer_id += index_offset\n            if isinstance(model, nn.Sequential):\n                layer = model[layer_id]\n            else:\n                layer = list(model.named_modules())[layer_id][1]\n        else:\n            layer_id = list(dict(model.named_modules()).keys()).index(layer_id)\n            layer_id += index_offset\n            layer = list(model.named_modules())[layer_id][1]\n\n        if return_id:\n            return layer, layer_id\n        else:\n            return layer\n\n    def prepare_extractor(self) -&gt; None:\n\"\"\"Prepare the feature extractor by adding hooks to self.model\"\"\"\n        # remove forward hooks attached to the model\n        self._clean_forward_hooks()\n\n        # === If react method, clip activations from penultimate layer ===\n        if self.react_threshold is not None:\n            pen_layer = self.find_layer(self.model, -2)\n            pen_layer.register_forward_hook(self._get_clip_hook(self.react_threshold))\n\n        # === If SCALE method, scale activations from penultimate layer ===\n        if self.scale_percentile is not None:\n            pen_layer = self.find_layer(self.model, -2)\n            pen_layer.register_forward_hook(self._get_scale_hook(self.scale_percentile))\n\n        # === If ASH method, scale and prune activations from penultimate layer ===\n        if self.ash_percentile is not None:\n            pen_layer = self.find_layer(self.model, -2)\n            pen_layer.register_forward_hook(self._get_ash_hook(self.ash_percentile))\n\n        # Register a hook to store feature values for each considered layer + last layer\n        for layer_id in self._hook_layers_id:\n            layer = self.find_layer(self.model, layer_id)\n            layer.register_forward_hook(self._get_features_hook(layer_id))\n\n        # Crop model if input layer is provided\n        if not (self.input_layer_id) is None:\n            if isinstance(self.input_layer_id, int):\n                if isinstance(self.model, nn.Sequential):\n                    self.model = nn.Sequential(\n                        *list(self.model.modules())[self.input_layer_id :]\n                    )\n                else:\n                    raise NotImplementedError\n            elif isinstance(self.input_layer_id, str):\n                if isinstance(self.model, nn.Sequential):\n                    module_names = list(\n                        filter(\n                            lambda x: x != \"\",\n                            map(lambda x: x[0], self.model.named_modules()),\n                        )\n                    )\n                    input_module_idx = module_names.index(self.input_layer_id)\n                    self.model = nn.Sequential(\n                        *list(self.model.modules())[(input_module_idx + 1) :]\n                    )\n                else:\n                    raise NotImplementedError\n            else:\n                raise NotImplementedError\n\n    @sanitize_input\n    def predict_tensor(\n        self,\n        x: TensorType,\n        postproc_fns: Optional[List[Callable]] = None,\n        detach: bool = True,\n    ) -&gt; Tuple[List[torch.Tensor], torch.Tensor]:\n\"\"\"Get the projection of tensor in the feature space of self.model\n\n        Args:\n            x (TensorType): input tensor (or dataset elem)\n            postproc_fns (Optional[List[Callable]]): postprocessing function to apply to\n                each feature immediately after forward. Default to None.\n            detach (bool): if True, return features detached from the computational\n                graph. Defaults to True.\n\n        Returns:\n            List[torch.Tensor], torch.Tensor: features, logits\n        \"\"\"\n        if x.device != self._device:\n            x = x.to(self._device)\n        _ = self.model(x)\n\n        if detach:\n            features = [\n                self._features[layer_id].detach() for layer_id in self._hook_layers_id\n            ]\n        else:\n            features = [self._features[layer_id] for layer_id in self._hook_layers_id]\n\n        # split features and logits\n        logits = features.pop()\n\n        if postproc_fns is not None:\n            features = [\n                postproc_fn(feature)\n                for feature, postproc_fn in zip(features, postproc_fns)\n            ]\n\n        self._last_logits = logits\n        return features, logits\n\n    def predict(\n        self,\n        dataset: Union[DataLoader, ItemType],\n        postproc_fns: Optional[List[Callable]] = None,\n        detach: bool = True,\n        verbose: bool = False,\n        **kwargs,\n    ) -&gt; Tuple[List[torch.Tensor], dict]:\n\"\"\"Get the projection of the dataset in the feature space of self.model\n\n        Args:\n            dataset (Union[DataLoader, ItemType]): input dataset\n            postproc_fns (Optional[List[Callable]]): postprocessing function to apply to\n                each feature immediately after forward. Default to None.\n            detach (bool): if True, return features detached from the computational\n                graph. Defaults to True.\n            verbose (bool): if True, display a progress bar. Defaults to False.\n            kwargs (dict): additional arguments not considered for prediction\n\n        Returns:\n            List[torch.Tensor], dict: features and extra information (logits, labels) as\n                a dictionary.\n        \"\"\"\n        labels = None\n\n        if isinstance(dataset, get_args(ItemType)):\n            tensor = TorchDataHandler.get_input_from_dataset_item(dataset)\n            features, logits = self.predict_tensor(tensor, postproc_fns, detach=detach)\n\n            # Get labels if dataset is a tuple/list\n            if isinstance(dataset, (list, tuple)) and len(dataset) &gt; 1:\n                labels = TorchDataHandler.get_label_from_dataset_item(dataset)\n\n        else:\n            features = [None for i in range(len(self.feature_layers_id))]\n            logits = None\n            batch = next(iter(dataset))\n            contains_labels = isinstance(batch, (list, tuple)) and len(batch) &gt; 1\n            for elem in tqdm(dataset, desc=\"Predicting\", disable=not verbose):\n                tensor = TorchDataHandler.get_input_from_dataset_item(elem)\n                features_batch, logits_batch = self.predict_tensor(\n                    tensor, postproc_fns, detach=detach\n                )\n                for i, f in enumerate(features_batch):\n                    features[i] = (\n                        f if features[i] is None else torch.cat([features[i], f], dim=0)\n                    )\n                # concatenate logits\n                logits = (\n                    logits_batch\n                    if logits is None\n                    else torch.cat([logits, logits_batch], axis=0)\n                )\n                # concatenate labels of current batch with previous batches\n                if contains_labels:\n                    lbl_batch = TorchDataHandler.get_label_from_dataset_item(elem)\n\n                    if labels is None:\n                        labels = lbl_batch\n                    else:\n                        labels = torch.cat([labels, lbl_batch], dim=0)\n\n        # store extra information in a dict\n        info = dict(labels=labels, logits=logits)\n        return features, info\n\n    def get_weights(self, layer_id: Union[str, int]) -&gt; List[torch.Tensor]:\n\"\"\"Get the weights of a layer\n\n        Args:\n            layer_id (Union[int, str]): layer identifier\n\n        Returns:\n            List[torch.Tensor]: weights and biases matrixes\n        \"\"\"\n        layer = self.find_layer(self.model, layer_id)\n        return [layer.weight.detach().cpu().numpy(), layer.bias.detach().cpu().numpy()]\n\n    def _get_clip_hook(self, threshold: float) -&gt; Callable:\n\"\"\"\n        Hook that truncate activation features under a threshold value\n\n        Args:\n            threshold (float): threshold value\n\n        Returns:\n            Callable: hook function\n        \"\"\"\n\n        def hook(_, __, output):\n            output = torch.clip(output, max=threshold)\n            return output\n\n        return hook\n\n    def _get_scale_hook(self, percentile: float) -&gt; Callable:\n\"\"\"\n        Hook that scales activation features.\n\n        Args:\n            threshold (float): threshold value\n\n        Returns:\n            Callable: hook function\n        \"\"\"\n\n        def hook(_, __, output):\n            output_percentile = torch.quantile(output, percentile, dim=1)\n            mask = output &gt; output_percentile[:, None]\n            output_masked = output * mask\n            s = torch.exp(torch.sum(output, dim=1) / torch.sum(output_masked, dim=1))\n            s = torch.unsqueeze(s, 1)\n            output = output * s\n            return output\n\n        return hook\n\n    def _get_ash_hook(self, percentile: float) -&gt; Callable:\n\"\"\"\n        Hook that scales and prunes activation features under a threshold value\n\n        Args:\n            threshold (float): threshold value\n\n        Returns:\n            Callable: hook function\n        \"\"\"\n\n        def hook(_, __, output):\n            output_percentile = torch.quantile(output, percentile, dim=1)\n            mask = output &gt; output_percentile[:, None]\n            output_masked = output * mask\n            s = torch.exp(torch.sum(output, dim=1) / torch.sum(output_masked, dim=1))\n            s = torch.unsqueeze(s, 1)\n            output = output_masked * s\n            return output\n\n        return hook\n\n    def _clean_forward_hooks(self) -&gt; None:\n\"\"\"\n        Remove all the forward hook attached to the model's layers. This function should\n        be called at the __init__, and prevent from accumulating the hooks when\n        defining a new TorchFeatureExtractor for the same model.\n        \"\"\"\n\n        def __clean_hooks(m: nn.Module):\n            for _, child in m._modules.items():\n                if child is not None:\n                    if hasattr(child, \"_forward_hooks\"):\n                        child._forward_hooks = OrderedDict()\n                    __clean_hooks(child)\n\n        return __clean_hooks(self.model)\n</code></pre>"},{"location":"api/torch_feature_extractor/#oodeel.extractor.torch_feature_extractor.TorchFeatureExtractor._clean_forward_hooks","title":"<code>_clean_forward_hooks()</code>","text":"<p>Remove all the forward hook attached to the model's layers. This function should be called at the init, and prevent from accumulating the hooks when defining a new TorchFeatureExtractor for the same model.</p> Source code in <code>oodeel/extractor/torch_feature_extractor.py</code> <pre><code>def _clean_forward_hooks(self) -&gt; None:\n\"\"\"\n    Remove all the forward hook attached to the model's layers. This function should\n    be called at the __init__, and prevent from accumulating the hooks when\n    defining a new TorchFeatureExtractor for the same model.\n    \"\"\"\n\n    def __clean_hooks(m: nn.Module):\n        for _, child in m._modules.items():\n            if child is not None:\n                if hasattr(child, \"_forward_hooks\"):\n                    child._forward_hooks = OrderedDict()\n                __clean_hooks(child)\n\n    return __clean_hooks(self.model)\n</code></pre>"},{"location":"api/torch_feature_extractor/#oodeel.extractor.torch_feature_extractor.TorchFeatureExtractor._get_ash_hook","title":"<code>_get_ash_hook(percentile)</code>","text":"<p>Hook that scales and prunes activation features under a threshold value</p> <p>Parameters:</p> Name Type Description Default <code>threshold</code> <code>float</code> <p>threshold value</p> required <p>Returns:</p> Name Type Description <code>Callable</code> <code>Callable</code> <p>hook function</p> Source code in <code>oodeel/extractor/torch_feature_extractor.py</code> <pre><code>def _get_ash_hook(self, percentile: float) -&gt; Callable:\n\"\"\"\n    Hook that scales and prunes activation features under a threshold value\n\n    Args:\n        threshold (float): threshold value\n\n    Returns:\n        Callable: hook function\n    \"\"\"\n\n    def hook(_, __, output):\n        output_percentile = torch.quantile(output, percentile, dim=1)\n        mask = output &gt; output_percentile[:, None]\n        output_masked = output * mask\n        s = torch.exp(torch.sum(output, dim=1) / torch.sum(output_masked, dim=1))\n        s = torch.unsqueeze(s, 1)\n        output = output_masked * s\n        return output\n\n    return hook\n</code></pre>"},{"location":"api/torch_feature_extractor/#oodeel.extractor.torch_feature_extractor.TorchFeatureExtractor._get_clip_hook","title":"<code>_get_clip_hook(threshold)</code>","text":"<p>Hook that truncate activation features under a threshold value</p> <p>Parameters:</p> Name Type Description Default <code>threshold</code> <code>float</code> <p>threshold value</p> required <p>Returns:</p> Name Type Description <code>Callable</code> <code>Callable</code> <p>hook function</p> Source code in <code>oodeel/extractor/torch_feature_extractor.py</code> <pre><code>def _get_clip_hook(self, threshold: float) -&gt; Callable:\n\"\"\"\n    Hook that truncate activation features under a threshold value\n\n    Args:\n        threshold (float): threshold value\n\n    Returns:\n        Callable: hook function\n    \"\"\"\n\n    def hook(_, __, output):\n        output = torch.clip(output, max=threshold)\n        return output\n\n    return hook\n</code></pre>"},{"location":"api/torch_feature_extractor/#oodeel.extractor.torch_feature_extractor.TorchFeatureExtractor._get_features_hook","title":"<code>_get_features_hook(layer_id)</code>","text":"<p>Hook that stores features corresponding to a specific layer in a class dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>layer_id</code> <code>Union[str, int]</code> <p>layer identifier</p> required <p>Returns:</p> Name Type Description <code>Callable</code> <code>Callable</code> <p>hook function</p> Source code in <code>oodeel/extractor/torch_feature_extractor.py</code> <pre><code>def _get_features_hook(self, layer_id: Union[str, int]) -&gt; Callable:\n\"\"\"\n    Hook that stores features corresponding to a specific layer\n    in a class dictionary.\n\n    Args:\n        layer_id (Union[str, int]): layer identifier\n\n    Returns:\n        Callable: hook function\n    \"\"\"\n\n    def hook(_, __, output):\n        if isinstance(output, torch.Tensor):\n            self._features[layer_id] = output\n        else:\n            raise NotImplementedError\n\n    return hook\n</code></pre>"},{"location":"api/torch_feature_extractor/#oodeel.extractor.torch_feature_extractor.TorchFeatureExtractor._get_scale_hook","title":"<code>_get_scale_hook(percentile)</code>","text":"<p>Hook that scales activation features.</p> <p>Parameters:</p> Name Type Description Default <code>threshold</code> <code>float</code> <p>threshold value</p> required <p>Returns:</p> Name Type Description <code>Callable</code> <code>Callable</code> <p>hook function</p> Source code in <code>oodeel/extractor/torch_feature_extractor.py</code> <pre><code>def _get_scale_hook(self, percentile: float) -&gt; Callable:\n\"\"\"\n    Hook that scales activation features.\n\n    Args:\n        threshold (float): threshold value\n\n    Returns:\n        Callable: hook function\n    \"\"\"\n\n    def hook(_, __, output):\n        output_percentile = torch.quantile(output, percentile, dim=1)\n        mask = output &gt; output_percentile[:, None]\n        output_masked = output * mask\n        s = torch.exp(torch.sum(output, dim=1) / torch.sum(output_masked, dim=1))\n        s = torch.unsqueeze(s, 1)\n        output = output * s\n        return output\n\n    return hook\n</code></pre>"},{"location":"api/torch_feature_extractor/#oodeel.extractor.torch_feature_extractor.TorchFeatureExtractor.find_layer","title":"<code>find_layer(model, layer_id, index_offset=0, return_id=False)</code>  <code>staticmethod</code>","text":"<p>Find a layer in a model either by his name or by his index.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>nn.Module</code> <p>model whose identified layer will be returned</p> required <code>layer_id</code> <code>Union[str, int]</code> <p>layer identifier</p> required <code>index_offset</code> <code>int</code> <p>index offset to find layers located before (negative offset) or after (positive offset) the identified layer</p> <code>0</code> <code>return_id</code> <code>bool</code> <p>if True, the layer will be returned with its id</p> <code>False</code> <p>Returns:</p> Type Description <code>Union[nn.Module, Tuple[nn.Module, str]]</code> <p>Union[nn.Module, Tuple[nn.Module, str]]: the corresponding layer and its id if return_id is True.</p> Source code in <code>oodeel/extractor/torch_feature_extractor.py</code> <pre><code>@staticmethod\ndef find_layer(\n    model: nn.Module,\n    layer_id: Union[str, int],\n    index_offset: int = 0,\n    return_id: bool = False,\n) -&gt; Union[nn.Module, Tuple[nn.Module, str]]:\n\"\"\"Find a layer in a model either by his name or by his index.\n\n    Args:\n        model (nn.Module): model whose identified layer will be returned\n        layer_id (Union[str, int]): layer identifier\n        index_offset (int): index offset to find layers located before (negative\n            offset) or after (positive offset) the identified layer\n        return_id (bool): if True, the layer will be returned with its id\n\n    Returns:\n        Union[nn.Module, Tuple[nn.Module, str]]: the corresponding layer and its id\n            if return_id is True.\n    \"\"\"\n    if isinstance(layer_id, int):\n        layer_id += index_offset\n        if isinstance(model, nn.Sequential):\n            layer = model[layer_id]\n        else:\n            layer = list(model.named_modules())[layer_id][1]\n    else:\n        layer_id = list(dict(model.named_modules()).keys()).index(layer_id)\n        layer_id += index_offset\n        layer = list(model.named_modules())[layer_id][1]\n\n    if return_id:\n        return layer, layer_id\n    else:\n        return layer\n</code></pre>"},{"location":"api/torch_feature_extractor/#oodeel.extractor.torch_feature_extractor.TorchFeatureExtractor.get_weights","title":"<code>get_weights(layer_id)</code>","text":"<p>Get the weights of a layer</p> <p>Parameters:</p> Name Type Description Default <code>layer_id</code> <code>Union[int, str]</code> <p>layer identifier</p> required <p>Returns:</p> Type Description <code>List[torch.Tensor]</code> <p>List[torch.Tensor]: weights and biases matrixes</p> Source code in <code>oodeel/extractor/torch_feature_extractor.py</code> <pre><code>def get_weights(self, layer_id: Union[str, int]) -&gt; List[torch.Tensor]:\n\"\"\"Get the weights of a layer\n\n    Args:\n        layer_id (Union[int, str]): layer identifier\n\n    Returns:\n        List[torch.Tensor]: weights and biases matrixes\n    \"\"\"\n    layer = self.find_layer(self.model, layer_id)\n    return [layer.weight.detach().cpu().numpy(), layer.bias.detach().cpu().numpy()]\n</code></pre>"},{"location":"api/torch_feature_extractor/#oodeel.extractor.torch_feature_extractor.TorchFeatureExtractor.predict","title":"<code>predict(dataset, postproc_fns=None, detach=True, verbose=False, **kwargs)</code>","text":"<p>Get the projection of the dataset in the feature space of self.model</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>Union[DataLoader, ItemType]</code> <p>input dataset</p> required <code>postproc_fns</code> <code>Optional[List[Callable]]</code> <p>postprocessing function to apply to each feature immediately after forward. Default to None.</p> <code>None</code> <code>detach</code> <code>bool</code> <p>if True, return features detached from the computational graph. Defaults to True.</p> <code>True</code> <code>verbose</code> <code>bool</code> <p>if True, display a progress bar. Defaults to False.</p> <code>False</code> <code>kwargs</code> <code>dict</code> <p>additional arguments not considered for prediction</p> <code>{}</code> <p>Returns:</p> Type Description <code>Tuple[List[torch.Tensor], dict]</code> <p>List[torch.Tensor], dict: features and extra information (logits, labels) as a dictionary.</p> Source code in <code>oodeel/extractor/torch_feature_extractor.py</code> <pre><code>def predict(\n    self,\n    dataset: Union[DataLoader, ItemType],\n    postproc_fns: Optional[List[Callable]] = None,\n    detach: bool = True,\n    verbose: bool = False,\n    **kwargs,\n) -&gt; Tuple[List[torch.Tensor], dict]:\n\"\"\"Get the projection of the dataset in the feature space of self.model\n\n    Args:\n        dataset (Union[DataLoader, ItemType]): input dataset\n        postproc_fns (Optional[List[Callable]]): postprocessing function to apply to\n            each feature immediately after forward. Default to None.\n        detach (bool): if True, return features detached from the computational\n            graph. Defaults to True.\n        verbose (bool): if True, display a progress bar. Defaults to False.\n        kwargs (dict): additional arguments not considered for prediction\n\n    Returns:\n        List[torch.Tensor], dict: features and extra information (logits, labels) as\n            a dictionary.\n    \"\"\"\n    labels = None\n\n    if isinstance(dataset, get_args(ItemType)):\n        tensor = TorchDataHandler.get_input_from_dataset_item(dataset)\n        features, logits = self.predict_tensor(tensor, postproc_fns, detach=detach)\n\n        # Get labels if dataset is a tuple/list\n        if isinstance(dataset, (list, tuple)) and len(dataset) &gt; 1:\n            labels = TorchDataHandler.get_label_from_dataset_item(dataset)\n\n    else:\n        features = [None for i in range(len(self.feature_layers_id))]\n        logits = None\n        batch = next(iter(dataset))\n        contains_labels = isinstance(batch, (list, tuple)) and len(batch) &gt; 1\n        for elem in tqdm(dataset, desc=\"Predicting\", disable=not verbose):\n            tensor = TorchDataHandler.get_input_from_dataset_item(elem)\n            features_batch, logits_batch = self.predict_tensor(\n                tensor, postproc_fns, detach=detach\n            )\n            for i, f in enumerate(features_batch):\n                features[i] = (\n                    f if features[i] is None else torch.cat([features[i], f], dim=0)\n                )\n            # concatenate logits\n            logits = (\n                logits_batch\n                if logits is None\n                else torch.cat([logits, logits_batch], axis=0)\n            )\n            # concatenate labels of current batch with previous batches\n            if contains_labels:\n                lbl_batch = TorchDataHandler.get_label_from_dataset_item(elem)\n\n                if labels is None:\n                    labels = lbl_batch\n                else:\n                    labels = torch.cat([labels, lbl_batch], dim=0)\n\n    # store extra information in a dict\n    info = dict(labels=labels, logits=logits)\n    return features, info\n</code></pre>"},{"location":"api/torch_feature_extractor/#oodeel.extractor.torch_feature_extractor.TorchFeatureExtractor.predict_tensor","title":"<code>predict_tensor(x, postproc_fns=None, detach=True)</code>","text":"<p>Get the projection of tensor in the feature space of self.model</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>TensorType</code> <p>input tensor (or dataset elem)</p> required <code>postproc_fns</code> <code>Optional[List[Callable]]</code> <p>postprocessing function to apply to each feature immediately after forward. Default to None.</p> <code>None</code> <code>detach</code> <code>bool</code> <p>if True, return features detached from the computational graph. Defaults to True.</p> <code>True</code> <p>Returns:</p> Type Description <code>Tuple[List[torch.Tensor], torch.Tensor]</code> <p>List[torch.Tensor], torch.Tensor: features, logits</p> Source code in <code>oodeel/extractor/torch_feature_extractor.py</code> <pre><code>@sanitize_input\ndef predict_tensor(\n    self,\n    x: TensorType,\n    postproc_fns: Optional[List[Callable]] = None,\n    detach: bool = True,\n) -&gt; Tuple[List[torch.Tensor], torch.Tensor]:\n\"\"\"Get the projection of tensor in the feature space of self.model\n\n    Args:\n        x (TensorType): input tensor (or dataset elem)\n        postproc_fns (Optional[List[Callable]]): postprocessing function to apply to\n            each feature immediately after forward. Default to None.\n        detach (bool): if True, return features detached from the computational\n            graph. Defaults to True.\n\n    Returns:\n        List[torch.Tensor], torch.Tensor: features, logits\n    \"\"\"\n    if x.device != self._device:\n        x = x.to(self._device)\n    _ = self.model(x)\n\n    if detach:\n        features = [\n            self._features[layer_id].detach() for layer_id in self._hook_layers_id\n        ]\n    else:\n        features = [self._features[layer_id] for layer_id in self._hook_layers_id]\n\n    # split features and logits\n    logits = features.pop()\n\n    if postproc_fns is not None:\n        features = [\n            postproc_fn(feature)\n            for feature, postproc_fn in zip(features, postproc_fns)\n        ]\n\n    self._last_logits = logits\n    return features, logits\n</code></pre>"},{"location":"api/torch_feature_extractor/#oodeel.extractor.torch_feature_extractor.TorchFeatureExtractor.prepare_extractor","title":"<code>prepare_extractor()</code>","text":"<p>Prepare the feature extractor by adding hooks to self.model</p> Source code in <code>oodeel/extractor/torch_feature_extractor.py</code> <pre><code>def prepare_extractor(self) -&gt; None:\n\"\"\"Prepare the feature extractor by adding hooks to self.model\"\"\"\n    # remove forward hooks attached to the model\n    self._clean_forward_hooks()\n\n    # === If react method, clip activations from penultimate layer ===\n    if self.react_threshold is not None:\n        pen_layer = self.find_layer(self.model, -2)\n        pen_layer.register_forward_hook(self._get_clip_hook(self.react_threshold))\n\n    # === If SCALE method, scale activations from penultimate layer ===\n    if self.scale_percentile is not None:\n        pen_layer = self.find_layer(self.model, -2)\n        pen_layer.register_forward_hook(self._get_scale_hook(self.scale_percentile))\n\n    # === If ASH method, scale and prune activations from penultimate layer ===\n    if self.ash_percentile is not None:\n        pen_layer = self.find_layer(self.model, -2)\n        pen_layer.register_forward_hook(self._get_ash_hook(self.ash_percentile))\n\n    # Register a hook to store feature values for each considered layer + last layer\n    for layer_id in self._hook_layers_id:\n        layer = self.find_layer(self.model, layer_id)\n        layer.register_forward_hook(self._get_features_hook(layer_id))\n\n    # Crop model if input layer is provided\n    if not (self.input_layer_id) is None:\n        if isinstance(self.input_layer_id, int):\n            if isinstance(self.model, nn.Sequential):\n                self.model = nn.Sequential(\n                    *list(self.model.modules())[self.input_layer_id :]\n                )\n            else:\n                raise NotImplementedError\n        elif isinstance(self.input_layer_id, str):\n            if isinstance(self.model, nn.Sequential):\n                module_names = list(\n                    filter(\n                        lambda x: x != \"\",\n                        map(lambda x: x[0], self.model.named_modules()),\n                    )\n                )\n                input_module_idx = module_names.index(self.input_layer_id)\n                self.model = nn.Sequential(\n                    *list(self.model.modules())[(input_module_idx + 1) :]\n                )\n            else:\n                raise NotImplementedError\n        else:\n            raise NotImplementedError\n</code></pre>"},{"location":"api/torch_operator/","title":"TorchOperator","text":""},{"location":"api/torch_operator/#oodeel.utils.torch_operator.TorchOperator","title":"<code>TorchOperator</code>","text":"<p>         Bases: <code>Operator</code></p> <p>Class to handle torch operations with a unified API</p> Source code in <code>oodeel/utils/torch_operator.py</code> <pre><code>class TorchOperator(Operator):\n\"\"\"Class to handle torch operations with a unified API\"\"\"\n\n    def __init__(self, model: Optional[torch.nn.Module] = None):\n        if model is not None:\n            self._device = next(model.parameters()).device\n        else:\n            self._device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n    @staticmethod\n    def softmax(tensor: TensorType) -&gt; torch.Tensor:\n\"\"\"Softmax function along the last dimension\"\"\"\n        return torch.nn.functional.softmax(tensor, dim=-1)\n\n    @staticmethod\n    def argmax(tensor: TensorType, dim: Optional[int] = None) -&gt; torch.Tensor:\n\"\"\"Argmax function\"\"\"\n        return torch.argmax(tensor, dim=dim)\n\n    @staticmethod\n    def max(\n        tensor: TensorType, dim: Optional[int] = None, keepdim: Optional[bool] = False\n    ) -&gt; torch.Tensor:\n\"\"\"Max function\"\"\"\n        if dim is None:\n            return torch.max(tensor)\n        else:\n            return torch.max(tensor, dim, keepdim=keepdim)[0]\n\n    @staticmethod\n    def min(\n        tensor: TensorType, dim: Optional[int] = None, keepdim: bool = False\n    ) -&gt; torch.Tensor:\n\"\"\"Min function\"\"\"\n        if dim is None:\n            return torch.min(tensor)\n        else:\n            return torch.min(tensor, dim, keepdim=keepdim)[0]\n\n    @staticmethod\n    def one_hot(tensor: TensorType, num_classes: int) -&gt; torch.Tensor:\n\"\"\"One hot function\"\"\"\n        return torch.nn.functional.one_hot(tensor, num_classes)\n\n    @staticmethod\n    def sign(tensor: TensorType) -&gt; torch.Tensor:\n\"\"\"Sign function\"\"\"\n        return torch.sign(tensor)\n\n    @staticmethod\n    def CrossEntropyLoss(reduction: str = \"mean\"):\n\"\"\"Cross Entropy Loss from logits\"\"\"\n\n        def sanitized_ce_loss(inputs, targets):\n            return torch.nn.CrossEntropyLoss(reduction=reduction)(inputs, targets)\n\n        return sanitized_ce_loss\n\n    @staticmethod\n    def norm(tensor: TensorType, dim: Optional[int] = None) -&gt; torch.Tensor:\n\"\"\"Tensor Norm\"\"\"\n        return torch.norm(tensor, dim=dim)\n\n    @staticmethod\n    def matmul(tensor_1: TensorType, tensor_2: TensorType) -&gt; torch.Tensor:\n\"\"\"Matmul operation\"\"\"\n        return torch.matmul(tensor_1, tensor_2)\n\n    @staticmethod\n    def convert_from_tensorflow(tensor: TensorType) -&gt; torch.Tensor:\n\"\"\"Convert a tensorflow tensor into a torch tensor\n\n        Used when using a pytorch model on a dataset loaded from tensorflow datasets\n        \"\"\"\n        return torch.Tensor(tensor.numpy())\n\n    @staticmethod\n    def convert_to_numpy(tensor: TensorType) -&gt; np.ndarray:\n\"\"\"Convert tensor into a np.ndarray\"\"\"\n        if tensor.device != \"cpu\":\n            tensor = tensor.to(\"cpu\")\n        return tensor.detach().numpy()\n\n    @staticmethod\n    def gradient(func: Callable, inputs: torch.Tensor, *args, **kwargs) -&gt; torch.Tensor:\n\"\"\"Compute gradients for a batch of samples.\n\n        Args:\n            func (Callable): Function used for computing gradient. Must be built with\n                torch differentiable operations only, and return a scalar.\n            inputs (torch.Tensor): Input tensor wrt which the gradients are computed\n            *args: Additional Args for func.\n            **kwargs: Additional Kwargs for func.\n\n        Returns:\n            torch.Tensor: Gradients computed, with the same shape as the inputs.\n        \"\"\"\n        inputs.requires_grad_(True)\n        outputs = func(inputs, *args, **kwargs)\n        gradients = torch.autograd.grad(outputs, inputs)\n        inputs.requires_grad_(False)\n        return gradients[0]\n\n    @staticmethod\n    def stack(tensors: List[TensorType], dim: int = 0) -&gt; torch.Tensor:\n        \"Stack tensors along a new dimension\"\n        return torch.stack(tensors, dim)\n\n    @staticmethod\n    def cat(tensors: List[TensorType], dim: int = 0) -&gt; torch.Tensor:\n        \"Concatenate tensors in a given dimension\"\n        return torch.cat(tensors, dim)\n\n    @staticmethod\n    def mean(tensor: TensorType, dim: Optional[int] = None) -&gt; torch.Tensor:\n        \"Mean function\"\n        if dim is None:\n            return torch.mean(tensor)\n        else:\n            return torch.mean(tensor, dim)\n\n    @staticmethod\n    def flatten(tensor: TensorType) -&gt; torch.Tensor:\n        \"Flatten function\"\n        # Flatten the features to 2D (n_batch, n_features)\n        return tensor.view(tensor.size(0), -1)\n\n    def from_numpy(self, arr: np.ndarray) -&gt; torch.Tensor:\n        \"Convert a NumPy array to a tensor\"\n        # TODO change dtype\n        return torch.tensor(arr).to(self._device)\n\n    @staticmethod\n    def t(tensor: TensorType) -&gt; torch.Tensor:\n        \"Transpose function for tensor of rank 2\"\n        return tensor.t()\n\n    @staticmethod\n    def permute(tensor: TensorType, dims) -&gt; torch.Tensor:\n        \"Transpose function for tensor of rank 2\"\n        return torch.permute(tensor, dims)\n\n    @staticmethod\n    def diag(tensor: TensorType) -&gt; torch.Tensor:\n        \"Diagonal function: return the diagonal of a 2D tensor\"\n        return tensor.diag()\n\n    @staticmethod\n    def reshape(tensor: TensorType, shape: List[int]) -&gt; torch.Tensor:\n        \"Reshape function\"\n        return tensor.view(*shape)\n\n    @staticmethod\n    def equal(tensor: TensorType, other: Union[TensorType, int, float]) -&gt; torch.Tensor:\n        \"Computes element-wise equality\"\n        return torch.eq(tensor, other)\n\n    @staticmethod\n    def pinv(tensor: TensorType) -&gt; torch.Tensor:\n        \"Computes the pseudoinverse (Moore-Penrose inverse) of a matrix.\"\n        return torch.linalg.pinv(tensor)\n\n    @staticmethod\n    def eigh(tensor: TensorType) -&gt; torch.Tensor:\n        \"Computes the eigen decomposition of a self-adjoint matrix.\"\n        eigval, eigvec = torch.linalg.eigh(tensor)\n        return eigval, eigvec\n\n    @staticmethod\n    def quantile(tensor: TensorType, q: float, dim: int = None) -&gt; torch.Tensor:\n        \"Computes the quantile of a tensor's components. q in (0,1)\"\n        if dim is None:\n            # keep the 16 millions first elements (see torch.quantile issue:\n            # https://github.com/pytorch/pytorch/issues/64947)\n            tensor_flatten = tensor.view(-1)[:16_000_000]\n            return torch.quantile(tensor_flatten, q).item()\n        else:\n            return torch.quantile(tensor, q, dim)\n\n    @staticmethod\n    def relu(tensor: TensorType) -&gt; torch.Tensor:\n        \"Apply relu to a tensor\"\n        return torch.nn.functional.relu(tensor)\n\n    @staticmethod\n    def einsum(equation: str, *tensors: TensorType) -&gt; torch.Tensor:\n        \"Computes the einsum between tensors following equation\"\n        return torch.einsum(equation, *tensors)\n\n    @staticmethod\n    def tril(tensor: TensorType, diagonal: int = 0) -&gt; torch.Tensor:\n        \"Set the upper triangle of the matrix formed by the last two dimensions of\"\n        \"tensor to zero\"\n        return torch.tril(tensor, diagonal)\n\n    @staticmethod\n    def sum(tensor: TensorType, dim: Union[tuple, list, int] = None) -&gt; torch.Tensor:\n        \"sum along dim\"\n        return torch.sum(tensor, dim)\n\n    @staticmethod\n    def unsqueeze(tensor: TensorType, dim: int) -&gt; torch.Tensor:\n        \"unsqueeze along dim\"\n        return torch.unsqueeze(tensor, dim)\n\n    @staticmethod\n    def squeeze(tensor: TensorType, dim: int = None) -&gt; torch.Tensor:\n        \"squeeze along dim\"\n\n        if dim is None:\n            return torch.squeeze(tensor)\n\n        return torch.squeeze(tensor, dim)\n\n    @staticmethod\n    def abs(tensor: TensorType) -&gt; torch.Tensor:\n        \"compute absolute value\"\n        return torch.abs(tensor)\n\n    @staticmethod\n    def where(\n        condition: TensorType,\n        input: Union[TensorType, float],\n        other: Union[TensorType, float],\n    ) -&gt; torch.Tensor:\n        \"Applies where function , to condition\"\n        return torch.where(condition, input, other)\n\n    @staticmethod\n    def avg_pool_2d(tensor: TensorType) -&gt; torch.Tensor:\n\"\"\"Perform avg pool in 2d as in torch.nn.functional.adaptive_avg_pool2d\"\"\"\n        return torch.mean(tensor, dim=(-2, -1))\n\n    @staticmethod\n    def log(tensor: TensorType) -&gt; torch.Tensor:\n\"\"\"Perform log\"\"\"\n        return torch.log(tensor)\n</code></pre>"},{"location":"api/torch_operator/#oodeel.utils.torch_operator.TorchOperator.CrossEntropyLoss","title":"<code>CrossEntropyLoss(reduction='mean')</code>  <code>staticmethod</code>","text":"<p>Cross Entropy Loss from logits</p> Source code in <code>oodeel/utils/torch_operator.py</code> <pre><code>@staticmethod\ndef CrossEntropyLoss(reduction: str = \"mean\"):\n\"\"\"Cross Entropy Loss from logits\"\"\"\n\n    def sanitized_ce_loss(inputs, targets):\n        return torch.nn.CrossEntropyLoss(reduction=reduction)(inputs, targets)\n\n    return sanitized_ce_loss\n</code></pre>"},{"location":"api/torch_operator/#oodeel.utils.torch_operator.TorchOperator.abs","title":"<code>abs(tensor)</code>  <code>staticmethod</code>","text":"<p>compute absolute value</p> Source code in <code>oodeel/utils/torch_operator.py</code> <pre><code>@staticmethod\ndef abs(tensor: TensorType) -&gt; torch.Tensor:\n    \"compute absolute value\"\n    return torch.abs(tensor)\n</code></pre>"},{"location":"api/torch_operator/#oodeel.utils.torch_operator.TorchOperator.argmax","title":"<code>argmax(tensor, dim=None)</code>  <code>staticmethod</code>","text":"<p>Argmax function</p> Source code in <code>oodeel/utils/torch_operator.py</code> <pre><code>@staticmethod\ndef argmax(tensor: TensorType, dim: Optional[int] = None) -&gt; torch.Tensor:\n\"\"\"Argmax function\"\"\"\n    return torch.argmax(tensor, dim=dim)\n</code></pre>"},{"location":"api/torch_operator/#oodeel.utils.torch_operator.TorchOperator.avg_pool_2d","title":"<code>avg_pool_2d(tensor)</code>  <code>staticmethod</code>","text":"<p>Perform avg pool in 2d as in torch.nn.functional.adaptive_avg_pool2d</p> Source code in <code>oodeel/utils/torch_operator.py</code> <pre><code>@staticmethod\ndef avg_pool_2d(tensor: TensorType) -&gt; torch.Tensor:\n\"\"\"Perform avg pool in 2d as in torch.nn.functional.adaptive_avg_pool2d\"\"\"\n    return torch.mean(tensor, dim=(-2, -1))\n</code></pre>"},{"location":"api/torch_operator/#oodeel.utils.torch_operator.TorchOperator.cat","title":"<code>cat(tensors, dim=0)</code>  <code>staticmethod</code>","text":"<p>Concatenate tensors in a given dimension</p> Source code in <code>oodeel/utils/torch_operator.py</code> <pre><code>@staticmethod\ndef cat(tensors: List[TensorType], dim: int = 0) -&gt; torch.Tensor:\n    \"Concatenate tensors in a given dimension\"\n    return torch.cat(tensors, dim)\n</code></pre>"},{"location":"api/torch_operator/#oodeel.utils.torch_operator.TorchOperator.convert_from_tensorflow","title":"<code>convert_from_tensorflow(tensor)</code>  <code>staticmethod</code>","text":"<p>Convert a tensorflow tensor into a torch tensor</p> <p>Used when using a pytorch model on a dataset loaded from tensorflow datasets</p> Source code in <code>oodeel/utils/torch_operator.py</code> <pre><code>@staticmethod\ndef convert_from_tensorflow(tensor: TensorType) -&gt; torch.Tensor:\n\"\"\"Convert a tensorflow tensor into a torch tensor\n\n    Used when using a pytorch model on a dataset loaded from tensorflow datasets\n    \"\"\"\n    return torch.Tensor(tensor.numpy())\n</code></pre>"},{"location":"api/torch_operator/#oodeel.utils.torch_operator.TorchOperator.convert_to_numpy","title":"<code>convert_to_numpy(tensor)</code>  <code>staticmethod</code>","text":"<p>Convert tensor into a np.ndarray</p> Source code in <code>oodeel/utils/torch_operator.py</code> <pre><code>@staticmethod\ndef convert_to_numpy(tensor: TensorType) -&gt; np.ndarray:\n\"\"\"Convert tensor into a np.ndarray\"\"\"\n    if tensor.device != \"cpu\":\n        tensor = tensor.to(\"cpu\")\n    return tensor.detach().numpy()\n</code></pre>"},{"location":"api/torch_operator/#oodeel.utils.torch_operator.TorchOperator.diag","title":"<code>diag(tensor)</code>  <code>staticmethod</code>","text":"<p>Diagonal function: return the diagonal of a 2D tensor</p> Source code in <code>oodeel/utils/torch_operator.py</code> <pre><code>@staticmethod\ndef diag(tensor: TensorType) -&gt; torch.Tensor:\n    \"Diagonal function: return the diagonal of a 2D tensor\"\n    return tensor.diag()\n</code></pre>"},{"location":"api/torch_operator/#oodeel.utils.torch_operator.TorchOperator.eigh","title":"<code>eigh(tensor)</code>  <code>staticmethod</code>","text":"<p>Computes the eigen decomposition of a self-adjoint matrix.</p> Source code in <code>oodeel/utils/torch_operator.py</code> <pre><code>@staticmethod\ndef eigh(tensor: TensorType) -&gt; torch.Tensor:\n    \"Computes the eigen decomposition of a self-adjoint matrix.\"\n    eigval, eigvec = torch.linalg.eigh(tensor)\n    return eigval, eigvec\n</code></pre>"},{"location":"api/torch_operator/#oodeel.utils.torch_operator.TorchOperator.einsum","title":"<code>einsum(equation, *tensors)</code>  <code>staticmethod</code>","text":"<p>Computes the einsum between tensors following equation</p> Source code in <code>oodeel/utils/torch_operator.py</code> <pre><code>@staticmethod\ndef einsum(equation: str, *tensors: TensorType) -&gt; torch.Tensor:\n    \"Computes the einsum between tensors following equation\"\n    return torch.einsum(equation, *tensors)\n</code></pre>"},{"location":"api/torch_operator/#oodeel.utils.torch_operator.TorchOperator.equal","title":"<code>equal(tensor, other)</code>  <code>staticmethod</code>","text":"<p>Computes element-wise equality</p> Source code in <code>oodeel/utils/torch_operator.py</code> <pre><code>@staticmethod\ndef equal(tensor: TensorType, other: Union[TensorType, int, float]) -&gt; torch.Tensor:\n    \"Computes element-wise equality\"\n    return torch.eq(tensor, other)\n</code></pre>"},{"location":"api/torch_operator/#oodeel.utils.torch_operator.TorchOperator.flatten","title":"<code>flatten(tensor)</code>  <code>staticmethod</code>","text":"<p>Flatten function</p> Source code in <code>oodeel/utils/torch_operator.py</code> <pre><code>@staticmethod\ndef flatten(tensor: TensorType) -&gt; torch.Tensor:\n    \"Flatten function\"\n    # Flatten the features to 2D (n_batch, n_features)\n    return tensor.view(tensor.size(0), -1)\n</code></pre>"},{"location":"api/torch_operator/#oodeel.utils.torch_operator.TorchOperator.from_numpy","title":"<code>from_numpy(arr)</code>","text":"<p>Convert a NumPy array to a tensor</p> Source code in <code>oodeel/utils/torch_operator.py</code> <pre><code>def from_numpy(self, arr: np.ndarray) -&gt; torch.Tensor:\n    \"Convert a NumPy array to a tensor\"\n    # TODO change dtype\n    return torch.tensor(arr).to(self._device)\n</code></pre>"},{"location":"api/torch_operator/#oodeel.utils.torch_operator.TorchOperator.gradient","title":"<code>gradient(func, inputs, *args, **kwargs)</code>  <code>staticmethod</code>","text":"<p>Compute gradients for a batch of samples.</p> <p>Parameters:</p> Name Type Description Default <code>func</code> <code>Callable</code> <p>Function used for computing gradient. Must be built with torch differentiable operations only, and return a scalar.</p> required <code>inputs</code> <code>torch.Tensor</code> <p>Input tensor wrt which the gradients are computed</p> required <code>*args</code> <p>Additional Args for func.</p> <code>()</code> <code>**kwargs</code> <p>Additional Kwargs for func.</p> <code>{}</code> <p>Returns:</p> Type Description <code>torch.Tensor</code> <p>torch.Tensor: Gradients computed, with the same shape as the inputs.</p> Source code in <code>oodeel/utils/torch_operator.py</code> <pre><code>@staticmethod\ndef gradient(func: Callable, inputs: torch.Tensor, *args, **kwargs) -&gt; torch.Tensor:\n\"\"\"Compute gradients for a batch of samples.\n\n    Args:\n        func (Callable): Function used for computing gradient. Must be built with\n            torch differentiable operations only, and return a scalar.\n        inputs (torch.Tensor): Input tensor wrt which the gradients are computed\n        *args: Additional Args for func.\n        **kwargs: Additional Kwargs for func.\n\n    Returns:\n        torch.Tensor: Gradients computed, with the same shape as the inputs.\n    \"\"\"\n    inputs.requires_grad_(True)\n    outputs = func(inputs, *args, **kwargs)\n    gradients = torch.autograd.grad(outputs, inputs)\n    inputs.requires_grad_(False)\n    return gradients[0]\n</code></pre>"},{"location":"api/torch_operator/#oodeel.utils.torch_operator.TorchOperator.log","title":"<code>log(tensor)</code>  <code>staticmethod</code>","text":"<p>Perform log</p> Source code in <code>oodeel/utils/torch_operator.py</code> <pre><code>@staticmethod\ndef log(tensor: TensorType) -&gt; torch.Tensor:\n\"\"\"Perform log\"\"\"\n    return torch.log(tensor)\n</code></pre>"},{"location":"api/torch_operator/#oodeel.utils.torch_operator.TorchOperator.matmul","title":"<code>matmul(tensor_1, tensor_2)</code>  <code>staticmethod</code>","text":"<p>Matmul operation</p> Source code in <code>oodeel/utils/torch_operator.py</code> <pre><code>@staticmethod\ndef matmul(tensor_1: TensorType, tensor_2: TensorType) -&gt; torch.Tensor:\n\"\"\"Matmul operation\"\"\"\n    return torch.matmul(tensor_1, tensor_2)\n</code></pre>"},{"location":"api/torch_operator/#oodeel.utils.torch_operator.TorchOperator.max","title":"<code>max(tensor, dim=None, keepdim=False)</code>  <code>staticmethod</code>","text":"<p>Max function</p> Source code in <code>oodeel/utils/torch_operator.py</code> <pre><code>@staticmethod\ndef max(\n    tensor: TensorType, dim: Optional[int] = None, keepdim: Optional[bool] = False\n) -&gt; torch.Tensor:\n\"\"\"Max function\"\"\"\n    if dim is None:\n        return torch.max(tensor)\n    else:\n        return torch.max(tensor, dim, keepdim=keepdim)[0]\n</code></pre>"},{"location":"api/torch_operator/#oodeel.utils.torch_operator.TorchOperator.mean","title":"<code>mean(tensor, dim=None)</code>  <code>staticmethod</code>","text":"<p>Mean function</p> Source code in <code>oodeel/utils/torch_operator.py</code> <pre><code>@staticmethod\ndef mean(tensor: TensorType, dim: Optional[int] = None) -&gt; torch.Tensor:\n    \"Mean function\"\n    if dim is None:\n        return torch.mean(tensor)\n    else:\n        return torch.mean(tensor, dim)\n</code></pre>"},{"location":"api/torch_operator/#oodeel.utils.torch_operator.TorchOperator.min","title":"<code>min(tensor, dim=None, keepdim=False)</code>  <code>staticmethod</code>","text":"<p>Min function</p> Source code in <code>oodeel/utils/torch_operator.py</code> <pre><code>@staticmethod\ndef min(\n    tensor: TensorType, dim: Optional[int] = None, keepdim: bool = False\n) -&gt; torch.Tensor:\n\"\"\"Min function\"\"\"\n    if dim is None:\n        return torch.min(tensor)\n    else:\n        return torch.min(tensor, dim, keepdim=keepdim)[0]\n</code></pre>"},{"location":"api/torch_operator/#oodeel.utils.torch_operator.TorchOperator.norm","title":"<code>norm(tensor, dim=None)</code>  <code>staticmethod</code>","text":"<p>Tensor Norm</p> Source code in <code>oodeel/utils/torch_operator.py</code> <pre><code>@staticmethod\ndef norm(tensor: TensorType, dim: Optional[int] = None) -&gt; torch.Tensor:\n\"\"\"Tensor Norm\"\"\"\n    return torch.norm(tensor, dim=dim)\n</code></pre>"},{"location":"api/torch_operator/#oodeel.utils.torch_operator.TorchOperator.one_hot","title":"<code>one_hot(tensor, num_classes)</code>  <code>staticmethod</code>","text":"<p>One hot function</p> Source code in <code>oodeel/utils/torch_operator.py</code> <pre><code>@staticmethod\ndef one_hot(tensor: TensorType, num_classes: int) -&gt; torch.Tensor:\n\"\"\"One hot function\"\"\"\n    return torch.nn.functional.one_hot(tensor, num_classes)\n</code></pre>"},{"location":"api/torch_operator/#oodeel.utils.torch_operator.TorchOperator.permute","title":"<code>permute(tensor, dims)</code>  <code>staticmethod</code>","text":"<p>Transpose function for tensor of rank 2</p> Source code in <code>oodeel/utils/torch_operator.py</code> <pre><code>@staticmethod\ndef permute(tensor: TensorType, dims) -&gt; torch.Tensor:\n    \"Transpose function for tensor of rank 2\"\n    return torch.permute(tensor, dims)\n</code></pre>"},{"location":"api/torch_operator/#oodeel.utils.torch_operator.TorchOperator.pinv","title":"<code>pinv(tensor)</code>  <code>staticmethod</code>","text":"<p>Computes the pseudoinverse (Moore-Penrose inverse) of a matrix.</p> Source code in <code>oodeel/utils/torch_operator.py</code> <pre><code>@staticmethod\ndef pinv(tensor: TensorType) -&gt; torch.Tensor:\n    \"Computes the pseudoinverse (Moore-Penrose inverse) of a matrix.\"\n    return torch.linalg.pinv(tensor)\n</code></pre>"},{"location":"api/torch_operator/#oodeel.utils.torch_operator.TorchOperator.quantile","title":"<code>quantile(tensor, q, dim=None)</code>  <code>staticmethod</code>","text":"<p>Computes the quantile of a tensor's components. q in (0,1)</p> Source code in <code>oodeel/utils/torch_operator.py</code> <pre><code>@staticmethod\ndef quantile(tensor: TensorType, q: float, dim: int = None) -&gt; torch.Tensor:\n    \"Computes the quantile of a tensor's components. q in (0,1)\"\n    if dim is None:\n        # keep the 16 millions first elements (see torch.quantile issue:\n        # https://github.com/pytorch/pytorch/issues/64947)\n        tensor_flatten = tensor.view(-1)[:16_000_000]\n        return torch.quantile(tensor_flatten, q).item()\n    else:\n        return torch.quantile(tensor, q, dim)\n</code></pre>"},{"location":"api/torch_operator/#oodeel.utils.torch_operator.TorchOperator.relu","title":"<code>relu(tensor)</code>  <code>staticmethod</code>","text":"<p>Apply relu to a tensor</p> Source code in <code>oodeel/utils/torch_operator.py</code> <pre><code>@staticmethod\ndef relu(tensor: TensorType) -&gt; torch.Tensor:\n    \"Apply relu to a tensor\"\n    return torch.nn.functional.relu(tensor)\n</code></pre>"},{"location":"api/torch_operator/#oodeel.utils.torch_operator.TorchOperator.reshape","title":"<code>reshape(tensor, shape)</code>  <code>staticmethod</code>","text":"<p>Reshape function</p> Source code in <code>oodeel/utils/torch_operator.py</code> <pre><code>@staticmethod\ndef reshape(tensor: TensorType, shape: List[int]) -&gt; torch.Tensor:\n    \"Reshape function\"\n    return tensor.view(*shape)\n</code></pre>"},{"location":"api/torch_operator/#oodeel.utils.torch_operator.TorchOperator.sign","title":"<code>sign(tensor)</code>  <code>staticmethod</code>","text":"<p>Sign function</p> Source code in <code>oodeel/utils/torch_operator.py</code> <pre><code>@staticmethod\ndef sign(tensor: TensorType) -&gt; torch.Tensor:\n\"\"\"Sign function\"\"\"\n    return torch.sign(tensor)\n</code></pre>"},{"location":"api/torch_operator/#oodeel.utils.torch_operator.TorchOperator.softmax","title":"<code>softmax(tensor)</code>  <code>staticmethod</code>","text":"<p>Softmax function along the last dimension</p> Source code in <code>oodeel/utils/torch_operator.py</code> <pre><code>@staticmethod\ndef softmax(tensor: TensorType) -&gt; torch.Tensor:\n\"\"\"Softmax function along the last dimension\"\"\"\n    return torch.nn.functional.softmax(tensor, dim=-1)\n</code></pre>"},{"location":"api/torch_operator/#oodeel.utils.torch_operator.TorchOperator.squeeze","title":"<code>squeeze(tensor, dim=None)</code>  <code>staticmethod</code>","text":"<p>squeeze along dim</p> Source code in <code>oodeel/utils/torch_operator.py</code> <pre><code>@staticmethod\ndef squeeze(tensor: TensorType, dim: int = None) -&gt; torch.Tensor:\n    \"squeeze along dim\"\n\n    if dim is None:\n        return torch.squeeze(tensor)\n\n    return torch.squeeze(tensor, dim)\n</code></pre>"},{"location":"api/torch_operator/#oodeel.utils.torch_operator.TorchOperator.stack","title":"<code>stack(tensors, dim=0)</code>  <code>staticmethod</code>","text":"<p>Stack tensors along a new dimension</p> Source code in <code>oodeel/utils/torch_operator.py</code> <pre><code>@staticmethod\ndef stack(tensors: List[TensorType], dim: int = 0) -&gt; torch.Tensor:\n    \"Stack tensors along a new dimension\"\n    return torch.stack(tensors, dim)\n</code></pre>"},{"location":"api/torch_operator/#oodeel.utils.torch_operator.TorchOperator.sum","title":"<code>sum(tensor, dim=None)</code>  <code>staticmethod</code>","text":"<p>sum along dim</p> Source code in <code>oodeel/utils/torch_operator.py</code> <pre><code>@staticmethod\ndef sum(tensor: TensorType, dim: Union[tuple, list, int] = None) -&gt; torch.Tensor:\n    \"sum along dim\"\n    return torch.sum(tensor, dim)\n</code></pre>"},{"location":"api/torch_operator/#oodeel.utils.torch_operator.TorchOperator.t","title":"<code>t(tensor)</code>  <code>staticmethod</code>","text":"<p>Transpose function for tensor of rank 2</p> Source code in <code>oodeel/utils/torch_operator.py</code> <pre><code>@staticmethod\ndef t(tensor: TensorType) -&gt; torch.Tensor:\n    \"Transpose function for tensor of rank 2\"\n    return tensor.t()\n</code></pre>"},{"location":"api/torch_operator/#oodeel.utils.torch_operator.TorchOperator.tril","title":"<code>tril(tensor, diagonal=0)</code>  <code>staticmethod</code>","text":"<p>Set the upper triangle of the matrix formed by the last two dimensions of</p> Source code in <code>oodeel/utils/torch_operator.py</code> <pre><code>@staticmethod\ndef tril(tensor: TensorType, diagonal: int = 0) -&gt; torch.Tensor:\n    \"Set the upper triangle of the matrix formed by the last two dimensions of\"\n    \"tensor to zero\"\n    return torch.tril(tensor, diagonal)\n</code></pre>"},{"location":"api/torch_operator/#oodeel.utils.torch_operator.TorchOperator.unsqueeze","title":"<code>unsqueeze(tensor, dim)</code>  <code>staticmethod</code>","text":"<p>unsqueeze along dim</p> Source code in <code>oodeel/utils/torch_operator.py</code> <pre><code>@staticmethod\ndef unsqueeze(tensor: TensorType, dim: int) -&gt; torch.Tensor:\n    \"unsqueeze along dim\"\n    return torch.unsqueeze(tensor, dim)\n</code></pre>"},{"location":"api/torch_operator/#oodeel.utils.torch_operator.TorchOperator.where","title":"<code>where(condition, input, other)</code>  <code>staticmethod</code>","text":"<p>Applies where function , to condition</p> Source code in <code>oodeel/utils/torch_operator.py</code> <pre><code>@staticmethod\ndef where(\n    condition: TensorType,\n    input: Union[TensorType, float],\n    other: Union[TensorType, float],\n) -&gt; torch.Tensor:\n    \"Applies where function , to condition\"\n    return torch.where(condition, input, other)\n</code></pre>"},{"location":"api/torch_operator/#oodeel.utils.torch_operator.sanitize_input","title":"<code>sanitize_input(tensor_arg_func)</code>","text":"<p>ensures the decorated function receives a torch.Tensor</p> Source code in <code>oodeel/utils/torch_operator.py</code> <pre><code>def sanitize_input(tensor_arg_func: Callable):\n\"\"\"ensures the decorated function receives a torch.Tensor\"\"\"\n\n    def wrapper(obj, tensor, *args, **kwargs):\n        if isinstance(tensor, torch.Tensor):\n            pass\n        elif is_from(tensor, \"tensorflow\"):\n            tensor = torch.Tensor(tensor.numpy())\n        else:\n            tensor = torch.Tensor(tensor)\n\n        return tensor_arg_func(obj, tensor, *args, **kwargs)\n\n    return wrapper\n</code></pre>"},{"location":"api/training_tools/","title":"Training tools","text":""},{"location":"api/training_tools/#oodeel.utils.tf_training_tools.get_toy_keras_convnet","title":"<code>get_toy_keras_convnet(num_classes)</code>","text":"<p>Basic keras convolutional classifier for toy datasets.</p> <p>Parameters:</p> Name Type Description Default <code>num_classes</code> <code>int</code> <p>Number of classes for the classification task.</p> required <p>Returns:</p> Type Description <code>tf.keras.Model</code> <p>tf.keras.Model: model</p> Source code in <code>oodeel/utils/tf_training_tools.py</code> <pre><code>def get_toy_keras_convnet(num_classes: int) -&gt; tf.keras.Model:\n\"\"\"Basic keras convolutional classifier for toy datasets.\n\n    Args:\n        num_classes (int): Number of classes for the classification task.\n\n    Returns:\n        tf.keras.Model: model\n    \"\"\"\n    return Sequential(\n        [\n            Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n            MaxPooling2D(pool_size=(2, 2)),\n            Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n            MaxPooling2D(pool_size=(2, 2)),\n            Flatten(),\n            Dropout(0.5),\n            Dense(num_classes, activation=\"softmax\"),\n        ]\n    )\n</code></pre>"},{"location":"api/training_tools/#oodeel.utils.tf_training_tools.get_toy_mlp","title":"<code>get_toy_mlp(input_shape, num_classes)</code>","text":"<p>Basic keras MLP classifier for toy datasets.</p> <p>Parameters:</p> Name Type Description Default <code>input_shape</code> <code>tuple</code> <p>Input data shape.</p> required <code>num_classes</code> <code>int</code> <p>Number of classes for the classification task.</p> required <p>Returns:</p> Type Description <code>tf.keras.Model</code> <p>tf.keras.Model: model</p> Source code in <code>oodeel/utils/tf_training_tools.py</code> <pre><code>def get_toy_mlp(input_shape: tuple, num_classes: int) -&gt; tf.keras.Model:\n\"\"\"Basic keras MLP classifier for toy datasets.\n\n    Args:\n        input_shape (tuple): Input data shape.\n        num_classes (int): Number of classes for the classification task.\n\n    Returns:\n        tf.keras.Model: model\n    \"\"\"\n    return tf.keras.models.Sequential(\n        [\n            tf.keras.layers.Input(shape=input_shape),\n            tf.keras.layers.Flatten(),\n            tf.keras.layers.Dense(300, activation=\"relu\"),\n            tf.keras.layers.Dense(150, activation=\"relu\"),\n            tf.keras.layers.Dense(num_classes, activation=\"softmax\"),\n        ]\n    )\n</code></pre>"},{"location":"api/training_tools/#oodeel.utils.tf_training_tools.train_tf_model","title":"<code>train_tf_model(train_data, model, input_shape, num_classes, batch_size=128, epochs=50, loss='sparse_categorical_crossentropy', optimizer='adam', lr_scheduler=None, learning_rate=0.001, metrics=['accuracy'], imagenet_pretrained=False, validation_data=None, save_dir=None, save_best_only=True)</code>","text":"<p>Loads a model from tensorflow.python.keras.applications. If the dataset is different from imagenet, trains on provided dataset.</p> <p>Parameters:</p> Name Type Description Default <code>train_data</code> <code>tf.data.Dataset</code> <p>training dataset.</p> required <code>model</code> <code>Union[tf.keras.Model, str]</code> <p>if a string is provided, must be a model from tf.keras.applications or \"toy_convnet\" or \"toy_mlp\"</p> required <code>input_shape</code> <code>tuple</code> <p>Shape of the input images.</p> required <code>num_classes</code> <code>int</code> <p>Number of output classes.</p> required <code>batch_size</code> <code>int</code> <p>Defaults to 128.</p> <code>128</code> <code>epochs</code> <code>int</code> <p>Defaults to 50.</p> <code>50</code> <code>loss</code> <code>str</code> <p>Defaults to \"sparse_categorical_crossentropy\".</p> <code>'sparse_categorical_crossentropy'</code> <code>optimizer</code> <code>str</code> <p>Defaults to \"adam\".</p> <code>'adam'</code> <code>lr_scheduler</code> <code>str</code> <p>(\"cosine\" | \"steps\" | None). Defaults to None.</p> <code>None</code> <code>learning_rate</code> <code>float</code> <p>Defaults to 1e-3.</p> <code>0.001</code> <code>metrics</code> <code>List[str]</code> <p>Validation metrics. Defaults to [\"accuracy\"].</p> <code>['accuracy']</code> <code>imagenet_pretrained</code> <code>bool</code> <p>Load a model pretrained on imagenet or not. Defaults to False.</p> <code>False</code> <code>validation_data</code> <code>Optional[tf.data.Dataset]</code> <p>Defaults to None.</p> <code>None</code> <code>save_dir</code> <code>Optional[str]</code> <p>Directory to save the model. Defaults to None.</p> <code>None</code> <code>save_best_only</code> <code>bool</code> <p>If False, saved model will be the last one. Defaults to True.</p> <code>True</code> <p>Returns:</p> Type Description <code>tf.keras.Model</code> <p>tf.keras.Model: Trained model</p> Source code in <code>oodeel/utils/tf_training_tools.py</code> <pre><code>def train_tf_model(\n    train_data: tf.data.Dataset,\n    model: Union[tf.keras.Model, str],\n    input_shape: tuple,\n    num_classes: int,\n    batch_size: int = 128,\n    epochs: int = 50,\n    loss: str = \"sparse_categorical_crossentropy\",\n    optimizer: str = \"adam\",\n    lr_scheduler: Optional[str] = None,\n    learning_rate: float = 1e-3,\n    metrics: List[str] = [\"accuracy\"],\n    imagenet_pretrained: bool = False,\n    validation_data: Optional[tf.data.Dataset] = None,\n    save_dir: Optional[str] = None,\n    save_best_only: bool = True,\n) -&gt; tf.keras.Model:\n\"\"\"Loads a model from tensorflow.python.keras.applications.\n    If the dataset is different from imagenet, trains on provided dataset.\n\n    Args:\n        train_data (tf.data.Dataset): training dataset.\n        model (Union[tf.keras.Model, str]): if a string is provided, must be a model\n            from tf.keras.applications or \"toy_convnet\" or \"toy_mlp\"\n        input_shape (tuple): Shape of the input images.\n        num_classes (int): Number of output classes.\n        batch_size (int, optional): Defaults to 128.\n        epochs (int, optional): Defaults to 50.\n        loss (str, optional): Defaults to \"sparse_categorical_crossentropy\".\n        optimizer (str, optional): Defaults to \"adam\".\n        lr_scheduler (str, optional): (\"cosine\" | \"steps\" | None). Defaults to None.\n        learning_rate (float, optional): Defaults to 1e-3.\n        metrics (List[str], optional): Validation metrics. Defaults to [\"accuracy\"].\n        imagenet_pretrained (bool, optional): Load a model pretrained on imagenet or\n            not. Defaults to False.\n        validation_data (Optional[tf.data.Dataset], optional): Defaults to None.\n        save_dir (Optional[str], optional): Directory to save the model.\n            Defaults to None.\n        save_best_only (bool): If False, saved model will be the last one. Defaults to\n            True.\n\n    Returns:\n        tf.keras.Model: Trained model\n    \"\"\"\n    # get data infos from dataset\n    if isinstance(train_data.element_spec, dict):\n        input_id = \"image\"\n        label_id = \"label\"\n    else:\n        input_id = 0\n        label_id = -1\n    if input_shape is None:\n        input_shape = TFDataHandler.get_feature_shape(train_data, input_id)\n    if num_classes is None:\n        classes = TFDataHandler.get_feature(train_data, label_id).unique()\n        num_classes = len(list(classes.as_numpy_iterator()))\n\n    # prepare model\n    if isinstance(model, tf.keras.Model):\n        pass\n    elif isinstance(model, str):\n        if model == \"toy_convnet\":\n            model = get_toy_keras_convnet(num_classes)\n        elif model == \"toy_mlp\":\n            model = get_toy_mlp(input_shape, num_classes)\n        else:\n            weights = \"imagenet\" if imagenet_pretrained else None\n            backbone = getattr(tf.keras.applications, model)(\n                include_top=False, weights=weights, input_shape=input_shape\n            )\n\n            features = tf.keras.layers.Flatten()(backbone.layers[-1].output)\n            output = tf.keras.layers.Dense(\n                num_classes,\n                activation=\"softmax\",\n            )(features)\n            model = tf.keras.Model(backbone.layers[0].input, output)\n\n    n_samples = TFDataHandler.get_dataset_length(train_data)\n\n    # Prepare callbacks\n    model_checkpoint_callback = []\n\n    if save_dir is not None:\n        checkpoint_filepath = save_dir\n        model_checkpoint_callback.append(\n            tf.keras.callbacks.ModelCheckpoint(\n                filepath=checkpoint_filepath,\n                save_weights_only=True,\n                monitor=\"val_accuracy\",\n                mode=\"max\",\n                save_best_only=save_best_only,\n            )\n        )\n\n    if len(model_checkpoint_callback) == 0:\n        model_checkpoint_callback = None\n\n    # optimizer\n    decay_steps = int(epochs * n_samples / batch_size)\n    if lr_scheduler == \"cosine\":\n        learning_rate_fn = tf.keras.experimental.CosineDecay(\n            learning_rate, decay_steps=decay_steps\n        )\n    elif lr_scheduler == \"steps\":\n        values = list(learning_rate * np.array([1, 0.1, 0.01]))\n        boundaries = list(np.round(decay_steps * np.array([1 / 3, 2 / 3])).astype(int))\n        learning_rate_fn = tf.keras.optimizers.schedules.PiecewiseConstantDecay(\n            boundaries, values\n        )\n    else:\n        learning_rate_fn = learning_rate\n\n    config = {\n        \"class_name\": optimizer,\n        \"config\": {\n            \"learning_rate\": learning_rate_fn,\n        },\n    }\n\n    if optimizer == \"SGD\":\n        config[\"config\"][\"momentum\"] = 0.9\n        config[\"config\"][\"decay\"] = 5e-4\n\n    keras_optimizer = tf.keras.optimizers.get(config)\n\n    model.compile(loss=loss, optimizer=keras_optimizer, metrics=metrics)\n\n    model.fit(\n        train_data,\n        validation_data=validation_data,\n        epochs=epochs,\n        callbacks=model_checkpoint_callback,\n    )\n\n    if save_dir is not None:\n        model.load_weights(save_dir)\n        model.save(save_dir)\n    return model\n</code></pre>"},{"location":"api/training_tools/#oodeel.utils.torch_training_tools.ToyTorchConvnet","title":"<code>ToyTorchConvnet</code>","text":"<p>         Bases: <code>nn.Sequential</code></p> <p>Basic torch convolutional classifier for toy datasets.</p> <p>Parameters:</p> Name Type Description Default <code>input_shape</code> <code>tuple</code> <p>Input data shape.</p> required <code>num_classes</code> <code>int</code> <p>Number of classes for the classification task.</p> required Source code in <code>oodeel/utils/torch_training_tools.py</code> <pre><code>class ToyTorchConvnet(nn.Sequential):\n\"\"\"Basic torch convolutional classifier for toy datasets.\n\n    Args:\n        input_shape (tuple): Input data shape.\n        num_classes (int): Number of classes for the classification task.\n    \"\"\"\n\n    def __init__(self, input_shape: tuple, num_classes: int):\n        self.input_shape = input_shape\n\n        # features\n        features = nn.Sequential(\n            OrderedDict(\n                [\n                    (\"conv1\", nn.Conv2d(input_shape[0], 32, 3)),\n                    (\"relu1\", nn.ReLU()),\n                    (\"pool1\", nn.MaxPool2d(2, 2)),\n                    (\"conv2\", nn.Conv2d(32, 64, 3)),\n                    (\"relu2\", nn.ReLU()),\n                    (\"pool2\", nn.MaxPool2d(2, 2)),\n                    (\"flatten\", nn.Flatten()),\n                ]\n            )\n        )\n\n        # fc head\n        fc_input_shape = self._calculate_fc_input_shape(features)\n        fcs = nn.Sequential(\n            OrderedDict(\n                [\n                    (\"dropout\", nn.Dropout(0.5)),\n                    (\"fc1\", nn.Linear(fc_input_shape, num_classes)),\n                ]\n            )\n        )\n\n        # Sequential class init\n        super().__init__(\n            OrderedDict([*features._modules.items(), *fcs._modules.items()])\n        )\n\n    def _calculate_fc_input_shape(self, features):\n\"\"\"Get tensor shape after passing a features network.\"\"\"\n        input_tensor = torch.ones(tuple([1] + list(self.input_shape)))\n        x = features(input_tensor)\n        output_size = x.view(x.size(0), -1).size(1)\n        return output_size\n</code></pre>"},{"location":"api/training_tools/#oodeel.utils.torch_training_tools.ToyTorchMLP","title":"<code>ToyTorchMLP</code>","text":"<p>         Bases: <code>nn.Sequential</code></p> <p>Basic torch MLP classifier for toy datasets.</p> <p>Parameters:</p> Name Type Description Default <code>input_shape</code> <code>tuple</code> <p>Input data shape.</p> required <code>num_classes</code> <code>int</code> <p>Number of classes for the classification task.</p> required Source code in <code>oodeel/utils/torch_training_tools.py</code> <pre><code>class ToyTorchMLP(nn.Sequential):\n\"\"\"Basic torch MLP classifier for toy datasets.\n\n    Args:\n        input_shape (tuple): Input data shape.\n        num_classes (int): Number of classes for the classification task.\n    \"\"\"\n\n    def __init__(self, input_shape: tuple, num_classes: int):\n        self.input_shape = input_shape\n\n        # build toy mlp\n        mlp_modules = OrderedDict(\n            [\n                (\"flatten\", nn.Flatten()),\n                (\"dense1\", nn.Linear(np.prod(input_shape), 300)),\n                (\"relu1\", nn.ReLU()),\n                (\"dense2\", nn.Linear(300, 150)),\n                (\"relu2\", nn.ReLU()),\n                (\"fc1\", nn.Linear(150, num_classes)),\n            ]\n        )\n        super().__init__(mlp_modules)\n</code></pre>"},{"location":"api/training_tools/#oodeel.utils.torch_training_tools.train_torch_model","title":"<code>train_torch_model(train_data, model, num_classes, epochs=50, loss='CrossEntropyLoss', optimizer='Adam', lr_scheduler='cosine', learning_rate=0.001, imagenet_pretrained=False, validation_data=None, save_dir=None, cuda_idx=0)</code>","text":"<p>Load a model (toy classifier or from torchvision.models) and train it over a torch dataloader.</p> <p>Parameters:</p> Name Type Description Default <code>train_data</code> <code>DataLoader</code> <p>train dataloader</p> required <code>model</code> <code>Union[nn.Module, str]</code> <p>if a string is provided, must be a model from torchvision.models or \"toy_convnet\" or \"toy_mlp.</p> required <code>num_classes</code> <code>int</code> <p>Number of output classes.</p> required <code>epochs</code> <code>int</code> <p>Defaults to 50.</p> <code>50</code> <code>loss</code> <code>str</code> <p>Defaults to \"CrossEntropyLoss\".</p> <code>'CrossEntropyLoss'</code> <code>optimizer</code> <code>str</code> <p>Defaults to \"Adam\".</p> <code>'Adam'</code> <code>lr_scheduler</code> <code>str</code> <p>(\"cosine\" | \"steps\" | None). Defaults to None.</p> <code>'cosine'</code> <code>learning_rate</code> <code>float</code> <p>Defaults to 1e-3.</p> <code>0.001</code> <code>imagenet_pretrained</code> <code>bool</code> <p>Load a model pretrained on imagenet or not. Defaults to False.</p> <code>False</code> <code>validation_data</code> <code>Optional[DataLoader]</code> <p>Defaults to None.</p> <code>None</code> <code>save_dir</code> <code>Optional[str]</code> <p>Directory to save the model. Defaults to None.</p> <code>None</code> <code>cuda_idx</code> <code>int</code> <p>idx of cuda device to use. Defaults to 0.</p> <code>0</code> <p>Returns:</p> Type Description <code>nn.Module</code> <p>nn.Module: trained model</p> Source code in <code>oodeel/utils/torch_training_tools.py</code> <pre><code>def train_torch_model(\n    train_data: DataLoader,\n    model: Union[nn.Module, str],\n    num_classes: int,\n    epochs: int = 50,\n    loss: str = \"CrossEntropyLoss\",\n    optimizer: str = \"Adam\",\n    lr_scheduler: str = \"cosine\",\n    learning_rate: float = 1e-3,\n    imagenet_pretrained: bool = False,\n    validation_data: Optional[DataLoader] = None,\n    save_dir: Optional[str] = None,\n    cuda_idx: int = 0,\n) -&gt; nn.Module:\n\"\"\"\n    Load a model (toy classifier or from torchvision.models) and train\n    it over a torch dataloader.\n\n    Args:\n        train_data (DataLoader): train dataloader\n        model (Union[nn.Module, str]): if a string is provided, must be a model from\n            torchvision.models or \"toy_convnet\" or \"toy_mlp.\n        num_classes (int): Number of output classes.\n        epochs (int, optional): Defaults to 50.\n        loss (str, optional): Defaults to \"CrossEntropyLoss\".\n        optimizer (str, optional): Defaults to \"Adam\".\n        lr_scheduler (str, optional): (\"cosine\" | \"steps\" | None). Defaults to None.\n        learning_rate (float, optional): Defaults to 1e-3.\n        imagenet_pretrained (bool, optional): Load a model pretrained on imagenet or\n            not. Defaults to False.\n        validation_data (Optional[DataLoader], optional): Defaults to None.\n        save_dir (Optional[str], optional): Directory to save the model.\n            Defaults to None.\n        cuda_idx (int): idx of cuda device to use. Defaults to 0.\n\n    Returns:\n        nn.Module: trained model\n    \"\"\"\n    # device\n    device = torch.device(\n        f\"cuda:{cuda_idx}\"\n        if torch.cuda.is_available() and cuda_idx is not None\n        else \"cpu\"\n    )\n\n    # Prepare model\n    if isinstance(model, nn.Module):\n        model = model.to(device)\n    elif isinstance(model, str):\n        if model == \"toy_convnet\":\n            # toy model\n            input_shape = tuple(next(iter(train_data))[0].shape[1:])\n            model = ToyTorchConvnet(input_shape, num_classes).to(device)\n        elif model == \"toy_mlp\":\n            # toy model\n            input_shape = tuple(next(iter(train_data))[0].shape[1:])\n            model = ToyTorchMLP(input_shape, num_classes).to(device)\n        else:\n            # torchvision model\n            model = getattr(torchvision.models, model)(\n                num_classes=num_classes, pretrained=imagenet_pretrained\n            ).to(device)\n\n    # define optimizer and learning rate scheduler\n    optimizer = getattr(optim, optimizer)(model.parameters(), lr=learning_rate)\n    n_steps = len(train_data) * epochs\n    if lr_scheduler == \"cosine\":\n        lr_scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, n_steps)\n    elif lr_scheduler == \"steps\":\n        boundaries = list(np.round(n_steps * np.array([1 / 3, 2 / 3])).astype(int))\n        lr_scheduler = optim.lr_scheduler.MultiStepLR(\n            optimizer, milestones=boundaries, gamma=0.1\n        )\n\n    # define loss\n    criterion = getattr(nn, loss)()\n\n    # train\n    model = _train(\n        model,\n        train_data,\n        validation_data=validation_data,\n        epochs=epochs,\n        criterion=criterion,\n        optimizer=optimizer,\n        lr_scheduler=lr_scheduler,\n        save_dir=save_dir,\n        device=device,\n    )\n    return model\n</code></pre>"},{"location":"api/utils/","title":"Utils","text":""},{"location":"api/utils/#oodeel.utils.general_utils.import_backend_specific_stuff","title":"<code>import_backend_specific_stuff(model)</code>","text":"<p>Get backend specific data handler, operator and feature extractor class.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Callable</code> <p>a model (Keras or PyTorch) used to identify the backend.</p> required <p>Returns:</p> Name Type Description <code>str</code> <p>backend name</p> <code>DataHandler</code> <p>torch or tf data handler</p> <code>Operator</code> <p>torch or tf operator</p> <code>FeatureExtractor</code> <p>torch or tf feature extractor class</p> Source code in <code>oodeel/utils/general_utils.py</code> <pre><code>def import_backend_specific_stuff(model: Callable):\n\"\"\"Get backend specific data handler, operator and feature extractor class.\n\n    Args:\n        model (Callable): a model (Keras or PyTorch) used to identify the backend.\n\n    Returns:\n        str: backend name\n        DataHandler: torch or tf data handler\n        Operator: torch or tf operator\n        FeatureExtractor: torch or tf feature extractor class\n    \"\"\"\n    if is_from(model, \"keras\"):\n        from ..extractor.keras_feature_extractor import KerasFeatureExtractor\n        from ..datasets.tf_data_handler import TFDataHandler\n        from ..utils import TFOperator\n\n        backend = \"tensorflow\"\n        data_handler = TFDataHandler()\n        op = TFOperator()\n        FeatureExtractorClass = KerasFeatureExtractor\n\n    elif is_from(model, \"torch\"):\n        from ..extractor.torch_feature_extractor import TorchFeatureExtractor\n        from ..datasets.torch_data_handler import TorchDataHandler\n        from ..utils import TorchOperator\n\n        backend = \"torch\"\n        data_handler = TorchDataHandler()\n        op = TorchOperator(model)\n        FeatureExtractorClass = TorchFeatureExtractor\n\n    else:\n        raise NotImplementedError()\n\n    return backend, data_handler, op, FeatureExtractorClass\n</code></pre>"},{"location":"api/utils/#oodeel.utils.general_utils.is_from","title":"<code>is_from(model_or_tensor, framework)</code>","text":"<p>Check whether a model or tensor belongs to a specific framework</p> <p>Parameters:</p> Name Type Description Default <code>model_or_tensor</code> <code>Any</code> <p>Neural network or Tensor</p> required <code>framework</code> <code>str</code> <p>Model or tensor framework (\"torch\" | \"keras\" | \"tensorflow\")</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>Whether the model belongs to specified framework or not</p> Source code in <code>oodeel/utils/general_utils.py</code> <pre><code>def is_from(model_or_tensor: Any, framework: str) -&gt; bool:\n\"\"\"Check whether a model or tensor belongs to a specific framework\n\n    Args:\n        model_or_tensor (Any): Neural network or Tensor\n        framework (str):  Model or tensor framework (\"torch\" | \"keras\" | \"tensorflow\")\n\n    Returns:\n        bool: Whether the model belongs to specified framework or not\n    \"\"\"\n    keywords_list = []\n    class_parents = list(model_or_tensor.__class__.__mro__)\n    for class_id in class_parents:\n        class_list = str(class_id).split(\"'\")[1].split(\".\")\n        for keyword in class_list:\n            keywords_list.append(keyword)\n    return framework in keywords_list\n</code></pre>"},{"location":"notebooks/tensorflow/demo_ash_tf/","title":"ASH","text":"In\u00a0[1]: Copied! <pre>%load_ext autoreload\n\nimport os\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\" \n\nfrom IPython.display import clear_output\nimport numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n\nfrom oodeel.methods import MLS, Energy, GEN, ODIN, Entropy\nfrom oodeel.eval.metrics import bench_metrics\nfrom oodeel.eval.plots import plot_ood_scores, plot_roc_curve, plot_2D_features\nfrom oodeel.datasets import OODDataset\nfrom oodeel.utils.tf_training_tools import train_tf_model\n</pre> %load_ext autoreload  import os os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"   from IPython.display import clear_output import numpy as np import tensorflow as tf import matplotlib.pyplot as plt  from oodeel.methods import MLS, Energy, GEN, ODIN, Entropy from oodeel.eval.metrics import bench_metrics from oodeel.eval.plots import plot_ood_scores, plot_roc_curve, plot_2D_features from oodeel.datasets import OODDataset from oodeel.utils.tf_training_tools import train_tf_model <p>Note that models are saved at ~/.oodeel/saved_models and data is supposed to be found at ~/.oodeel/datasets by default. Change the following cell for a custom path.</p> In\u00a0[2]: Copied! <pre>model_path = os.path.expanduser(\"~/\") + \".oodeel/saved_models\"\ndata_path = os.path.expanduser(\"~/\") + \".oodeel/datasets\"\nos.makedirs(model_path, exist_ok=True)\nos.makedirs(data_path, exist_ok=True)\n</pre> model_path = os.path.expanduser(\"~/\") + \".oodeel/saved_models\" data_path = os.path.expanduser(\"~/\") + \".oodeel/datasets\" os.makedirs(model_path, exist_ok=True) os.makedirs(data_path, exist_ok=True) In\u00a0[3]: Copied! <pre># === Load ID and OOD data ===\nbatch_size = 128\n\n# 1a- Load in-distribution dataset: CIFAR-10\nds_fit = OODDataset(\"cifar10\", load_kwargs={\"split\": \"train\"}, input_key=\"image\")\nds_in = OODDataset(\"cifar10\", load_kwargs={\"split\": \"test\"}, input_key=\"image\")\n\n# 1b- Load out-of-distribution dataset: SVHN\nds_out = OODDataset(\"svhn_cropped\", load_kwargs={\"split\": \"test\"})\n\n\n# 2- prepare data (preprocess, shuffle, batch)\ndef preprocess_fn(*inputs):\n    x = inputs[0] / 255\n    return tuple([x] + list(inputs[1:]))\n\n\nds_fit = ds_fit.prepare(batch_size, preprocess_fn)\nds_in = ds_in.prepare(batch_size, preprocess_fn)\nds_out = ds_out.prepare(batch_size, preprocess_fn)\n\nclear_output()\n</pre> # === Load ID and OOD data === batch_size = 128  # 1a- Load in-distribution dataset: CIFAR-10 ds_fit = OODDataset(\"cifar10\", load_kwargs={\"split\": \"train\"}, input_key=\"image\") ds_in = OODDataset(\"cifar10\", load_kwargs={\"split\": \"test\"}, input_key=\"image\")  # 1b- Load out-of-distribution dataset: SVHN ds_out = OODDataset(\"svhn_cropped\", load_kwargs={\"split\": \"test\"})   # 2- prepare data (preprocess, shuffle, batch) def preprocess_fn(*inputs):     x = inputs[0] / 255     return tuple([x] + list(inputs[1:]))   ds_fit = ds_fit.prepare(batch_size, preprocess_fn) ds_in = ds_in.prepare(batch_size, preprocess_fn) ds_out = ds_out.prepare(batch_size, preprocess_fn)  clear_output() In\u00a0[4]: Copied! <pre># === Load model ===\n# ResNet pretrained on CIFAR-10\nmodel_path_resnet_cifar10 = tf.keras.utils.get_file(\n    \"cifar10_resnet256.h5\",\n    origin=\"https://share.deel.ai/s/kram9kLpx6JwRX4/download/cifar10_resnet256.h5\",\n    cache_dir=model_path,\n    cache_subdir=\"\",\n)\nmodel = tf.keras.models.load_model(model_path_resnet_cifar10)\n\n# Evaluate model\nmodel.compile(metrics=[\"accuracy\"])\n_, accuracy = model.evaluate(ds_in)\nprint(f\"Test accuracy:\\t{accuracy:.4f}\")\n\n# penultimate features 2d visualization\nprint(\"\\n=== Penultimate features viz ===\")\nplt.figure(figsize=(4.5, 3))\nplot_2D_features(\n    model=model,\n    in_dataset=ds_in,\n    out_dataset=ds_out,\n    output_layer_id=-2,\n)\nplt.tight_layout()\nplt.show()\n</pre> # === Load model === # ResNet pretrained on CIFAR-10 model_path_resnet_cifar10 = tf.keras.utils.get_file(     \"cifar10_resnet256.h5\",     origin=\"https://share.deel.ai/s/kram9kLpx6JwRX4/download/cifar10_resnet256.h5\",     cache_dir=model_path,     cache_subdir=\"\", ) model = tf.keras.models.load_model(model_path_resnet_cifar10)  # Evaluate model model.compile(metrics=[\"accuracy\"]) _, accuracy = model.evaluate(ds_in) print(f\"Test accuracy:\\t{accuracy:.4f}\")  # penultimate features 2d visualization print(\"\\n=== Penultimate features viz ===\") plt.figure(figsize=(4.5, 3)) plot_2D_features(     model=model,     in_dataset=ds_in,     out_dataset=ds_out,     output_layer_id=-2, ) plt.tight_layout() plt.show() <pre>79/79 [==============================] - 4s 14ms/step - loss: 0.1268 - accuracy: 0.9278\nTest accuracy:\t0.9278\n\n=== Penultimate features viz ===\n</pre> In\u00a0[5]: Copied! <pre>%autoreload 2\ndetectors = {\n    \"odin\": {\n        \"class\": ODIN,\n        \"kwargs\": dict(temperature=1000),\n    },\n    \"mls\": {\n        \"class\": MLS,\n        \"kwargs\": dict(),\n    },\n    \"energy\": {\n        \"class\": Energy,\n        \"kwargs\": dict(),\n    },\n}\n\nfor d in detectors.keys():\n    print(f\"=== {d.upper()} ===\")\n\n    for use_ash in [False, True]:\n        print([\"~ Without\", \"~ With\"][int(use_ash)] + \" ASH ~\")\n        # === ood scores ===\n        d_kwargs = detectors[d][\"kwargs\"]\n        d_kwargs.update(dict(\n            use_ash=use_ash,\n            ash_percentile=0.90,\n        ))\n        detector = detectors[d][\"class\"](**d_kwargs)\n        detector.fit(model)\n        scores_in, _ = detector.score(ds_in)\n        scores_out, _ = detector.score(ds_out)\n\n        # === metrics ===\n        # auroc / fpr95\n        metrics = bench_metrics(\n            (scores_in, scores_out),\n            metrics=[\"auroc\", \"fpr95tpr\"],\n        )\n        for k, v in metrics.items():\n            print(f\"{k:&lt;10} {v:.6f}\")\n\n        # hists / roc\n        plt.figure(figsize=(9, 3))\n        plt.subplot(121)\n        plot_ood_scores(scores_in, scores_out)\n        plt.subplot(122)\n        plot_roc_curve(scores_in, scores_out)\n        plt.tight_layout()\n        plt.show()\n</pre> %autoreload 2 detectors = {     \"odin\": {         \"class\": ODIN,         \"kwargs\": dict(temperature=1000),     },     \"mls\": {         \"class\": MLS,         \"kwargs\": dict(),     },     \"energy\": {         \"class\": Energy,         \"kwargs\": dict(),     }, }  for d in detectors.keys():     print(f\"=== {d.upper()} ===\")      for use_ash in [False, True]:         print([\"~ Without\", \"~ With\"][int(use_ash)] + \" ASH ~\")         # === ood scores ===         d_kwargs = detectors[d][\"kwargs\"]         d_kwargs.update(dict(             use_ash=use_ash,             ash_percentile=0.90,         ))         detector = detectors[d][\"class\"](**d_kwargs)         detector.fit(model)         scores_in, _ = detector.score(ds_in)         scores_out, _ = detector.score(ds_out)          # === metrics ===         # auroc / fpr95         metrics = bench_metrics(             (scores_in, scores_out),             metrics=[\"auroc\", \"fpr95tpr\"],         )         for k, v in metrics.items():             print(f\"{k:&lt;10} {v:.6f}\")          # hists / roc         plt.figure(figsize=(9, 3))         plt.subplot(121)         plot_ood_scores(scores_in, scores_out)         plt.subplot(122)         plot_roc_curve(scores_in, scores_out)         plt.tight_layout()         plt.show() <pre>=== ODIN ===\n~ Without ASH ~\nauroc      0.950493\nfpr95tpr   0.151200\n</pre> <pre>~ With ASH ~\nauroc      0.976817\nfpr95tpr   0.087200\n</pre> <pre>=== MLS ===\n~ Without ASH ~\nauroc      0.915857\nfpr95tpr   0.205700\n</pre> <pre>~ With ASH ~\nauroc      0.982385\nfpr95tpr   0.084700\n</pre> <pre>=== ENERGY ===\n~ Without ASH ~\nauroc      0.909186\nfpr95tpr   0.206900\n</pre> <pre>~ With ASH ~\nauroc      0.982398\nfpr95tpr   0.084600\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"notebooks/tensorflow/demo_ash_tf/#ash-method","title":"ASH method\u00b6","text":"<p>This notebook aims at evaluating the ASH method.</p> <p>ASH method basically consists in re-using existing logit-based OOD methods, but with penultimate layer activations scaled and pruned. Let $a$ be the activation vector, and $P_p(a)$ the $p$-th percentile of $a$'s values. The scaling is computed using the formula $$ s = \\exp(\\frac{\\sum_{i} a_i}{\\sum_{a_i &gt; P_p(a)} a_i}) $$ The activation is pruned for values $a_i \\leq P_p(a)$.</p> <p>Here, we focus on a Resnet trained on CIFAR10, challenged on SVHN.</p> <p>Reference Extremely Simple Activation Shaping for Out-of-Distribution Detection, ICLR 2023 http://arxiv.org/abs/2209.09858</p>"},{"location":"notebooks/tensorflow/demo_ash_tf/#imports","title":"Imports\u00b6","text":""},{"location":"notebooks/tensorflow/demo_ash_tf/#data-loading","title":"Data loading\u00b6","text":"<ul> <li>In-distribution data: CIFAR-10</li> <li>Out-of-distribution data: SVHN</li> </ul> <p>Note: We denote In-Distribution (ID) data with <code>_in</code> and Out-Of-Distribution (OOD) data with <code>_out</code> to avoid confusion with OOD detection which is the name of the task, and is therefore used to denote core classes such as <code>OODDataset</code> and <code>OODBaseDetector</code>.</p>"},{"location":"notebooks/tensorflow/demo_ash_tf/#model-training","title":"Model training\u00b6","text":"<p>Now let's train a simple model on MNIST[0-4] using <code>train_tf_model</code> function.</p>"},{"location":"notebooks/tensorflow/demo_ash_tf/#ash-scores","title":"ASH scores\u00b6","text":"<p>We now fit some OOD detectors using ASH + [MLS, Energy, ODIN] with MNIST[0-4] train dataset, and compare OOD scores returned for MNIST[0-4] (ID) and MNIST[5-9] (OOD) test datasets.</p>"},{"location":"notebooks/tensorflow/demo_dknn_tf/","title":"DKNN","text":"In\u00a0[1]: Copied! <pre>%load_ext autoreload\n\nimport os\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\" \n\nfrom IPython.display import clear_output\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n\nfrom oodeel.methods import DKNN\nfrom oodeel.eval.metrics import bench_metrics\nfrom oodeel.eval.plots import plot_ood_scores, plot_roc_curve, plot_2D_features\nfrom oodeel.datasets import OODDataset\nfrom oodeel.utils.tf_training_tools import train_tf_model\n</pre> %load_ext autoreload  import os os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"   from IPython.display import clear_output import tensorflow as tf import matplotlib.pyplot as plt  from oodeel.methods import DKNN from oodeel.eval.metrics import bench_metrics from oodeel.eval.plots import plot_ood_scores, plot_roc_curve, plot_2D_features from oodeel.datasets import OODDataset from oodeel.utils.tf_training_tools import train_tf_model <p>Note that models are saved at ~/.oodeel/saved_models and data is supposed to be found at ~/.oodeel/datasets by default. Change the following cell for a custom path.</p> In\u00a0[2]: Copied! <pre>model_path = os.path.expanduser(\"~/\") + \".oodeel/saved_models\"\ndata_path = os.path.expanduser(\"~/\") + \".oodeel/datasets\"\nos.makedirs(model_path, exist_ok=True)\nos.makedirs(data_path, exist_ok=True)\n</pre> model_path = os.path.expanduser(\"~/\") + \".oodeel/saved_models\" data_path = os.path.expanduser(\"~/\") + \".oodeel/datasets\" os.makedirs(model_path, exist_ok=True) os.makedirs(data_path, exist_ok=True) In\u00a0[3]: Copied! <pre># === Load ID and OOD data ===\nbatch_size = 128\nin_labels = [0, 1, 2, 3, 4]\n\n# 1- Load train/test MNIST dataset\nds_train = OODDataset(\"mnist\", load_kwargs=dict(split=\"train\"))\ndata_test = OODDataset(\"mnist\", load_kwargs=dict(split=\"test\"))\n\n# 2- Split ID / OOD data depending on label value:\n# in-distribution: MNIST[0-4] / out-of-distribution: MNIST[5-9]\nds_train, _ = ds_train.split_by_class(in_labels)\noods_in, oods_out = data_test.split_by_class(in_labels)\n\n\n# 3- Prepare data (preprocess, shuffle, batch)\ndef preprocess_fn(*inputs):\n    x = inputs[0] / 255\n    return tuple([x] + list(inputs[1:]))\n\n\nds_train = ds_train.prepare(batch_size, preprocess_fn, shuffle=True)\nds_in = oods_in.prepare(batch_size, preprocess_fn, with_ood_labels=False)\nds_out = oods_out.prepare(batch_size, preprocess_fn, with_ood_labels=False)\n\nclear_output()\n</pre> # === Load ID and OOD data === batch_size = 128 in_labels = [0, 1, 2, 3, 4]  # 1- Load train/test MNIST dataset ds_train = OODDataset(\"mnist\", load_kwargs=dict(split=\"train\")) data_test = OODDataset(\"mnist\", load_kwargs=dict(split=\"test\"))  # 2- Split ID / OOD data depending on label value: # in-distribution: MNIST[0-4] / out-of-distribution: MNIST[5-9] ds_train, _ = ds_train.split_by_class(in_labels) oods_in, oods_out = data_test.split_by_class(in_labels)   # 3- Prepare data (preprocess, shuffle, batch) def preprocess_fn(*inputs):     x = inputs[0] / 255     return tuple([x] + list(inputs[1:]))   ds_train = ds_train.prepare(batch_size, preprocess_fn, shuffle=True) ds_in = oods_in.prepare(batch_size, preprocess_fn, with_ood_labels=False) ds_out = oods_out.prepare(batch_size, preprocess_fn, with_ood_labels=False)  clear_output() In\u00a0[4]: Copied! <pre># === Train / Load model ===\nmodel_path_mnist_04 = os.path.join(model_path, \"mnist_model_0-4.h5\")\n\ntry:\n    # if the model exists, load it\n    model = tf.keras.models.load_model(model_path_mnist_04)\nexcept OSError:\n    # else, train a new model\n    train_config = {\n        \"model\": \"toy_convnet\",\n        \"input_shape\": (28, 28, 1),\n        \"num_classes\": 10,\n        \"batch_size\": 128,\n        \"epochs\": 5,\n        \"save_dir\": model_path_mnist_04,\n        \"validation_data\": ds_in,\n    }\n\n    model = train_tf_model(ds_train, **train_config)\n\n_, accuracy = model.evaluate(ds_in)\nprint(f\"Test accuracy:\\t{accuracy:.4f}\")\n\n# penultimate features 2d visualization\nprint(\"\\n=== Penultimate features viz ===\")\nplt.figure(figsize=(4.5, 3))\nplot_2D_features(\n    model=model,\n    in_dataset=ds_in,\n    out_dataset=ds_out,\n    output_layer_id=-2,\n)\nplt.tight_layout()\nplt.show()\n</pre> # === Train / Load model === model_path_mnist_04 = os.path.join(model_path, \"mnist_model_0-4.h5\")  try:     # if the model exists, load it     model = tf.keras.models.load_model(model_path_mnist_04) except OSError:     # else, train a new model     train_config = {         \"model\": \"toy_convnet\",         \"input_shape\": (28, 28, 1),         \"num_classes\": 10,         \"batch_size\": 128,         \"epochs\": 5,         \"save_dir\": model_path_mnist_04,         \"validation_data\": ds_in,     }      model = train_tf_model(ds_train, **train_config)  _, accuracy = model.evaluate(ds_in) print(f\"Test accuracy:\\t{accuracy:.4f}\")  # penultimate features 2d visualization print(\"\\n=== Penultimate features viz ===\") plt.figure(figsize=(4.5, 3)) plot_2D_features(     model=model,     in_dataset=ds_in,     out_dataset=ds_out,     output_layer_id=-2, ) plt.tight_layout() plt.show() <pre>41/41 [==============================] - 2s 11ms/step - loss: 0.0118 - accuracy: 0.9965\nTest accuracy:\t0.9965\n\n=== Penultimate features viz ===\n</pre> In\u00a0[5]: Copied! <pre># === DKNN scores ===\ndknn = DKNN(nearest=50)\ndknn.fit(model, feature_layers_id=[-2], fit_dataset=ds_train)\nscores_in, _ = dknn.score(ds_in)\nscores_out, _ = dknn.score(ds_out)\n\n# === metrics ===\n# auroc / fpr95\nmetrics = bench_metrics(\n    (scores_in, scores_out),\n    metrics=[\"auroc\", \"fpr95tpr\"],\n)\nprint(\"=== Metrics ===\")\nfor k, v in metrics.items():\n    print(f\"{k:&lt;10} {v:.6f}\")\n\nprint(\"\\n=== Plots ===\")\n# hists / roc\nplt.figure(figsize=(9, 3))\nplt.subplot(121)\nplot_ood_scores(scores_in, scores_out, log_scale=False)\nplt.subplot(122)\nplot_roc_curve(scores_in, scores_out)\nplt.tight_layout()\nplt.show()\n</pre> # === DKNN scores === dknn = DKNN(nearest=50) dknn.fit(model, feature_layers_id=[-2], fit_dataset=ds_train) scores_in, _ = dknn.score(ds_in) scores_out, _ = dknn.score(ds_out)  # === metrics === # auroc / fpr95 metrics = bench_metrics(     (scores_in, scores_out),     metrics=[\"auroc\", \"fpr95tpr\"], ) print(\"=== Metrics ===\") for k, v in metrics.items():     print(f\"{k:&lt;10} {v:.6f}\")  print(\"\\n=== Plots ===\") # hists / roc plt.figure(figsize=(9, 3)) plt.subplot(121) plot_ood_scores(scores_in, scores_out, log_scale=False) plt.subplot(122) plot_roc_curve(scores_in, scores_out) plt.tight_layout() plt.show() <pre>=== Metrics ===\nauroc      0.974605\nfpr95tpr   0.091652\n\n=== Plots ===\n</pre> In\u00a0[6]: Copied! <pre># === Load ID and OOD data ===\nbatch_size = 128\n\n# 1a- Load in-distribution dataset: CIFAR-10\nds_fit = OODDataset(\"cifar10\", load_kwargs={\"split\": \"train\"}, input_key=\"image\")\nds_in = OODDataset(\"cifar10\", load_kwargs={\"split\": \"test\"}, input_key=\"image\")\n\n# 1b- Load out-of-distribution dataset: SVHN\nds_out = OODDataset(\"svhn_cropped\", load_kwargs={\"split\": \"test\"})\n\n\n# 2- prepare data (preprocess, shuffle, batch)\ndef preprocess_fn(*inputs):\n    x = inputs[0] / 255\n    return tuple([x] + list(inputs[1:]))\n\n\nds_fit = ds_fit.prepare(batch_size, preprocess_fn)\nds_in = ds_in.prepare(batch_size, preprocess_fn)\nds_out = ds_out.prepare(batch_size, preprocess_fn)\n</pre> # === Load ID and OOD data === batch_size = 128  # 1a- Load in-distribution dataset: CIFAR-10 ds_fit = OODDataset(\"cifar10\", load_kwargs={\"split\": \"train\"}, input_key=\"image\") ds_in = OODDataset(\"cifar10\", load_kwargs={\"split\": \"test\"}, input_key=\"image\")  # 1b- Load out-of-distribution dataset: SVHN ds_out = OODDataset(\"svhn_cropped\", load_kwargs={\"split\": \"test\"})   # 2- prepare data (preprocess, shuffle, batch) def preprocess_fn(*inputs):     x = inputs[0] / 255     return tuple([x] + list(inputs[1:]))   ds_fit = ds_fit.prepare(batch_size, preprocess_fn) ds_in = ds_in.prepare(batch_size, preprocess_fn) ds_out = ds_out.prepare(batch_size, preprocess_fn) In\u00a0[7]: Copied! <pre># === Load model ===\n# ResNet pretrained on CIFAR-10\nmodel_path_resnet_cifar10 = tf.keras.utils.get_file(\n    \"cifar10_resnet256.h5\",\n    origin=\"https://share.deel.ai/s/kram9kLpx6JwRX4/download/cifar10_resnet256.h5\",\n    cache_dir=model_path,\n    cache_subdir=\"\",\n)\nmodel = tf.keras.models.load_model(model_path_resnet_cifar10)\n\n# Evaluate model\nmodel.compile(metrics=[\"accuracy\"])\n_, accuracy = model.evaluate(ds_in)\nprint(f\"Test accuracy:\\t{accuracy:.4f}\")\n\n# penultimate features 2d visualization\nprint(\"\\n=== Penultimate features viz ===\")\nplt.figure(figsize=(4.5, 3))\nplot_2D_features(\n    model=model,\n    in_dataset=ds_in,\n    out_dataset=ds_out,\n    output_layer_id=-2,\n)\nplt.tight_layout()\nplt.show()\n</pre> # === Load model === # ResNet pretrained on CIFAR-10 model_path_resnet_cifar10 = tf.keras.utils.get_file(     \"cifar10_resnet256.h5\",     origin=\"https://share.deel.ai/s/kram9kLpx6JwRX4/download/cifar10_resnet256.h5\",     cache_dir=model_path,     cache_subdir=\"\", ) model = tf.keras.models.load_model(model_path_resnet_cifar10)  # Evaluate model model.compile(metrics=[\"accuracy\"]) _, accuracy = model.evaluate(ds_in) print(f\"Test accuracy:\\t{accuracy:.4f}\")  # penultimate features 2d visualization print(\"\\n=== Penultimate features viz ===\") plt.figure(figsize=(4.5, 3)) plot_2D_features(     model=model,     in_dataset=ds_in,     out_dataset=ds_out,     output_layer_id=-2, ) plt.tight_layout() plt.show() <pre>79/79 [==============================] - 3s 26ms/step - loss: 0.1268 - accuracy: 0.9276\nTest accuracy:\t0.9276\n\n=== Penultimate features viz ===\n</pre> In\u00a0[8]: Copied! <pre># === DKNN scores ===\ndknn = DKNN(nearest=50)\ndknn.fit(model, feature_layers_id=[-2], fit_dataset=ds_fit)\nscores_in, _ = dknn.score(ds_in)\nscores_out, _ = dknn.score(ds_out)\n\n# === metrics ===\n# auroc / fpr95\nmetrics = bench_metrics(\n    (scores_in, scores_out),\n    metrics=[\"auroc\", \"fpr95tpr\"],\n)\nprint(\"=== Metrics ===\")\nfor k, v in metrics.items():\n    print(f\"{k:&lt;10} {v:.6f}\")\n\nprint(\"\\n=== Plots ===\")\n# hists / roc\nplt.figure(figsize=(9, 3))\nplt.subplot(121)\nplot_ood_scores(scores_in, scores_out, log_scale=False)\nplt.subplot(122)\nplot_roc_curve(scores_in, scores_out)\nplt.tight_layout()\nplt.show()\n</pre> # === DKNN scores === dknn = DKNN(nearest=50) dknn.fit(model, feature_layers_id=[-2], fit_dataset=ds_fit) scores_in, _ = dknn.score(ds_in) scores_out, _ = dknn.score(ds_out)  # === metrics === # auroc / fpr95 metrics = bench_metrics(     (scores_in, scores_out),     metrics=[\"auroc\", \"fpr95tpr\"], ) print(\"=== Metrics ===\") for k, v in metrics.items():     print(f\"{k:&lt;10} {v:.6f}\")  print(\"\\n=== Plots ===\") # hists / roc plt.figure(figsize=(9, 3)) plt.subplot(121) plot_ood_scores(scores_in, scores_out, log_scale=False) plt.subplot(122) plot_roc_curve(scores_in, scores_out) plt.tight_layout() plt.show() <pre>=== Metrics ===\nauroc      0.993147\nfpr95tpr   0.034300\n\n=== Plots ===\n</pre>"},{"location":"notebooks/tensorflow/demo_dknn_tf/#deep-knn-method","title":"Deep KNN method\u00b6","text":"<p>This notebook aims at evaluating the DKNN method.</p> <p>The method consists in performing K-Nearest-Neighbors in the feature space of a neural network trained on the in-distribution dataset.</p> <p>Here, we focus on a toy convolutional network trained on MNIST[0-4] and a ResNet model trained on CIFAR-10, respectively challenged on MNIST[5-9] and SVHN OOD datasets.</p> <p>Reference Out-of-Distribution Detection with Deep Nearest Neighbors, ICML 2022.</p>"},{"location":"notebooks/tensorflow/demo_dknn_tf/#imports","title":"Imports\u00b6","text":""},{"location":"notebooks/tensorflow/demo_dknn_tf/#first-experiment-mnist0-4-vs-mnist5-9","title":"First experiment: MNIST[0-4] vs MNIST[5-9]\u00b6","text":"<p>For this first experiment, we train a toy convolutional network on the MNIST dataset restricted to digits 0 to 4. After fitting the train subset of this dataset to the DKNN method, we will compare the scores returned for MNIST[0-4] (in-distribution) and MNIST[5-9] (out-of-distribution) test subsets.</p>"},{"location":"notebooks/tensorflow/demo_dknn_tf/#data-loading","title":"Data loading\u00b6","text":"<ul> <li>In-distribution data: MNIST[0-4]</li> <li>Out-of-distribution data: MNIST[5-9]</li> </ul> <p>Note: We denote In-Distribution (ID) data with <code>_in</code> and Out-Of-Distribution (OOD) data with <code>_out</code> to avoid confusion with OOD detection which is the name of the task, and is therefore used to denote core classes such as <code>OODDataset</code> and <code>OODBaseDetector</code>.</p>"},{"location":"notebooks/tensorflow/demo_dknn_tf/#model-training","title":"Model training\u00b6","text":"<p>Now let's train a simple model on MNIST[0-4] using <code>train_tf_model</code> function.</p>"},{"location":"notebooks/tensorflow/demo_dknn_tf/#dknn-score","title":"DKNN score\u00b6","text":"<p>We now fit a DKNN detector with MNIST[0-4] train dataset, and compare OOD scores returned for MNIST[0-4] (ID) and MNIST[5-9] (OOD) test datasets.</p>"},{"location":"notebooks/tensorflow/demo_dknn_tf/#second-experiment-cifar-10-vs-svhn","title":"Second experiment: CIFAR-10 vs SVHN\u00b6","text":"<p>For this second experiment, we oppose CIFAR-10 (in-distribution dataset) to SVHN (out-of-distribution dataset).</p>"},{"location":"notebooks/tensorflow/demo_dknn_tf/#data-loading","title":"Data loading\u00b6","text":"<ul> <li>In-distribution data: CIFAR-10</li> <li>Out-of-distribution data: SVHN</li> </ul>"},{"location":"notebooks/tensorflow/demo_dknn_tf/#model-loading","title":"Model loading\u00b6","text":"<p>The model is a ResNet pretrained on CIFAR-10 and getting an accuracy score of 92.75%.</p>"},{"location":"notebooks/tensorflow/demo_dknn_tf/#dknn-score","title":"DKNN score\u00b6","text":"<p>We now fit a DKNN detector with CIFAR-10 train dataset, and compare OOD scores returned for CIFAR-10 (ID) and SVHN (OOD) test datasets.</p>"},{"location":"notebooks/tensorflow/demo_energy_tf/","title":"Energy","text":"In\u00a0[1]: Copied! <pre>%load_ext autoreload\n\nimport os\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\" \n\nfrom IPython.display import clear_output\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n\nfrom oodeel.methods import Energy\nfrom oodeel.eval.metrics import bench_metrics\nfrom oodeel.eval.plots import plot_ood_scores, plot_roc_curve, plot_2D_features\nfrom oodeel.datasets import OODDataset\nfrom oodeel.utils.tf_training_tools import train_tf_model\n</pre> %load_ext autoreload  import os os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"   from IPython.display import clear_output import tensorflow as tf import matplotlib.pyplot as plt  from oodeel.methods import Energy from oodeel.eval.metrics import bench_metrics from oodeel.eval.plots import plot_ood_scores, plot_roc_curve, plot_2D_features from oodeel.datasets import OODDataset from oodeel.utils.tf_training_tools import train_tf_model <p>Note that models are saved at ~/.oodeel/saved_models and data is supposed to be found at ~/.oodeel/datasets by default. Change the following cell for a custom path.</p> In\u00a0[2]: Copied! <pre>model_path = os.path.expanduser(\"~/\") + \".oodeel/saved_models\"\ndata_path = os.path.expanduser(\"~/\") + \".oodeel/datasets\"\nos.makedirs(model_path, exist_ok=True)\nos.makedirs(data_path, exist_ok=True)\n</pre> model_path = os.path.expanduser(\"~/\") + \".oodeel/saved_models\" data_path = os.path.expanduser(\"~/\") + \".oodeel/datasets\" os.makedirs(model_path, exist_ok=True) os.makedirs(data_path, exist_ok=True) In\u00a0[3]: Copied! <pre># === Load ID and OOD data ===\nbatch_size = 128\nin_labels = [0, 1, 2, 3, 4]\n\n# 1- Load train/test MNIST dataset\nds_train = OODDataset(\"mnist\", load_kwargs=dict(split=\"train\"))\ndata_test = OODDataset(\"mnist\", load_kwargs=dict(split=\"test\"))\n\n# 2- Split ID / OOD data depending on label value:\n# in-distribution: MNIST[0-4] / out-of-distribution: MNIST[5-9]\nds_train, _ = ds_train.split_by_class(in_labels)\noods_in, oods_out = data_test.split_by_class(in_labels)\n\n\n# 3- Prepare data (preprocess, shuffle, batch)\ndef preprocess_fn(*inputs):\n    x = inputs[0] / 255\n    return tuple([x] + list(inputs[1:]))\n\n\nds_train = ds_train.prepare(batch_size, preprocess_fn, shuffle=True)\nds_in = oods_in.prepare(batch_size, preprocess_fn, with_ood_labels=False)\nds_out = oods_out.prepare(batch_size, preprocess_fn, with_ood_labels=False)\n\nclear_output()\n</pre> # === Load ID and OOD data === batch_size = 128 in_labels = [0, 1, 2, 3, 4]  # 1- Load train/test MNIST dataset ds_train = OODDataset(\"mnist\", load_kwargs=dict(split=\"train\")) data_test = OODDataset(\"mnist\", load_kwargs=dict(split=\"test\"))  # 2- Split ID / OOD data depending on label value: # in-distribution: MNIST[0-4] / out-of-distribution: MNIST[5-9] ds_train, _ = ds_train.split_by_class(in_labels) oods_in, oods_out = data_test.split_by_class(in_labels)   # 3- Prepare data (preprocess, shuffle, batch) def preprocess_fn(*inputs):     x = inputs[0] / 255     return tuple([x] + list(inputs[1:]))   ds_train = ds_train.prepare(batch_size, preprocess_fn, shuffle=True) ds_in = oods_in.prepare(batch_size, preprocess_fn, with_ood_labels=False) ds_out = oods_out.prepare(batch_size, preprocess_fn, with_ood_labels=False)  clear_output() In\u00a0[4]: Copied! <pre># === Train / Load model ===\nmodel_path_mnist_04 = os.path.join(model_path, \"mnist_model_0-4.h5\")\n\ntry:\n    # if the model exists, load it\n    model = tf.keras.models.load_model(model_path_mnist_04)\nexcept OSError:\n    # else, train a new model\n    train_config = {\n        \"model\": \"toy_convnet\",\n        \"input_shape\": (28, 28, 1),\n        \"num_classes\": 10,\n        \"batch_size\": 128,\n        \"epochs\": 5,\n        \"save_dir\": model_path_mnist_04,\n        \"validation_data\": ds_in,\n    }\n\n    model = train_tf_model(ds_train, **train_config)\n\n_, accuracy = model.evaluate(ds_in)\nprint(f\"Test accuracy:\\t{accuracy:.4f}\")\n\n# penultimate features 2d visualization\nprint(\"\\n=== Penultimate features viz ===\")\nplt.figure(figsize=(4.5, 3))\nplot_2D_features(\n    model=model,\n    in_dataset=ds_in,\n    out_dataset=ds_out,\n    output_layer_id=-2,\n)\nplt.tight_layout()\nplt.show()\n</pre> # === Train / Load model === model_path_mnist_04 = os.path.join(model_path, \"mnist_model_0-4.h5\")  try:     # if the model exists, load it     model = tf.keras.models.load_model(model_path_mnist_04) except OSError:     # else, train a new model     train_config = {         \"model\": \"toy_convnet\",         \"input_shape\": (28, 28, 1),         \"num_classes\": 10,         \"batch_size\": 128,         \"epochs\": 5,         \"save_dir\": model_path_mnist_04,         \"validation_data\": ds_in,     }      model = train_tf_model(ds_train, **train_config)  _, accuracy = model.evaluate(ds_in) print(f\"Test accuracy:\\t{accuracy:.4f}\")  # penultimate features 2d visualization print(\"\\n=== Penultimate features viz ===\") plt.figure(figsize=(4.5, 3)) plot_2D_features(     model=model,     in_dataset=ds_in,     out_dataset=ds_out,     output_layer_id=-2, ) plt.tight_layout() plt.show() <pre>41/41 [==============================] - 2s 41ms/step - loss: 0.0135 - accuracy: 0.9955\nTest accuracy:\t0.9955\n\n=== Penultimate features viz ===\n</pre> In\u00a0[5]: Copied! <pre># === Energy OOD scores ===\nenergy = Energy()\nenergy.fit(model)\nscores_in, _ = energy.score(ds_in)\nscores_out, _ = energy.score(ds_out)\n\n# === metrics ===\n# auroc / fpr95\nmetrics = bench_metrics(\n    (scores_in, scores_out),\n    metrics=[\"auroc\", \"fpr95tpr\"],\n)\nprint(\"=== Metrics ===\")\nfor k, v in metrics.items():\n    print(f\"{k:&lt;10} {v:.6f}\")\n\nprint(\"\\n=== Plots ===\")\n# hists / roc\nplt.figure(figsize=(9, 3))\nplt.subplot(121)\nplot_ood_scores(scores_in, scores_out, log_scale=False)\nplt.subplot(122)\nplot_roc_curve(scores_in, scores_out)\nplt.tight_layout()\nplt.show()\n</pre> # === Energy OOD scores === energy = Energy() energy.fit(model) scores_in, _ = energy.score(ds_in) scores_out, _ = energy.score(ds_out)  # === metrics === # auroc / fpr95 metrics = bench_metrics(     (scores_in, scores_out),     metrics=[\"auroc\", \"fpr95tpr\"], ) print(\"=== Metrics ===\") for k, v in metrics.items():     print(f\"{k:&lt;10} {v:.6f}\")  print(\"\\n=== Plots ===\") # hists / roc plt.figure(figsize=(9, 3)) plt.subplot(121) plot_ood_scores(scores_in, scores_out, log_scale=False) plt.subplot(122) plot_roc_curve(scores_in, scores_out) plt.tight_layout() plt.show() <pre>=== Metrics ===\nauroc      0.914771\nfpr95tpr   0.479082\n\n=== Plots ===\n</pre> In\u00a0[6]: Copied! <pre># === Load ID and OOD data ===\nbatch_size = 128\n\n# 1a- Load in-distribution dataset: CIFAR-10\nds_in = OODDataset(\"cifar10\", load_kwargs={\"split\": \"test\"}, input_key=\"image\")\n\n# 1b- Load out-of-distribution dataset: SVHN\nds_out = OODDataset(\"svhn_cropped\", load_kwargs={\"split\": \"test\"})\n\n\n# 2- prepare data (preprocess, shuffle, batch)\ndef preprocess_fn(*inputs):\n    x = inputs[0] / 255\n    return tuple([x] + list(inputs[1:]))\n\n\nds_in = ds_in.prepare(batch_size, preprocess_fn)\nds_out = ds_out.prepare(batch_size, preprocess_fn)\n</pre> # === Load ID and OOD data === batch_size = 128  # 1a- Load in-distribution dataset: CIFAR-10 ds_in = OODDataset(\"cifar10\", load_kwargs={\"split\": \"test\"}, input_key=\"image\")  # 1b- Load out-of-distribution dataset: SVHN ds_out = OODDataset(\"svhn_cropped\", load_kwargs={\"split\": \"test\"})   # 2- prepare data (preprocess, shuffle, batch) def preprocess_fn(*inputs):     x = inputs[0] / 255     return tuple([x] + list(inputs[1:]))   ds_in = ds_in.prepare(batch_size, preprocess_fn) ds_out = ds_out.prepare(batch_size, preprocess_fn) In\u00a0[7]: Copied! <pre># === Load model ===\n# ResNet pretrained on CIFAR-10\nmodel_path_resnet_cifar10 = tf.keras.utils.get_file(\n    \"cifar10_resnet256.h5\",\n    origin=\"https://share.deel.ai/s/kram9kLpx6JwRX4/download/cifar10_resnet256.h5\",\n    cache_dir=model_path,\n    cache_subdir=\"\",\n)\nmodel = tf.keras.models.load_model(model_path_resnet_cifar10)\n\n# Evaluate model\nmodel.compile(metrics=[\"accuracy\"])\n_, accuracy = model.evaluate(ds_in)\nprint(f\"Test accuracy:\\t{accuracy:.4f}\")\n\n# penultimate features 2d visualization\nprint(\"\\n=== Penultimate features viz ===\")\nplt.figure(figsize=(4.5, 3))\nplot_2D_features(\n    model=model,\n    in_dataset=ds_in,\n    out_dataset=ds_out,\n    output_layer_id=-2,\n)\nplt.tight_layout()\nplt.show()\n</pre> # === Load model === # ResNet pretrained on CIFAR-10 model_path_resnet_cifar10 = tf.keras.utils.get_file(     \"cifar10_resnet256.h5\",     origin=\"https://share.deel.ai/s/kram9kLpx6JwRX4/download/cifar10_resnet256.h5\",     cache_dir=model_path,     cache_subdir=\"\", ) model = tf.keras.models.load_model(model_path_resnet_cifar10)  # Evaluate model model.compile(metrics=[\"accuracy\"]) _, accuracy = model.evaluate(ds_in) print(f\"Test accuracy:\\t{accuracy:.4f}\")  # penultimate features 2d visualization print(\"\\n=== Penultimate features viz ===\") plt.figure(figsize=(4.5, 3)) plot_2D_features(     model=model,     in_dataset=ds_in,     out_dataset=ds_out,     output_layer_id=-2, ) plt.tight_layout() plt.show() <pre>79/79 [==============================] - 26s 289ms/step - loss: 0.1268 - accuracy: 0.9276\nTest accuracy:\t0.9276\n\n=== Penultimate features viz ===\n</pre> In\u00a0[8]: Copied! <pre># === Energy OOD scores ===\nenergy = Energy()\nenergy.fit(model)\nscores_in, _ = energy.score(ds_in)\nscores_out, _ = energy.score(ds_out)\n\n# === metrics ===\n# auroc / fpr95\nmetrics = bench_metrics(\n    (scores_in, scores_out),\n    metrics=[\"auroc\", \"fpr95tpr\"],\n)\nprint(\"=== Metrics ===\")\nfor k, v in metrics.items():\n    print(f\"{k:&lt;10} {v:.6f}\")\n\nprint(\"\\n=== Plots ===\")\n# hists / roc\nplt.figure(figsize=(9, 3))\nplt.subplot(121)\nplot_ood_scores(scores_in, scores_out, log_scale=False)\nplt.subplot(122)\nplot_roc_curve(scores_in, scores_out)\nplt.tight_layout()\nplt.show()\n</pre> # === Energy OOD scores === energy = Energy() energy.fit(model) scores_in, _ = energy.score(ds_in) scores_out, _ = energy.score(ds_out)  # === metrics === # auroc / fpr95 metrics = bench_metrics(     (scores_in, scores_out),     metrics=[\"auroc\", \"fpr95tpr\"], ) print(\"=== Metrics ===\") for k, v in metrics.items():     print(f\"{k:&lt;10} {v:.6f}\")  print(\"\\n=== Plots ===\") # hists / roc plt.figure(figsize=(9, 3)) plt.subplot(121) plot_ood_scores(scores_in, scores_out, log_scale=False) plt.subplot(122) plot_roc_curve(scores_in, scores_out) plt.tight_layout() plt.show() <pre>=== Metrics ===\nauroc      0.909189\nfpr95tpr   0.206900\n\n=== Plots ===\n</pre>"},{"location":"notebooks/tensorflow/demo_energy_tf/#energy-method","title":"Energy method\u00b6","text":"<p>This notebook aims at evaluating the Energy method.</p> <p>The method consists in using the energy of the input data computed using the energy $-\\log \\sum_{c=0}^C \\exp(l_c)$ computed using the logits $l_c$ such that $\\text{model}(x)=(l_{c})_{c=1}^{C}$.</p> <p>Here, we focus on a toy convolutional network trained on MNIST[0-4] and a ResNet model trained on CIFAR-10, respectively challenged on MNIST[5-9] and SVHN OOD datasets.</p> <p>Reference Energy-based Out-of-distribution Detection, Neurips 2020.</p>"},{"location":"notebooks/tensorflow/demo_energy_tf/#imports","title":"Imports\u00b6","text":""},{"location":"notebooks/tensorflow/demo_energy_tf/#first-experiment-mnist0-4-vs-mnist5-9","title":"First experiment: MNIST[0-4] vs MNIST[5-9]\u00b6","text":"<p>For this first experiment, we train a toy convolutional network on the MNIST dataset restricted to digits 0 to 4. After fitting the train subset of this dataset to the Energy method, we will compare the scores returned for MNIST[0-4] (in-distribution) and MNIST[5-9] (out-of-distribution) test subsets.</p>"},{"location":"notebooks/tensorflow/demo_energy_tf/#data-loading","title":"Data loading\u00b6","text":"<ul> <li>In-distribution data: MNIST[0-4]</li> <li>Out-of-distribution data: MNIST[5-9]</li> </ul> <p>Note: We denote In-Distribution (ID) data with <code>_in</code> and Out-Of-Distribution (OOD) data with <code>_out</code> to avoid confusion with OOD detection which is the name of the task, and is therefore used to denote core classes such as <code>OODDataset</code> and <code>OODBaseDetector</code>.</p>"},{"location":"notebooks/tensorflow/demo_energy_tf/#model-training","title":"Model training\u00b6","text":"<p>Now let's train a simple model on MNIST[0-4] using <code>train_tf_model</code> function.</p>"},{"location":"notebooks/tensorflow/demo_energy_tf/#energy-ood-score","title":"Energy OOD score\u00b6","text":"<p>We now fit an Energy OOD detector with MNIST[0-4] train dataset, and compare OOD scores returned for MNIST[0-4] (ID) and MNIST[5-9] (OOD) test datasets.</p>"},{"location":"notebooks/tensorflow/demo_energy_tf/#second-experiment-cifar-10-vs-svhn","title":"Second experiment: CIFAR-10 vs SVHN\u00b6","text":"<p>For this second experiment, we oppose CIFAR-10 (in-distribution dataset) to SVHN (out-of-distribution dataset).</p>"},{"location":"notebooks/tensorflow/demo_energy_tf/#data-loading","title":"Data loading\u00b6","text":"<ul> <li>In-distribution data: CIFAR-10</li> <li>Out-of-distribution data: SVHN</li> </ul>"},{"location":"notebooks/tensorflow/demo_energy_tf/#model-loading","title":"Model loading\u00b6","text":"<p>The model is a ResNet pretrained on CIFAR-10 and getting an accuracy score of 92.75%.</p>"},{"location":"notebooks/tensorflow/demo_energy_tf/#energy-ood-score","title":"Energy OOD score\u00b6","text":"<p>We now fit an Energy OOD detector with CIFAR-10 train dataset, and compare OOD scores returned for CIFAR-10 (ID) and SVHN (OOD) test datasets.</p>"},{"location":"notebooks/tensorflow/demo_entropy_tf/","title":"Entropy","text":"In\u00a0[1]: Copied! <pre>%load_ext autoreload\n\nimport os\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\" \n\nfrom IPython.display import clear_output\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n\nfrom oodeel.methods import Entropy\nfrom oodeel.eval.metrics import bench_metrics\nfrom oodeel.eval.plots import plot_ood_scores, plot_roc_curve, plot_2D_features\nfrom oodeel.datasets import OODDataset\nfrom oodeel.utils.tf_training_tools import train_tf_model\n</pre> %load_ext autoreload  import os os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"   from IPython.display import clear_output import tensorflow as tf import matplotlib.pyplot as plt  from oodeel.methods import Entropy from oodeel.eval.metrics import bench_metrics from oodeel.eval.plots import plot_ood_scores, plot_roc_curve, plot_2D_features from oodeel.datasets import OODDataset from oodeel.utils.tf_training_tools import train_tf_model <p>Note that models are saved at ~/.oodeel/saved_models and data is supposed to be found at ~/.oodeel/datasets by default. Change the following cell for a custom path.</p> In\u00a0[2]: Copied! <pre>model_path = os.path.expanduser(\"~/\") + \".oodeel/saved_models\"\ndata_path = os.path.expanduser(\"~/\") + \".oodeel/datasets\"\nos.makedirs(model_path, exist_ok=True)\nos.makedirs(data_path, exist_ok=True)\n</pre> model_path = os.path.expanduser(\"~/\") + \".oodeel/saved_models\" data_path = os.path.expanduser(\"~/\") + \".oodeel/datasets\" os.makedirs(model_path, exist_ok=True) os.makedirs(data_path, exist_ok=True) In\u00a0[3]: Copied! <pre># === Load ID and OOD data ===\nbatch_size = 128\nin_labels = [0, 1, 2, 3, 4]\n\n# 1- Load train/test MNIST dataset\nds_train = OODDataset(\"mnist\", load_kwargs=dict(split=\"train\"))\ndata_test = OODDataset(\"mnist\", load_kwargs=dict(split=\"test\"))\n\n# 2- Split ID / OOD data depending on label value:\n# in-distribution: MNIST[0-4] / out-of-distribution: MNIST[5-9]\nds_train, _ = ds_train.split_by_class(in_labels)\noods_in, oods_out = data_test.split_by_class(in_labels)\n\n\n# 3- Prepare data (preprocess, shuffle, batch)\ndef preprocess_fn(*inputs):\n    x = inputs[0] / 255\n    return tuple([x] + list(inputs[1:]))\n\n\nds_train = ds_train.prepare(batch_size, preprocess_fn, shuffle=True)\nds_in = oods_in.prepare(batch_size, preprocess_fn, with_ood_labels=False)\nds_out = oods_out.prepare(batch_size, preprocess_fn, with_ood_labels=False)\n\nclear_output()\n</pre> # === Load ID and OOD data === batch_size = 128 in_labels = [0, 1, 2, 3, 4]  # 1- Load train/test MNIST dataset ds_train = OODDataset(\"mnist\", load_kwargs=dict(split=\"train\")) data_test = OODDataset(\"mnist\", load_kwargs=dict(split=\"test\"))  # 2- Split ID / OOD data depending on label value: # in-distribution: MNIST[0-4] / out-of-distribution: MNIST[5-9] ds_train, _ = ds_train.split_by_class(in_labels) oods_in, oods_out = data_test.split_by_class(in_labels)   # 3- Prepare data (preprocess, shuffle, batch) def preprocess_fn(*inputs):     x = inputs[0] / 255     return tuple([x] + list(inputs[1:]))   ds_train = ds_train.prepare(batch_size, preprocess_fn, shuffle=True) ds_in = oods_in.prepare(batch_size, preprocess_fn, with_ood_labels=False) ds_out = oods_out.prepare(batch_size, preprocess_fn, with_ood_labels=False)  clear_output() In\u00a0[4]: Copied! <pre># === Train / Load model ===\nmodel_path_mnist_04 = os.path.join(model_path, \"mnist_model_0-4.h5\")\n\ntry:\n    # if the model exists, load it\n    model = tf.keras.models.load_model(model_path_mnist_04)\nexcept OSError:\n    # else, train a new model\n    train_config = {\n        \"model\": \"toy_convnet\",\n        \"input_shape\": (28, 28, 1),\n        \"num_classes\": 10,\n        \"batch_size\": 128,\n        \"epochs\": 5,\n        \"save_dir\": model_path_mnist_04,\n        \"validation_data\": ds_in,\n    }\n\n    model = train_tf_model(ds_train, **train_config)\n\n_, accuracy = model.evaluate(ds_in)\nprint(f\"Test accuracy:\\t{accuracy:.4f}\")\n\n# penultimate features 2d visualization\nprint(\"\\n=== Penultimate features viz ===\")\nplt.figure(figsize=(4.5, 3))\nplot_2D_features(\n    model=model,\n    in_dataset=ds_in,\n    out_dataset=ds_out,\n    output_layer_id=-2,\n)\nplt.tight_layout()\nplt.show()\n</pre> # === Train / Load model === model_path_mnist_04 = os.path.join(model_path, \"mnist_model_0-4.h5\")  try:     # if the model exists, load it     model = tf.keras.models.load_model(model_path_mnist_04) except OSError:     # else, train a new model     train_config = {         \"model\": \"toy_convnet\",         \"input_shape\": (28, 28, 1),         \"num_classes\": 10,         \"batch_size\": 128,         \"epochs\": 5,         \"save_dir\": model_path_mnist_04,         \"validation_data\": ds_in,     }      model = train_tf_model(ds_train, **train_config)  _, accuracy = model.evaluate(ds_in) print(f\"Test accuracy:\\t{accuracy:.4f}\")  # penultimate features 2d visualization print(\"\\n=== Penultimate features viz ===\") plt.figure(figsize=(4.5, 3)) plot_2D_features(     model=model,     in_dataset=ds_in,     out_dataset=ds_out,     output_layer_id=-2, ) plt.tight_layout() plt.show() <pre>41/41 [==============================] - 2s 11ms/step - loss: 0.0118 - accuracy: 0.9965\nTest accuracy:\t0.9965\n\n=== Penultimate features viz ===\n</pre> In\u00a0[5]: Copied! <pre># === Entropy OOD scores ===\nentropy = Entropy()\nentropy.fit(model)\nscores_in, _ = entropy.score(ds_in)\nscores_out, _ = entropy.score(ds_out)\n\n# === metrics ===\n# auroc / fpr95\nmetrics = bench_metrics(\n    (scores_in, scores_out),\n    metrics=[\"auroc\", \"fpr95tpr\"],\n)\nprint(\"=== Metrics ===\")\nfor k, v in metrics.items():\n    print(f\"{k:&lt;10} {v:.6f}\")\n\nprint(\"\\n=== Plots ===\")\n# hists / roc\nplt.figure(figsize=(9, 3))\nplt.subplot(121)\nplot_ood_scores(scores_in, scores_out, log_scale=True)\nplt.subplot(122)\nplot_roc_curve(scores_in, scores_out)\nplt.tight_layout()\nplt.show()\n</pre> # === Entropy OOD scores === entropy = Entropy() entropy.fit(model) scores_in, _ = entropy.score(ds_in) scores_out, _ = entropy.score(ds_out)  # === metrics === # auroc / fpr95 metrics = bench_metrics(     (scores_in, scores_out),     metrics=[\"auroc\", \"fpr95tpr\"], ) print(\"=== Metrics ===\") for k, v in metrics.items():     print(f\"{k:&lt;10} {v:.6f}\")  print(\"\\n=== Plots ===\") # hists / roc plt.figure(figsize=(9, 3)) plt.subplot(121) plot_ood_scores(scores_in, scores_out, log_scale=True) plt.subplot(122) plot_roc_curve(scores_in, scores_out) plt.tight_layout() plt.show() <pre>=== Metrics ===\nauroc      0.937896\nfpr95tpr   0.417007\n\n=== Plots ===\n</pre> In\u00a0[6]: Copied! <pre># === Load ID and OOD data ===\nbatch_size = 128\n\n# 1a- Load in-distribution dataset: CIFAR-10\nds_in = OODDataset(\"cifar10\", load_kwargs={\"split\": \"test\"}, input_key=\"image\")\n\n# 1b- Load out-of-distribution dataset: SVHN\nds_out = OODDataset(\"svhn_cropped\", load_kwargs={\"split\": \"test\"})\n\n\n# 2- prepare data (preprocess, shuffle, batch)\ndef preprocess_fn(*inputs):\n    x = inputs[0] / 255\n    return tuple([x] + list(inputs[1:]))\n\n\nds_in = ds_in.prepare(batch_size, preprocess_fn)\nds_out = ds_out.prepare(batch_size, preprocess_fn)\n</pre> # === Load ID and OOD data === batch_size = 128  # 1a- Load in-distribution dataset: CIFAR-10 ds_in = OODDataset(\"cifar10\", load_kwargs={\"split\": \"test\"}, input_key=\"image\")  # 1b- Load out-of-distribution dataset: SVHN ds_out = OODDataset(\"svhn_cropped\", load_kwargs={\"split\": \"test\"})   # 2- prepare data (preprocess, shuffle, batch) def preprocess_fn(*inputs):     x = inputs[0] / 255     return tuple([x] + list(inputs[1:]))   ds_in = ds_in.prepare(batch_size, preprocess_fn) ds_out = ds_out.prepare(batch_size, preprocess_fn) In\u00a0[7]: Copied! <pre># === Load model ===\n# ResNet pretrained on CIFAR-10\nmodel_path_resnet_cifar10 = tf.keras.utils.get_file(\n    \"cifar10_resnet256.h5\",\n    origin=\"https://share.deel.ai/s/kram9kLpx6JwRX4/download/cifar10_resnet256.h5\",\n    cache_dir=model_path,\n    cache_subdir=\"\",\n)\nmodel = tf.keras.models.load_model(model_path_resnet_cifar10)\n\n# Evaluate model\nmodel.compile(metrics=[\"accuracy\"])\n_, accuracy = model.evaluate(ds_in)\nprint(f\"Test accuracy:\\t{accuracy:.4f}\")\n\n# penultimate features 2d visualization\nprint(\"\\n=== Penultimate features viz ===\")\nplt.figure(figsize=(4.5, 3))\nplot_2D_features(\n    model=model,\n    in_dataset=ds_in,\n    out_dataset=ds_out,\n    output_layer_id=-2,\n)\nplt.tight_layout()\nplt.show()\n</pre> # === Load model === # ResNet pretrained on CIFAR-10 model_path_resnet_cifar10 = tf.keras.utils.get_file(     \"cifar10_resnet256.h5\",     origin=\"https://share.deel.ai/s/kram9kLpx6JwRX4/download/cifar10_resnet256.h5\",     cache_dir=model_path,     cache_subdir=\"\", ) model = tf.keras.models.load_model(model_path_resnet_cifar10)  # Evaluate model model.compile(metrics=[\"accuracy\"]) _, accuracy = model.evaluate(ds_in) print(f\"Test accuracy:\\t{accuracy:.4f}\")  # penultimate features 2d visualization print(\"\\n=== Penultimate features viz ===\") plt.figure(figsize=(4.5, 3)) plot_2D_features(     model=model,     in_dataset=ds_in,     out_dataset=ds_out,     output_layer_id=-2, ) plt.tight_layout() plt.show() <pre>79/79 [==============================] - 3s 25ms/step - loss: 0.1268 - accuracy: 0.9276\nTest accuracy:\t0.9276\n\n=== Penultimate features viz ===\n</pre> In\u00a0[8]: Copied! <pre># === Entropy OOD scores ===\nentropy = Entropy()\nentropy.fit(model)\nscores_in, _ = entropy.score(ds_in)\nscores_out, _ = entropy.score(ds_out)\n\n# === metrics ===\n# auroc / fpr95\nmetrics = bench_metrics(\n    (scores_in, scores_out),\n    metrics=[\"auroc\", \"fpr95tpr\"],\n)\nprint(\"=== Metrics ===\")\nfor k, v in metrics.items():\n    print(f\"{k:&lt;10} {v:.6f}\")\n\nprint(\"\\n=== Plots ===\")\n# hists / roc\nplt.figure(figsize=(9, 3))\nplt.subplot(121)\nplot_ood_scores(scores_in, scores_out, log_scale=True)\nplt.subplot(122)\nplot_roc_curve(scores_in, scores_out)\nplt.tight_layout()\nplt.show()\n</pre> # === Entropy OOD scores === entropy = Entropy() entropy.fit(model) scores_in, _ = entropy.score(ds_in) scores_out, _ = entropy.score(ds_out)  # === metrics === # auroc / fpr95 metrics = bench_metrics(     (scores_in, scores_out),     metrics=[\"auroc\", \"fpr95tpr\"], ) print(\"=== Metrics ===\") for k, v in metrics.items():     print(f\"{k:&lt;10} {v:.6f}\")  print(\"\\n=== Plots ===\") # hists / roc plt.figure(figsize=(9, 3)) plt.subplot(121) plot_ood_scores(scores_in, scores_out, log_scale=True) plt.subplot(122) plot_roc_curve(scores_in, scores_out) plt.tight_layout() plt.show() <pre>=== Metrics ===\nauroc      0.942947\nfpr95tpr   0.205700\n\n=== Plots ===\n</pre>"},{"location":"notebooks/tensorflow/demo_entropy_tf/#entropy-method","title":"Entropy method\u00b6","text":"<p>This notebook aims at evaluating the Entropy method.</p> <p>The method consists in using the Entropy of the input data computed using the Entropy $\\sum_{c=0}^C p(y=c| x) \\times log(p(y=c | x))$ where $p(y=c| x) = \\text{model}(x)$.</p> <p>Here, we focus on a toy convolutional network trained on MNIST[0-4] and a ResNet model trained on CIFAR-10, respectively challenged on MNIST[5-9] and SVHN OOD datasets.</p> <p>Reference Likelihood Ratios for Out-of-Distribution Detection, Neurips 2019.</p>"},{"location":"notebooks/tensorflow/demo_entropy_tf/#imports","title":"Imports\u00b6","text":""},{"location":"notebooks/tensorflow/demo_entropy_tf/#first-experiment-mnist0-4-vs-mnist5-9","title":"First experiment: MNIST[0-4] vs MNIST[5-9]\u00b6","text":"<p>For this first experiment, we train a toy convolutional network on the MNIST dataset restricted to digits 0 to 4. After fitting the train subset of this dataset to the Entropy method, we will compare the scores returned for MNIST[0-4] (in-distribution) and MNIST[5-9] (out-of-distribution) test subsets.</p>"},{"location":"notebooks/tensorflow/demo_entropy_tf/#data-loading","title":"Data loading\u00b6","text":"<ul> <li>In-distribution data: MNIST[0-4]</li> <li>Out-of-distribution data: MNIST[5-9]</li> </ul> <p>Note: We denote In-Distribution (ID) data with <code>_in</code> and Out-Of-Distribution (OOD) data with <code>_out</code> to avoid confusion with OOD detection which is the name of the task, and is therefore used to denote core classes such as <code>OODDataset</code> and <code>OODBaseDetector</code>.</p>"},{"location":"notebooks/tensorflow/demo_entropy_tf/#model-training","title":"Model training\u00b6","text":"<p>Now let's train a simple model on MNIST[0-4] using <code>train_tf_model</code> function.</p>"},{"location":"notebooks/tensorflow/demo_entropy_tf/#entropy-ood-score","title":"Entropy OOD score\u00b6","text":"<p>We now fit an Entropy OOD detector with MNIST[0-4] train dataset, and compare OOD scores returned for MNIST[0-4] (ID) and MNIST[5-9] (OOD) test datasets.</p>"},{"location":"notebooks/tensorflow/demo_entropy_tf/#second-experiment-cifar-10-vs-svhn","title":"Second experiment: CIFAR-10 vs SVHN\u00b6","text":"<p>For this second experiment, we oppose CIFAR-10 (in-distribution dataset) to SVHN (out-of-distribution dataset).</p>"},{"location":"notebooks/tensorflow/demo_entropy_tf/#data-loading","title":"Data loading\u00b6","text":"<ul> <li>In-distribution data: CIFAR-10</li> <li>Out-of-distribution data: SVHN</li> </ul>"},{"location":"notebooks/tensorflow/demo_entropy_tf/#model-loading","title":"Model loading\u00b6","text":"<p>The model is a ResNet pretrained on CIFAR-10 and getting an accuracy score of 92.75%.</p>"},{"location":"notebooks/tensorflow/demo_entropy_tf/#entropy-ood-score","title":"Entropy OOD score\u00b6","text":"<p>We now fit an Entropy OOD detector with CIFAR-10 train dataset, and compare OOD scores returned for CIFAR-10 (ID) and SVHN (OOD) test datasets.</p>"},{"location":"notebooks/tensorflow/demo_gen_tf/","title":"GEN","text":"In\u00a0[1]: Copied! <pre>%load_ext autoreload\n\nimport os\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n\nfrom IPython.display import clear_output\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n\nfrom oodeel.methods import GEN\nfrom oodeel.eval.metrics import bench_metrics\nfrom oodeel.eval.plots import plot_ood_scores, plot_roc_curve, plot_2D_features\nfrom oodeel.datasets import OODDataset\nfrom oodeel.utils.tf_training_tools import train_tf_model\n</pre> %load_ext autoreload  import os os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"  from IPython.display import clear_output import tensorflow as tf import matplotlib.pyplot as plt  from oodeel.methods import GEN from oodeel.eval.metrics import bench_metrics from oodeel.eval.plots import plot_ood_scores, plot_roc_curve, plot_2D_features from oodeel.datasets import OODDataset from oodeel.utils.tf_training_tools import train_tf_model <pre>/home/corentin.friedrich/dev/oodeel/venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n</pre> <p>Note that models are saved at ~/.oodeel/saved_models and data is supposed to be found at ~/.oodeel/datasets by default. Change the following cell for a custom path.</p> In\u00a0[2]: Copied! <pre>model_path = os.path.expanduser(\"~/\") + \".oodeel/saved_models\"\ndata_path = os.path.expanduser(\"~/\") + \".oodeel/datasets\"\nos.makedirs(model_path, exist_ok=True)\nos.makedirs(data_path, exist_ok=True)\n</pre> model_path = os.path.expanduser(\"~/\") + \".oodeel/saved_models\" data_path = os.path.expanduser(\"~/\") + \".oodeel/datasets\" os.makedirs(model_path, exist_ok=True) os.makedirs(data_path, exist_ok=True) In\u00a0[3]: Copied! <pre># === Load ID and OOD data ===\nbatch_size = 128\nin_labels = [0, 1, 2, 3, 4]\n\n# 1- Load train/test MNIST dataset\nds_train = OODDataset(\"mnist\", load_kwargs=dict(split=\"train\"))\ndata_test = OODDataset(\"mnist\", load_kwargs=dict(split=\"test\"))\n\n# 2- Split ID / OOD data depending on label value:\n# in-distribution: MNIST[0-4] / out-of-distribution: MNIST[5-9]\nds_train, _ = ds_train.split_by_class(in_labels)\noods_in, oods_out = data_test.split_by_class(in_labels)\n\n\n# 3- Prepare data (preprocess, shuffle, batch)\ndef preprocess_fn(*inputs):\n    x = inputs[0] / 255\n    return tuple([x] + list(inputs[1:]))\n\n\nds_train = ds_train.prepare(batch_size, preprocess_fn, shuffle=True)\nds_in = oods_in.prepare(batch_size, preprocess_fn, with_ood_labels=False)\nds_out = oods_out.prepare(batch_size, preprocess_fn, with_ood_labels=False)\n\nclear_output()\n</pre> # === Load ID and OOD data === batch_size = 128 in_labels = [0, 1, 2, 3, 4]  # 1- Load train/test MNIST dataset ds_train = OODDataset(\"mnist\", load_kwargs=dict(split=\"train\")) data_test = OODDataset(\"mnist\", load_kwargs=dict(split=\"test\"))  # 2- Split ID / OOD data depending on label value: # in-distribution: MNIST[0-4] / out-of-distribution: MNIST[5-9] ds_train, _ = ds_train.split_by_class(in_labels) oods_in, oods_out = data_test.split_by_class(in_labels)   # 3- Prepare data (preprocess, shuffle, batch) def preprocess_fn(*inputs):     x = inputs[0] / 255     return tuple([x] + list(inputs[1:]))   ds_train = ds_train.prepare(batch_size, preprocess_fn, shuffle=True) ds_in = oods_in.prepare(batch_size, preprocess_fn, with_ood_labels=False) ds_out = oods_out.prepare(batch_size, preprocess_fn, with_ood_labels=False)  clear_output() In\u00a0[4]: Copied! <pre># === Train / Load model ===\nmodel_path_mnist_04 = os.path.join(model_path, \"mnist_model_0-4.h5\")\n\ntry:\n    # if the model exists, load it\n    model = tf.keras.models.load_model(model_path_mnist_04)\nexcept OSError:\n    # else, train a new model\n    train_config = {\n        \"model\": \"toy_convnet\",\n        \"input_shape\": (28, 28, 1),\n        \"num_classes\": 10,\n        \"batch_size\": 128,\n        \"epochs\": 5,\n        \"save_dir\": model_path_mnist_04,\n        \"validation_data\": ds_in,\n    }\n\n    model = train_tf_model(ds_train, **train_config)\n\n_, accuracy = model.evaluate(ds_in)\nprint(f\"Test accuracy:\\t{accuracy:.4f}\")\n\n# penultimate features 2d visualization\nprint(\"\\n=== Penultimate features viz ===\")\nplt.figure(figsize=(4.5, 3))\nplot_2D_features(\n    model=model,\n    in_dataset=ds_in,\n    out_dataset=ds_out,\n    output_layer_id=-2,\n)\nplt.tight_layout()\nplt.show()\n</pre> # === Train / Load model === model_path_mnist_04 = os.path.join(model_path, \"mnist_model_0-4.h5\")  try:     # if the model exists, load it     model = tf.keras.models.load_model(model_path_mnist_04) except OSError:     # else, train a new model     train_config = {         \"model\": \"toy_convnet\",         \"input_shape\": (28, 28, 1),         \"num_classes\": 10,         \"batch_size\": 128,         \"epochs\": 5,         \"save_dir\": model_path_mnist_04,         \"validation_data\": ds_in,     }      model = train_tf_model(ds_train, **train_config)  _, accuracy = model.evaluate(ds_in) print(f\"Test accuracy:\\t{accuracy:.4f}\")  # penultimate features 2d visualization print(\"\\n=== Penultimate features viz ===\") plt.figure(figsize=(4.5, 3)) plot_2D_features(     model=model,     in_dataset=ds_in,     out_dataset=ds_out,     output_layer_id=-2, ) plt.tight_layout() plt.show() <pre>41/41 [==============================] - 1s 25ms/step - loss: 0.0059 - accuracy: 0.9979\nTest accuracy:\t0.9979\n\n=== Penultimate features viz ===\n</pre> In\u00a0[5]: Copied! <pre># === GEN scores ===\ngen = GEN()\ngen.fit(model)\nscores_in, _ = gen.score(ds_in)\nscores_out, _ = gen.score(ds_out)\n\n# === metrics ===\n# auroc / fpr95\nmetrics = bench_metrics(\n    (scores_in, scores_out),\n    metrics=[\"auroc\", \"fpr95tpr\"],\n)\nprint(\"=== Metrics ===\")\nfor k, v in metrics.items():\n    print(f\"{k:&lt;10} {v:.6f}\")\n\nprint(\"\\n=== Plots ===\")\n# hists / roc\nplt.figure(figsize=(9, 3))\nplt.subplot(121)\nplot_ood_scores(scores_in, scores_out, log_scale=False)\nplt.subplot(122)\nplot_roc_curve(scores_in, scores_out)\nplt.tight_layout()\nplt.show()\n</pre> # === GEN scores === gen = GEN() gen.fit(model) scores_in, _ = gen.score(ds_in) scores_out, _ = gen.score(ds_out)  # === metrics === # auroc / fpr95 metrics = bench_metrics(     (scores_in, scores_out),     metrics=[\"auroc\", \"fpr95tpr\"], ) print(\"=== Metrics ===\") for k, v in metrics.items():     print(f\"{k:&lt;10} {v:.6f}\")  print(\"\\n=== Plots ===\") # hists / roc plt.figure(figsize=(9, 3)) plt.subplot(121) plot_ood_scores(scores_in, scores_out, log_scale=False) plt.subplot(122) plot_roc_curve(scores_in, scores_out) plt.tight_layout() plt.show() <pre>=== Metrics ===\nauroc      0.914862\nfpr95tpr   0.529675\n\n=== Plots ===\n</pre> In\u00a0[6]: Copied! <pre># === Load ID and OOD data ===\nbatch_size = 128\n\n# 1a- Load in-distribution dataset: CIFAR-10\nds_in = OODDataset(\"cifar10\", load_kwargs={\"split\": \"test\"}, input_key=\"image\")\n\n# 1b- Load out-of-distribution dataset: SVHN\nds_out = OODDataset(\"svhn_cropped\", load_kwargs={\"split\": \"test\"})\n\n\n# 2- prepare data (preprocess, shuffle, batch)\ndef preprocess_fn(*inputs):\n    x = inputs[0] / 255\n    return tuple([x] + list(inputs[1:]))\n\n\nds_in = ds_in.prepare(batch_size, preprocess_fn)\nds_out = ds_out.prepare(batch_size, preprocess_fn)\n</pre> # === Load ID and OOD data === batch_size = 128  # 1a- Load in-distribution dataset: CIFAR-10 ds_in = OODDataset(\"cifar10\", load_kwargs={\"split\": \"test\"}, input_key=\"image\")  # 1b- Load out-of-distribution dataset: SVHN ds_out = OODDataset(\"svhn_cropped\", load_kwargs={\"split\": \"test\"})   # 2- prepare data (preprocess, shuffle, batch) def preprocess_fn(*inputs):     x = inputs[0] / 255     return tuple([x] + list(inputs[1:]))   ds_in = ds_in.prepare(batch_size, preprocess_fn) ds_out = ds_out.prepare(batch_size, preprocess_fn) In\u00a0[7]: Copied! <pre># === Load model ===\n# ResNet pretrained on CIFAR-10\nmodel_path_resnet_cifar10 = tf.keras.utils.get_file(\n    \"cifar10_resnet256.h5\",\n    origin=\"https://share.deel.ai/s/kram9kLpx6JwRX4/download/cifar10_resnet256.h5\",\n    cache_dir=model_path,\n    cache_subdir=\"\",\n)\nmodel = tf.keras.models.load_model(model_path_resnet_cifar10)\n\n# Evaluate model\nmodel.compile(metrics=[\"accuracy\"])\n_, accuracy = model.evaluate(ds_in)\nprint(f\"Test accuracy:\\t{accuracy:.4f}\")\n\n# penultimate features 2d visualization\nprint(\"\\n=== Penultimate features viz ===\")\nplt.figure(figsize=(4.5, 3))\nplot_2D_features(\n    model=model,\n    in_dataset=ds_in,\n    out_dataset=ds_out,\n    output_layer_id=-2,\n)\nplt.tight_layout()\nplt.show()\n</pre> # === Load model === # ResNet pretrained on CIFAR-10 model_path_resnet_cifar10 = tf.keras.utils.get_file(     \"cifar10_resnet256.h5\",     origin=\"https://share.deel.ai/s/kram9kLpx6JwRX4/download/cifar10_resnet256.h5\",     cache_dir=model_path,     cache_subdir=\"\", ) model = tf.keras.models.load_model(model_path_resnet_cifar10)  # Evaluate model model.compile(metrics=[\"accuracy\"]) _, accuracy = model.evaluate(ds_in) print(f\"Test accuracy:\\t{accuracy:.4f}\")  # penultimate features 2d visualization print(\"\\n=== Penultimate features viz ===\") plt.figure(figsize=(4.5, 3)) plot_2D_features(     model=model,     in_dataset=ds_in,     out_dataset=ds_out,     output_layer_id=-2, ) plt.tight_layout() plt.show() <pre>79/79 [==============================] - 2s 9ms/step - loss: 0.1268 - accuracy: 0.9275\nTest accuracy:\t0.9275\n\n=== Penultimate features viz ===\n</pre> In\u00a0[8]: Copied! <pre># === GEN scores ===\ngen = GEN()\ngen.fit(model)\nscores_in, _ = gen.score(ds_in)\nscores_out, _ = gen.score(ds_out)\n\n# === metrics ===\n# auroc / fpr95\nmetrics = bench_metrics(\n    (scores_in, scores_out),\n    metrics=[\"auroc\", \"fpr95tpr\"],\n)\nprint(\"=== Metrics ===\")\nfor k, v in metrics.items():\n    print(f\"{k:&lt;10} {v:.6f}\")\n\nprint(\"\\n=== Plots ===\")\n# hists / roc\nplt.figure(figsize=(9, 3))\nplt.subplot(121)\nplot_ood_scores(scores_in, scores_out, log_scale=False)\nplt.subplot(122)\nplot_roc_curve(scores_in, scores_out)\nplt.tight_layout()\nplt.show()\n</pre> # === GEN scores === gen = GEN() gen.fit(model) scores_in, _ = gen.score(ds_in) scores_out, _ = gen.score(ds_out)  # === metrics === # auroc / fpr95 metrics = bench_metrics(     (scores_in, scores_out),     metrics=[\"auroc\", \"fpr95tpr\"], ) print(\"=== Metrics ===\") for k, v in metrics.items():     print(f\"{k:&lt;10} {v:.6f}\")  print(\"\\n=== Plots ===\") # hists / roc plt.figure(figsize=(9, 3)) plt.subplot(121) plot_ood_scores(scores_in, scores_out, log_scale=False) plt.subplot(122) plot_roc_curve(scores_in, scores_out) plt.tight_layout() plt.show() <pre>=== Metrics ===\nauroc      0.969413\nfpr95tpr   0.133700\n\n=== Plots ===\n</pre>"},{"location":"notebooks/tensorflow/demo_gen_tf/#generalized-entropy","title":"Generalized Entropy\u00b6","text":"<p>This notebook aims at evaluating the GEN method (Generalized ENtropy).</p> <p>This method consists in computing a generalized entropy score based on the softmax probabilities. Considering the softmax output values $p_i$ (one per class), the OOD score is defined as</p> $$ S(p) = \\sum \\_{j=1}^k p_i^\\gamma (1-p_i)^\\gamma. $$<p>The two parameters the method are:</p> <ul> <li>$\\gamma$, corresponding to the order of the generalized entropy form, between 0 and 1. The authors of the original paper propose to set $\\gamma=0.1$.</li> <li>$k$, corresponding to the top-k largest softmax values to keep in the entropy computation. Removing the smallest values makes the method more robust to small variations.</li> </ul> <p>Here, we focus on a toy convolutional network trained on MNIST[0-4] and a ResNet20 model trained on CIFAR-10, respectively challenged on MNIST[5-9] and SVHN OOD datasets.</p> <p>Reference</p> <p>GEN: Pushing the Limits of Softmax-Based Out-of-Distribution Detection, CVPR 2023</p>"},{"location":"notebooks/tensorflow/demo_gen_tf/#imports","title":"Imports\u00b6","text":""},{"location":"notebooks/tensorflow/demo_gen_tf/#first-experiment-mnist0-4-vs-mnist5-9","title":"First experiment: MNIST[0-4] vs MNIST[5-9]\u00b6","text":"<p>For this first experiment, we train a toy convolutional network on the MNIST dataset restricted to digits 0 to 4.</p>"},{"location":"notebooks/tensorflow/demo_gen_tf/#data-loading","title":"Data loading\u00b6","text":"<ul> <li>In-distribution data: MNIST[0-4]</li> <li>Out-of-distribution data: MNIST[5-9]</li> </ul> <p>Note: We denote In-Distribution (ID) data with <code>_in</code> and Out-Of-Distribution (OOD) data with <code>_out</code> to avoid confusion with OOD detection which is the name of the task, and is therefore used to denote core classes such as <code>OODDataset</code> and <code>OODBaseDetector</code>.</p>"},{"location":"notebooks/tensorflow/demo_gen_tf/#model-training","title":"Model training\u00b6","text":"<p>Now let's train a simple model on MNIST[0-4] using <code>train_tf_model</code> function.</p>"},{"location":"notebooks/tensorflow/demo_gen_tf/#gen-score","title":"GEN score\u00b6","text":"<p>We now fit a GEN OOD detector with MNIST[0-4] train dataset, and compare OOD scores returned for MNIST[0-4] (ID) and MNIST[5-9] (OOD) test datasets.</p>"},{"location":"notebooks/tensorflow/demo_gen_tf/#second-experiment-cifar-10-vs-svhn","title":"Second experiment: CIFAR-10 vs SVHN\u00b6","text":"<p>For this second experiment, we oppose CIFAR-10 (in-distribution dataset) to SVHN (out-of-distribution dataset).</p>"},{"location":"notebooks/tensorflow/demo_gen_tf/#data-loading","title":"Data loading\u00b6","text":"<ul> <li>In-distribution data: CIFAR-10</li> <li>Out-of-distribution data: SVHN</li> </ul>"},{"location":"notebooks/tensorflow/demo_gen_tf/#model-loading","title":"Model loading\u00b6","text":"<p>The model is a ResNet pretrained on CIFAR-10 and getting an accuracy score of 92.75%.</p>"},{"location":"notebooks/tensorflow/demo_gen_tf/#gen-score","title":"GEN score\u00b6","text":"<p>We now fit a GEN OOD detector with CIFAR-10 train dataset, and compare OOD scores returned for CIFAR-10 (ID) and SVHN (OOD) test datasets.</p>"},{"location":"notebooks/tensorflow/demo_gram_tf/","title":"Gram","text":"In\u00a0[\u00a0]: Copied! <pre>%load_ext autoreload\n%autoreload 2\n\nimport os\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n\nfrom IPython.display import clear_output\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfrom oodeel.methods import Gram\nfrom oodeel.eval.metrics import bench_metrics\nfrom oodeel.eval.plots import plot_ood_scores, plot_roc_curve, plot_2D_features\nfrom oodeel.datasets import OODDataset\nfrom oodeel.utils.tf_training_tools import train_tf_model\n</pre> %load_ext autoreload %autoreload 2  import os os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"  from IPython.display import clear_output import tensorflow as tf import matplotlib.pyplot as plt import numpy as np  from oodeel.methods import Gram from oodeel.eval.metrics import bench_metrics from oodeel.eval.plots import plot_ood_scores, plot_roc_curve, plot_2D_features from oodeel.datasets import OODDataset from oodeel.utils.tf_training_tools import train_tf_model <p>Note that models are saved at ~/.oodeel/saved_models and data is supposed to be found at ~/.oodeel/datasets by default. Change the following cell for a custom path.</p> In\u00a0[2]: Copied! <pre>model_path = os.path.expanduser(\"~/\") + \".oodeel/saved_models\"\ndata_path = os.path.expanduser(\"~/\") + \".oodeel/datasets\"\nos.makedirs(model_path, exist_ok=True)\nos.makedirs(data_path, exist_ok=True)\n</pre> model_path = os.path.expanduser(\"~/\") + \".oodeel/saved_models\" data_path = os.path.expanduser(\"~/\") + \".oodeel/datasets\" os.makedirs(model_path, exist_ok=True) os.makedirs(data_path, exist_ok=True) In\u00a0[3]: Copied! <pre># === Load ID and OOD data ===\nbatch_size = 128\nin_labels = [0, 1, 2, 3, 4]\n\n# 1- Load train/test MNIST dataset\nds_train = OODDataset(\"mnist\", load_kwargs=dict(split=\"train\"))\ndata_test = OODDataset(\"mnist\", load_kwargs=dict(split=\"test\"))\n\n# 2- Split ID / OOD data depending on label value:\n# in-distribution: MNIST[0-4] / out-of-distribution: MNIST[5-9]\nds_train, _ = ds_train.split_by_class(in_labels)\noods_in, oods_out = data_test.split_by_class(in_labels)\n\n\n# 3- Prepare data (preprocess, shuffle, batch)\ndef preprocess_fn(*inputs):\n    x = inputs[0] / 255\n    return tuple([x] + list(inputs[1:]))\n\n\nds_train = ds_train.prepare(batch_size, preprocess_fn, shuffle=True)\nds_in = oods_in.prepare(batch_size, preprocess_fn, with_ood_labels=False)\nds_out = oods_out.prepare(batch_size, preprocess_fn, with_ood_labels=False)\n\nclear_output()\n</pre> # === Load ID and OOD data === batch_size = 128 in_labels = [0, 1, 2, 3, 4]  # 1- Load train/test MNIST dataset ds_train = OODDataset(\"mnist\", load_kwargs=dict(split=\"train\")) data_test = OODDataset(\"mnist\", load_kwargs=dict(split=\"test\"))  # 2- Split ID / OOD data depending on label value: # in-distribution: MNIST[0-4] / out-of-distribution: MNIST[5-9] ds_train, _ = ds_train.split_by_class(in_labels) oods_in, oods_out = data_test.split_by_class(in_labels)   # 3- Prepare data (preprocess, shuffle, batch) def preprocess_fn(*inputs):     x = inputs[0] / 255     return tuple([x] + list(inputs[1:]))   ds_train = ds_train.prepare(batch_size, preprocess_fn, shuffle=True) ds_in = oods_in.prepare(batch_size, preprocess_fn, with_ood_labels=False) ds_out = oods_out.prepare(batch_size, preprocess_fn, with_ood_labels=False)  clear_output() In\u00a0[4]: Copied! <pre># === Train / Load model ===\nmodel_path_mnist_04 = os.path.join(model_path, \"mnist_mlp_0-4.h5\")\n\ntry:\n    # if the model exists, load it\n    model = tf.keras.models.load_model(model_path_mnist_04)\nexcept OSError:\n    # else, train a new model\n    train_config = {\n        \"model\": \"toy_mlp\",\n        \"input_shape\": (28, 28, 1),\n        \"num_classes\": 10,\n        \"batch_size\": 128,\n        \"epochs\": 5,\n        \"save_dir\": model_path_mnist_04,\n        \"validation_data\": ds_in,\n    }\n\n    model = train_tf_model(ds_train, **train_config)\n</pre> # === Train / Load model === model_path_mnist_04 = os.path.join(model_path, \"mnist_mlp_0-4.h5\")  try:     # if the model exists, load it     model = tf.keras.models.load_model(model_path_mnist_04) except OSError:     # else, train a new model     train_config = {         \"model\": \"toy_mlp\",         \"input_shape\": (28, 28, 1),         \"num_classes\": 10,         \"batch_size\": 128,         \"epochs\": 5,         \"save_dir\": model_path_mnist_04,         \"validation_data\": ds_in,     }      model = train_tf_model(ds_train, **train_config)  <pre>Epoch 1/5\n240/240 [==============================] - 2s 6ms/step - loss: 0.1480 - accuracy: 0.9572 - val_loss: 0.0459 - val_accuracy: 0.9879\nEpoch 2/5\n240/240 [==============================] - 1s 2ms/step - loss: 0.0437 - accuracy: 0.9871 - val_loss: 0.0310 - val_accuracy: 0.9895\nEpoch 3/5\n240/240 [==============================] - 1s 2ms/step - loss: 0.0301 - accuracy: 0.9904 - val_loss: 0.0239 - val_accuracy: 0.9918\nEpoch 4/5\n240/240 [==============================] - 1s 2ms/step - loss: 0.0156 - accuracy: 0.9957 - val_loss: 0.0239 - val_accuracy: 0.9930\nEpoch 5/5\n240/240 [==============================] - 1s 2ms/step - loss: 0.0105 - accuracy: 0.9970 - val_loss: 0.0188 - val_accuracy: 0.9928\n</pre> In\u00a0[6]: Copied! <pre>_, accuracy = model.evaluate(ds_in)\nprint(f\"Test accuracy:\\t{accuracy:.4f}\")\n\n# penultimate features 2d visualization\nprint(\"\\n=== Penultimate features viz ===\")\nplt.figure(figsize=(4.5, 3))\nplot_2D_features(\n    model=model,\n    in_dataset=ds_in,\n    out_dataset=ds_out,\n    output_layer_id=-2,\n)\nplt.tight_layout()\nplt.show()\n</pre> _, accuracy = model.evaluate(ds_in) print(f\"Test accuracy:\\t{accuracy:.4f}\")  # penultimate features 2d visualization print(\"\\n=== Penultimate features viz ===\") plt.figure(figsize=(4.5, 3)) plot_2D_features(     model=model,     in_dataset=ds_in,     out_dataset=ds_out,     output_layer_id=-2, ) plt.tight_layout() plt.show() <pre>41/41 [==============================] - 0s 1ms/step - loss: 0.0239 - accuracy: 0.9930\nTest accuracy:\t0.9930\n\n=== Penultimate features viz ===\n</pre> In\u00a0[7]: Copied! <pre># === gram scores ===\ngram = Gram(quantile=0.2)\ngram.fit(model, ds_train, feature_layers_id=[\"dense\", \"dense_1\"])\n</pre> # === gram scores === gram = Gram(quantile=0.2) gram.fit(model, ds_train, feature_layers_id=[\"dense\", \"dense_1\"])  In\u00a0[8]: Copied! <pre>scores_in, _ = gram.score(ds_in)\nscores_out, _ = gram.score(ds_out)\n\n# Since many scores are equal to 0, we add a random noise to avoid bugs\n# in Auroc and TPR computation.\nscores_in += np.random.random_sample(size=scores_in.shape) * 10e-6\nscores_out += np.random.random_sample(size=scores_out.shape) * 10e-6\n\n# === metrics ===\n# auroc / fpr95\nmetrics = bench_metrics(\n    (scores_in, scores_out),\n    metrics=[\"auroc\", \"fpr95tpr\"],\n)\nprint(\"=== Metrics ===\")\nfor k, v in metrics.items():\n    print(f\"{k:&lt;10} {v:.6f}\")\n</pre> scores_in, _ = gram.score(ds_in) scores_out, _ = gram.score(ds_out)  # Since many scores are equal to 0, we add a random noise to avoid bugs # in Auroc and TPR computation. scores_in += np.random.random_sample(size=scores_in.shape) * 10e-6 scores_out += np.random.random_sample(size=scores_out.shape) * 10e-6  # === metrics === # auroc / fpr95 metrics = bench_metrics(     (scores_in, scores_out),     metrics=[\"auroc\", \"fpr95tpr\"], ) print(\"=== Metrics ===\") for k, v in metrics.items():     print(f\"{k:&lt;10} {v:.6f}\") <pre>=== Metrics ===\nauroc      0.889509\nfpr95tpr   0.412921\n</pre> In\u00a0[9]: Copied! <pre>print(\"\\n=== Plots ===\")\n# hists / roc\nplt.figure(figsize=(9, 3))\nplt.subplot(121)\nplot_ood_scores(scores_in, scores_out, log_scale=True)\nplt.subplot(122)\nplot_roc_curve(scores_in, scores_out)\nplt.tight_layout()\nplt.show()\n</pre>  print(\"\\n=== Plots ===\") # hists / roc plt.figure(figsize=(9, 3)) plt.subplot(121) plot_ood_scores(scores_in, scores_out, log_scale=True) plt.subplot(122) plot_roc_curve(scores_in, scores_out) plt.tight_layout() plt.show() <pre>\n=== Plots ===\n</pre> In\u00a0[10]: Copied! <pre># === Load ID and OOD data ===\nbatch_size = 128\n\n# 1a- Load in-distribution dataset: CIFAR-10\nds_fit = OODDataset(\"cifar10\", load_kwargs={\"split\": \"train\"}, input_key=\"image\")\nds_in = OODDataset(\"cifar10\", load_kwargs={\"split\": \"test\"}, input_key=\"image\")\n\n# 1b- Load out-of-distribution dataset: SVHN\nds_out = OODDataset(\"svhn_cropped\", load_kwargs={\"split\": \"test\"})\n\n\n# 2- prepare data (preprocess, shuffle, batch)\ndef preprocess_fn(*inputs):\n    x = inputs[0] / 255\n    return tuple([x] + list(inputs[1:]))\n\nds_fit = ds_fit.prepare(batch_size, preprocess_fn)\nds_in = ds_in.prepare(batch_size, preprocess_fn)\nds_out = ds_out.prepare(batch_size, preprocess_fn)\nclear_output()\n</pre> # === Load ID and OOD data === batch_size = 128  # 1a- Load in-distribution dataset: CIFAR-10 ds_fit = OODDataset(\"cifar10\", load_kwargs={\"split\": \"train\"}, input_key=\"image\") ds_in = OODDataset(\"cifar10\", load_kwargs={\"split\": \"test\"}, input_key=\"image\")  # 1b- Load out-of-distribution dataset: SVHN ds_out = OODDataset(\"svhn_cropped\", load_kwargs={\"split\": \"test\"})   # 2- prepare data (preprocess, shuffle, batch) def preprocess_fn(*inputs):     x = inputs[0] / 255     return tuple([x] + list(inputs[1:]))  ds_fit = ds_fit.prepare(batch_size, preprocess_fn) ds_in = ds_in.prepare(batch_size, preprocess_fn) ds_out = ds_out.prepare(batch_size, preprocess_fn) clear_output() In\u00a0[11]: Copied! <pre># === Load model ===\n# ResNet pretrained on CIFAR-10\nmodel_path_resnet_cifar10 = tf.keras.utils.get_file(\n    \"cifar10_resnet256.h5\",\n    origin=\"https://share.deel.ai/s/kram9kLpx6JwRX4/download/cifar10_resnet256.h5\",\n    cache_dir=model_path,\n    cache_subdir=\"\",\n)\nmodel = tf.keras.models.load_model(model_path_resnet_cifar10)\n</pre> # === Load model === # ResNet pretrained on CIFAR-10 model_path_resnet_cifar10 = tf.keras.utils.get_file(     \"cifar10_resnet256.h5\",     origin=\"https://share.deel.ai/s/kram9kLpx6JwRX4/download/cifar10_resnet256.h5\",     cache_dir=model_path,     cache_subdir=\"\", ) model = tf.keras.models.load_model(model_path_resnet_cifar10)  In\u00a0[12]: Copied! <pre># Evaluate model\nmodel.compile(metrics=[\"accuracy\"])\n_, accuracy = model.evaluate(ds_in)\nprint(f\"Test accuracy:\\t{accuracy:.4f}\")\n\n# penultimate features 2d visualization\nprint(\"\\n=== Penultimate features viz ===\")\nplt.figure(figsize=(4.5, 3))\nplot_2D_features(\n    model=model,\n    in_dataset=ds_in,\n    out_dataset=ds_out,\n    output_layer_id=-2,\n)\nplt.tight_layout()\nplt.show()\n</pre> # Evaluate model model.compile(metrics=[\"accuracy\"]) _, accuracy = model.evaluate(ds_in) print(f\"Test accuracy:\\t{accuracy:.4f}\")  # penultimate features 2d visualization print(\"\\n=== Penultimate features viz ===\") plt.figure(figsize=(4.5, 3)) plot_2D_features(     model=model,     in_dataset=ds_in,     out_dataset=ds_out,     output_layer_id=-2, ) plt.tight_layout() plt.show() <pre>79/79 [==============================] - 3s 14ms/step - loss: 0.1268 - accuracy: 0.9276\nTest accuracy:\t0.9276\n\n=== Penultimate features viz ===\n</pre> In\u00a0[13]: Copied! <pre># === gram scores ===\n%autoreload 2 \n\n\ngram = Gram(orders = [i for i in range(1, 11)], quantile=0.01)\ngram.fit(\n    model, \n    ds_fit, \n    feature_layers_id=['conv2d_18', 'activation_17', 'conv2d_37', 'activation_35', 'conv2d_56', 'activation_53']\n)\nscores_in, _ = gram.score(ds_in)\nscores_out, _ = gram.score(ds_out)\n\nscores_in += np.random.random_sample(size=scores_in.shape) * 10e-6\nscores_out += np.random.random_sample(size=scores_out.shape) * 10e-6\n\n# === metrics ===\n# auroc / fpr95\nmetrics = bench_metrics(\n    (scores_in, scores_out),\n    metrics=[\"auroc\", \"fpr95tpr\"],\n)\nprint(\"=== Metrics ===\")\nfor k, v in metrics.items():\n    print(f\"{k:&lt;10} {v:.6f}\")\n</pre> # === gram scores === %autoreload 2    gram = Gram(orders = [i for i in range(1, 11)], quantile=0.01) gram.fit(     model,      ds_fit,      feature_layers_id=['conv2d_18', 'activation_17', 'conv2d_37', 'activation_35', 'conv2d_56', 'activation_53'] ) scores_in, _ = gram.score(ds_in) scores_out, _ = gram.score(ds_out)  scores_in += np.random.random_sample(size=scores_in.shape) * 10e-6 scores_out += np.random.random_sample(size=scores_out.shape) * 10e-6  # === metrics === # auroc / fpr95 metrics = bench_metrics(     (scores_in, scores_out),     metrics=[\"auroc\", \"fpr95tpr\"], ) print(\"=== Metrics ===\") for k, v in metrics.items():     print(f\"{k:&lt;10} {v:.6f}\")  <pre>=== Metrics ===\nauroc      0.982648\nfpr95tpr   0.067800\n</pre> In\u00a0[14]: Copied! <pre>print(\"\\n=== Plots ===\")\n# hists / roc\nplt.figure(figsize=(9, 3))\nplt.subplot(121)\nplot_ood_scores(scores_in, scores_out, log_scale=True)\nplt.subplot(122)\nplot_roc_curve(scores_in, scores_out)\nplt.tight_layout()\nplt.show()\n</pre>  print(\"\\n=== Plots ===\") # hists / roc plt.figure(figsize=(9, 3)) plt.subplot(121) plot_ood_scores(scores_in, scores_out, log_scale=True) plt.subplot(122) plot_roc_curve(scores_in, scores_out) plt.tight_layout() plt.show() <pre>\n=== Plots ===\n</pre>"},{"location":"notebooks/tensorflow/demo_gram_tf/#gram-method","title":"Gram method\u00b6","text":"<p>This notebook aims at evaluating the gram method.</p> <p>The method consists in computing the Gram matrices of several layers to evaluate the channel-wise correlation of internal features. A score is built by computing these correlations for a new input and evaluating their deviation from regular correlations values computed on the in-distribution dataset.</p> <p>Important Disclaimer: Taking the statistics of min/max deviation, as in the paper raises some problems.</p> <p>The method often yields a score of zero for some tasks. This is expected since the min/max among the samples of a random variable becomes more and more extreme with the sample size. As a result, computing the min/max over the training set is likely to produce min/max values that are so extreme that none of the in distribution correlations of the validation set goes beyond these threshold. The worst is that a significant part of ood data does not exceed the thresholds either. This can be aleviated by computing the min/max over a limited number of sample. However, it is counter-intuitive and, in our opinion, not desirable: adding some more information should only improve a method.</p> <p>Hence, we decided to replace the min/max by the q / 1-q quantile, with q a new parameter of the method. Specifically, instead of the deviation as defined in eq. 3 of the paper, we use the definition $$ \\delta(t_q, t_{1-q}, value) = \\begin{cases}     0 &amp; \\text{if} \\; t_q \\leq value \\leq t_{1-q} \\\\     \\frac{t_q - value}{|t_q|} &amp; \\text{if } value &lt; t_q,  \\\\     \\frac{value - t_{1-q}}{|t_q|} &amp; \\text{if } value &gt; t_{1-q} \\end{cases} $$ With this new deviation, the more point we add, the more accurate the quantile becomes. In addition, the method can be made more or less discriminative by toggling the value of q.</p> <p>Finally, we found that this approach improved the performance of the baseline in our experiments.</p> <p>Here, we focus on a toy convolutional network trained on MNIST[0-4] and a ResNet model trained on CIFAR-10, respectively challenged on MNIST[5-9] and SVHN OOD datasets.</p> <p>Reference Detecting Out-of-Distribution Examples with Gram Matrices, ICML 2020</p>"},{"location":"notebooks/tensorflow/demo_gram_tf/#imports","title":"Imports\u00b6","text":""},{"location":"notebooks/tensorflow/demo_gram_tf/#first-experiment-mnist0-4-vs-mnist5-9","title":"First experiment: MNIST[0-4] vs MNIST[5-9]\u00b6","text":"<p>For this first experiment, we train a toy convolutional network on the MNIST dataset restricted to digits 0 to 4. After fitting the train subset of this dataset to the gram method, we will compare the scores returned for MNIST[0-4] (in-distribution) and MNIST[5-9] (out-of-distribution) test subsets.</p>"},{"location":"notebooks/tensorflow/demo_gram_tf/#data-loading","title":"Data loading\u00b6","text":"<ul> <li>In-distribution data: MNIST[0-4]</li> <li>Out-of-distribution data: MNIST[5-9]</li> </ul> <p>Note: We denote In-Distribution (ID) data with <code>_in</code> and Out-Of-Distribution (OOD) data with <code>_out</code> to avoid confusion with OOD detection which is the name of the task, and is therefore used to denote core classes such as <code>OODDataset</code> and <code>OODBaseDetector</code>.</p>"},{"location":"notebooks/tensorflow/demo_gram_tf/#model-training","title":"Model training\u00b6","text":"<p>Now let's train a simple model on MNIST[0-4] on a simple MLP using <code>train_tf_model</code> function.</p>"},{"location":"notebooks/tensorflow/demo_gram_tf/#gram-score","title":"gram score\u00b6","text":"<p>We now fit a gram detector with MNIST[0-4] train dataset, and compare OOD scores returned for MNIST[0-4] (ID) and MNIST[5-9] (OOD) test datasets.</p>"},{"location":"notebooks/tensorflow/demo_gram_tf/#second-experiment-cifar-10-vs-svhn","title":"Second experiment: CIFAR-10 vs SVHN\u00b6","text":"<p>For this second experiment, we oppose CIFAR-10 (in-distribution dataset) to SVHN (out-of-distribution dataset).</p>"},{"location":"notebooks/tensorflow/demo_gram_tf/#data-loading","title":"Data loading\u00b6","text":"<ul> <li>In-distribution data: CIFAR-10</li> <li>Out-of-distribution data: SVHN</li> </ul>"},{"location":"notebooks/tensorflow/demo_gram_tf/#model-loading","title":"Model loading\u00b6","text":"<p>The model is a ResNet pretrained on CIFAR-10 and getting an accuracy score of 92.75%.</p>"},{"location":"notebooks/tensorflow/demo_gram_tf/#gram-score","title":"gram score\u00b6","text":"<p>We now fit a gram detector with CIFAR-10 train dataset, and compare OOD scores returned for CIFAR-10 (ID) and SVHN (OOD) test datasets.</p>"},{"location":"notebooks/tensorflow/demo_mahalanobis_tf/","title":"Mahalanobis","text":"In\u00a0[1]: Copied! <pre>%load_ext autoreload\n\nimport os\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n\nfrom IPython.display import clear_output\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n\nfrom oodeel.methods import Mahalanobis\nfrom oodeel.eval.metrics import bench_metrics\nfrom oodeel.eval.plots import plot_ood_scores, plot_roc_curve, plot_2D_features\nfrom oodeel.datasets import OODDataset\nfrom oodeel.utils.tf_training_tools import train_tf_model\n</pre> %load_ext autoreload  import os os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"  from IPython.display import clear_output import tensorflow as tf import matplotlib.pyplot as plt  from oodeel.methods import Mahalanobis from oodeel.eval.metrics import bench_metrics from oodeel.eval.plots import plot_ood_scores, plot_roc_curve, plot_2D_features from oodeel.datasets import OODDataset from oodeel.utils.tf_training_tools import train_tf_model <p>Note that models are saved at ~/.oodeel/saved_models and data is supposed to be found at ~/.oodeel/datasets by default. Change the following cell for a custom path.</p> In\u00a0[2]: Copied! <pre>model_path = os.path.expanduser(\"~/\") + \".oodeel/saved_models\"\ndata_path = os.path.expanduser(\"~/\") + \".oodeel/datasets\"\nos.makedirs(model_path, exist_ok=True)\nos.makedirs(data_path, exist_ok=True)\n</pre> model_path = os.path.expanduser(\"~/\") + \".oodeel/saved_models\" data_path = os.path.expanduser(\"~/\") + \".oodeel/datasets\" os.makedirs(model_path, exist_ok=True) os.makedirs(data_path, exist_ok=True) In\u00a0[3]: Copied! <pre># === Load ID and OOD data ===\nbatch_size = 128\nin_labels = [0, 1, 2, 3, 4]\n\n# 1- Load train/test MNIST dataset\nds_train = OODDataset(\"mnist\", load_kwargs=dict(split=\"train\"))\ndata_test = OODDataset(\"mnist\", load_kwargs=dict(split=\"test\"))\n\n# 2- Split ID / OOD data depending on label value:\n# in-distribution: MNIST[0-4] / out-of-distribution: MNIST[5-9]\nds_train, _ = ds_train.split_by_class(in_labels)\noods_in, oods_out = data_test.split_by_class(in_labels)\n\n\n# 3- Prepare data (preprocess, shuffle, batch)\ndef preprocess_fn(*inputs):\n    x = inputs[0] / 255\n    return tuple([x] + list(inputs[1:]))\n\n\nds_train = ds_train.prepare(batch_size, preprocess_fn, shuffle=True)\nds_in = oods_in.prepare(batch_size, preprocess_fn, with_ood_labels=False)\nds_out = oods_out.prepare(batch_size, preprocess_fn, with_ood_labels=False)\n\nclear_output()\n</pre> # === Load ID and OOD data === batch_size = 128 in_labels = [0, 1, 2, 3, 4]  # 1- Load train/test MNIST dataset ds_train = OODDataset(\"mnist\", load_kwargs=dict(split=\"train\")) data_test = OODDataset(\"mnist\", load_kwargs=dict(split=\"test\"))  # 2- Split ID / OOD data depending on label value: # in-distribution: MNIST[0-4] / out-of-distribution: MNIST[5-9] ds_train, _ = ds_train.split_by_class(in_labels) oods_in, oods_out = data_test.split_by_class(in_labels)   # 3- Prepare data (preprocess, shuffle, batch) def preprocess_fn(*inputs):     x = inputs[0] / 255     return tuple([x] + list(inputs[1:]))   ds_train = ds_train.prepare(batch_size, preprocess_fn, shuffle=True) ds_in = oods_in.prepare(batch_size, preprocess_fn, with_ood_labels=False) ds_out = oods_out.prepare(batch_size, preprocess_fn, with_ood_labels=False)  clear_output() In\u00a0[4]: Copied! <pre># === Train / Load model ===\nmodel_path_mnist_04 = os.path.join(model_path, \"mnist_model_0-4.h5\")\n\ntry:\n    # if the model exists, load it\n    model = tf.keras.models.load_model(model_path_mnist_04)\nexcept OSError:\n    # else, train a new model\n    train_config = {\n        \"model\": \"toy_convnet\",\n        \"input_shape\": (28, 28, 1),\n        \"num_classes\": 10,\n        \"batch_size\": 128,\n        \"epochs\": 5,\n        \"save_dir\": model_path_mnist_04,\n        \"validation_data\": ds_in,\n    }\n\n    model = train_tf_model(ds_train, **train_config)\n\n_, accuracy = model.evaluate(ds_in)\nprint(f\"Test accuracy:\\t{accuracy:.4f}\")\n\n# penultimate features 2d visualization\nprint(\"\\n=== Penultimate features viz ===\")\nplt.figure(figsize=(4.5, 3))\nplot_2D_features(\n    model=model,\n    in_dataset=ds_in,\n    out_dataset=ds_out,\n    output_layer_id=-2,\n)\nplt.tight_layout()\nplt.show()\n</pre> # === Train / Load model === model_path_mnist_04 = os.path.join(model_path, \"mnist_model_0-4.h5\")  try:     # if the model exists, load it     model = tf.keras.models.load_model(model_path_mnist_04) except OSError:     # else, train a new model     train_config = {         \"model\": \"toy_convnet\",         \"input_shape\": (28, 28, 1),         \"num_classes\": 10,         \"batch_size\": 128,         \"epochs\": 5,         \"save_dir\": model_path_mnist_04,         \"validation_data\": ds_in,     }      model = train_tf_model(ds_train, **train_config)  _, accuracy = model.evaluate(ds_in) print(f\"Test accuracy:\\t{accuracy:.4f}\")  # penultimate features 2d visualization print(\"\\n=== Penultimate features viz ===\") plt.figure(figsize=(4.5, 3)) plot_2D_features(     model=model,     in_dataset=ds_in,     out_dataset=ds_out,     output_layer_id=-2, ) plt.tight_layout() plt.show() <pre>41/41 [==============================] - 2s 38ms/step - loss: 0.0135 - accuracy: 0.9955\nTest accuracy:\t0.9955\n\n=== Penultimate features viz ===\n</pre> In\u00a0[5]: Copied! <pre># === Mahalanobis scores ===\nmahalanobis = Mahalanobis(eps=0.002)\nmahalanobis.fit(model, feature_layers_id=[-2], fit_dataset=ds_train)\nscores_in, _ = mahalanobis.score(ds_in)\nscores_out, _ = mahalanobis.score(ds_out)\nclear_output()\n\n# === metrics ===\n# auroc / fpr95\nmetrics = bench_metrics(\n    (scores_in, scores_out),\n    metrics=[\"auroc\", \"fpr95tpr\"],\n)\nprint(\"=== Metrics ===\")\nfor k, v in metrics.items():\n    print(f\"{k:&lt;10} {v:.6f}\")\n\nprint(\"\\n=== Plots ===\")\n# hists / roc\nplt.figure(figsize=(9, 3))\nplt.subplot(121)\nplot_ood_scores(scores_in, scores_out, log_scale=False)\nplt.subplot(122)\nplot_roc_curve(scores_in, scores_out)\nplt.tight_layout()\nplt.show()\n</pre> # === Mahalanobis scores === mahalanobis = Mahalanobis(eps=0.002) mahalanobis.fit(model, feature_layers_id=[-2], fit_dataset=ds_train) scores_in, _ = mahalanobis.score(ds_in) scores_out, _ = mahalanobis.score(ds_out) clear_output()  # === metrics === # auroc / fpr95 metrics = bench_metrics(     (scores_in, scores_out),     metrics=[\"auroc\", \"fpr95tpr\"], ) print(\"=== Metrics ===\") for k, v in metrics.items():     print(f\"{k:&lt;10} {v:.6f}\")  print(\"\\n=== Plots ===\") # hists / roc plt.figure(figsize=(9, 3)) plt.subplot(121) plot_ood_scores(scores_in, scores_out, log_scale=False) plt.subplot(122) plot_roc_curve(scores_in, scores_out) plt.tight_layout() plt.show() <pre>=== Metrics ===\nauroc      0.884979\nfpr95tpr   0.426348\n\n=== Plots ===\n</pre> In\u00a0[6]: Copied! <pre># === Load ID and OOD data ===\nbatch_size = 128\n\n# 1a- Load in-distribution dataset: CIFAR-10\nds_fit = OODDataset(\"cifar10\", load_kwargs={\"split\": \"train\"}, input_key=\"image\")\nds_in = OODDataset(\"cifar10\", load_kwargs={\"split\": \"test\"}, input_key=\"image\")\n\n# 1b- Load out-of-distribution dataset: SVHN\nds_out = OODDataset(\"svhn_cropped\", load_kwargs={\"split\": \"test\"})\n\n\n# 2- prepare data (preprocess, shuffle, batch)\ndef preprocess_fn(*inputs):\n    x = inputs[0] / 255\n    return tuple([x] + list(inputs[1:]))\n\n\nds_fit = ds_fit.prepare(batch_size, preprocess_fn)\nds_in = ds_in.prepare(batch_size, preprocess_fn)\nds_out = ds_out.prepare(batch_size, preprocess_fn)\n</pre> # === Load ID and OOD data === batch_size = 128  # 1a- Load in-distribution dataset: CIFAR-10 ds_fit = OODDataset(\"cifar10\", load_kwargs={\"split\": \"train\"}, input_key=\"image\") ds_in = OODDataset(\"cifar10\", load_kwargs={\"split\": \"test\"}, input_key=\"image\")  # 1b- Load out-of-distribution dataset: SVHN ds_out = OODDataset(\"svhn_cropped\", load_kwargs={\"split\": \"test\"})   # 2- prepare data (preprocess, shuffle, batch) def preprocess_fn(*inputs):     x = inputs[0] / 255     return tuple([x] + list(inputs[1:]))   ds_fit = ds_fit.prepare(batch_size, preprocess_fn) ds_in = ds_in.prepare(batch_size, preprocess_fn) ds_out = ds_out.prepare(batch_size, preprocess_fn) In\u00a0[7]: Copied! <pre># === Load model ===\n# ResNet pretrained on CIFAR-10\nmodel_path_resnet_cifar10 = tf.keras.utils.get_file(\n    \"cifar10_resnet256.h5\",\n    origin=\"https://share.deel.ai/s/kram9kLpx6JwRX4/download/cifar10_resnet256.h5\",\n    cache_dir=model_path,\n    cache_subdir=\"\",\n)\nmodel = tf.keras.models.load_model(model_path_resnet_cifar10)\n\n# Evaluate model\nmodel.compile(metrics=[\"accuracy\"])\n_, accuracy = model.evaluate(ds_in)\nprint(f\"Test accuracy:\\t{accuracy:.4f}\")\n\n# penultimate features 2d visualization\nprint(\"\\n=== Penultimate features viz ===\")\nplt.figure(figsize=(4.5, 3))\nplot_2D_features(\n    model=model,\n    in_dataset=ds_in,\n    out_dataset=ds_out,\n    output_layer_id=-2,\n)\nplt.tight_layout()\nplt.show()\n</pre> # === Load model === # ResNet pretrained on CIFAR-10 model_path_resnet_cifar10 = tf.keras.utils.get_file(     \"cifar10_resnet256.h5\",     origin=\"https://share.deel.ai/s/kram9kLpx6JwRX4/download/cifar10_resnet256.h5\",     cache_dir=model_path,     cache_subdir=\"\", ) model = tf.keras.models.load_model(model_path_resnet_cifar10)  # Evaluate model model.compile(metrics=[\"accuracy\"]) _, accuracy = model.evaluate(ds_in) print(f\"Test accuracy:\\t{accuracy:.4f}\")  # penultimate features 2d visualization print(\"\\n=== Penultimate features viz ===\") plt.figure(figsize=(4.5, 3)) plot_2D_features(     model=model,     in_dataset=ds_in,     out_dataset=ds_out,     output_layer_id=-2, ) plt.tight_layout() plt.show() <pre>79/79 [==============================] - 34s 397ms/step - loss: 0.1268 - accuracy: 0.9276\nTest accuracy:\t0.9276\n\n=== Penultimate features viz ===\n</pre> In\u00a0[9]: Copied! <pre># === Mahalanobis OOD scores ===\nmahalanobis = Mahalanobis(eps=0.002)\nmahalanobis.fit(model, feature_layers_id=[-2], fit_dataset=ds_fit)\nscores_in, _ = mahalanobis.score(ds_in)\nscores_out, _ = mahalanobis.score(ds_out)\n\n# === metrics ===\n# auroc / fpr95\nmetrics = bench_metrics(\n    (scores_in, scores_out),\n    metrics=[\"auroc\", \"fpr95tpr\"],\n)\nprint(\"=== Metrics ===\")\nfor k, v in metrics.items():\n    print(f\"{k:&lt;10} {v:.6f}\")\n\nprint(\"\\n=== Plots ===\")\n# hists / roc\nplt.figure(figsize=(9, 3))\nplt.subplot(121)\nplot_ood_scores(scores_in, scores_out, log_scale=False)\nplt.subplot(122)\nplot_roc_curve(scores_in, scores_out)\nplt.tight_layout()\nplt.show()\n</pre> # === Mahalanobis OOD scores === mahalanobis = Mahalanobis(eps=0.002) mahalanobis.fit(model, feature_layers_id=[-2], fit_dataset=ds_fit) scores_in, _ = mahalanobis.score(ds_in) scores_out, _ = mahalanobis.score(ds_out)  # === metrics === # auroc / fpr95 metrics = bench_metrics(     (scores_in, scores_out),     metrics=[\"auroc\", \"fpr95tpr\"], ) print(\"=== Metrics ===\") for k, v in metrics.items():     print(f\"{k:&lt;10} {v:.6f}\")  print(\"\\n=== Plots ===\") # hists / roc plt.figure(figsize=(9, 3)) plt.subplot(121) plot_ood_scores(scores_in, scores_out, log_scale=False) plt.subplot(122) plot_roc_curve(scores_in, scores_out) plt.tight_layout() plt.show() <pre>=== Metrics ===\nauroc      0.859480\nfpr95tpr   0.594900\n\n=== Plots ===\n</pre>"},{"location":"notebooks/tensorflow/demo_mahalanobis_tf/#mahalanobis-method","title":"Mahalanobis method\u00b6","text":"<p>This notebook aims at evaluating the Mahalanobis method.</p> <p>Here, we focus on a toy convolutional network trained on MNIST[0-4] and a ResNet model trained on CIFAR-10, respectively challenged on MNIST[5-9] and SVHN OOD datasets.</p> <p>Reference A Simple Unified Framework for Detecting Out-of-Distribution Samples and Adversarial Attacks LEE, Kimin, LEE, Kibok, LEE, Honglak, et al. Advances in neural information processing systems, 2018, vol. 31. https://arxiv.org/abs/1807.03888</p>"},{"location":"notebooks/tensorflow/demo_mahalanobis_tf/#imports","title":"Imports\u00b6","text":""},{"location":"notebooks/tensorflow/demo_mahalanobis_tf/#first-experiment-mnist0-4-vs-mnist5-9","title":"First experiment: MNIST[0-4] vs MNIST[5-9]\u00b6","text":"<p>For this first experiment, we train a toy convolutional network on the MNIST dataset restricted to digits 0 to 4. After fitting the train subset of this dataset to the Mahalanobis method, we will compare the scores returned for MNIST[0-4] (in-distribution) and MNIST[5-9] (out-of-distribution) test subsets.</p>"},{"location":"notebooks/tensorflow/demo_mahalanobis_tf/#data-loading","title":"Data loading\u00b6","text":"<ul> <li>In-distribution data: MNIST[0-4]</li> <li>Out-of-distribution data: MNIST[5-9]</li> </ul> <p>Note: We denote In-Distribution (ID) data with <code>_in</code> and Out-Of-Distribution (OOD) data with <code>_out</code> to avoid confusion with OOD detection which is the name of the task, and is therefore used to denote core classes such as <code>OODDataset</code> and <code>OODBaseDetector</code>.</p>"},{"location":"notebooks/tensorflow/demo_mahalanobis_tf/#model-training","title":"Model training\u00b6","text":"<p>Now let's train a simple model on MNIST[0-4] using <code>train_tf_model</code> function.</p>"},{"location":"notebooks/tensorflow/demo_mahalanobis_tf/#mahalanobis-score","title":"Mahalanobis score\u00b6","text":"<p>We now fit a Mahalanobis OOD detector with MNIST[0-4] train dataset, and compare OOD scores returned for MNIST[0-4] (ID) and MNIST[5-9] (OOD) test datasets.</p>"},{"location":"notebooks/tensorflow/demo_mahalanobis_tf/#second-experiment-cifar-10-vs-svhn","title":"Second experiment: CIFAR-10 vs SVHN\u00b6","text":"<p>For this second experiment, we oppose CIFAR-10 (in-distribution dataset) to SVHN (out-of-distribution dataset).</p>"},{"location":"notebooks/tensorflow/demo_mahalanobis_tf/#data-loading","title":"Data loading\u00b6","text":"<ul> <li>In-distribution data: CIFAR-10</li> <li>Out-of-distribution data: SVHN</li> </ul>"},{"location":"notebooks/tensorflow/demo_mahalanobis_tf/#model-loading","title":"Model loading\u00b6","text":"<p>The model is a ResNet pretrained on CIFAR-10 and getting an accuracy score of 92.75%.</p>"},{"location":"notebooks/tensorflow/demo_mahalanobis_tf/#mahalanobis-score","title":"Mahalanobis score\u00b6","text":"<p>We now fit a Mahalanobis OOD detector with CIFAR-10 train dataset, and compare OOD scores returned for CIFAR-10 (ID) and SVHN (OOD) test datasets.</p>"},{"location":"notebooks/tensorflow/demo_mls_msp_tf/","title":"MLS/MSP","text":"In\u00a0[1]: Copied! <pre>%load_ext autoreload\n\nimport os\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n\nfrom IPython.display import clear_output\nimport numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n\nfrom oodeel.methods import MLS\nfrom oodeel.eval.metrics import bench_metrics\nfrom oodeel.eval.plots import plot_ood_scores, plot_roc_curve, plot_2D_features\nfrom oodeel.datasets import OODDataset\nfrom oodeel.utils.tf_training_tools import train_tf_model\n</pre> %load_ext autoreload  import os os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"  from IPython.display import clear_output import numpy as np import tensorflow as tf import matplotlib.pyplot as plt  from oodeel.methods import MLS from oodeel.eval.metrics import bench_metrics from oodeel.eval.plots import plot_ood_scores, plot_roc_curve, plot_2D_features from oodeel.datasets import OODDataset from oodeel.utils.tf_training_tools import train_tf_model <p>Note that models are saved at ~/.oodeel/saved_models and data is supposed to be found at ~/.oodeel/datasets by default. Change the following cell for a custom path.</p> In\u00a0[2]: Copied! <pre>model_path = os.path.expanduser(\"~/\") + \".oodeel/saved_models\"\ndata_path = os.path.expanduser(\"~/\") + \".oodeel/datasets\"\nos.makedirs(model_path, exist_ok=True)\nos.makedirs(data_path, exist_ok=True)\n</pre> model_path = os.path.expanduser(\"~/\") + \".oodeel/saved_models\" data_path = os.path.expanduser(\"~/\") + \".oodeel/datasets\" os.makedirs(model_path, exist_ok=True) os.makedirs(data_path, exist_ok=True) In\u00a0[3]: Copied! <pre># === Load ID and OOD data ===\nbatch_size = 128\nin_labels = [0, 1, 2, 3, 4]\n\n# 1- Load train/test MNIST dataset\nds_train = OODDataset(\"mnist\", load_kwargs=dict(split=\"train\"))\ndata_test = OODDataset(\"mnist\", load_kwargs=dict(split=\"test\"))\n\n# 2- Split ID / OOD data depending on label value:\n# in-distribution: MNIST[0-4] / out-of-distribution: MNIST[5-9]\nds_train, _ = ds_train.split_by_class(in_labels)\noods_in, oods_out = data_test.split_by_class(in_labels)\n\n\n# 3- Prepare data (preprocess, shuffle, batch)\ndef preprocess_fn(*inputs):\n    x = inputs[0] / 255\n    return tuple([x] + list(inputs[1:]))\n\n\nds_train = ds_train.prepare(batch_size, preprocess_fn, shuffle=True)\nds_in = oods_in.prepare(batch_size, preprocess_fn, with_ood_labels=False)\nds_out = oods_out.prepare(batch_size, preprocess_fn, with_ood_labels=False)\n\nclear_output()\n</pre> # === Load ID and OOD data === batch_size = 128 in_labels = [0, 1, 2, 3, 4]  # 1- Load train/test MNIST dataset ds_train = OODDataset(\"mnist\", load_kwargs=dict(split=\"train\")) data_test = OODDataset(\"mnist\", load_kwargs=dict(split=\"test\"))  # 2- Split ID / OOD data depending on label value: # in-distribution: MNIST[0-4] / out-of-distribution: MNIST[5-9] ds_train, _ = ds_train.split_by_class(in_labels) oods_in, oods_out = data_test.split_by_class(in_labels)   # 3- Prepare data (preprocess, shuffle, batch) def preprocess_fn(*inputs):     x = inputs[0] / 255     return tuple([x] + list(inputs[1:]))   ds_train = ds_train.prepare(batch_size, preprocess_fn, shuffle=True) ds_in = oods_in.prepare(batch_size, preprocess_fn, with_ood_labels=False) ds_out = oods_out.prepare(batch_size, preprocess_fn, with_ood_labels=False)  clear_output() In\u00a0[4]: Copied! <pre># === Train / Load model ===\nmodel_path_mnist_04 = os.path.join(model_path, \"mnist_model_0-4.h5\")\n\ntry:\n    # if the model exists, load it\n    model = tf.keras.models.load_model(model_path_mnist_04)\nexcept OSError:\n    # else, train a new model\n    train_config = {\n        \"model\": \"toy_convnet\",\n        \"input_shape\": (28, 28, 1),\n        \"num_classes\": 10,\n        \"batch_size\": 128,\n        \"epochs\": 5,\n        \"save_dir\": model_path_mnist_04,\n        \"validation_data\": ds_in,\n    }\n\n    model = train_tf_model(ds_train, **train_config)\n\n_, accuracy = model.evaluate(ds_in)\nprint(f\"Test accuracy:\\t{accuracy:.4f}\")\n\n# penultimate features 2d visualization\nprint(\"\\n=== Penultimate features viz ===\")\nplt.figure(figsize=(4.5, 3))\nplot_2D_features(\n    model=model,\n    in_dataset=ds_in,\n    out_dataset=ds_out,\n    output_layer_id=-2,\n)\nplt.tight_layout()\nplt.show()\n</pre> # === Train / Load model === model_path_mnist_04 = os.path.join(model_path, \"mnist_model_0-4.h5\")  try:     # if the model exists, load it     model = tf.keras.models.load_model(model_path_mnist_04) except OSError:     # else, train a new model     train_config = {         \"model\": \"toy_convnet\",         \"input_shape\": (28, 28, 1),         \"num_classes\": 10,         \"batch_size\": 128,         \"epochs\": 5,         \"save_dir\": model_path_mnist_04,         \"validation_data\": ds_in,     }      model = train_tf_model(ds_train, **train_config)  _, accuracy = model.evaluate(ds_in) print(f\"Test accuracy:\\t{accuracy:.4f}\")  # penultimate features 2d visualization print(\"\\n=== Penultimate features viz ===\") plt.figure(figsize=(4.5, 3)) plot_2D_features(     model=model,     in_dataset=ds_in,     out_dataset=ds_out,     output_layer_id=-2, ) plt.tight_layout() plt.show() <pre>41/41 [==============================] - 2s 12ms/step - loss: 0.0118 - accuracy: 0.9965\nTest accuracy:\t0.9965\n\n=== Penultimate features viz ===\n</pre> In\u00a0[5]: Copied! <pre># === MLS scores ===\nmls = MLS()\nmls.fit(model)\nscores_in, _ = mls.score(ds_in)\nscores_out, _ = mls.score(ds_out)\n\n# === metrics ===\n# auroc / fpr95\nmetrics = bench_metrics(\n    (scores_in, scores_out),\n    metrics=[\"auroc\", \"fpr95tpr\"],\n)\nprint(\"=== Metrics ===\")\nfor k, v in metrics.items():\n    print(f\"{k:&lt;10} {v:.6f}\")\n\nprint(\"\\n=== Plots ===\")\n# hists / roc\nplt.figure(figsize=(9, 3))\nplt.subplot(121)\nplot_ood_scores(scores_in, scores_out, log_scale=False)\nplt.subplot(122)\nplot_roc_curve(scores_in, scores_out)\nplt.tight_layout()\nplt.show()\n</pre> # === MLS scores === mls = MLS() mls.fit(model) scores_in, _ = mls.score(ds_in) scores_out, _ = mls.score(ds_out)  # === metrics === # auroc / fpr95 metrics = bench_metrics(     (scores_in, scores_out),     metrics=[\"auroc\", \"fpr95tpr\"], ) print(\"=== Metrics ===\") for k, v in metrics.items():     print(f\"{k:&lt;10} {v:.6f}\")  print(\"\\n=== Plots ===\") # hists / roc plt.figure(figsize=(9, 3)) plt.subplot(121) plot_ood_scores(scores_in, scores_out, log_scale=False) plt.subplot(122) plot_roc_curve(scores_in, scores_out) plt.tight_layout() plt.show() <pre>=== Metrics ===\nauroc      0.934842\nfpr95tpr   0.392878\n\n=== Plots ===\n</pre> In\u00a0[6]: Copied! <pre># === MSP scores ===\nmsp = MLS(output_activation=\"softmax\")\nmsp.fit(model)\nscores_in, _ = msp.score(ds_in)\nscores_out, _ = msp.score(ds_out)\n\n# === metrics ===\n# auroc / fpr95\nmetrics = bench_metrics(\n    (scores_in, scores_out),\n    metrics=[\"auroc\", \"fpr95tpr\"],\n)\nprint(\"=== Metrics ===\")\nfor k, v in metrics.items():\n    print(f\"{k:&lt;10} {v:.6f}\")\n\nprint(\"\\n=== Plots ===\")\n# Normalize scores for a better hist visualization\nminim = np.min([np.min(scores_in), np.min(scores_out)])\nscores_in_ = scores_in - 2 * minim + np.min(scores_in[np.where(scores_in != minim)])\nscores_out_ = scores_out - 2 * minim + np.min(scores_in[np.where(scores_in != minim)])\n\n# hists / roc\nplt.figure(figsize=(9, 3))\nplt.subplot(121)\nplot_ood_scores(scores_in_, scores_out_, log_scale=True)\nplt.subplot(122)\nplot_roc_curve(scores_in, scores_out)\nplt.tight_layout()\nplt.show()\n</pre> # === MSP scores === msp = MLS(output_activation=\"softmax\") msp.fit(model) scores_in, _ = msp.score(ds_in) scores_out, _ = msp.score(ds_out)  # === metrics === # auroc / fpr95 metrics = bench_metrics(     (scores_in, scores_out),     metrics=[\"auroc\", \"fpr95tpr\"], ) print(\"=== Metrics ===\") for k, v in metrics.items():     print(f\"{k:&lt;10} {v:.6f}\")  print(\"\\n=== Plots ===\") # Normalize scores for a better hist visualization minim = np.min([np.min(scores_in), np.min(scores_out)]) scores_in_ = scores_in - 2 * minim + np.min(scores_in[np.where(scores_in != minim)]) scores_out_ = scores_out - 2 * minim + np.min(scores_in[np.where(scores_in != minim)])  # hists / roc plt.figure(figsize=(9, 3)) plt.subplot(121) plot_ood_scores(scores_in_, scores_out_, log_scale=True) plt.subplot(122) plot_roc_curve(scores_in, scores_out) plt.tight_layout() plt.show() <pre>=== Metrics ===\nauroc      0.937479\nfpr95tpr   0.416229\n\n=== Plots ===\n</pre> In\u00a0[7]: Copied! <pre># === Load ID and OOD data ===\nbatch_size = 128\n\n# 1a- Load in-distribution dataset: CIFAR-10\nds_in = OODDataset(\"cifar10\", load_kwargs={\"split\": \"test\"}, input_key=\"image\")\n\n# 1b- Load out-of-distribution dataset: SVHN\nds_out = OODDataset(\"svhn_cropped\", load_kwargs={\"split\": \"test\"})\n\n\n# 2- prepare data (preprocess, shuffle, batch)\ndef preprocess_fn(*inputs):\n    x = inputs[0] / 255\n    return tuple([x] + list(inputs[1:]))\n\n\nds_in = ds_in.prepare(batch_size, preprocess_fn)\nds_out = ds_out.prepare(batch_size, preprocess_fn)\n</pre> # === Load ID and OOD data === batch_size = 128  # 1a- Load in-distribution dataset: CIFAR-10 ds_in = OODDataset(\"cifar10\", load_kwargs={\"split\": \"test\"}, input_key=\"image\")  # 1b- Load out-of-distribution dataset: SVHN ds_out = OODDataset(\"svhn_cropped\", load_kwargs={\"split\": \"test\"})   # 2- prepare data (preprocess, shuffle, batch) def preprocess_fn(*inputs):     x = inputs[0] / 255     return tuple([x] + list(inputs[1:]))   ds_in = ds_in.prepare(batch_size, preprocess_fn) ds_out = ds_out.prepare(batch_size, preprocess_fn) In\u00a0[8]: Copied! <pre># === Load model ===\n# ResNet pretrained on CIFAR-10\nmodel_path_resnet_cifar10 = tf.keras.utils.get_file(\n    \"cifar10_resnet256.h5\",\n    origin=\"https://share.deel.ai/s/kram9kLpx6JwRX4/download/cifar10_resnet256.h5\",\n    cache_dir=model_path,\n    cache_subdir=\"\",\n)\nmodel = tf.keras.models.load_model(model_path_resnet_cifar10)\n\n# Evaluate model\nmodel.compile(metrics=[\"accuracy\"])\n_, accuracy = model.evaluate(ds_in)\nprint(f\"Test accuracy:\\t{accuracy:.4f}\")\n\n# penultimate features 2d visualization\nprint(\"\\n=== Penultimate features viz ===\")\nplt.figure(figsize=(4.5, 3))\nplot_2D_features(\n    model=model,\n    in_dataset=ds_in,\n    out_dataset=ds_out,\n    output_layer_id=-2,\n)\nplt.tight_layout()\nplt.show()\n</pre> # === Load model === # ResNet pretrained on CIFAR-10 model_path_resnet_cifar10 = tf.keras.utils.get_file(     \"cifar10_resnet256.h5\",     origin=\"https://share.deel.ai/s/kram9kLpx6JwRX4/download/cifar10_resnet256.h5\",     cache_dir=model_path,     cache_subdir=\"\", ) model = tf.keras.models.load_model(model_path_resnet_cifar10)  # Evaluate model model.compile(metrics=[\"accuracy\"]) _, accuracy = model.evaluate(ds_in) print(f\"Test accuracy:\\t{accuracy:.4f}\")  # penultimate features 2d visualization print(\"\\n=== Penultimate features viz ===\") plt.figure(figsize=(4.5, 3)) plot_2D_features(     model=model,     in_dataset=ds_in,     out_dataset=ds_out,     output_layer_id=-2, ) plt.tight_layout() plt.show() <pre>79/79 [==============================] - 3s 25ms/step - loss: 0.1268 - accuracy: 0.9276\nTest accuracy:\t0.9276\n\n=== Penultimate features viz ===\n</pre> In\u00a0[9]: Copied! <pre># === MLS scores ===\nmls = MLS()\nmls.fit(model)\nscores_in, _ = mls.score(ds_in)\nscores_out, _ = mls.score(ds_out)\n\n# === metrics ===\n# auroc / fpr95\nmetrics = bench_metrics(\n    (scores_in, scores_out),\n    metrics=[\"auroc\", \"fpr95tpr\"],\n)\nprint(\"=== Metrics ===\")\nfor k, v in metrics.items():\n    print(f\"{k:&lt;10} {v:.6f}\")\n\nprint(\"\\n=== Plots ===\")\n# hists / roc\nplt.figure(figsize=(9, 3))\nplt.subplot(121)\nplot_ood_scores(scores_in, scores_out, log_scale=False)\nplt.subplot(122)\nplot_roc_curve(scores_in, scores_out)\nplt.tight_layout()\nplt.show()\n</pre> # === MLS scores === mls = MLS() mls.fit(model) scores_in, _ = mls.score(ds_in) scores_out, _ = mls.score(ds_out)  # === metrics === # auroc / fpr95 metrics = bench_metrics(     (scores_in, scores_out),     metrics=[\"auroc\", \"fpr95tpr\"], ) print(\"=== Metrics ===\") for k, v in metrics.items():     print(f\"{k:&lt;10} {v:.6f}\")  print(\"\\n=== Plots ===\") # hists / roc plt.figure(figsize=(9, 3)) plt.subplot(121) plot_ood_scores(scores_in, scores_out, log_scale=False) plt.subplot(122) plot_roc_curve(scores_in, scores_out) plt.tight_layout() plt.show() <pre>=== Metrics ===\nauroc      0.915858\nfpr95tpr   0.205700\n\n=== Plots ===\n</pre> In\u00a0[10]: Copied! <pre># === MSP scores ===\nmsp = MLS(output_activation=\"softmax\")\nmsp.fit(model)\nscores_in, _ = msp.score(ds_in)\nscores_out, _ = msp.score(ds_out)\n\n# === metrics ===\n# auroc / fpr95\nmetrics = bench_metrics(\n    (scores_in, scores_out),\n    metrics=[\"auroc\", \"fpr95tpr\"],\n)\nprint(\"=== Metrics ===\")\nfor k, v in metrics.items():\n    print(f\"{k:&lt;10} {v:.6f}\")\n\nprint(\"\\n=== Plots ===\")\n# Normalize scores for a better hist visualization\nminim = np.min([np.min(scores_in), np.min(scores_out)])\nscores_in_ = scores_in - 2 * minim + np.min(scores_in[np.where(scores_in != minim)])\nscores_out_ = scores_out - 2 * minim + np.min(scores_in[np.where(scores_in != minim)])\n\n# hists / roc\nplt.figure(figsize=(9, 3))\nplt.subplot(121)\nplot_ood_scores(scores_in_, scores_out_, log_scale=True)\nplt.subplot(122)\nplot_roc_curve(scores_in, scores_out)\nplt.tight_layout()\nplt.show()\n</pre> # === MSP scores === msp = MLS(output_activation=\"softmax\") msp.fit(model) scores_in, _ = msp.score(ds_in) scores_out, _ = msp.score(ds_out)  # === metrics === # auroc / fpr95 metrics = bench_metrics(     (scores_in, scores_out),     metrics=[\"auroc\", \"fpr95tpr\"], ) print(\"=== Metrics ===\") for k, v in metrics.items():     print(f\"{k:&lt;10} {v:.6f}\")  print(\"\\n=== Plots ===\") # Normalize scores for a better hist visualization minim = np.min([np.min(scores_in), np.min(scores_out)]) scores_in_ = scores_in - 2 * minim + np.min(scores_in[np.where(scores_in != minim)]) scores_out_ = scores_out - 2 * minim + np.min(scores_in[np.where(scores_in != minim)])  # hists / roc plt.figure(figsize=(9, 3)) plt.subplot(121) plot_ood_scores(scores_in_, scores_out_, log_scale=True) plt.subplot(122) plot_roc_curve(scores_in, scores_out) plt.tight_layout() plt.show() <pre>=== Metrics ===\nauroc      0.932143\nfpr95tpr   0.209000\n\n=== Plots ===\n</pre>"},{"location":"notebooks/tensorflow/demo_mls_msp_tf/#maximum-logit-score-maximum-softmax-probability","title":"Maximum Logit Score / Maximum Softmax Probability\u00b6","text":"<p>This notebook aims at evaluating the MLS and MSP methods.</p> <p>These methods return an OOD score based on the maximum value of the output logits or softmax activations.</p> <p>Here, we focus on a toy convolutional network trained on MNIST[0-4] and a ResNet model trained on CIFAR-10, respectively challenged on MNIST[5-9] and SVHN OOD datasets.</p> <p>References</p> <ul> <li>MLS: Open-Set Recognition: a Good Closed-Set Classifier is All You Need?, ICLR 2022.</li> <li>MSP: A Baseline for Detecting Misclassified and Out-of-Distribution Examples in Neural Networks, ICLR 2017.</li> </ul>"},{"location":"notebooks/tensorflow/demo_mls_msp_tf/#imports","title":"Imports\u00b6","text":""},{"location":"notebooks/tensorflow/demo_mls_msp_tf/#first-experiment-mnist0-4-vs-mnist5-9","title":"First experiment: MNIST[0-4] vs MNIST[5-9]\u00b6","text":"<p>For this first experiment, we train a toy convolutional network on the MNIST dataset restricted to digits 0 to 4. After fitting the train subset of this dataset to the MLS method, we will compare the scores returned for MNIST[0-4] (in-distribution) and MNIST[5-9] (out-of-distribution) test subsets.</p>"},{"location":"notebooks/tensorflow/demo_mls_msp_tf/#data-loading","title":"Data loading\u00b6","text":"<ul> <li>In-distribution data: MNIST[0-4]</li> <li>Out-of-distribution data: MNIST[5-9]</li> </ul> <p>Note: We denote In-Distribution (ID) data with <code>_in</code> and Out-Of-Distribution (OOD) data with <code>_out</code> to avoid confusion with OOD detection which is the name of the task, and is therefore used to denote core classes such as <code>OODDataset</code> and <code>OODBaseDetector</code>.</p>"},{"location":"notebooks/tensorflow/demo_mls_msp_tf/#model-training","title":"Model training\u00b6","text":"<p>Now let's train a simple model on MNIST[0-4] using <code>train_tf_model</code> function.</p>"},{"location":"notebooks/tensorflow/demo_mls_msp_tf/#mls-score","title":"MLS score\u00b6","text":"<p>We now fit a MLS OOD detector with MNIST[0-4] train dataset, and compare OOD scores returned for MNIST[0-4] (ID) and MNIST[5-9] (OOD) test datasets.</p>"},{"location":"notebooks/tensorflow/demo_mls_msp_tf/#msp-score","title":"MSP score\u00b6","text":"<p>Using the softmax activations instead, we get the MSP scores for MNIST[0-4] (ID) and MNIST[5-9] (OOD) test datasets.</p>"},{"location":"notebooks/tensorflow/demo_mls_msp_tf/#second-experiment-cifar-10-vs-svhn","title":"Second experiment: CIFAR-10 vs SVHN\u00b6","text":"<p>For this second experiment, we oppose CIFAR-10 (in-distribution dataset) to SVHN (out-of-distribution dataset).</p>"},{"location":"notebooks/tensorflow/demo_mls_msp_tf/#data-loading","title":"Data loading\u00b6","text":"<ul> <li>In-distribution data: CIFAR-10</li> <li>Out-of-distribution data: SVHN</li> </ul>"},{"location":"notebooks/tensorflow/demo_mls_msp_tf/#model-loading","title":"Model loading\u00b6","text":"<p>The model is a ResNet pretrained on CIFAR-10 and getting an accuracy score of 92.75%.</p>"},{"location":"notebooks/tensorflow/demo_mls_msp_tf/#mls-score","title":"MLS score\u00b6","text":"<p>We now fit a MLS OOD detector with CIFAR-10 train dataset, and compare OOD scores returned for CIFAR-10 (ID) and SVHN (OOD) test datasets.</p>"},{"location":"notebooks/tensorflow/demo_mls_msp_tf/#msp-score","title":"MSP score\u00b6","text":"<p>Using the softmax activations instead, we get the MSP scores for CIFAR-10 (ID) and SVHN (OOD) test datasets.</p>"},{"location":"notebooks/tensorflow/demo_odin_tf/","title":"ODIN","text":"In\u00a0[1]: Copied! <pre>%load_ext autoreload\n\nimport os\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n\nfrom IPython.display import clear_output\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n\nfrom oodeel.methods import ODIN\nfrom oodeel.eval.metrics import bench_metrics\nfrom oodeel.eval.plots import plot_ood_scores, plot_roc_curve, plot_2D_features\nfrom oodeel.datasets import OODDataset\nfrom oodeel.utils.tf_training_tools import train_tf_model\n</pre> %load_ext autoreload  import os os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"  from IPython.display import clear_output import tensorflow as tf import matplotlib.pyplot as plt  from oodeel.methods import ODIN from oodeel.eval.metrics import bench_metrics from oodeel.eval.plots import plot_ood_scores, plot_roc_curve, plot_2D_features from oodeel.datasets import OODDataset from oodeel.utils.tf_training_tools import train_tf_model <p>Note that models are saved at ~/.oodeel/saved_models and data is supposed to be found at ~/.oodeel/datasets by default. Change the following cell for a custom path.</p> In\u00a0[2]: Copied! <pre>model_path = os.path.expanduser(\"~/\") + \".oodeel/saved_models\"\ndata_path = os.path.expanduser(\"~/\") + \".oodeel/datasets\"\nos.makedirs(model_path, exist_ok=True)\nos.makedirs(data_path, exist_ok=True)\n</pre> model_path = os.path.expanduser(\"~/\") + \".oodeel/saved_models\" data_path = os.path.expanduser(\"~/\") + \".oodeel/datasets\" os.makedirs(model_path, exist_ok=True) os.makedirs(data_path, exist_ok=True) In\u00a0[3]: Copied! <pre># === Load ID and OOD data ===\nbatch_size = 128\nin_labels = [0, 1, 2, 3, 4]\n\n# 1- Load train/test MNIST dataset\nds_train = OODDataset(\"mnist\", load_kwargs=dict(split=\"train\"))\ndata_test = OODDataset(\"mnist\", load_kwargs=dict(split=\"test\"))\n\n# 2- Split ID / OOD data depending on label value:\n# in-distribution: MNIST[0-4] / out-of-distribution: MNIST[5-9]\nds_train, _ = ds_train.split_by_class(in_labels)\noods_in, oods_out = data_test.split_by_class(in_labels)\n\n\n# 3- Prepare data (preprocess, shuffle, batch)\ndef preprocess_fn(*inputs):\n    x = inputs[0] / 255\n    return tuple([x] + list(inputs[1:]))\n\n\nds_train = ds_train.prepare(batch_size, preprocess_fn, shuffle=True)\nds_in = oods_in.prepare(batch_size, preprocess_fn, with_ood_labels=False)\nds_out = oods_out.prepare(batch_size, preprocess_fn, with_ood_labels=False)\n\nclear_output()\n</pre> # === Load ID and OOD data === batch_size = 128 in_labels = [0, 1, 2, 3, 4]  # 1- Load train/test MNIST dataset ds_train = OODDataset(\"mnist\", load_kwargs=dict(split=\"train\")) data_test = OODDataset(\"mnist\", load_kwargs=dict(split=\"test\"))  # 2- Split ID / OOD data depending on label value: # in-distribution: MNIST[0-4] / out-of-distribution: MNIST[5-9] ds_train, _ = ds_train.split_by_class(in_labels) oods_in, oods_out = data_test.split_by_class(in_labels)   # 3- Prepare data (preprocess, shuffle, batch) def preprocess_fn(*inputs):     x = inputs[0] / 255     return tuple([x] + list(inputs[1:]))   ds_train = ds_train.prepare(batch_size, preprocess_fn, shuffle=True) ds_in = oods_in.prepare(batch_size, preprocess_fn, with_ood_labels=False) ds_out = oods_out.prepare(batch_size, preprocess_fn, with_ood_labels=False)  clear_output() In\u00a0[4]: Copied! <pre># === Train / Load model ===\nmodel_path_mnist_04 = os.path.join(model_path, \"mnist_model_0-4.h5\")\n\ntry:\n    # if the model exists, load it\n    model = tf.keras.models.load_model(model_path_mnist_04)\nexcept OSError:\n    # else, train a new model\n    train_config = {\n        \"model\": \"toy_convnet\",\n        \"input_shape\": (28, 28, 1),\n        \"num_classes\": 10,\n        \"batch_size\": 128,\n        \"epochs\": 5,\n        \"save_dir\": model_path_mnist_04,\n        \"validation_data\": ds_in,\n    }\n\n    model = train_tf_model(ds_train, **train_config)\n\n_, accuracy = model.evaluate(ds_in)\nprint(f\"Test accuracy:\\t{accuracy:.4f}\")\n\n# penultimate features 2d visualization\nprint(\"\\n=== Penultimate features viz ===\")\nplt.figure(figsize=(4.5, 3))\nplot_2D_features(\n    model=model,\n    in_dataset=ds_in,\n    out_dataset=ds_out,\n    output_layer_id=-2,\n)\nplt.tight_layout()\nplt.show()\n</pre> # === Train / Load model === model_path_mnist_04 = os.path.join(model_path, \"mnist_model_0-4.h5\")  try:     # if the model exists, load it     model = tf.keras.models.load_model(model_path_mnist_04) except OSError:     # else, train a new model     train_config = {         \"model\": \"toy_convnet\",         \"input_shape\": (28, 28, 1),         \"num_classes\": 10,         \"batch_size\": 128,         \"epochs\": 5,         \"save_dir\": model_path_mnist_04,         \"validation_data\": ds_in,     }      model = train_tf_model(ds_train, **train_config)  _, accuracy = model.evaluate(ds_in) print(f\"Test accuracy:\\t{accuracy:.4f}\")  # penultimate features 2d visualization print(\"\\n=== Penultimate features viz ===\") plt.figure(figsize=(4.5, 3)) plot_2D_features(     model=model,     in_dataset=ds_in,     out_dataset=ds_out,     output_layer_id=-2, ) plt.tight_layout() plt.show() <pre>41/41 [==============================] - 2s 11ms/step - loss: 0.0118 - accuracy: 0.9965\nTest accuracy:\t0.9965\n\n=== Penultimate features viz ===\n</pre> In\u00a0[5]: Copied! <pre># === ODIN scores ===\nodin = ODIN(temperature=1000)\nodin.fit(model)\nscores_in, _ = odin.score(ds_in)\nscores_out, _ = odin.score(ds_out)\nclear_output()\n\n# === metrics ===\n# auroc / fpr95\nmetrics = bench_metrics(\n    (scores_in, scores_out),\n    metrics=[\"auroc\", \"fpr95tpr\"],\n)\nprint(\"=== Metrics ===\")\nfor k, v in metrics.items():\n    print(f\"{k:&lt;10} {v:.6f}\")\n\nprint(\"\\n=== Plots ===\")\n# hists / roc\nplt.figure(figsize=(9, 3))\nplt.subplot(121)\nplot_ood_scores(scores_in, scores_out, log_scale=False)\nplt.subplot(122)\nplot_roc_curve(scores_in, scores_out)\nplt.tight_layout()\nplt.show()\n</pre> # === ODIN scores === odin = ODIN(temperature=1000) odin.fit(model) scores_in, _ = odin.score(ds_in) scores_out, _ = odin.score(ds_out) clear_output()  # === metrics === # auroc / fpr95 metrics = bench_metrics(     (scores_in, scores_out),     metrics=[\"auroc\", \"fpr95tpr\"], ) print(\"=== Metrics ===\") for k, v in metrics.items():     print(f\"{k:&lt;10} {v:.6f}\")  print(\"\\n=== Plots ===\") # hists / roc plt.figure(figsize=(9, 3)) plt.subplot(121) plot_ood_scores(scores_in, scores_out, log_scale=False) plt.subplot(122) plot_roc_curve(scores_in, scores_out) plt.tight_layout() plt.show() <pre>=== Metrics ===\nauroc      0.888694\nfpr95tpr   0.446390\n\n=== Plots ===\n</pre> In\u00a0[6]: Copied! <pre># === Load ID and OOD data ===\nbatch_size = 128\n\n# 1a- Load in-distribution dataset: CIFAR-10\nds_in = OODDataset(\"cifar10\", load_kwargs={\"split\": \"test\"}, input_key=\"image\")\n\n# 1b- Load out-of-distribution dataset: SVHN\nds_out = OODDataset(\"svhn_cropped\", load_kwargs={\"split\": \"test\"})\n\n\n# 2- prepare data (preprocess, shuffle, batch)\ndef preprocess_fn(*inputs):\n    x = inputs[0] / 255\n    return tuple([x] + list(inputs[1:]))\n\n\nds_in = ds_in.prepare(batch_size, preprocess_fn)\nds_out = ds_out.prepare(batch_size, preprocess_fn)\n</pre> # === Load ID and OOD data === batch_size = 128  # 1a- Load in-distribution dataset: CIFAR-10 ds_in = OODDataset(\"cifar10\", load_kwargs={\"split\": \"test\"}, input_key=\"image\")  # 1b- Load out-of-distribution dataset: SVHN ds_out = OODDataset(\"svhn_cropped\", load_kwargs={\"split\": \"test\"})   # 2- prepare data (preprocess, shuffle, batch) def preprocess_fn(*inputs):     x = inputs[0] / 255     return tuple([x] + list(inputs[1:]))   ds_in = ds_in.prepare(batch_size, preprocess_fn) ds_out = ds_out.prepare(batch_size, preprocess_fn) In\u00a0[7]: Copied! <pre># === Load model ===\n# ResNet pretrained on CIFAR-10\nmodel_path_resnet_cifar10 = tf.keras.utils.get_file(\n    \"cifar10_resnet256.h5\",\n    origin=\"https://share.deel.ai/s/kram9kLpx6JwRX4/download/cifar10_resnet256.h5\",\n    cache_dir=model_path,\n    cache_subdir=\"\",\n)\nmodel = tf.keras.models.load_model(model_path_resnet_cifar10)\n\n# Evaluate model\nmodel.compile(metrics=[\"accuracy\"])\n_, accuracy = model.evaluate(ds_in)\nprint(f\"Test accuracy:\\t{accuracy:.4f}\")\n\n# penultimate features 2d visualization\nprint(\"\\n=== Penultimate features viz ===\")\nplt.figure(figsize=(4.5, 3))\nplot_2D_features(\n    model=model,\n    in_dataset=ds_in,\n    out_dataset=ds_out,\n    output_layer_id=-2,\n)\nplt.tight_layout()\nplt.show()\n</pre> # === Load model === # ResNet pretrained on CIFAR-10 model_path_resnet_cifar10 = tf.keras.utils.get_file(     \"cifar10_resnet256.h5\",     origin=\"https://share.deel.ai/s/kram9kLpx6JwRX4/download/cifar10_resnet256.h5\",     cache_dir=model_path,     cache_subdir=\"\", ) model = tf.keras.models.load_model(model_path_resnet_cifar10)  # Evaluate model model.compile(metrics=[\"accuracy\"]) _, accuracy = model.evaluate(ds_in) print(f\"Test accuracy:\\t{accuracy:.4f}\")  # penultimate features 2d visualization print(\"\\n=== Penultimate features viz ===\") plt.figure(figsize=(4.5, 3)) plot_2D_features(     model=model,     in_dataset=ds_in,     out_dataset=ds_out,     output_layer_id=-2, ) plt.tight_layout() plt.show() <pre>79/79 [==============================] - 3s 26ms/step - loss: 0.1268 - accuracy: 0.9276\nTest accuracy:\t0.9276\n\n=== Penultimate features viz ===\n</pre> In\u00a0[8]: Copied! <pre># === ODIN scores ===\nodin = ODIN(temperature=1000)\nodin.fit(model)\nscores_in, _ = odin.score(ds_in)\nscores_out, _ = odin.score(ds_out)\n\n# === metrics ===\n# auroc / fpr95\nmetrics = bench_metrics(\n    (scores_in, scores_out),\n    metrics=[\"auroc\", \"fpr95tpr\"],\n)\nprint(\"=== Metrics ===\")\nfor k, v in metrics.items():\n    print(f\"{k:&lt;10} {v:.6f}\")\n\nprint(\"\\n=== Plots ===\")\n# hists / roc\nplt.figure(figsize=(9, 3))\nplt.subplot(121)\nplot_ood_scores(scores_in, scores_out, log_scale=False)\nplt.subplot(122)\nplot_roc_curve(scores_in, scores_out)\nplt.tight_layout()\nplt.show()\n</pre> # === ODIN scores === odin = ODIN(temperature=1000) odin.fit(model) scores_in, _ = odin.score(ds_in) scores_out, _ = odin.score(ds_out)  # === metrics === # auroc / fpr95 metrics = bench_metrics(     (scores_in, scores_out),     metrics=[\"auroc\", \"fpr95tpr\"], ) print(\"=== Metrics ===\") for k, v in metrics.items():     print(f\"{k:&lt;10} {v:.6f}\")  print(\"\\n=== Plots ===\") # hists / roc plt.figure(figsize=(9, 3)) plt.subplot(121) plot_ood_scores(scores_in, scores_out, log_scale=False) plt.subplot(122) plot_roc_curve(scores_in, scores_out) plt.tight_layout() plt.show() <pre>=== Metrics ===\nauroc      0.950393\nfpr95tpr   0.150900\n\n=== Plots ===\n</pre>"},{"location":"notebooks/tensorflow/demo_odin_tf/#odin-method","title":"ODIN method\u00b6","text":"<p>This notebook aims at evaluating the ODIN method.</p> <p>Here, we focus on a toy convolutional network trained on MNIST[0-4] and a ResNet model trained on CIFAR-10, respectively challenged on MNIST[5-9] and SVHN OOD datasets.</p> <p>Reference Enhancing The Reliability of Out-of-distribution Image Detection in Neural Networks Liang, Shiyu and Li, Yixuan and Srikant, R. International Conference on Learning Representations, 2018 https://openreview.net/forum?id=H1VGkIxRZ</p>"},{"location":"notebooks/tensorflow/demo_odin_tf/#imports","title":"Imports\u00b6","text":""},{"location":"notebooks/tensorflow/demo_odin_tf/#first-experiment-mnist0-4-vs-mnist5-9","title":"First experiment: MNIST[0-4] vs MNIST[5-9]\u00b6","text":"<p>For this first experiment, we train a toy convolutional network on the MNIST dataset restricted to digits 0 to 4. After fitting the train subset of this dataset to the ODIN method, we will compare the scores returned for MNIST[0-4] (in-distribution) and MNIST[5-9] (out-of-distribution) test subsets.</p>"},{"location":"notebooks/tensorflow/demo_odin_tf/#data-loading","title":"Data loading\u00b6","text":"<ul> <li>In-distribution data: MNIST[0-4]</li> <li>Out-of-distribution data: MNIST[5-9]</li> </ul> <p>Note: We denote In-Distribution (ID) data with <code>_in</code> and Out-Of-Distribution (OOD) data with <code>_out</code> to avoid confusion with OOD detection which is the name of the task, and is therefore used to denote core classes such as <code>OODDataset</code> and <code>OODBaseDetector</code>.</p>"},{"location":"notebooks/tensorflow/demo_odin_tf/#model-training","title":"Model training\u00b6","text":"<p>Now let's train a simple model on MNIST[0-4] using <code>train_tf_model</code> function.</p>"},{"location":"notebooks/tensorflow/demo_odin_tf/#odin-score","title":"ODIN score\u00b6","text":"<p>We now fit a ODIN detector with MNIST[0-4] train dataset, and compare OOD scores returned for MNIST[0-4] (ID) and MNIST[5-9] (OOD) test datasets.</p>"},{"location":"notebooks/tensorflow/demo_odin_tf/#second-experiment-cifar-10-vs-svhn","title":"Second experiment: CIFAR-10 vs SVHN\u00b6","text":"<p>For this second experiment, we oppose CIFAR-10 (in-distribution dataset) to SVHN (out-of-distribution dataset).</p>"},{"location":"notebooks/tensorflow/demo_odin_tf/#data-loading","title":"Data loading\u00b6","text":"<ul> <li>In-distribution data: CIFAR-10</li> <li>Out-of-distribution data: SVHN</li> </ul>"},{"location":"notebooks/tensorflow/demo_odin_tf/#model-loading","title":"Model loading\u00b6","text":"<p>The model is a ResNet pretrained on CIFAR-10 and getting an accuracy score of 92.75%.</p>"},{"location":"notebooks/tensorflow/demo_odin_tf/#odin-score","title":"ODIN score\u00b6","text":"<p>We now fit a ODIN detector with CIFAR-10 train dataset, and compare OOD scores returned for CIFAR-10 (ID) and SVHN (OOD) test datasets.</p>"},{"location":"notebooks/tensorflow/demo_react_tf/","title":"React","text":"In\u00a0[1]: Copied! <pre>%load_ext autoreload\n\nimport os\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n\nfrom IPython.display import clear_output\nimport numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n\nfrom oodeel.methods import MLS, Energy, Entropy, ODIN\nfrom oodeel.eval.metrics import bench_metrics\nfrom oodeel.eval.plots import plot_ood_scores, plot_roc_curve, plot_2D_features\nfrom oodeel.datasets import OODDataset\nfrom oodeel.utils.tf_training_tools import train_tf_model\n</pre> %load_ext autoreload  import os os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"  from IPython.display import clear_output import numpy as np import tensorflow as tf import matplotlib.pyplot as plt  from oodeel.methods import MLS, Energy, Entropy, ODIN from oodeel.eval.metrics import bench_metrics from oodeel.eval.plots import plot_ood_scores, plot_roc_curve, plot_2D_features from oodeel.datasets import OODDataset from oodeel.utils.tf_training_tools import train_tf_model <p>Note that models are saved at ~/.oodeel/saved_models and data is supposed to be found at ~/.oodeel/datasets by default. Change the following cell for a custom path.</p> In\u00a0[2]: Copied! <pre>model_path = os.path.expanduser(\"~/\") + \".oodeel/saved_models\"\ndata_path = os.path.expanduser(\"~/\") + \".oodeel/datasets\"\nos.makedirs(model_path, exist_ok=True)\nos.makedirs(data_path, exist_ok=True)\n</pre> model_path = os.path.expanduser(\"~/\") + \".oodeel/saved_models\" data_path = os.path.expanduser(\"~/\") + \".oodeel/datasets\" os.makedirs(model_path, exist_ok=True) os.makedirs(data_path, exist_ok=True) In\u00a0[3]: Copied! <pre># === Load ID and OOD data ===\nbatch_size = 128\nin_labels = [0, 1, 2, 3, 4]\n\n# 1- Load train/test MNIST dataset\nds_train = OODDataset(\"mnist\", load_kwargs=dict(split=\"train\"))\ndata_test = OODDataset(\"mnist\", load_kwargs=dict(split=\"test\"))\n\n# 2- Split ID / OOD data depending on label value:\n# in-distribution: MNIST[0-4] / out-of-distribution: MNIST[5-9]\nds_train, _ = ds_train.split_by_class(in_labels)\noods_in, oods_out = data_test.split_by_class(in_labels)\n\n\n# 3- Prepare data (preprocess, shuffle, batch)\ndef preprocess_fn(*inputs):\n    x = inputs[0] / 255\n    return tuple([x] + list(inputs[1:]))\n\n\nds_train = ds_train.prepare(batch_size, preprocess_fn, shuffle=True)\nds_in = oods_in.prepare(batch_size, preprocess_fn, with_ood_labels=False)\nds_out = oods_out.prepare(batch_size, preprocess_fn, with_ood_labels=False)\n\nclear_output()\n</pre> # === Load ID and OOD data === batch_size = 128 in_labels = [0, 1, 2, 3, 4]  # 1- Load train/test MNIST dataset ds_train = OODDataset(\"mnist\", load_kwargs=dict(split=\"train\")) data_test = OODDataset(\"mnist\", load_kwargs=dict(split=\"test\"))  # 2- Split ID / OOD data depending on label value: # in-distribution: MNIST[0-4] / out-of-distribution: MNIST[5-9] ds_train, _ = ds_train.split_by_class(in_labels) oods_in, oods_out = data_test.split_by_class(in_labels)   # 3- Prepare data (preprocess, shuffle, batch) def preprocess_fn(*inputs):     x = inputs[0] / 255     return tuple([x] + list(inputs[1:]))   ds_train = ds_train.prepare(batch_size, preprocess_fn, shuffle=True) ds_in = oods_in.prepare(batch_size, preprocess_fn, with_ood_labels=False) ds_out = oods_out.prepare(batch_size, preprocess_fn, with_ood_labels=False)  clear_output() In\u00a0[4]: Copied! <pre># === Train / Load model ===\nmodel_path_mnist_04 = os.path.join(model_path, \"mnist_model_0-4.h5\")\n\ntry:\n    # if the model exists, load it\n    model = tf.keras.models.load_model(model_path_mnist_04)\nexcept OSError:\n    # else, train a new model\n    train_config = {\n        \"model\": \"toy_convnet\",\n        \"input_shape\": (28, 28, 1),\n        \"num_classes\": 10,\n        \"batch_size\": 128,\n        \"epochs\": 5,\n        \"save_dir\": model_path_mnist_04,\n        \"validation_data\": ds_in,\n    }\n\n    model = train_tf_model(ds_train, **train_config)\n\n_, accuracy = model.evaluate(ds_in)\nprint(f\"Test accuracy:\\t{accuracy:.4f}\")\n\n# penultimate features 2d visualization\nprint(\"\\n=== Penultimate features viz ===\")\nplt.figure(figsize=(4.5, 3))\nplot_2D_features(\n    model=model,\n    in_dataset=ds_in,\n    out_dataset=ds_out,\n    output_layer_id=-2,\n)\nplt.tight_layout()\nplt.show()\n</pre> # === Train / Load model === model_path_mnist_04 = os.path.join(model_path, \"mnist_model_0-4.h5\")  try:     # if the model exists, load it     model = tf.keras.models.load_model(model_path_mnist_04) except OSError:     # else, train a new model     train_config = {         \"model\": \"toy_convnet\",         \"input_shape\": (28, 28, 1),         \"num_classes\": 10,         \"batch_size\": 128,         \"epochs\": 5,         \"save_dir\": model_path_mnist_04,         \"validation_data\": ds_in,     }      model = train_tf_model(ds_train, **train_config)  _, accuracy = model.evaluate(ds_in) print(f\"Test accuracy:\\t{accuracy:.4f}\")  # penultimate features 2d visualization print(\"\\n=== Penultimate features viz ===\") plt.figure(figsize=(4.5, 3)) plot_2D_features(     model=model,     in_dataset=ds_in,     out_dataset=ds_out,     output_layer_id=-2, ) plt.tight_layout() plt.show() <pre>41/41 [==============================] - 2s 12ms/step - loss: 0.0175 - accuracy: 0.9953\nTest accuracy:\t0.9953\n\n=== Penultimate features viz ===\n</pre> In\u00a0[5]: Copied! <pre>%autoreload 2\ndetectors = {\n    \"odin\": {\n        \"class\": ODIN,\n        \"kwargs\": dict(temperature=1000),\n    },\n    \"mls\": {\n        \"class\": MLS,\n        \"kwargs\": dict(),\n    },\n    \"msp\": {\n        \"class\": MLS,\n        \"kwargs\": dict(output_activation=\"softmax\"),\n    },\n    \"energy\": {\n        \"class\": Energy,\n        \"kwargs\": dict(),\n    },\n    \"entropy\": {\n        \"class\": Entropy,\n        \"kwargs\": dict(),\n    },\n}\n\nfor d in detectors.keys():\n    print(f\"=== {d.upper()} ===\")\n\n    for use_react in [False, True]:\n        print([\"~ Without\", \"~ With\"][int(use_react)] + \" react ~\")\n        # === ood scores ===\n        d_kwargs = detectors[d][\"kwargs\"]\n        d_kwargs.update(dict(\n            use_react=use_react,\n            react_quantile=0.8,\n        ))\n        detector = detectors[d][\"class\"](**d_kwargs)\n        detector.fit(model, fit_dataset=ds_train)\n        scores_in, _ = detector.score(ds_in)\n        scores_out, _ = detector.score(ds_out)\n\n        # === metrics ===\n        # auroc / fpr95\n        metrics = bench_metrics(\n            (scores_in, scores_out),\n            metrics=[\"auroc\", \"fpr95tpr\"],\n        )\n        for k, v in metrics.items():\n            print(f\"{k:&lt;10} {v:.6f}\")\n\n        log_scale = d in [\"msp\", \"entropy\"]\n        # hists / roc\n        plt.figure(figsize=(9, 3))\n        plt.subplot(121)\n        if d == \"msp\":\n            # Normalize scores for a better hist visualization\n            minim = np.min([np.min(scores_in), np.min(scores_out)])\n            scores_in_ = scores_in - 2 * minim + np.min(scores_in[np.where(scores_in != minim)])\n            scores_out_ = scores_out - 2 * minim + np.min(scores_in[np.where(scores_in != minim)])\n            plot_ood_scores(scores_in_, scores_out_, log_scale=log_scale)\n        else:\n            plot_ood_scores(scores_in, scores_out, log_scale=log_scale)\n        plt.subplot(122)\n        plot_roc_curve(scores_in, scores_out)\n        plt.tight_layout()\n        plt.show()\n</pre> %autoreload 2 detectors = {     \"odin\": {         \"class\": ODIN,         \"kwargs\": dict(temperature=1000),     },     \"mls\": {         \"class\": MLS,         \"kwargs\": dict(),     },     \"msp\": {         \"class\": MLS,         \"kwargs\": dict(output_activation=\"softmax\"),     },     \"energy\": {         \"class\": Energy,         \"kwargs\": dict(),     },     \"entropy\": {         \"class\": Entropy,         \"kwargs\": dict(),     }, }  for d in detectors.keys():     print(f\"=== {d.upper()} ===\")      for use_react in [False, True]:         print([\"~ Without\", \"~ With\"][int(use_react)] + \" react ~\")         # === ood scores ===         d_kwargs = detectors[d][\"kwargs\"]         d_kwargs.update(dict(             use_react=use_react,             react_quantile=0.8,         ))         detector = detectors[d][\"class\"](**d_kwargs)         detector.fit(model, fit_dataset=ds_train)         scores_in, _ = detector.score(ds_in)         scores_out, _ = detector.score(ds_out)          # === metrics ===         # auroc / fpr95         metrics = bench_metrics(             (scores_in, scores_out),             metrics=[\"auroc\", \"fpr95tpr\"],         )         for k, v in metrics.items():             print(f\"{k:&lt;10} {v:.6f}\")          log_scale = d in [\"msp\", \"entropy\"]         # hists / roc         plt.figure(figsize=(9, 3))         plt.subplot(121)         if d == \"msp\":             # Normalize scores for a better hist visualization             minim = np.min([np.min(scores_in), np.min(scores_out)])             scores_in_ = scores_in - 2 * minim + np.min(scores_in[np.where(scores_in != minim)])             scores_out_ = scores_out - 2 * minim + np.min(scores_in[np.where(scores_in != minim)])             plot_ood_scores(scores_in_, scores_out_, log_scale=log_scale)         else:             plot_ood_scores(scores_in, scores_out, log_scale=log_scale)         plt.subplot(122)         plot_roc_curve(scores_in, scores_out)         plt.tight_layout()         plt.show() <pre>=== ODIN ===\n~ Without react ~\nauroc      0.852353\nfpr95tpr   0.476746\n</pre> <pre>~ With react ~\nauroc      0.860170\nfpr95tpr   0.405332\n</pre> <pre>=== MLS ===\n~ Without react ~\nauroc      0.923506\nfpr95tpr   0.395797\n</pre> <pre>~ With react ~\nauroc      0.940908\nfpr95tpr   0.321074\n</pre> <pre>=== MSP ===\n~ Without react ~\nauroc      0.935694\nfpr95tpr   0.374003\n</pre> <pre>~ With react ~\nauroc      0.950559\nfpr95tpr   0.228449\n</pre> <pre>=== ENERGY ===\n~ Without react ~\nauroc      0.920665\nfpr95tpr   0.395991\n</pre> <pre>~ With react ~\nauroc      0.933476\nfpr95tpr   0.339949\n</pre> <pre>=== ENTROPY ===\n~ Without react ~\nauroc      0.936042\nfpr95tpr   0.375754\n</pre> <pre>~ With react ~\nauroc      0.950874\nfpr95tpr   0.234676\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"notebooks/tensorflow/demo_react_tf/#react-method","title":"ReAct method\u00b6","text":"<p>This notebook aims at evaluating the ReAct method.</p> <p>ReAct method basically consists in re-using existing logit-based OOD methods, but with penultimate layer activations clipped to a certain threshold value. In practice, this threshold is set based on the $p$-th percentile of penultimate activations estimated on the ID data.</p> <p>Here, we focus on a toy convolutional network trained on MNIST[0-4] challenged on MNIST[5-9].</p> <p>Reference React: Out-of-distribution detection with rectified activations. Sun, Yiyou, Chuan Guo, and Yixuan Li. Advances in Neural Information Processing Systems 34 (2021) https://arxiv.org/pdf/2111.12797.pdf</p>"},{"location":"notebooks/tensorflow/demo_react_tf/#imports","title":"Imports\u00b6","text":""},{"location":"notebooks/tensorflow/demo_react_tf/#mnist0-4-vs-mnist5-9","title":"MNIST[0-4] vs MNIST[5-9]\u00b6","text":"<p>We train a toy convolutional network on the MNIST dataset restricted to digits 0 to 4. After fitting the train subset of this dataset to different OOD methods with react option enabled, we will compare the scores returned for MNIST[0-4] (in-distrubtion) and MNIST[5-9] (out-of-distribution) test subsets.</p>"},{"location":"notebooks/tensorflow/demo_react_tf/#data-loading","title":"Data loading\u00b6","text":"<ul> <li>In-distribution data: MNIST[0-4]</li> <li>Out-of-distribution data: MNIST[5-9]</li> </ul> <p>Note: We denote In-Distribution (ID) data with <code>_in</code> and Out-Of-Distribution (OOD) data with <code>_out</code> to avoid confusion with OOD detection which is the name of the task, and is therefore used to denote core classes such as <code>OODDataset</code> and <code>OODBaseDetector</code>.</p>"},{"location":"notebooks/tensorflow/demo_react_tf/#model-training","title":"Model training\u00b6","text":"<p>Now let's train a simple model on MNIST[0-4] using <code>train_tf_model</code> function.</p>"},{"location":"notebooks/tensorflow/demo_react_tf/#react-scores","title":"ReAct scores\u00b6","text":"<p>We now fit some OOD detectors using ReAct + [MLS, MSP, Energy, Entropy, ODIN] with MNIST[0-4] train dataset, and compare OOD scores returned for MNIST[0-4] (ID) and MNIST[5-9] (OOD) test datasets.</p>"},{"location":"notebooks/tensorflow/demo_rmds_tf/","title":"RMDS","text":"In\u00a0[1]: Copied! <pre>%load_ext autoreload\n\nimport os\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n\nfrom IPython.display import clear_output\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n\nfrom oodeel.methods import RMDS\nfrom oodeel.eval.metrics import bench_metrics\nfrom oodeel.eval.plots import plot_ood_scores, plot_roc_curve, plot_2D_features\nfrom oodeel.datasets import OODDataset\nfrom oodeel.utils.tf_training_tools import train_tf_model\n</pre> %load_ext autoreload  import os os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"  from IPython.display import clear_output import tensorflow as tf import matplotlib.pyplot as plt  from oodeel.methods import RMDS from oodeel.eval.metrics import bench_metrics from oodeel.eval.plots import plot_ood_scores, plot_roc_curve, plot_2D_features from oodeel.datasets import OODDataset from oodeel.utils.tf_training_tools import train_tf_model <p>Note that models are saved at ~/.oodeel/saved_models and data is supposed to be found at ~/.oodeel/datasets by default. Change the following cell for a custom path.</p> In\u00a0[2]: Copied! <pre>model_path = os.path.expanduser(\"~/\") + \".oodeel/saved_models\"\ndata_path = os.path.expanduser(\"~/\") + \".oodeel/datasets\"\nos.makedirs(model_path, exist_ok=True)\nos.makedirs(data_path, exist_ok=True)\n</pre> model_path = os.path.expanduser(\"~/\") + \".oodeel/saved_models\" data_path = os.path.expanduser(\"~/\") + \".oodeel/datasets\" os.makedirs(model_path, exist_ok=True) os.makedirs(data_path, exist_ok=True) In\u00a0[3]: Copied! <pre># === Load ID and OOD data ===\nbatch_size = 128\nin_labels = [0, 1, 2, 3, 4]\n\n# 1- Load train/test MNIST dataset\nds_train = OODDataset(\"mnist\", load_kwargs=dict(split=\"train\"))\ndata_test = OODDataset(\"mnist\", load_kwargs=dict(split=\"test\"))\n\n# 2- Split ID / OOD data depending on label value:\n# in-distribution: MNIST[0-4] / out-of-distribution: MNIST[5-9]\nds_train, _ = ds_train.split_by_class(in_labels)\noods_in, oods_out = data_test.split_by_class(in_labels)\n\n\n# 3- Prepare data (preprocess, shuffle, batch)\ndef preprocess_fn(*inputs):\n    x = inputs[0] / 255\n    return tuple([x] + list(inputs[1:]))\n\n\nds_train = ds_train.prepare(batch_size, preprocess_fn, shuffle=True)\nds_in = oods_in.prepare(batch_size, preprocess_fn, with_ood_labels=False)\nds_out = oods_out.prepare(batch_size, preprocess_fn, with_ood_labels=False)\n\nclear_output()\n</pre> # === Load ID and OOD data === batch_size = 128 in_labels = [0, 1, 2, 3, 4]  # 1- Load train/test MNIST dataset ds_train = OODDataset(\"mnist\", load_kwargs=dict(split=\"train\")) data_test = OODDataset(\"mnist\", load_kwargs=dict(split=\"test\"))  # 2- Split ID / OOD data depending on label value: # in-distribution: MNIST[0-4] / out-of-distribution: MNIST[5-9] ds_train, _ = ds_train.split_by_class(in_labels) oods_in, oods_out = data_test.split_by_class(in_labels)   # 3- Prepare data (preprocess, shuffle, batch) def preprocess_fn(*inputs):     x = inputs[0] / 255     return tuple([x] + list(inputs[1:]))   ds_train = ds_train.prepare(batch_size, preprocess_fn, shuffle=True) ds_in = oods_in.prepare(batch_size, preprocess_fn, with_ood_labels=False) ds_out = oods_out.prepare(batch_size, preprocess_fn, with_ood_labels=False)  clear_output() In\u00a0[4]: Copied! <pre># === Train / Load model ===\nmodel_path_mnist_04 = os.path.join(model_path, \"mnist_model_0-4.h5\")\n\ntry:\n    # if the model exists, load it\n    model = tf.keras.models.load_model(model_path_mnist_04)\nexcept OSError:\n    # else, train a new model\n    train_config = {\n        \"model\": \"toy_convnet\",\n        \"input_shape\": (28, 28, 1),\n        \"num_classes\": 10,\n        \"batch_size\": 128,\n        \"epochs\": 5,\n        \"save_dir\": model_path_mnist_04,\n        \"validation_data\": ds_in,\n    }\n\n    model = train_tf_model(ds_train, **train_config)\n\n_, accuracy = model.evaluate(ds_in)\nprint(f\"Test accuracy:\\t{accuracy:.4f}\")\n\n# penultimate features 2d visualization\nprint(\"\\n=== Penultimate features viz ===\")\nplt.figure(figsize=(4.5, 3))\nplot_2D_features(\n    model=model,\n    in_dataset=ds_in,\n    out_dataset=ds_out,\n    output_layer_id=-2,\n)\nplt.tight_layout()\nplt.show()\n</pre> # === Train / Load model === model_path_mnist_04 = os.path.join(model_path, \"mnist_model_0-4.h5\")  try:     # if the model exists, load it     model = tf.keras.models.load_model(model_path_mnist_04) except OSError:     # else, train a new model     train_config = {         \"model\": \"toy_convnet\",         \"input_shape\": (28, 28, 1),         \"num_classes\": 10,         \"batch_size\": 128,         \"epochs\": 5,         \"save_dir\": model_path_mnist_04,         \"validation_data\": ds_in,     }      model = train_tf_model(ds_train, **train_config)  _, accuracy = model.evaluate(ds_in) print(f\"Test accuracy:\\t{accuracy:.4f}\")  # penultimate features 2d visualization print(\"\\n=== Penultimate features viz ===\") plt.figure(figsize=(4.5, 3)) plot_2D_features(     model=model,     in_dataset=ds_in,     out_dataset=ds_out,     output_layer_id=-2, ) plt.tight_layout() plt.show() <pre>41/41 [==============================] - 1s 18ms/step - loss: 0.0108 - accuracy: 0.9963\nTest accuracy:\t0.9963\n\n=== Penultimate features viz ===\n</pre> In\u00a0[6]: Copied! <pre># === RMDS scores ===\nrmds = RMDS(eps=0.002)\nrmds.fit(model, feature_layers_id=[-2], fit_dataset=ds_train)\nscores_in, _ = rmds.score(ds_in)\nscores_out, _ = rmds.score(ds_out)\nclear_output()\n\n# === metrics ===\n# auroc / fpr95\nmetrics = bench_metrics(\n    (scores_in, scores_out),\n    metrics=[\"auroc\", \"fpr95tpr\"],\n)\nprint(\"=== Metrics ===\")\nfor k, v in metrics.items():\n    print(f\"{k:&lt;10} {v:.6f}\")\n\nprint(\"\\n=== Plots ===\")\n# hists / roc\nplt.figure(figsize=(9, 3))\nplt.subplot(121)\nplot_ood_scores(scores_in, scores_out, log_scale=False)\nplt.subplot(122)\nplot_roc_curve(scores_in, scores_out)\nplt.tight_layout()\nplt.show()\n</pre> # === RMDS scores === rmds = RMDS(eps=0.002) rmds.fit(model, feature_layers_id=[-2], fit_dataset=ds_train) scores_in, _ = rmds.score(ds_in) scores_out, _ = rmds.score(ds_out) clear_output()  # === metrics === # auroc / fpr95 metrics = bench_metrics(     (scores_in, scores_out),     metrics=[\"auroc\", \"fpr95tpr\"], ) print(\"=== Metrics ===\") for k, v in metrics.items():     print(f\"{k:&lt;10} {v:.6f}\")  print(\"\\n=== Plots ===\") # hists / roc plt.figure(figsize=(9, 3)) plt.subplot(121) plot_ood_scores(scores_in, scores_out, log_scale=False) plt.subplot(122) plot_roc_curve(scores_in, scores_out) plt.tight_layout() plt.show() <pre>=== Metrics ===\nauroc      0.843254\nfpr95tpr   0.513524\n\n=== Plots ===\n</pre> In\u00a0[7]: Copied! <pre># === Load ID and OOD data ===\nbatch_size = 128\n\n# 1a- Load in-distribution dataset: CIFAR-10\nds_fit = OODDataset(\"cifar10\", load_kwargs={\"split\": \"train\"}, input_key=\"image\")\nds_in = OODDataset(\"cifar10\", load_kwargs={\"split\": \"test\"}, input_key=\"image\")\n\n# 1b- Load out-of-distribution dataset: SVHN\nds_out = OODDataset(\"svhn_cropped\", load_kwargs={\"split\": \"test\"})\n\n\n# 2- prepare data (preprocess, shuffle, batch)\ndef preprocess_fn(*inputs):\n    x = inputs[0] / 255\n    return tuple([x] + list(inputs[1:]))\n\n\nds_fit = ds_fit.prepare(batch_size, preprocess_fn)\nds_in = ds_in.prepare(batch_size, preprocess_fn)\nds_out = ds_out.prepare(batch_size, preprocess_fn)\n</pre> # === Load ID and OOD data === batch_size = 128  # 1a- Load in-distribution dataset: CIFAR-10 ds_fit = OODDataset(\"cifar10\", load_kwargs={\"split\": \"train\"}, input_key=\"image\") ds_in = OODDataset(\"cifar10\", load_kwargs={\"split\": \"test\"}, input_key=\"image\")  # 1b- Load out-of-distribution dataset: SVHN ds_out = OODDataset(\"svhn_cropped\", load_kwargs={\"split\": \"test\"})   # 2- prepare data (preprocess, shuffle, batch) def preprocess_fn(*inputs):     x = inputs[0] / 255     return tuple([x] + list(inputs[1:]))   ds_fit = ds_fit.prepare(batch_size, preprocess_fn) ds_in = ds_in.prepare(batch_size, preprocess_fn) ds_out = ds_out.prepare(batch_size, preprocess_fn) In\u00a0[8]: Copied! <pre># === Load model ===\n# ResNet pretrained on CIFAR-10\nmodel_path_resnet_cifar10 = tf.keras.utils.get_file(\n    \"cifar10_resnet256.h5\",\n    origin=\"https://share.deel.ai/s/kram9kLpx6JwRX4/download/cifar10_resnet256.h5\",\n    cache_dir=model_path,\n    cache_subdir=\"\",\n)\nmodel = tf.keras.models.load_model(model_path_resnet_cifar10)\n\n# Evaluate model\nmodel.compile(metrics=[\"accuracy\"])\n_, accuracy = model.evaluate(ds_in)\nprint(f\"Test accuracy:\\t{accuracy:.4f}\")\n\n# penultimate features 2d visualization\nprint(\"\\n=== Penultimate features viz ===\")\nplt.figure(figsize=(4.5, 3))\nplot_2D_features(\n    model=model,\n    in_dataset=ds_in,\n    out_dataset=ds_out,\n    output_layer_id=-2,\n)\nplt.tight_layout()\nplt.show()\n</pre> # === Load model === # ResNet pretrained on CIFAR-10 model_path_resnet_cifar10 = tf.keras.utils.get_file(     \"cifar10_resnet256.h5\",     origin=\"https://share.deel.ai/s/kram9kLpx6JwRX4/download/cifar10_resnet256.h5\",     cache_dir=model_path,     cache_subdir=\"\", ) model = tf.keras.models.load_model(model_path_resnet_cifar10)  # Evaluate model model.compile(metrics=[\"accuracy\"]) _, accuracy = model.evaluate(ds_in) print(f\"Test accuracy:\\t{accuracy:.4f}\")  # penultimate features 2d visualization print(\"\\n=== Penultimate features viz ===\") plt.figure(figsize=(4.5, 3)) plot_2D_features(     model=model,     in_dataset=ds_in,     out_dataset=ds_out,     output_layer_id=-2, ) plt.tight_layout() plt.show() <pre>Downloading data from https://share.deel.ai/s/kram9kLpx6JwRX4/download/cifar10_resnet256.h5\n21088832/21088832 [==============================] - 9s 0us/step\n79/79 [==============================] - 2s 13ms/step - loss: 0.1268 - accuracy: 0.9276\nTest accuracy:\t0.9276\n\n=== Penultimate features viz ===\n</pre> In\u00a0[10]: Copied! <pre># === RMDS OOD scores ===\nrmds = RMDS(eps=0.002)\nrmds.fit(model, feature_layers_id=[-2], fit_dataset=ds_fit)\nscores_in, _ = rmds.score(ds_in)\nscores_out, _ = rmds.score(ds_out)\n\n# === metrics ===\n# auroc / fpr95\nmetrics = bench_metrics(\n    (scores_in, scores_out),\n    metrics=[\"auroc\", \"fpr95tpr\"],\n)\nprint(\"=== Metrics ===\")\nfor k, v in metrics.items():\n    print(f\"{k:&lt;10} {v:.6f}\")\n\nprint(\"\\n=== Plots ===\")\n# hists / roc\nplt.figure(figsize=(9, 3))\nplt.subplot(121)\nplot_ood_scores(scores_in, scores_out, log_scale=False)\nplt.subplot(122)\nplot_roc_curve(scores_in, scores_out)\nplt.tight_layout()\nplt.show()\n</pre> # === RMDS OOD scores === rmds = RMDS(eps=0.002) rmds.fit(model, feature_layers_id=[-2], fit_dataset=ds_fit) scores_in, _ = rmds.score(ds_in) scores_out, _ = rmds.score(ds_out)  # === metrics === # auroc / fpr95 metrics = bench_metrics(     (scores_in, scores_out),     metrics=[\"auroc\", \"fpr95tpr\"], ) print(\"=== Metrics ===\") for k, v in metrics.items():     print(f\"{k:&lt;10} {v:.6f}\")  print(\"\\n=== Plots ===\") # hists / roc plt.figure(figsize=(9, 3)) plt.subplot(121) plot_ood_scores(scores_in, scores_out, log_scale=False) plt.subplot(122) plot_roc_curve(scores_in, scores_out) plt.tight_layout() plt.show() <pre>=== Metrics ===\nauroc      0.842031\nfpr95tpr   0.652300\n\n=== Plots ===\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"notebooks/tensorflow/demo_rmds_tf/#rmds-method","title":"RMDS method\u00b6","text":"<p>This notebook aims at evaluating the RMDS method.</p> <p>Here, we focus on a toy convolutional network trained on MNIST[0-4] and a ResNet20 model trained on CIFAR-10, respectively challenged on MNIST[5-9] and SVHN OOD datasets.</p> <p>Reference A Simple Fix to Mahalanobis Distance for Improving Near-OOD Detection REN, Jie, FORT, Stanislav, LIU, Jeremiah, et al. preprint https://arxiv.org/abs/2106.09022</p>"},{"location":"notebooks/tensorflow/demo_rmds_tf/#imports","title":"Imports\u00b6","text":""},{"location":"notebooks/tensorflow/demo_rmds_tf/#first-experiment-mnist0-4-vs-mnist5-9","title":"First experiment: MNIST[0-4] vs MNIST[5-9]\u00b6","text":"<p>For this first experiment, we train a toy convolutional network on the MNIST dataset restricted to digits 0 to 4. After fitting the train subset of this dataset to the Mahalanobis method, we will compare the scores returned for MNIST[0-4] (in-distribution) and MNIST[5-9] (out-of-distribution) test subsets.</p>"},{"location":"notebooks/tensorflow/demo_rmds_tf/#data-loading","title":"Data loading\u00b6","text":"<ul> <li>In-distribution data: MNIST[0-4]</li> <li>Out-of-distribution data: MNIST[5-9]</li> </ul> <p>Note: We denote In-Distribution (ID) data with <code>_in</code> and Out-Of-Distribution (OOD) data with <code>_out</code> to avoid confusion with OOD detection which is the name of the task, and is therefore used to denote core classes such as <code>OODDataset</code> and <code>OODBaseDetector</code>.</p>"},{"location":"notebooks/tensorflow/demo_rmds_tf/#model-training","title":"Model training\u00b6","text":"<p>Now let's train a simple model on MNIST[0-4] using <code>train_tf_model</code> function.</p>"},{"location":"notebooks/tensorflow/demo_rmds_tf/#mahalanobis-score","title":"Mahalanobis score\u00b6","text":"<p>We now fit a Mahalanobis OOD detector with MNIST[0-4] train dataset, and compare OOD scores returned for MNIST[0-4] (ID) and MNIST[5-9] (OOD) test datasets.</p>"},{"location":"notebooks/tensorflow/demo_rmds_tf/#second-experiment-cifar-10-vs-svhn","title":"Second experiment: CIFAR-10 vs SVHN\u00b6","text":"<p>For this second experiment, we oppose CIFAR-10 (in-distribution dataset) to SVHN (out-of-distribution dataset).</p>"},{"location":"notebooks/tensorflow/demo_rmds_tf/#data-loading","title":"Data loading\u00b6","text":"<ul> <li>In-distribution data: CIFAR-10</li> <li>Out-of-distribution data: SVHN</li> </ul>"},{"location":"notebooks/tensorflow/demo_rmds_tf/#model-loading","title":"Model loading\u00b6","text":"<p>The model is a ResNet pretrained on CIFAR-10 and getting an accuracy score of 92.75%.</p>"},{"location":"notebooks/tensorflow/demo_rmds_tf/#mahalanobis-score","title":"Mahalanobis score\u00b6","text":"<p>We now fit a Mahalanobis OOD detector with CIFAR-10 train dataset, and compare OOD scores returned for CIFAR-10 (ID) and SVHN (OOD) test datasets.</p>"},{"location":"notebooks/tensorflow/demo_scale_tf/","title":"SCALE","text":"In\u00a0[1]: Copied! <pre>%load_ext autoreload\n\nimport os\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n\nfrom IPython.display import clear_output\nimport numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n\nfrom oodeel.methods import MLS, Energy, GEN, ODIN\nfrom oodeel.eval.metrics import bench_metrics\nfrom oodeel.eval.plots import plot_ood_scores, plot_roc_curve, plot_2D_features\nfrom oodeel.datasets import OODDataset\nfrom oodeel.utils.tf_training_tools import train_tf_model\n</pre> %load_ext autoreload  import os os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"  from IPython.display import clear_output import numpy as np import tensorflow as tf import matplotlib.pyplot as plt  from oodeel.methods import MLS, Energy, GEN, ODIN from oodeel.eval.metrics import bench_metrics from oodeel.eval.plots import plot_ood_scores, plot_roc_curve, plot_2D_features from oodeel.datasets import OODDataset from oodeel.utils.tf_training_tools import train_tf_model <p>Note that models are saved at ~/.oodeel/saved_models and data is supposed to be found at ~/.oodeel/datasets by default. Change the following cell for a custom path.</p> In\u00a0[2]: Copied! <pre>model_path = os.path.expanduser(\"~/\") + \".oodeel/saved_models\"\ndata_path = os.path.expanduser(\"~/\") + \".oodeel/datasets\"\nos.makedirs(model_path, exist_ok=True)\nos.makedirs(data_path, exist_ok=True)\n</pre> model_path = os.path.expanduser(\"~/\") + \".oodeel/saved_models\" data_path = os.path.expanduser(\"~/\") + \".oodeel/datasets\" os.makedirs(model_path, exist_ok=True) os.makedirs(data_path, exist_ok=True) In\u00a0[3]: Copied! <pre># === Load ID and OOD data ===\nbatch_size = 128\n\n# 1a- Load in-distribution dataset: CIFAR-10\nds_fit = OODDataset(\"cifar10\", load_kwargs={\"split\": \"train\"}, input_key=\"image\")\nds_in = OODDataset(\"cifar10\", load_kwargs={\"split\": \"test\"}, input_key=\"image\")\n\n# 1b- Load out-of-distribution dataset: SVHN\nds_out = OODDataset(\"svhn_cropped\", load_kwargs={\"split\": \"test\"})\n\n\n# 2- prepare data (preprocess, shuffle, batch)\ndef preprocess_fn(*inputs):\n    x = inputs[0] / 255\n    return tuple([x] + list(inputs[1:]))\n\n\nds_fit = ds_fit.prepare(batch_size, preprocess_fn)\nds_in = ds_in.prepare(batch_size, preprocess_fn)\nds_out = ds_out.prepare(batch_size, preprocess_fn)\n\nclear_output()\n</pre> # === Load ID and OOD data === batch_size = 128  # 1a- Load in-distribution dataset: CIFAR-10 ds_fit = OODDataset(\"cifar10\", load_kwargs={\"split\": \"train\"}, input_key=\"image\") ds_in = OODDataset(\"cifar10\", load_kwargs={\"split\": \"test\"}, input_key=\"image\")  # 1b- Load out-of-distribution dataset: SVHN ds_out = OODDataset(\"svhn_cropped\", load_kwargs={\"split\": \"test\"})   # 2- prepare data (preprocess, shuffle, batch) def preprocess_fn(*inputs):     x = inputs[0] / 255     return tuple([x] + list(inputs[1:]))   ds_fit = ds_fit.prepare(batch_size, preprocess_fn) ds_in = ds_in.prepare(batch_size, preprocess_fn) ds_out = ds_out.prepare(batch_size, preprocess_fn)  clear_output() In\u00a0[4]: Copied! <pre># === Load model ===\n# ResNet pretrained on CIFAR-10\nmodel_path_resnet_cifar10 = tf.keras.utils.get_file(\n    \"cifar10_resnet256.h5\",\n    origin=\"https://share.deel.ai/s/kram9kLpx6JwRX4/download/cifar10_resnet256.h5\",\n    cache_dir=model_path,\n    cache_subdir=\"\",\n)\nmodel = tf.keras.models.load_model(model_path_resnet_cifar10)\n\n# Evaluate model\nmodel.compile(metrics=[\"accuracy\"])\n_, accuracy = model.evaluate(ds_in)\nprint(f\"Test accuracy:\\t{accuracy:.4f}\")\n\n# penultimate features 2d visualization\nprint(\"\\n=== Penultimate features viz ===\")\nplt.figure(figsize=(4.5, 3))\nplot_2D_features(\n    model=model,\n    in_dataset=ds_in,\n    out_dataset=ds_out,\n    output_layer_id=-2,\n)\nplt.tight_layout()\nplt.show()\n</pre> # === Load model === # ResNet pretrained on CIFAR-10 model_path_resnet_cifar10 = tf.keras.utils.get_file(     \"cifar10_resnet256.h5\",     origin=\"https://share.deel.ai/s/kram9kLpx6JwRX4/download/cifar10_resnet256.h5\",     cache_dir=model_path,     cache_subdir=\"\", ) model = tf.keras.models.load_model(model_path_resnet_cifar10)  # Evaluate model model.compile(metrics=[\"accuracy\"]) _, accuracy = model.evaluate(ds_in) print(f\"Test accuracy:\\t{accuracy:.4f}\")  # penultimate features 2d visualization print(\"\\n=== Penultimate features viz ===\") plt.figure(figsize=(4.5, 3)) plot_2D_features(     model=model,     in_dataset=ds_in,     out_dataset=ds_out,     output_layer_id=-2, ) plt.tight_layout() plt.show() <pre>79/79 [==============================] - 4s 14ms/step - loss: 0.1268 - accuracy: 0.9278\nTest accuracy:\t0.9278\n\n=== Penultimate features viz ===\n</pre> In\u00a0[8]: Copied! <pre>%autoreload 2\ndetectors = {\n    \"odin\": {\n        \"class\": ODIN,\n        \"kwargs\": dict(temperature=1000),\n    },\n    \"mls\": {\n        \"class\": MLS,\n        \"kwargs\": dict(),\n    },\n    \"energy\": {\n        \"class\": Energy,\n        \"kwargs\": dict(),\n    },\n}\n\nfor d in detectors.keys():\n    print(f\"=== {d.upper()} ===\")\n\n    for use_scale in [False, True]:\n        print([\"~ Without\", \"~ With\"][int(use_scale)] + \" SCALE ~\")\n        # === ood scores ===\n        d_kwargs = detectors[d][\"kwargs\"]\n        d_kwargs.update(dict(\n            use_scale=use_scale,\n            scale_percentile=0.85,\n        ))\n        detector = detectors[d][\"class\"](**d_kwargs)\n        detector.fit(model)\n        scores_in, _ = detector.score(ds_in)\n        scores_out, _ = detector.score(ds_out)\n\n        # === metrics ===\n        # auroc / fpr95\n        metrics = bench_metrics(\n            (scores_in, scores_out),\n            metrics=[\"auroc\", \"fpr95tpr\"],\n        )\n        for k, v in metrics.items():\n            print(f\"{k:&lt;10} {v:.6f}\")\n\n        log_scale = d in [\"gen\"]\n        # hists / roc\n        plt.figure(figsize=(9, 3))\n        plt.subplot(121)\n        plot_ood_scores(scores_in, scores_out)\n        plt.subplot(122)\n        plot_roc_curve(scores_in, scores_out)\n        plt.tight_layout()\n        plt.show()\n</pre> %autoreload 2 detectors = {     \"odin\": {         \"class\": ODIN,         \"kwargs\": dict(temperature=1000),     },     \"mls\": {         \"class\": MLS,         \"kwargs\": dict(),     },     \"energy\": {         \"class\": Energy,         \"kwargs\": dict(),     }, }  for d in detectors.keys():     print(f\"=== {d.upper()} ===\")      for use_scale in [False, True]:         print([\"~ Without\", \"~ With\"][int(use_scale)] + \" SCALE ~\")         # === ood scores ===         d_kwargs = detectors[d][\"kwargs\"]         d_kwargs.update(dict(             use_scale=use_scale,             scale_percentile=0.85,         ))         detector = detectors[d][\"class\"](**d_kwargs)         detector.fit(model)         scores_in, _ = detector.score(ds_in)         scores_out, _ = detector.score(ds_out)          # === metrics ===         # auroc / fpr95         metrics = bench_metrics(             (scores_in, scores_out),             metrics=[\"auroc\", \"fpr95tpr\"],         )         for k, v in metrics.items():             print(f\"{k:&lt;10} {v:.6f}\")          log_scale = d in [\"gen\"]         # hists / roc         plt.figure(figsize=(9, 3))         plt.subplot(121)         plot_ood_scores(scores_in, scores_out)         plt.subplot(122)         plot_roc_curve(scores_in, scores_out)         plt.tight_layout()         plt.show() <pre>=== ODIN ===\n~ Without SCALE ~\nauroc      0.950493\nfpr95tpr   0.151200\n</pre> <pre>~ With SCALE ~\nauroc      0.977042\nfpr95tpr   0.087900\n</pre> <pre>=== MLS ===\n~ Without SCALE ~\nauroc      0.915857\nfpr95tpr   0.205700\n</pre> <pre>~ With SCALE ~\nauroc      0.945725\nfpr95tpr   0.132300\n</pre> <pre>=== ENERGY ===\n~ Without SCALE ~\nauroc      0.909186\nfpr95tpr   0.206900\n</pre> <pre>~ With SCALE ~\nauroc      0.945675\nfpr95tpr   0.132300\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"notebooks/tensorflow/demo_scale_tf/#scale-method","title":"SCALE method\u00b6","text":"<p>This notebook aims at evaluating the SCALE method.</p> <p>SCALE method basically consists in re-using existing logit-based OOD methods, but with penultimate layer activations scaled. Let $a$ be the activation vector, and $P_p(a)$ the $p$-th percentile of $a$'s values. The scaling is computed using the formula $$ s = \\exp(\\frac{\\sum_{i} a_i}{\\sum_{a_i &gt; P_p(a)} a_i}) $$</p> <p>Here, we focus on a Resnet trained on CIFAR10, challenged on SVHN.</p> <p>Reference Scaling for Training Time and Post-hoc Out-of-distribution Detection Enhancement, ICLR 2024 http://arxiv.org/abs/2310.00227</p>"},{"location":"notebooks/tensorflow/demo_scale_tf/#imports","title":"Imports\u00b6","text":""},{"location":"notebooks/tensorflow/demo_scale_tf/#data-loading","title":"Data loading\u00b6","text":"<ul> <li>In-distribution data: CIFAR-10</li> <li>Out-of-distribution data: SVHN</li> </ul> <p>Note: We denote In-Distribution (ID) data with <code>_in</code> and Out-Of-Distribution (OOD) data with <code>_out</code> to avoid confusion with OOD detection which is the name of the task, and is therefore used to denote core classes such as <code>OODDataset</code> and <code>OODBaseDetector</code>.</p>"},{"location":"notebooks/tensorflow/demo_scale_tf/#model-training","title":"Model training\u00b6","text":"<p>Now let's train a simple model on MNIST[0-4] using <code>train_tf_model</code> function.</p>"},{"location":"notebooks/tensorflow/demo_scale_tf/#scale-scores","title":"SCALE scores\u00b6","text":"<p>We now fit some OOD detectors using SCALE + [MLS, MSP, Energy, Entropy, ODIN] with MNIST[0-4] train dataset, and compare OOD scores returned for MNIST[0-4] (ID) and MNIST[5-9] (OOD) test datasets.</p>"},{"location":"notebooks/tensorflow/demo_she_tf/","title":"SHE","text":"In\u00a0[1]: Copied! <pre>%load_ext autoreload\n%autoreload 2\n\nimport os\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n\nfrom IPython.display import clear_output\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfrom oodeel.methods import SHE\nfrom oodeel.eval.metrics import bench_metrics\nfrom oodeel.eval.plots import plot_ood_scores, plot_roc_curve, plot_2D_features\nfrom oodeel.datasets import OODDataset\nfrom oodeel.utils.tf_training_tools import train_tf_model\n</pre> %load_ext autoreload %autoreload 2  import os os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"  from IPython.display import clear_output import tensorflow as tf import matplotlib.pyplot as plt import numpy as np  from oodeel.methods import SHE from oodeel.eval.metrics import bench_metrics from oodeel.eval.plots import plot_ood_scores, plot_roc_curve, plot_2D_features from oodeel.datasets import OODDataset from oodeel.utils.tf_training_tools import train_tf_model <p>Note that models are saved at ~/.oodeel/saved_models and data is supposed to be found at ~/.oodeel/datasets by default. Change the following cell for a custom path.</p> In\u00a0[2]: Copied! <pre>model_path = os.path.expanduser(\"~/\") + \".oodeel/saved_models\"\ndata_path = os.path.expanduser(\"~/\") + \".oodeel/datasets\"\nos.makedirs(model_path, exist_ok=True)\nos.makedirs(data_path, exist_ok=True)\n</pre> model_path = os.path.expanduser(\"~/\") + \".oodeel/saved_models\" data_path = os.path.expanduser(\"~/\") + \".oodeel/datasets\" os.makedirs(model_path, exist_ok=True) os.makedirs(data_path, exist_ok=True) In\u00a0[3]: Copied! <pre># === Load ID and OOD data ===\nbatch_size = 128\nin_labels = [0, 1, 2, 3, 4]\n\n# 1- Load train/test MNIST dataset\nds_train = OODDataset(\"mnist\", load_kwargs=dict(split=\"train\"))\ndata_test = OODDataset(\"mnist\", load_kwargs=dict(split=\"test\"))\n\n# 2- Split ID / OOD data depending on label value:\n# in-distribution: MNIST[0-4] / out-of-distribution: MNIST[5-9]\nds_train, _ = ds_train.split_by_class(in_labels)\noods_in, oods_out = data_test.split_by_class(in_labels)\n\n\n# 3- Prepare data (preprocess, shuffle, batch)\ndef preprocess_fn(*inputs):\n    x = inputs[0] / 255\n    return tuple([x] + list(inputs[1:]))\n\n\nds_train = ds_train.prepare(batch_size, preprocess_fn, shuffle=True)\nds_in = oods_in.prepare(batch_size, preprocess_fn, with_ood_labels=False)\nds_out = oods_out.prepare(batch_size, preprocess_fn, with_ood_labels=False)\n\nclear_output()\n</pre> # === Load ID and OOD data === batch_size = 128 in_labels = [0, 1, 2, 3, 4]  # 1- Load train/test MNIST dataset ds_train = OODDataset(\"mnist\", load_kwargs=dict(split=\"train\")) data_test = OODDataset(\"mnist\", load_kwargs=dict(split=\"test\"))  # 2- Split ID / OOD data depending on label value: # in-distribution: MNIST[0-4] / out-of-distribution: MNIST[5-9] ds_train, _ = ds_train.split_by_class(in_labels) oods_in, oods_out = data_test.split_by_class(in_labels)   # 3- Prepare data (preprocess, shuffle, batch) def preprocess_fn(*inputs):     x = inputs[0] / 255     return tuple([x] + list(inputs[1:]))   ds_train = ds_train.prepare(batch_size, preprocess_fn, shuffle=True) ds_in = oods_in.prepare(batch_size, preprocess_fn, with_ood_labels=False) ds_out = oods_out.prepare(batch_size, preprocess_fn, with_ood_labels=False)  clear_output() In\u00a0[4]: Copied! <pre># === Train / Load model ===\nmodel_path_mnist_04 = os.path.join(model_path, \"mnist_mlp_0-4.h5\")\n\ntry:\n    # if the model exists, load it\n    model = tf.keras.models.load_model(model_path_mnist_04)\nexcept OSError:\n    # else, train a new model\n    train_config = {\n        \"model\": \"toy_mlp\",\n        \"input_shape\": (28, 28, 1),\n        \"num_classes\": 10,\n        \"batch_size\": 128,\n        \"epochs\": 5,\n        \"save_dir\": model_path_mnist_04,\n        \"validation_data\": ds_in,\n    }\n\n    model = train_tf_model(ds_train, **train_config)\n</pre> # === Train / Load model === model_path_mnist_04 = os.path.join(model_path, \"mnist_mlp_0-4.h5\")  try:     # if the model exists, load it     model = tf.keras.models.load_model(model_path_mnist_04) except OSError:     # else, train a new model     train_config = {         \"model\": \"toy_mlp\",         \"input_shape\": (28, 28, 1),         \"num_classes\": 10,         \"batch_size\": 128,         \"epochs\": 5,         \"save_dir\": model_path_mnist_04,         \"validation_data\": ds_in,     }      model = train_tf_model(ds_train, **train_config) In\u00a0[5]: Copied! <pre>_, accuracy = model.evaluate(ds_in)\nprint(f\"Test accuracy:\\t{accuracy:.4f}\")\n\n# penultimate features 2d visualization\nprint(\"\\n=== Penultimate features viz ===\")\nplt.figure(figsize=(4.5, 3))\nplot_2D_features(\n    model=model,\n    in_dataset=ds_in,\n    out_dataset=ds_out,\n    output_layer_id=-2,\n)\nplt.tight_layout()\nplt.show()\n</pre> _, accuracy = model.evaluate(ds_in) print(f\"Test accuracy:\\t{accuracy:.4f}\")  # penultimate features 2d visualization print(\"\\n=== Penultimate features viz ===\") plt.figure(figsize=(4.5, 3)) plot_2D_features(     model=model,     in_dataset=ds_in,     out_dataset=ds_out,     output_layer_id=-2, ) plt.tight_layout() plt.show() <pre>41/41 [==============================] - 2s 21ms/step - loss: 0.0217 - accuracy: 0.9934\nTest accuracy:\t0.9934\n\n=== Penultimate features viz ===\n</pre> In\u00a0[6]: Copied! <pre># === gram scores ===\nshe = SHE()\nshe.fit(model, ds_train, feature_layers_id=[\"dense\", \"dense_1\"])\n</pre> # === gram scores === she = SHE() she.fit(model, ds_train, feature_layers_id=[\"dense\", \"dense_1\"]) In\u00a0[7]: Copied! <pre>scores_in, _ = she.score(ds_in)\nscores_out, _ = she.score(ds_out)\n\n# Since many scores are equal to 0, we add a random noise to avoid bugs\n# in Auroc and TPR computation.\nscores_in += np.random.random_sample(size=scores_in.shape) * 10e-6\nscores_out += np.random.random_sample(size=scores_out.shape) * 10e-6\n\n# === metrics ===\n# auroc / fpr95\nmetrics = bench_metrics(\n    (scores_in, scores_out),\n    metrics=[\"auroc\", \"fpr95tpr\"],\n)\nprint(\"=== Metrics ===\")\nfor k, v in metrics.items():\n    print(f\"{k:&lt;10} {v:.6f}\")\n</pre> scores_in, _ = she.score(ds_in) scores_out, _ = she.score(ds_out)  # Since many scores are equal to 0, we add a random noise to avoid bugs # in Auroc and TPR computation. scores_in += np.random.random_sample(size=scores_in.shape) * 10e-6 scores_out += np.random.random_sample(size=scores_out.shape) * 10e-6  # === metrics === # auroc / fpr95 metrics = bench_metrics(     (scores_in, scores_out),     metrics=[\"auroc\", \"fpr95tpr\"], ) print(\"=== Metrics ===\") for k, v in metrics.items():     print(f\"{k:&lt;10} {v:.6f}\") <pre>=== Metrics ===\nauroc      0.725269\nfpr95tpr   0.688655\n</pre> In\u00a0[8]: Copied! <pre>print(\"\\n=== Plots ===\")\n# hists / roc\nplt.figure(figsize=(9, 3))\nplt.subplot(121)\nplot_ood_scores(scores_in, scores_out)\nplt.subplot(122)\nplot_roc_curve(scores_in, scores_out)\nplt.tight_layout()\nplt.show()\n</pre> print(\"\\n=== Plots ===\") # hists / roc plt.figure(figsize=(9, 3)) plt.subplot(121) plot_ood_scores(scores_in, scores_out) plt.subplot(122) plot_roc_curve(scores_in, scores_out) plt.tight_layout() plt.show() <pre>\n=== Plots ===\n</pre> In\u00a0[3]: Copied! <pre># === Load ID and OOD data ===\nbatch_size = 128\n\n# 1a- Load in-distribution dataset: CIFAR-10\nds_fit = OODDataset(\"cifar10\", load_kwargs={\"split\": \"train\"}, input_key=\"image\")\nds_in = OODDataset(\"cifar10\", load_kwargs={\"split\": \"test\"}, input_key=\"image\")\n\n# 1b- Load out-of-distribution dataset: SVHN\nds_out = OODDataset(\"svhn_cropped\", load_kwargs={\"split\": \"test\"})\n\n\n# 2- prepare data (preprocess, shuffle, batch)\ndef preprocess_fn(*inputs):\n    x = inputs[0] / 255\n    return tuple([x] + list(inputs[1:]))\n\n\nds_fit = ds_fit.prepare(batch_size, preprocess_fn)\nds_in = ds_in.prepare(batch_size, preprocess_fn)\nds_out = ds_out.prepare(batch_size, preprocess_fn)\nclear_output()\n</pre> # === Load ID and OOD data === batch_size = 128  # 1a- Load in-distribution dataset: CIFAR-10 ds_fit = OODDataset(\"cifar10\", load_kwargs={\"split\": \"train\"}, input_key=\"image\") ds_in = OODDataset(\"cifar10\", load_kwargs={\"split\": \"test\"}, input_key=\"image\")  # 1b- Load out-of-distribution dataset: SVHN ds_out = OODDataset(\"svhn_cropped\", load_kwargs={\"split\": \"test\"})   # 2- prepare data (preprocess, shuffle, batch) def preprocess_fn(*inputs):     x = inputs[0] / 255     return tuple([x] + list(inputs[1:]))   ds_fit = ds_fit.prepare(batch_size, preprocess_fn) ds_in = ds_in.prepare(batch_size, preprocess_fn) ds_out = ds_out.prepare(batch_size, preprocess_fn) clear_output() In\u00a0[4]: Copied! <pre># === Load model ===\n# ResNet pretrained on CIFAR-10\nmodel_path_resnet_cifar10 = tf.keras.utils.get_file(\n    \"cifar10_resnet256.h5\",\n    origin=\"https://share.deel.ai/s/kram9kLpx6JwRX4/download/cifar10_resnet256.h5\",\n    cache_dir=model_path,\n    cache_subdir=\"\",\n)\nmodel = tf.keras.models.load_model(model_path_resnet_cifar10)\n</pre> # === Load model === # ResNet pretrained on CIFAR-10 model_path_resnet_cifar10 = tf.keras.utils.get_file(     \"cifar10_resnet256.h5\",     origin=\"https://share.deel.ai/s/kram9kLpx6JwRX4/download/cifar10_resnet256.h5\",     cache_dir=model_path,     cache_subdir=\"\", ) model = tf.keras.models.load_model(model_path_resnet_cifar10) In\u00a0[5]: Copied! <pre># Evaluate model\nmodel.compile(metrics=[\"accuracy\"])\n_, accuracy = model.evaluate(ds_in)\nprint(f\"Test accuracy:\\t{accuracy:.4f}\")\n\n# penultimate features 2d visualization\nprint(\"\\n=== Penultimate features viz ===\")\nplt.figure(figsize=(4.5, 3))\nplot_2D_features(\n    model=model,\n    in_dataset=ds_in,\n    out_dataset=ds_out,\n    output_layer_id=-2,\n)\nplt.tight_layout()\nplt.show()\n</pre> # Evaluate model model.compile(metrics=[\"accuracy\"]) _, accuracy = model.evaluate(ds_in) print(f\"Test accuracy:\\t{accuracy:.4f}\")  # penultimate features 2d visualization print(\"\\n=== Penultimate features viz ===\") plt.figure(figsize=(4.5, 3)) plot_2D_features(     model=model,     in_dataset=ds_in,     out_dataset=ds_out,     output_layer_id=-2, ) plt.tight_layout() plt.show() <pre>79/79 [==============================] - 4s 13ms/step - loss: 0.1268 - accuracy: 0.9278\nTest accuracy:\t0.9278\n\n=== Penultimate features viz ===\n</pre> In\u00a0[6]: Copied! <pre># === gram scores ===\nshe = SHE()\nshe.fit(\n    model,\n    ds_fit,\n    feature_layers_id=[\n        \"conv2d_18\",\n        \"activation_17\",\n        \"conv2d_37\",\n        \"activation_35\",\n        \"conv2d_56\",\n        \"activation_53\",\n        \"flatten\",\n    ],\n)\n\nscores_in, _ = she.score(ds_in)\nscores_out, _ = she.score(ds_out)\n\nscores_in += np.random.random_sample(size=scores_in.shape) * 10e-6\nscores_out += np.random.random_sample(size=scores_out.shape) * 10e-6\n\n# === metrics ===\n# auroc / fpr95\nmetrics = bench_metrics(\n    (scores_in, scores_out),\n    metrics=[\"auroc\", \"fpr95tpr\"],\n)\nprint(\"=== Metrics ===\")\nfor k, v in metrics.items():\n    print(f\"{k:&lt;10} {v:.6f}\")\n</pre> # === gram scores === she = SHE() she.fit(     model,     ds_fit,     feature_layers_id=[         \"conv2d_18\",         \"activation_17\",         \"conv2d_37\",         \"activation_35\",         \"conv2d_56\",         \"activation_53\",         \"flatten\",     ], )  scores_in, _ = she.score(ds_in) scores_out, _ = she.score(ds_out)  scores_in += np.random.random_sample(size=scores_in.shape) * 10e-6 scores_out += np.random.random_sample(size=scores_out.shape) * 10e-6  # === metrics === # auroc / fpr95 metrics = bench_metrics(     (scores_in, scores_out),     metrics=[\"auroc\", \"fpr95tpr\"], ) print(\"=== Metrics ===\") for k, v in metrics.items():     print(f\"{k:&lt;10} {v:.6f}\") <pre>WARNING:tensorflow:5 out of the last 1093 calls to &lt;function TFOperator.matmul at 0x7fcfa2f82ee0&gt; triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n</pre> <pre>WARNING:tensorflow:5 out of the last 1093 calls to &lt;function TFOperator.matmul at 0x7fcfa2f82ee0&gt; triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n</pre> <pre>WARNING:tensorflow:5 out of the last 2857 calls to &lt;function TFOperator.matmul at 0x7fcfa2f82ee0&gt; triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n</pre> <pre>WARNING:tensorflow:5 out of the last 2857 calls to &lt;function TFOperator.matmul at 0x7fcfa2f82ee0&gt; triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n</pre> <pre>=== Metrics ===\nauroc      0.988420\nfpr95tpr   0.055000\n</pre> In\u00a0[13]: Copied! <pre>print(\"\\n=== Plots ===\")\n# hists / roc\nplt.figure(figsize=(9, 3))\nplt.subplot(121)\nplot_ood_scores(scores_in, scores_out)\nplt.subplot(122)\nplot_roc_curve(scores_in, scores_out)\nplt.tight_layout()\nplt.show()\n</pre> print(\"\\n=== Plots ===\") # hists / roc plt.figure(figsize=(9, 3)) plt.subplot(121) plot_ood_scores(scores_in, scores_out) plt.subplot(122) plot_roc_curve(scores_in, scores_out) plt.tight_layout() plt.show() <pre>\n=== Plots ===\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"notebooks/tensorflow/demo_she_tf/#she-simplified-hopfield-energy-method","title":"SHE (Simplified Hopfield Energy) method\u00b6","text":"<p>This method first computes the mean of the internal layer representation of ID data for each ID class. This mean is seen as the average of the ID activation patterns as defined in the original paper. The method then returns the maximum value of the dot product between the internal layer representation of the input and the average patterns, which is a simplified version of Hopfield energy as defined in the original paper.</p> <p>Reference Out-of-Distribution Detection based on In-Distribution Data Patterns Memorization with Modern Hopfield Energy, ICLR 2023</p>"},{"location":"notebooks/tensorflow/demo_she_tf/#imports","title":"Imports\u00b6","text":""},{"location":"notebooks/tensorflow/demo_she_tf/#first-experiment-mnist0-4-vs-mnist5-9","title":"First experiment: MNIST[0-4] vs MNIST[5-9]\u00b6","text":"<p>For this first experiment, we train a toy convolutional network on the MNIST dataset restricted to digits 0 to 4. After fitting the train subset of this dataset to the gram method, we will compare the scores returned for MNIST[0-4] (in-distribution) and MNIST[5-9] (out-of-distribution) test subsets.</p>"},{"location":"notebooks/tensorflow/demo_she_tf/#data-loading","title":"Data loading\u00b6","text":"<ul> <li>In-distribution data: MNIST[0-4]</li> <li>Out-of-distribution data: MNIST[5-9]</li> </ul> <p>Note: We denote In-Distribution (ID) data with <code>_in</code> and Out-Of-Distribution (OOD) data with <code>_out</code> to avoid confusion with OOD detection which is the name of the task, and is therefore used to denote core classes such as <code>OODDataset</code> and <code>OODBaseDetector</code>.</p>"},{"location":"notebooks/tensorflow/demo_she_tf/#model-training","title":"Model training\u00b6","text":"<p>Now let's train a simple model on MNIST[0-4] on a simple MLP using <code>train_tf_model</code> function.</p>"},{"location":"notebooks/tensorflow/demo_she_tf/#she-score","title":"SHE score\u00b6","text":"<p>We now fit a SHE detector with MNIST[0-4] train dataset, and compare OOD scores returned for MNIST[0-4] (ID) and MNIST[5-9] (OOD) test datasets.</p>"},{"location":"notebooks/tensorflow/demo_she_tf/#second-experiment-cifar-10-vs-svhn","title":"Second experiment: CIFAR-10 vs SVHN\u00b6","text":"<p>For this second experiment, we oppose CIFAR-10 (in-distribution dataset) to SVHN (out-of-distribution dataset).</p>"},{"location":"notebooks/tensorflow/demo_she_tf/#data-loading","title":"Data loading\u00b6","text":"<ul> <li>In-distribution data: CIFAR-10</li> <li>Out-of-distribution data: SVHN</li> </ul>"},{"location":"notebooks/tensorflow/demo_she_tf/#model-loading","title":"Model loading\u00b6","text":"<p>The model is a ResNet pretrained on CIFAR-10 and getting an accuracy score of 92.75%.</p>"},{"location":"notebooks/tensorflow/demo_she_tf/#she-score","title":"SHE score\u00b6","text":"<p>We now fit a SHE detector with CIFAR-10 train dataset, and compare OOD scores returned for CIFAR-10 (ID) and SVHN (OOD) test datasets.</p>"},{"location":"notebooks/tensorflow/demo_vim_tf/","title":"VIM","text":"In\u00a0[1]: Copied! <pre>%load_ext autoreload\n%autoreload 2\n\nimport os\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n\nfrom IPython.display import clear_output\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n\nfrom oodeel.methods import VIM\nfrom oodeel.eval.metrics import bench_metrics\nfrom oodeel.eval.plots import plot_ood_scores, plot_roc_curve, plot_2D_features\nfrom oodeel.datasets import OODDataset\nfrom oodeel.utils.tf_training_tools import train_tf_model\n</pre> %load_ext autoreload %autoreload 2  import os os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"  from IPython.display import clear_output import tensorflow as tf import matplotlib.pyplot as plt  from oodeel.methods import VIM from oodeel.eval.metrics import bench_metrics from oodeel.eval.plots import plot_ood_scores, plot_roc_curve, plot_2D_features from oodeel.datasets import OODDataset from oodeel.utils.tf_training_tools import train_tf_model <p>Note that models are saved at ~/.oodeel/saved_models and data is supposed to be found at ~/.oodeel/datasets by default. Change the following cell for a custom path.</p> In\u00a0[6]: Copied! <pre>model_path = os.path.expanduser(\"~/\") + \".oodeel/saved_models\"\ndata_path = os.path.expanduser(\"~/\") + \".oodeel/datasets\"\nos.makedirs(model_path, exist_ok=True)\nos.makedirs(data_path, exist_ok=True)\n</pre> model_path = os.path.expanduser(\"~/\") + \".oodeel/saved_models\" data_path = os.path.expanduser(\"~/\") + \".oodeel/datasets\" os.makedirs(model_path, exist_ok=True) os.makedirs(data_path, exist_ok=True) In\u00a0[7]: Copied! <pre># === Load ID and OOD data ===\nbatch_size = 128\nin_labels = [0, 1, 2, 3, 4]\n\n# 1- Load train/test MNIST dataset\nds_train = OODDataset(\"mnist\", load_kwargs=dict(split=\"train\"))\ndata_test = OODDataset(\"mnist\", load_kwargs=dict(split=\"test\"))\n\n# 2- Split ID / OOD data depending on label value:\n# in-distribution: MNIST[0-4] / out-of-distribution: MNIST[5-9]\nds_train, _ = ds_train.split_by_class(in_labels)\noods_in, oods_out = data_test.split_by_class(in_labels)\n\n\n# 3- Prepare data (preprocess, shuffle, batch)\ndef preprocess_fn(*inputs):\n    x = inputs[0] / 255\n    return tuple([x] + list(inputs[1:]))\n\n\nds_train = ds_train.prepare(batch_size, preprocess_fn, shuffle=True)\nds_in = oods_in.prepare(batch_size, preprocess_fn, with_ood_labels=False)\nds_out = oods_out.prepare(batch_size, preprocess_fn, with_ood_labels=False)\n\nclear_output()\n</pre> # === Load ID and OOD data === batch_size = 128 in_labels = [0, 1, 2, 3, 4]  # 1- Load train/test MNIST dataset ds_train = OODDataset(\"mnist\", load_kwargs=dict(split=\"train\")) data_test = OODDataset(\"mnist\", load_kwargs=dict(split=\"test\"))  # 2- Split ID / OOD data depending on label value: # in-distribution: MNIST[0-4] / out-of-distribution: MNIST[5-9] ds_train, _ = ds_train.split_by_class(in_labels) oods_in, oods_out = data_test.split_by_class(in_labels)   # 3- Prepare data (preprocess, shuffle, batch) def preprocess_fn(*inputs):     x = inputs[0] / 255     return tuple([x] + list(inputs[1:]))   ds_train = ds_train.prepare(batch_size, preprocess_fn, shuffle=True) ds_in = oods_in.prepare(batch_size, preprocess_fn, with_ood_labels=False) ds_out = oods_out.prepare(batch_size, preprocess_fn, with_ood_labels=False)  clear_output() In\u00a0[8]: Copied! <pre># === Train / Load model ===\nmodel_path_mnist_04 = os.path.join(model_path, \"mnist_model_0-4.h5\")\n\ntry:\n    # if the model exists, load it\n    model = tf.keras.models.load_model(model_path_mnist_04)\nexcept OSError:\n    # else, train a new model\n    train_config = {\n        \"model\": \"toy_convnet\",\n        \"input_shape\": (28, 28, 1),\n        \"num_classes\": 10,\n        \"batch_size\": 128,\n        \"epochs\": 5,\n        \"save_dir\": model_path_mnist_04,\n        \"validation_data\": ds_in,\n    }\n\n    model = train_tf_model(ds_train, **train_config)\n\n_, accuracy = model.evaluate(ds_in)\nprint(f\"Test accuracy:\\t{accuracy:.4f}\")\n\n# penultimate features 2d visualization\nprint(\"\\n=== Penultimate features viz ===\")\nplt.figure(figsize=(4.5, 3))\nplot_2D_features(\n    model=model,\n    in_dataset=ds_in,\n    out_dataset=ds_out,\n    output_layer_id=-2,\n)\nplt.tight_layout()\nplt.show()\n</pre> # === Train / Load model === model_path_mnist_04 = os.path.join(model_path, \"mnist_model_0-4.h5\")  try:     # if the model exists, load it     model = tf.keras.models.load_model(model_path_mnist_04) except OSError:     # else, train a new model     train_config = {         \"model\": \"toy_convnet\",         \"input_shape\": (28, 28, 1),         \"num_classes\": 10,         \"batch_size\": 128,         \"epochs\": 5,         \"save_dir\": model_path_mnist_04,         \"validation_data\": ds_in,     }      model = train_tf_model(ds_train, **train_config)  _, accuracy = model.evaluate(ds_in) print(f\"Test accuracy:\\t{accuracy:.4f}\")  # penultimate features 2d visualization print(\"\\n=== Penultimate features viz ===\") plt.figure(figsize=(4.5, 3)) plot_2D_features(     model=model,     in_dataset=ds_in,     out_dataset=ds_out,     output_layer_id=-2, ) plt.tight_layout() plt.show() <pre>41/41 [==============================] - 2s 19ms/step - loss: 0.0135 - accuracy: 0.9955\nTest accuracy:\t0.9955\n\n=== Penultimate features viz ===\n</pre> In\u00a0[10]: Copied! <pre># === VIM scores ===\nvim = VIM(princ_dims=500)\nvim.fit(model, feature_layers_id=[-2], fit_dataset=ds_train)\nscores_in, _ = vim.score(ds_in)\nscores_out, _ = vim.score(ds_out)\n\n# === metrics ===\n# auroc / fpr95\nmetrics = bench_metrics(\n    (scores_in, scores_out),\n    metrics=[\"auroc\", \"fpr95tpr\"],\n)\nprint(\"=== Metrics ===\")\nfor k, v in metrics.items():\n    print(f\"{k:&lt;10} {v:.6f}\")\n\nprint(\"\\n=== Plots ===\")\n# hists / roc\nplt.figure(figsize=(13.5, 3))\nplt.subplot(131)\nplot_ood_scores(scores_in, scores_out, log_scale=False)\nplt.subplot(132)\nplot_roc_curve(scores_in, scores_out)\nplt.subplot(133)\nvim.plot_spectrum()\nplt.tight_layout()\nplt.show()\n</pre> # === VIM scores === vim = VIM(princ_dims=500) vim.fit(model, feature_layers_id=[-2], fit_dataset=ds_train) scores_in, _ = vim.score(ds_in) scores_out, _ = vim.score(ds_out)  # === metrics === # auroc / fpr95 metrics = bench_metrics(     (scores_in, scores_out),     metrics=[\"auroc\", \"fpr95tpr\"], ) print(\"=== Metrics ===\") for k, v in metrics.items():     print(f\"{k:&lt;10} {v:.6f}\")  print(\"\\n=== Plots ===\") # hists / roc plt.figure(figsize=(13.5, 3)) plt.subplot(131) plot_ood_scores(scores_in, scores_out, log_scale=False) plt.subplot(132) plot_roc_curve(scores_in, scores_out) plt.subplot(133) vim.plot_spectrum() plt.tight_layout() plt.show() <pre>=== Metrics ===\nauroc      0.965144\nfpr95tpr   0.137575\n\n=== Plots ===\n</pre> In\u00a0[11]: Copied! <pre># === Load ID and OOD data ===\nbatch_size = 128\n\n# 1a- Load in-distribution dataset: CIFAR-10\nds_fit = OODDataset(\"cifar10\", load_kwargs={\"split\": \"train\"}, input_key=\"image\")\nds_in = OODDataset(\"cifar10\", load_kwargs={\"split\": \"test\"}, input_key=\"image\")\n\n# 1b- Load out-of-distribution dataset: SVHN\nds_out = OODDataset(\"svhn_cropped\", load_kwargs={\"split\": \"test\"})\n\n\n# 2- prepare data (preprocess, shuffle, batch)\ndef preprocess_fn(*inputs):\n    x = inputs[0] / 255\n    return tuple([x] + list(inputs[1:]))\n\n\nds_fit = ds_fit.prepare(batch_size, preprocess_fn)\nds_in = ds_in.prepare(batch_size, preprocess_fn)\nds_out = ds_out.prepare(batch_size, preprocess_fn)\n</pre> # === Load ID and OOD data === batch_size = 128  # 1a- Load in-distribution dataset: CIFAR-10 ds_fit = OODDataset(\"cifar10\", load_kwargs={\"split\": \"train\"}, input_key=\"image\") ds_in = OODDataset(\"cifar10\", load_kwargs={\"split\": \"test\"}, input_key=\"image\")  # 1b- Load out-of-distribution dataset: SVHN ds_out = OODDataset(\"svhn_cropped\", load_kwargs={\"split\": \"test\"})   # 2- prepare data (preprocess, shuffle, batch) def preprocess_fn(*inputs):     x = inputs[0] / 255     return tuple([x] + list(inputs[1:]))   ds_fit = ds_fit.prepare(batch_size, preprocess_fn) ds_in = ds_in.prepare(batch_size, preprocess_fn) ds_out = ds_out.prepare(batch_size, preprocess_fn) In\u00a0[12]: Copied! <pre># === Load model ===\n# ResNet pretrained on CIFAR-10\nmodel_path_resnet_cifar10 = tf.keras.utils.get_file(\n    \"cifar10_resnet256.h5\",\n    origin=\"https://share.deel.ai/s/kram9kLpx6JwRX4/download/cifar10_resnet256.h5\",\n    cache_dir=model_path,\n    cache_subdir=\"\",\n)\nmodel = tf.keras.models.load_model(model_path_resnet_cifar10)\n\n# Evaluate model\nmodel.compile(metrics=[\"accuracy\"])\n_, accuracy = model.evaluate(ds_in)\nprint(f\"Test accuracy:\\t{accuracy:.4f}\")\n\n# penultimate features 2d visualization\nprint(\"\\n=== Penultimate features viz ===\")\nplt.figure(figsize=(4.5, 3))\nplot_2D_features(\n    model=model,\n    in_dataset=ds_in,\n    out_dataset=ds_out,\n    output_layer_id=-2,\n)\nplt.tight_layout()\nplt.show()\n</pre> # === Load model === # ResNet pretrained on CIFAR-10 model_path_resnet_cifar10 = tf.keras.utils.get_file(     \"cifar10_resnet256.h5\",     origin=\"https://share.deel.ai/s/kram9kLpx6JwRX4/download/cifar10_resnet256.h5\",     cache_dir=model_path,     cache_subdir=\"\", ) model = tf.keras.models.load_model(model_path_resnet_cifar10)  # Evaluate model model.compile(metrics=[\"accuracy\"]) _, accuracy = model.evaluate(ds_in) print(f\"Test accuracy:\\t{accuracy:.4f}\")  # penultimate features 2d visualization print(\"\\n=== Penultimate features viz ===\") plt.figure(figsize=(4.5, 3)) plot_2D_features(     model=model,     in_dataset=ds_in,     out_dataset=ds_out,     output_layer_id=-2, ) plt.tight_layout() plt.show() <pre>79/79 [==============================] - 26s 283ms/step - loss: 0.1268 - accuracy: 0.9276\nTest accuracy:\t0.9276\n\n=== Penultimate features viz ===\n</pre> In\u00a0[8]: Copied! <pre># === VIM scores ===\nvim = VIM(princ_dims=40)\nvim.fit(model, feature_layers_id=[-2], fit_dataset=ds_fit)\nscores_in, _ = vim.score(ds_in)\nscores_out, _ = vim.score(ds_out)\n\nclear_output()\n\n# === metrics ===\n# auroc / fpr95\nmetrics = bench_metrics(\n    (scores_in, scores_out),\n    metrics=[\"auroc\", \"fpr95tpr\"],\n)\nprint(\"=== Metrics ===\")\nfor k, v in metrics.items():\n    print(f\"{k:&lt;10} {v:.6f}\")\n\nprint(\"\\n=== Plots ===\")\n# hists / roc\nplt.figure(figsize=(13.5, 3))\nplt.subplot(131)\nplot_ood_scores(scores_in, scores_out, log_scale=False)\nplt.subplot(132)\nplot_roc_curve(scores_in, scores_out)\nplt.subplot(133)\nvim.plot_spectrum()\nplt.tight_layout()\nplt.show()\n</pre> # === VIM scores === vim = VIM(princ_dims=40) vim.fit(model, feature_layers_id=[-2], fit_dataset=ds_fit) scores_in, _ = vim.score(ds_in) scores_out, _ = vim.score(ds_out)  clear_output()  # === metrics === # auroc / fpr95 metrics = bench_metrics(     (scores_in, scores_out),     metrics=[\"auroc\", \"fpr95tpr\"], ) print(\"=== Metrics ===\") for k, v in metrics.items():     print(f\"{k:&lt;10} {v:.6f}\")  print(\"\\n=== Plots ===\") # hists / roc plt.figure(figsize=(13.5, 3)) plt.subplot(131) plot_ood_scores(scores_in, scores_out, log_scale=False) plt.subplot(132) plot_roc_curve(scores_in, scores_out) plt.subplot(133) vim.plot_spectrum() plt.tight_layout() plt.show() <pre>=== Metrics ===\nauroc      0.948077\nfpr95tpr   0.160900\n\n=== Plots ===\n</pre>"},{"location":"notebooks/tensorflow/demo_vim_tf/#virtual-logit-matching-vim-method","title":"Virtual Logit Matching (VIM) method\u00b6","text":"<p>This notebook aims at evaluating the VIM method.</p> <p>The method consists in analysing the projection of an input image in a feature subspace that contains the least information about in-distribution data. It is achieved by performing a PCA on the in-distribution dataset in the feature space. The norm of the projection of a new input data's feature representation onto the principal vectors explaining the least variance is then used for scoring.</p> <p>Here, we focus on a toy convolutional network trained on MNIST[0-4] and a ResNet model trained on CIFAR-10, respectively challenged on MNIST[5-9] and SVHN OOD datasets.</p> <p>Reference ViM: Out-Of-Distribution with Virtual-logit Matching, CVPR 2022.</p>"},{"location":"notebooks/tensorflow/demo_vim_tf/#imports","title":"Imports\u00b6","text":""},{"location":"notebooks/tensorflow/demo_vim_tf/#first-experiment-mnist0-4-vs-mnist5-9","title":"First experiment: MNIST[0-4] vs MNIST[5-9]\u00b6","text":"<p>For this first experiment, we train a toy convolutional network on the MNIST dataset restricted to digits 0 to 4. After fitting the train subset of this dataset to the VIM method, we will compare the scores returned for MNIST[0-4] (in-distribution) and MNIST[5-9] (out-of-distribution) test subsets.</p>"},{"location":"notebooks/tensorflow/demo_vim_tf/#data-loading","title":"Data loading\u00b6","text":"<ul> <li>In-distribution data: MNIST[0-4]</li> <li>Out-of-distribution data: MNIST[5-9]</li> </ul> <p>Note: We denote In-Distribution (ID) data with <code>_in</code> and Out-Of-Distribution (OOD) data with <code>_out</code> to avoid confusion with OOD detection which is the name of the task, and is therefore used to denote core classes such as <code>OODDataset</code> and <code>OODBaseDetector</code>.</p>"},{"location":"notebooks/tensorflow/demo_vim_tf/#model-training","title":"Model training\u00b6","text":"<p>Now let's train a simple model on MNIST[0-4] using <code>train_tf_model</code> function.</p>"},{"location":"notebooks/tensorflow/demo_vim_tf/#vim-score","title":"VIM score\u00b6","text":"<p>We now fit a VIM OOD detector with MNIST[0-4] train dataset, and compare OOD scores returned for MNIST[0-4] (ID) and MNIST[5-9] (OOD) test datasets.</p>"},{"location":"notebooks/tensorflow/demo_vim_tf/#second-experiment-cifar-10-vs-svhn","title":"Second experiment: CIFAR-10 vs SVHN\u00b6","text":"<p>For this second experiment, we oppose CIFAR-10 (in-distribution dataset) to SVHN (out-of-distribution dataset).</p>"},{"location":"notebooks/tensorflow/demo_vim_tf/#data-loading","title":"Data loading\u00b6","text":"<ul> <li>In-distribution data: CIFAR-10</li> <li>Out-of-distribution data: SVHN</li> </ul>"},{"location":"notebooks/tensorflow/demo_vim_tf/#model-loading","title":"Model loading\u00b6","text":"<p>The model is a ResNet pretrained on CIFAR-10 and getting an accuracy score of 92.75%.</p>"},{"location":"notebooks/tensorflow/demo_vim_tf/#vim-score","title":"VIM score\u00b6","text":"<p>We now fit a VIM OOD detector with CIFAR-10 train dataset, and compare OOD scores returned for CIFAR-10 (ID) and SVHN (OOD) test datasets.</p>"},{"location":"notebooks/torch/demo_ash_torch/","title":"ASH","text":"In\u00a0[2]: Copied! <pre>%load_ext autoreload\n%autoreload 2\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport os\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n\nfrom IPython.display import clear_output\nfrom sklearn.metrics import accuracy_score\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch\nfrom torchvision import transforms\n\nfrom oodeel.methods import MLS, Energy, ODIN, GEN\nfrom oodeel.eval.metrics import bench_metrics\nfrom oodeel.eval.plots import plot_ood_scores, plot_roc_curve, plot_2D_features\nfrom oodeel.datasets import OODDataset\nfrom oodeel.utils.torch_training_tools import train_torch_model\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n</pre> %load_ext autoreload %autoreload 2  import warnings warnings.filterwarnings(\"ignore\") import os os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"  from IPython.display import clear_output from sklearn.metrics import accuracy_score import matplotlib.pyplot as plt import numpy as np import torch from torchvision import transforms  from oodeel.methods import MLS, Energy, ODIN, GEN from oodeel.eval.metrics import bench_metrics from oodeel.eval.plots import plot_ood_scores, plot_roc_curve, plot_2D_features from oodeel.datasets import OODDataset from oodeel.utils.torch_training_tools import train_torch_model  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") <p>Note that models are saved at ~/.oodeel/saved_models and data is supposed to be found at ~/.oodeel/datasets by default. Change the following cell for a custom path.</p> In\u00a0[3]: Copied! <pre>model_path = os.path.expanduser(\"~/\") + \".oodeel/saved_models\"\ndata_path = os.path.expanduser(\"~/\") + \".oodeel/datasets\"\nos.makedirs(model_path, exist_ok=True)\nos.makedirs(data_path, exist_ok=True)\n</pre> model_path = os.path.expanduser(\"~/\") + \".oodeel/saved_models\" data_path = os.path.expanduser(\"~/\") + \".oodeel/datasets\" os.makedirs(model_path, exist_ok=True) os.makedirs(data_path, exist_ok=True) In\u00a0[4]: Copied! <pre># === load ID and OOD data ===\nbatch_size = 128\n\n# 1a- load in-distribution dataset: CIFAR-10\noods_fit = OODDataset(\n    dataset_id=\"CIFAR10\",\n    backend=\"torch\",\n    load_kwargs={\"root\": data_path, \"train\": True, \"download\": True},\n)\noods_in = OODDataset(\n    dataset_id=\"CIFAR10\",\n    backend=\"torch\",\n    load_kwargs={\"root\": data_path, \"train\": False, \"download\": True},\n)\n# 1b- load out-of-distribution dataset: SVHN\noods_out = OODDataset(\n    dataset_id=\"SVHN\",\n    backend=\"torch\",\n    load_kwargs={\"root\": data_path, \"split\": \"test\", \"download\": True},\n)\n\n\n# 2- prepare data (preprocess, shuffle, batch) =&gt; torch dataloaders\n\n\ndef preprocess_fn(*inputs):\n\"\"\"Preprocessing function from\n    https://github.com/chenyaofo/pytorch-cifar-models\n    \"\"\"\n    x = inputs[0] / 255.0\n    x = transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))(x)\n    return tuple([x] + list(inputs[1:]))\n\n\nds_fit = oods_fit.prepare(\n    batch_size=batch_size, shuffle=True, preprocess_fn=preprocess_fn\n)\nds_in = oods_in.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn)\nds_out = oods_out.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn)\n\nclear_output()\n</pre> # === load ID and OOD data === batch_size = 128  # 1a- load in-distribution dataset: CIFAR-10 oods_fit = OODDataset(     dataset_id=\"CIFAR10\",     backend=\"torch\",     load_kwargs={\"root\": data_path, \"train\": True, \"download\": True}, ) oods_in = OODDataset(     dataset_id=\"CIFAR10\",     backend=\"torch\",     load_kwargs={\"root\": data_path, \"train\": False, \"download\": True}, ) # 1b- load out-of-distribution dataset: SVHN oods_out = OODDataset(     dataset_id=\"SVHN\",     backend=\"torch\",     load_kwargs={\"root\": data_path, \"split\": \"test\", \"download\": True}, )   # 2- prepare data (preprocess, shuffle, batch) =&gt; torch dataloaders   def preprocess_fn(*inputs):     \"\"\"Preprocessing function from     https://github.com/chenyaofo/pytorch-cifar-models     \"\"\"     x = inputs[0] / 255.0     x = transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))(x)     return tuple([x] + list(inputs[1:]))   ds_fit = oods_fit.prepare(     batch_size=batch_size, shuffle=True, preprocess_fn=preprocess_fn ) ds_in = oods_in.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn) ds_out = oods_out.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn)  clear_output() In\u00a0[5]: Copied! <pre># === load model ===\n# resnet20 pretrained on CIFAR-10\nmodel = torch.hub.load(\n    repo_or_dir=\"chenyaofo/pytorch-cifar-models\",\n    model=\"cifar10_resnet20\",\n    pretrained=True,\n    verbose=False,\n).to(device)\nmodel.eval()\n\n# evaluate model\nlabels, preds = [], []\nfor x, y in ds_in:\n    x = x.to(device)\n    preds.append(torch.argmax(model(x), dim=-1).detach().cpu())\n    labels.append(y)\nprint(f\"Test accuracy:\\t{accuracy_score(torch.cat(labels), torch.cat(preds)):.6f}\")\n</pre> # === load model === # resnet20 pretrained on CIFAR-10 model = torch.hub.load(     repo_or_dir=\"chenyaofo/pytorch-cifar-models\",     model=\"cifar10_resnet20\",     pretrained=True,     verbose=False, ).to(device) model.eval()  # evaluate model labels, preds = [], [] for x, y in ds_in:     x = x.to(device)     preds.append(torch.argmax(model(x), dim=-1).detach().cpu())     labels.append(y) print(f\"Test accuracy:\\t{accuracy_score(torch.cat(labels), torch.cat(preds)):.6f}\") <pre>Test accuracy:\t0.925900\n</pre> In\u00a0[6]: Copied! <pre>detectors = {\n    \"odin\": {\n        \"class\": ODIN,\n        \"kwargs\": dict(temperature=1000),\n    },\n    \"mls\": {\n        \"class\": MLS,\n        \"kwargs\": dict(),\n    },\n    \"energy\": {\n        \"class\": Energy,\n        \"kwargs\": dict(),\n    },\n}\n\nfor d in detectors.keys():\n    print(f\"=== {d.upper()} ===\")\n\n    for use_ash in [False, True]:\n        print([\"~ Without\", \"~ With\"][int(use_ash)] + \" ASH ~\")\n        # === ood scores ===\n        d_kwargs = detectors[d][\"kwargs\"]\n        d_kwargs.update(\n            dict(\n                use_ash=use_ash,\n                ash_percentile=0.90,\n            )\n        )\n        detector = detectors[d][\"class\"](**d_kwargs)\n        detector.fit(model)\n        scores_in, _ = detector.score(ds_in)\n        scores_out, _ = detector.score(ds_out)\n\n        # === metrics ===\n        # auroc / fpr95\n        metrics = bench_metrics(\n            (scores_in, scores_out),\n            metrics=[\"auroc\", \"fpr95tpr\"],\n        )\n        for k, v in metrics.items():\n            print(f\"{k:&lt;10} {v:.6f}\")\n\n        # hists / roc\n        plt.figure(figsize=(9, 3))\n        plt.subplot(121)\n        plot_ood_scores(scores_in, scores_out)\n        plt.subplot(122)\n        plot_roc_curve(scores_in, scores_out)\n        plt.tight_layout()\n        plt.show()\n</pre> detectors = {     \"odin\": {         \"class\": ODIN,         \"kwargs\": dict(temperature=1000),     },     \"mls\": {         \"class\": MLS,         \"kwargs\": dict(),     },     \"energy\": {         \"class\": Energy,         \"kwargs\": dict(),     }, }  for d in detectors.keys():     print(f\"=== {d.upper()} ===\")      for use_ash in [False, True]:         print([\"~ Without\", \"~ With\"][int(use_ash)] + \" ASH ~\")         # === ood scores ===         d_kwargs = detectors[d][\"kwargs\"]         d_kwargs.update(             dict(                 use_ash=use_ash,                 ash_percentile=0.90,             )         )         detector = detectors[d][\"class\"](**d_kwargs)         detector.fit(model)         scores_in, _ = detector.score(ds_in)         scores_out, _ = detector.score(ds_out)          # === metrics ===         # auroc / fpr95         metrics = bench_metrics(             (scores_in, scores_out),             metrics=[\"auroc\", \"fpr95tpr\"],         )         for k, v in metrics.items():             print(f\"{k:&lt;10} {v:.6f}\")          # hists / roc         plt.figure(figsize=(9, 3))         plt.subplot(121)         plot_ood_scores(scores_in, scores_out)         plt.subplot(122)         plot_roc_curve(scores_in, scores_out)         plt.tight_layout()         plt.show() <pre>=== ODIN ===\n~ Without ASH ~\nauroc      0.872446\nfpr95tpr   0.489400\n</pre> <pre>~ With ASH ~\nauroc      0.397390\nfpr95tpr   0.951300\n</pre> <pre>=== MLS ===\n~ Without ASH ~\nauroc      0.904973\nfpr95tpr   0.303800\n</pre> <pre>~ With ASH ~\nauroc      0.355637\nfpr95tpr   0.970900\n</pre> <pre>=== ENERGY ===\n~ Without ASH ~\nauroc      0.906344\nfpr95tpr   0.302700\n</pre> <pre>~ With ASH ~\nauroc      0.355594\nfpr95tpr   0.970900\n</pre>"},{"location":"notebooks/torch/demo_ash_torch/#ash-method","title":"ASH method\u00b6","text":"<p>This notebook aims at evaluating the ASH method.</p> <p>ASH method basically consists in re-using existing logit-based OOD methods, but with penultimate layer activations scaled and pruned. Let $a$ be the activation vector, and $P_p(a)$ the $p$-th percentile of $a$'s values. The scaling is computed using the formula $$ s = \\exp(\\frac{\\sum_{i} a_i}{\\sum_{a_i &gt; P_p(a)} a_i}) $$ The activation is pruned for values $a_i \\leq P_p(a)$.</p> <p>Here, we focus on a Resnet trained on CIFAR10, challenged on SVHN.</p> <p>Reference Extremely Simple Activation Shaping for Out-of-Distribution Detection, ICLR 2023 http://arxiv.org/abs/2209.09858</p>"},{"location":"notebooks/torch/demo_ash_torch/#imports","title":"Imports\u00b6","text":""},{"location":"notebooks/torch/demo_ash_torch/#data-loading","title":"Data loading\u00b6","text":"<ul> <li>In-distribution data: CIFAR-10</li> <li>Out-of-distribution data: SVHN</li> </ul> <p>Note: We denote In-Distribution (ID) data with <code>_in</code> and Out-Of-Distribution (OOD) data</p> <p>with <code>_out</code> to avoid confusion with OOD detection which is the name of the task, and is therefore used to denote core classes such as <code>OODDataset</code> and <code>OODBaseDetector</code>.</p>"},{"location":"notebooks/torch/demo_ash_torch/#model-training","title":"Model training\u00b6","text":"<p>Now let's train a simple model on MNIST[0-4] using <code>train_torch_model</code> function.</p>"},{"location":"notebooks/torch/demo_ash_torch/#scale-scores","title":"SCALE scores\u00b6","text":"<p>We now fit some OOD detectors using SCALE + [MLS, MSP, Energy, Entropy, ODIN] with MNIST[0-4] train dataset, and compare OOD scores returned for MNIST[0-4] (ID) and MNIST[5-9] (OOD) test datasets.</p>"},{"location":"notebooks/torch/demo_dknn_torch/","title":"DKNN","text":"In\u00a0[1]: Copied! <pre>%load_ext autoreload\n%autoreload 2\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport os\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n\nfrom IPython.display import clear_output\nfrom sklearn.metrics import accuracy_score\nimport matplotlib.pyplot as plt\nimport torch\nfrom torchvision import transforms\n\nfrom oodeel.methods import DKNN\nfrom oodeel.eval.metrics import bench_metrics\nfrom oodeel.eval.plots import plot_ood_scores, plot_roc_curve, plot_2D_features\nfrom oodeel.datasets import OODDataset\nfrom oodeel.utils.torch_training_tools import train_torch_model\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n</pre> %load_ext autoreload %autoreload 2  import warnings warnings.filterwarnings(\"ignore\") import os os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"  from IPython.display import clear_output from sklearn.metrics import accuracy_score import matplotlib.pyplot as plt import torch from torchvision import transforms  from oodeel.methods import DKNN from oodeel.eval.metrics import bench_metrics from oodeel.eval.plots import plot_ood_scores, plot_roc_curve, plot_2D_features from oodeel.datasets import OODDataset from oodeel.utils.torch_training_tools import train_torch_model  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") <p>Note that models are saved at ~/.oodeel/saved_models and data is supposed to be found at ~/.oodeel/datasets by default. Change the following cell for a custom path.</p> In\u00a0[2]: Copied! <pre>model_path = os.path.expanduser(\"~/\") + \".oodeel/saved_models\"\ndata_path = os.path.expanduser(\"~/\") + \".oodeel/datasets\"\nos.makedirs(model_path, exist_ok=True)\nos.makedirs(data_path, exist_ok=True)\n</pre> model_path = os.path.expanduser(\"~/\") + \".oodeel/saved_models\" data_path = os.path.expanduser(\"~/\") + \".oodeel/datasets\" os.makedirs(model_path, exist_ok=True) os.makedirs(data_path, exist_ok=True) In\u00a0[3]: Copied! <pre># === load ID and OOD data ===\nbatch_size = 128\nin_labels = [0, 1, 2, 3, 4]\n\n# 1- load train/test MNIST dataset\nmnist_train = OODDataset(\n    dataset_id=\"MNIST\",\n    backend=\"torch\",\n    load_kwargs={\"root\": data_path, \"train\": True, \"download\": True},\n)\nmnist_test = OODDataset(\n    dataset_id=\"MNIST\",\n    backend=\"torch\",\n    load_kwargs={\"root\": data_path, \"train\": False, \"download\": True},\n)\n\n# 2- split ID / OOD data depending on label value:\n# in-distribution: MNIST[0-4] / out-of-distribution: MNIST[5-9]\noods_fit, _ = mnist_train.split_by_class(in_labels=in_labels)\noods_in, oods_out = mnist_test.split_by_class(in_labels=in_labels)\n\n\n# 3- prepare data (preprocess, shuffle, batch) =&gt; torch dataloaders\ndef preprocess_fn(*inputs):\n\"\"\"Simple preprocessing function to normalize images in [0, 1].\"\"\"\n    x = inputs[0] / 255.0\n    return tuple([x] + list(inputs[1:]))\n\n\nds_fit = oods_fit.prepare(\n    batch_size=batch_size, preprocess_fn=preprocess_fn, shuffle=True\n)\nds_in = oods_in.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn)\nds_out = oods_out.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn)\n\nclear_output()\n</pre> # === load ID and OOD data === batch_size = 128 in_labels = [0, 1, 2, 3, 4]  # 1- load train/test MNIST dataset mnist_train = OODDataset(     dataset_id=\"MNIST\",     backend=\"torch\",     load_kwargs={\"root\": data_path, \"train\": True, \"download\": True}, ) mnist_test = OODDataset(     dataset_id=\"MNIST\",     backend=\"torch\",     load_kwargs={\"root\": data_path, \"train\": False, \"download\": True}, )  # 2- split ID / OOD data depending on label value: # in-distribution: MNIST[0-4] / out-of-distribution: MNIST[5-9] oods_fit, _ = mnist_train.split_by_class(in_labels=in_labels) oods_in, oods_out = mnist_test.split_by_class(in_labels=in_labels)   # 3- prepare data (preprocess, shuffle, batch) =&gt; torch dataloaders def preprocess_fn(*inputs):     \"\"\"Simple preprocessing function to normalize images in [0, 1].\"\"\"     x = inputs[0] / 255.0     return tuple([x] + list(inputs[1:]))   ds_fit = oods_fit.prepare(     batch_size=batch_size, preprocess_fn=preprocess_fn, shuffle=True ) ds_in = oods_in.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn) ds_out = oods_out.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn)  clear_output() In\u00a0[4]: Copied! <pre># === Train / Load model ===\n# model path\nmodel_path_mnist_04 = os.path.join(model_path, \"mnist_model_0-4\")\n\ntry:\n    # if the model exists, load it\n    model = torch.load(os.path.join(model_path_mnist_04, \"best.pt\")).to(device)\nexcept OSError:\n    # else, train a new model\n    train_config = {\n        \"model\": \"toy_convnet\",\n        \"num_classes\": 10,\n        \"epochs\": 5,\n        \"save_dir\": model_path_mnist_04,\n        \"validation_data\": ds_in,\n    }\n    model = train_torch_model(ds_fit, **train_config).to(device)\n    clear_output()\n\n# evaluate model\nmodel.eval()\nlabels, preds = [], []\nfor x, y in ds_in:\n    x = x.to(device)\n    preds.append(torch.argmax(model(x), dim=-1).detach().cpu())\n    labels.append(y)\nprint(f\"Test accuracy:\\t{accuracy_score(torch.cat(labels), torch.cat(preds)):.6f}\")\n\n# penultimate features 2d visualization\nprint(\"\\n=== Penultimate features viz ===\")\nplt.figure(figsize=(4.5, 3))\nplot_2D_features(\n    model=model,\n    in_dataset=ds_in,\n    out_dataset=ds_out,\n    output_layer_id=-2,\n)\nplt.tight_layout()\nplt.show()\n</pre> # === Train / Load model === # model path model_path_mnist_04 = os.path.join(model_path, \"mnist_model_0-4\")  try:     # if the model exists, load it     model = torch.load(os.path.join(model_path_mnist_04, \"best.pt\")).to(device) except OSError:     # else, train a new model     train_config = {         \"model\": \"toy_convnet\",         \"num_classes\": 10,         \"epochs\": 5,         \"save_dir\": model_path_mnist_04,         \"validation_data\": ds_in,     }     model = train_torch_model(ds_fit, **train_config).to(device)     clear_output()  # evaluate model model.eval() labels, preds = [], [] for x, y in ds_in:     x = x.to(device)     preds.append(torch.argmax(model(x), dim=-1).detach().cpu())     labels.append(y) print(f\"Test accuracy:\\t{accuracy_score(torch.cat(labels), torch.cat(preds)):.6f}\")  # penultimate features 2d visualization print(\"\\n=== Penultimate features viz ===\") plt.figure(figsize=(4.5, 3)) plot_2D_features(     model=model,     in_dataset=ds_in,     out_dataset=ds_out,     output_layer_id=-2, ) plt.tight_layout() plt.show() <pre>Test accuracy:\t0.995914\n\n=== Penultimate features viz ===\n</pre> In\u00a0[5]: Copied! <pre># === dknn scores ===\ndknn = DKNN(nearest=50)\ndknn.fit(model, feature_layers_id=[-2], fit_dataset=ds_fit)\nscores_in, _ = dknn.score(ds_in)\nscores_out, _ = dknn.score(ds_out)\n\n# === metrics ===\n# auroc / fpr95\nmetrics = bench_metrics(\n    (scores_in, scores_out),\n    metrics=[\"auroc\", \"fpr95tpr\"],\n)\nprint(\"=== Metrics ===\")\nfor k, v in metrics.items():\n    print(f\"{k:&lt;10} {v:.6f}\")\n\nprint(\"\\n=== Plots ===\")\n# hists / roc\nplt.figure(figsize=(9, 3))\nplt.subplot(121)\nplot_ood_scores(scores_in, scores_out, log_scale=False)\nplt.subplot(122)\nplot_roc_curve(scores_in, scores_out)\nplt.tight_layout()\nplt.show()\n</pre> # === dknn scores === dknn = DKNN(nearest=50) dknn.fit(model, feature_layers_id=[-2], fit_dataset=ds_fit) scores_in, _ = dknn.score(ds_in) scores_out, _ = dknn.score(ds_out)  # === metrics === # auroc / fpr95 metrics = bench_metrics(     (scores_in, scores_out),     metrics=[\"auroc\", \"fpr95tpr\"], ) print(\"=== Metrics ===\") for k, v in metrics.items():     print(f\"{k:&lt;10} {v:.6f}\")  print(\"\\n=== Plots ===\") # hists / roc plt.figure(figsize=(9, 3)) plt.subplot(121) plot_ood_scores(scores_in, scores_out, log_scale=False) plt.subplot(122) plot_roc_curve(scores_in, scores_out) plt.tight_layout() plt.show() <pre>=== Metrics ===\nauroc      0.975472\nfpr95tpr   0.093987\n\n=== Plots ===\n</pre> In\u00a0[6]: Copied! <pre># === load ID and OOD data ===\nbatch_size = 128\n\n# 1a- load in-distribution dataset: CIFAR-10\noods_fit = OODDataset(\n    dataset_id=\"CIFAR10\",\n    backend=\"torch\",\n    load_kwargs={\"root\": data_path, \"train\": True, \"download\": True},\n)\noods_in = OODDataset(\n    dataset_id=\"CIFAR10\",\n    backend=\"torch\",\n    load_kwargs={\"root\": data_path, \"train\": False, \"download\": True},\n)\n# 1b- load out-of-distribution dataset: SVHN\noods_out = OODDataset(\n    dataset_id=\"SVHN\",\n    backend=\"torch\",\n    load_kwargs={\"root\": data_path, \"split\": \"test\", \"download\": True},\n)\n\n\n# 2- prepare data (preprocess, shuffle, batch) =&gt; torch dataloaders\n\n\ndef preprocess_fn(*inputs):\n\"\"\"Preprocessing function from\n    https://github.com/chenyaofo/pytorch-cifar-models\n    \"\"\"\n    x = inputs[0] / 255.0\n    x = transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))(x)\n    return tuple([x] + list(inputs[1:]))\n\n\nds_fit = oods_fit.prepare(\n    batch_size=batch_size, shuffle=True, preprocess_fn=preprocess_fn\n)\nds_in = oods_in.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn)\nds_out = oods_out.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn)\n\nclear_output()\n</pre> # === load ID and OOD data === batch_size = 128  # 1a- load in-distribution dataset: CIFAR-10 oods_fit = OODDataset(     dataset_id=\"CIFAR10\",     backend=\"torch\",     load_kwargs={\"root\": data_path, \"train\": True, \"download\": True}, ) oods_in = OODDataset(     dataset_id=\"CIFAR10\",     backend=\"torch\",     load_kwargs={\"root\": data_path, \"train\": False, \"download\": True}, ) # 1b- load out-of-distribution dataset: SVHN oods_out = OODDataset(     dataset_id=\"SVHN\",     backend=\"torch\",     load_kwargs={\"root\": data_path, \"split\": \"test\", \"download\": True}, )   # 2- prepare data (preprocess, shuffle, batch) =&gt; torch dataloaders   def preprocess_fn(*inputs):     \"\"\"Preprocessing function from     https://github.com/chenyaofo/pytorch-cifar-models     \"\"\"     x = inputs[0] / 255.0     x = transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))(x)     return tuple([x] + list(inputs[1:]))   ds_fit = oods_fit.prepare(     batch_size=batch_size, shuffle=True, preprocess_fn=preprocess_fn ) ds_in = oods_in.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn) ds_out = oods_out.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn)  clear_output() In\u00a0[7]: Copied! <pre># === load model ===\n# resnet20 pretrained on CIFAR-10\nmodel = torch.hub.load(\n    repo_or_dir=\"chenyaofo/pytorch-cifar-models\",\n    model=\"cifar10_resnet20\",\n    pretrained=True,\n    verbose=False,\n).to(device)\nmodel.eval()\n\n# evaluate model\nlabels, preds = [], []\nfor x, y in ds_in:\n    x = x.to(device)\n    preds.append(torch.argmax(model(x), dim=-1).detach().cpu())\n    labels.append(y)\nprint(f\"Test accuracy:\\t{accuracy_score(torch.cat(labels), torch.cat(preds)):.6f}\")\n\n# penultimate features 2d visualization\nprint(\"\\n=== Penultimate features viz ===\")\nplt.figure(figsize=(4.5, 3))\nplot_2D_features(\n    model=model,\n    in_dataset=ds_in,\n    out_dataset=ds_out,\n    output_layer_id=-2,\n)\nplt.tight_layout()\nplt.show()\n</pre> # === load model === # resnet20 pretrained on CIFAR-10 model = torch.hub.load(     repo_or_dir=\"chenyaofo/pytorch-cifar-models\",     model=\"cifar10_resnet20\",     pretrained=True,     verbose=False, ).to(device) model.eval()  # evaluate model labels, preds = [], [] for x, y in ds_in:     x = x.to(device)     preds.append(torch.argmax(model(x), dim=-1).detach().cpu())     labels.append(y) print(f\"Test accuracy:\\t{accuracy_score(torch.cat(labels), torch.cat(preds)):.6f}\")  # penultimate features 2d visualization print(\"\\n=== Penultimate features viz ===\") plt.figure(figsize=(4.5, 3)) plot_2D_features(     model=model,     in_dataset=ds_in,     out_dataset=ds_out,     output_layer_id=-2, ) plt.tight_layout() plt.show() <pre>Test accuracy:\t0.926000\n\n=== Penultimate features viz ===\n</pre> In\u00a0[8]: Copied! <pre># === dknn scores ===\ndknn = DKNN(nearest=50)\ndknn.fit(model, feature_layers_id=[-2], fit_dataset=ds_fit)\nscores_in, _ = dknn.score(ds_in)\nscores_out, _ = dknn.score(ds_out)\n\n# === metrics ===\n# auroc / fpr95\nmetrics = bench_metrics(\n    (scores_in, scores_out),\n    metrics=[\"auroc\", \"fpr95tpr\"],\n)\nprint(\"=== Metrics ===\")\nfor k, v in metrics.items():\n    print(f\"{k:&lt;10} {v:.6f}\")\n\nprint(\"\\n=== Plots ===\")\n# hists / roc\nplt.figure(figsize=(9, 3))\nplt.subplot(121)\nplot_ood_scores(scores_in, scores_out, log_scale=False)\nplt.subplot(122)\nplot_roc_curve(scores_in, scores_out)\nplt.tight_layout()\nplt.show()\n</pre> # === dknn scores === dknn = DKNN(nearest=50) dknn.fit(model, feature_layers_id=[-2], fit_dataset=ds_fit) scores_in, _ = dknn.score(ds_in) scores_out, _ = dknn.score(ds_out)  # === metrics === # auroc / fpr95 metrics = bench_metrics(     (scores_in, scores_out),     metrics=[\"auroc\", \"fpr95tpr\"], ) print(\"=== Metrics ===\") for k, v in metrics.items():     print(f\"{k:&lt;10} {v:.6f}\")  print(\"\\n=== Plots ===\") # hists / roc plt.figure(figsize=(9, 3)) plt.subplot(121) plot_ood_scores(scores_in, scores_out, log_scale=False) plt.subplot(122) plot_roc_curve(scores_in, scores_out) plt.tight_layout() plt.show() <pre>=== Metrics ===\nauroc      0.919887\nfpr95tpr   0.268600\n\n=== Plots ===\n</pre>"},{"location":"notebooks/torch/demo_dknn_torch/#deep-knn-method","title":"Deep KNN method\u00b6","text":"<p>This notebook aims at evaluating the DKNN method.</p> <p>The method consists in performing K-Nearest-Neighbors in the feature space of a neural network trained on the in-distribution dataset.</p> <p>Here, we focus on a toy convolutional network trained on MNIST[0-4] and a ResNet20 model trained on CIFAR-10, respectively challenged on MNIST[5-9] and SVHN OOD datasets.</p> <p>Reference Out-of-Distribution Detection with Deep Nearest Neighbors, ICML 2022.</p>"},{"location":"notebooks/torch/demo_dknn_torch/#imports","title":"Imports\u00b6","text":""},{"location":"notebooks/torch/demo_dknn_torch/#first-exp-mnist0-4-vs-mnist5-9","title":"First exp: MNIST[0-4] vs MNIST[5-9]\u00b6","text":"<p>For this first experiment, we train a toy convolutional network on the MNIST dataset restricted to digits 0 to 4. After fitting the train subset of this dataset to the DKNN method, we will compare the scores returned for MNIST[0-4] (in-distrubtion) and MNIST[5-9] (out-of-distribution) test subsets.</p>"},{"location":"notebooks/torch/demo_dknn_torch/#data-loading","title":"Data loading\u00b6","text":"<ul> <li>In-distribution data: MNIST[0-4]</li> <li>Out-of-distribution data: MNIST[5-9]</li> </ul> <p>Note: We denote In-Distribution (ID) data with <code>_in</code> and Out-Of-Distribution (OOD) data with <code>_out</code> to avoid confusion with OOD detection which is the name of the task, and is therefore used to denote core classes such as <code>OODDataset</code> and <code>OODBaseDetector</code>.</p>"},{"location":"notebooks/torch/demo_dknn_torch/#model-training","title":"Model training\u00b6","text":"<p>Now let's train a simple model on MNIST[0-4] using <code>train_torch_model</code> function.</p>"},{"location":"notebooks/torch/demo_dknn_torch/#dknn-score","title":"DKNN score\u00b6","text":"<p>We now fit a DKNN detector with MNIST[0-4] train dataset, and compare OOD scores returned for MNIST[0-4] (ID) and MNIST[5-9] (OOD) test datasets.</p>"},{"location":"notebooks/torch/demo_dknn_torch/#second-exp-cifar-10-vs-svhn","title":"Second exp: CIFAR-10 vs SVHN\u00b6","text":"<p>For this second experiment, we oppose CIFAR-10 (in-distribution dataset) to SVHN (out-of-distribution dataset).</p>"},{"location":"notebooks/torch/demo_dknn_torch/#data-loading","title":"Data loading\u00b6","text":"<ul> <li>In-distribution data: CIFAR-10</li> <li>Out-of-distribution data: SVHN</li> </ul>"},{"location":"notebooks/torch/demo_dknn_torch/#model-loading","title":"Model loading\u00b6","text":"<p>The model is a ResNet20 pretrained on CIFAR-10 and getting an accuracy score of 92.60%, loaded from pytorch-cifar-models repository.</p>"},{"location":"notebooks/torch/demo_dknn_torch/#dknn-score","title":"DKNN score\u00b6","text":"<p>We now fit a DKNN detector with CIFAR-10 train dataset, and compare OOD scores returned for CIFAR-10 (ID) and SVHN (OOD) test datasets.</p>"},{"location":"notebooks/torch/demo_energy_torch/","title":"Energy","text":"In\u00a0[1]: Copied! <pre>%load_ext autoreload\n%autoreload 2\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport os\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n\nfrom IPython.display import clear_output\nfrom sklearn.metrics import accuracy_score\nimport matplotlib.pyplot as plt\nimport torch\nfrom torchvision import transforms\n\nfrom oodeel.methods import Energy\nfrom oodeel.eval.metrics import bench_metrics\nfrom oodeel.eval.plots import plot_ood_scores, plot_roc_curve, plot_2D_features\nfrom oodeel.datasets import OODDataset\nfrom oodeel.utils.torch_training_tools import train_torch_model\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n</pre> %load_ext autoreload %autoreload 2  import warnings warnings.filterwarnings(\"ignore\") import os os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"  from IPython.display import clear_output from sklearn.metrics import accuracy_score import matplotlib.pyplot as plt import torch from torchvision import transforms  from oodeel.methods import Energy from oodeel.eval.metrics import bench_metrics from oodeel.eval.plots import plot_ood_scores, plot_roc_curve, plot_2D_features from oodeel.datasets import OODDataset from oodeel.utils.torch_training_tools import train_torch_model  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") <p>Note that models are saved at ~/.oodeel/saved_models and data is supposed to be found at ~/.oodeel/datasets by default. Change the following cell for a custom path.</p> In\u00a0[2]: Copied! <pre>model_path = os.path.expanduser(\"~/\") + \".oodeel/saved_models\"\ndata_path = os.path.expanduser(\"~/\") + \".oodeel/datasets\"\nos.makedirs(model_path, exist_ok=True)\nos.makedirs(data_path, exist_ok=True)\n</pre> model_path = os.path.expanduser(\"~/\") + \".oodeel/saved_models\" data_path = os.path.expanduser(\"~/\") + \".oodeel/datasets\" os.makedirs(model_path, exist_ok=True) os.makedirs(data_path, exist_ok=True) In\u00a0[3]: Copied! <pre># === load ID and OOD data ===\nbatch_size = 128\nin_labels = [0, 1, 2, 3, 4]\n\n# 1- load train/test MNIST dataset\nmnist_train = OODDataset(\n    dataset_id='MNIST', backend=\"torch\",\n    load_kwargs={\"root\": data_path, \"train\": True, \"download\": True}\n)\nmnist_test = OODDataset(\n    dataset_id='MNIST', backend=\"torch\",\n    load_kwargs={\"root\": data_path, \"train\": False, \"download\": True}\n)\n\n# 2- split ID / OOD data depending on label value:\n# in-distribution: MNIST[0-4] / out-of-distribution: MNIST[5-9]\noods_fit, _ = mnist_train.split_by_class(in_labels=in_labels)\noods_in, oods_out = mnist_test.split_by_class(in_labels=in_labels)\n\n# 3- prepare data (preprocess, shuffle, batch) =&gt; torch dataloaders\ndef preprocess_fn(*inputs):\n\"\"\"Simple preprocessing function to normalize images in [0, 1].\n    \"\"\"\n    x = inputs[0] / 255.0\n    return tuple([x] + list(inputs[1:]))\n\nds_fit = oods_fit.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn, shuffle=True)\nds_in = oods_in.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn)\nds_out = oods_out.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn)\n\nclear_output()\n</pre> # === load ID and OOD data === batch_size = 128 in_labels = [0, 1, 2, 3, 4]  # 1- load train/test MNIST dataset mnist_train = OODDataset(     dataset_id='MNIST', backend=\"torch\",     load_kwargs={\"root\": data_path, \"train\": True, \"download\": True} ) mnist_test = OODDataset(     dataset_id='MNIST', backend=\"torch\",     load_kwargs={\"root\": data_path, \"train\": False, \"download\": True} )  # 2- split ID / OOD data depending on label value: # in-distribution: MNIST[0-4] / out-of-distribution: MNIST[5-9] oods_fit, _ = mnist_train.split_by_class(in_labels=in_labels) oods_in, oods_out = mnist_test.split_by_class(in_labels=in_labels)  # 3- prepare data (preprocess, shuffle, batch) =&gt; torch dataloaders def preprocess_fn(*inputs):     \"\"\"Simple preprocessing function to normalize images in [0, 1].     \"\"\"     x = inputs[0] / 255.0     return tuple([x] + list(inputs[1:]))  ds_fit = oods_fit.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn, shuffle=True) ds_in = oods_in.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn) ds_out = oods_out.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn)  clear_output() In\u00a0[4]: Copied! <pre># === Train / Load model ===\n# model path\nmodel_path_mnist_04 = os.path.join(model_path, \"mnist_model_0-4\")\n\ntry:\n    # if the model exists, load it\n    model = torch.load(os.path.join(model_path_mnist_04, \"best.pt\")).to(device)\nexcept OSError:\n    # else, train a new model\n    train_config = {\n        \"model\": \"toy_convnet\",\n        \"num_classes\": 10,\n        \"epochs\": 5,\n        \"save_dir\": model_path_mnist_04,\n        \"validation_data\": ds_in\n    }\n    model = train_torch_model(ds_fit, **train_config).to(device)\n    clear_output()\n\n# evaluate model\nmodel.eval()\nlabels, preds = [], []\nfor (x, y) in ds_in:\n    x = x.to(device)\n    preds.append(torch.argmax(model(x), dim=-1).detach().cpu())\n    labels.append(y)\nprint(f\"Test accuracy:\\t{accuracy_score(torch.cat(labels), torch.cat(preds)):.6f}\")\n\n# penultimate features 2d visualization\nprint(\"\\n=== Penultimate features viz ===\")\nplt.figure(figsize=(4.5, 3))\nplot_2D_features(\n    model=model,\n    in_dataset=ds_in,\n    out_dataset=ds_out,\n    output_layer_id=-2,\n)\nplt.tight_layout()\nplt.show()\n</pre> # === Train / Load model === # model path model_path_mnist_04 = os.path.join(model_path, \"mnist_model_0-4\")  try:     # if the model exists, load it     model = torch.load(os.path.join(model_path_mnist_04, \"best.pt\")).to(device) except OSError:     # else, train a new model     train_config = {         \"model\": \"toy_convnet\",         \"num_classes\": 10,         \"epochs\": 5,         \"save_dir\": model_path_mnist_04,         \"validation_data\": ds_in     }     model = train_torch_model(ds_fit, **train_config).to(device)     clear_output()  # evaluate model model.eval() labels, preds = [], [] for (x, y) in ds_in:     x = x.to(device)     preds.append(torch.argmax(model(x), dim=-1).detach().cpu())     labels.append(y) print(f\"Test accuracy:\\t{accuracy_score(torch.cat(labels), torch.cat(preds)):.6f}\")  # penultimate features 2d visualization print(\"\\n=== Penultimate features viz ===\") plt.figure(figsize=(4.5, 3)) plot_2D_features(     model=model,     in_dataset=ds_in,     out_dataset=ds_out,     output_layer_id=-2, ) plt.tight_layout() plt.show() <pre>Test accuracy:\t0.996497\n\n=== Penultimate features viz ===\n</pre> In\u00a0[5]: Copied! <pre># === energy scores ===\nenergy = Energy()\nenergy.fit(model)\nscores_in, _ = energy.score(ds_in)\nscores_out, _ = energy.score(ds_out)\n\n# === metrics ===\n# auroc / fpr95\nmetrics = bench_metrics(\n    (scores_in, scores_out),\n    metrics=[\"auroc\", \"fpr95tpr\"],\n)\nprint(\"=== Metrics ===\")\nfor k, v in metrics.items():\n    print(f\"{k:&lt;10} {v:.6f}\")\n\nprint(\"\\n=== Plots ===\")\n# hists / roc\nplt.figure(figsize=(9, 3))\nplt.subplot(121)\nplot_ood_scores(scores_in, scores_out, log_scale=False)\nplt.subplot(122)\nplot_roc_curve(scores_in, scores_out)\nplt.tight_layout()\nplt.show()\n</pre> # === energy scores === energy = Energy() energy.fit(model) scores_in, _ = energy.score(ds_in) scores_out, _ = energy.score(ds_out)  # === metrics === # auroc / fpr95 metrics = bench_metrics(     (scores_in, scores_out),     metrics=[\"auroc\", \"fpr95tpr\"], ) print(\"=== Metrics ===\") for k, v in metrics.items():     print(f\"{k:&lt;10} {v:.6f}\")  print(\"\\n=== Plots ===\") # hists / roc plt.figure(figsize=(9, 3)) plt.subplot(121) plot_ood_scores(scores_in, scores_out, log_scale=False) plt.subplot(122) plot_roc_curve(scores_in, scores_out) plt.tight_layout() plt.show() <pre>=== Metrics ===\nauroc      0.911351\nfpr95tpr   0.428488\n\n=== Plots ===\n</pre> In\u00a0[6]: Copied! <pre># === load ID and OOD data ===\nbatch_size = 128\n\n# 1a- load in-distribution dataset: CIFAR-10\noods_fit = OODDataset(\n    dataset_id='CIFAR10', backend=\"torch\",\n    load_kwargs={\"root\": data_path, \"train\": True, \"download\": True}\n)\noods_in = OODDataset(\n    dataset_id='CIFAR10', backend=\"torch\",\n    load_kwargs={\"root\": data_path, \"train\": False, \"download\": True}\n)\n# 1b- load out-of-distribution dataset: SVHN\noods_out = OODDataset(\n    dataset_id='SVHN', backend=\"torch\",\n    load_kwargs={\"root\": data_path, \"split\": \"test\", \"download\": True})\n\n\n# 2- prepare data (preprocess, shuffle, batch) =&gt; torch dataloaders\n\ndef preprocess_fn(*inputs):\n\"\"\"Preprocessing function from\n    https://github.com/chenyaofo/pytorch-cifar-models\n    \"\"\"\n    x = inputs[0] / 255.0\n    x = transforms.Normalize(\n        (0.4914, 0.4822, 0.4465),\n        (0.2023, 0.1994, 0.2010)\n    )(x)\n    return tuple([x] + list(inputs[1:]))\n\nds_fit = oods_fit.prepare(batch_size=batch_size, shuffle=True, preprocess_fn=preprocess_fn)\nds_in = oods_in.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn)\nds_out = oods_out.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn)\n\nclear_output()\n</pre> # === load ID and OOD data === batch_size = 128  # 1a- load in-distribution dataset: CIFAR-10 oods_fit = OODDataset(     dataset_id='CIFAR10', backend=\"torch\",     load_kwargs={\"root\": data_path, \"train\": True, \"download\": True} ) oods_in = OODDataset(     dataset_id='CIFAR10', backend=\"torch\",     load_kwargs={\"root\": data_path, \"train\": False, \"download\": True} ) # 1b- load out-of-distribution dataset: SVHN oods_out = OODDataset(     dataset_id='SVHN', backend=\"torch\",     load_kwargs={\"root\": data_path, \"split\": \"test\", \"download\": True})   # 2- prepare data (preprocess, shuffle, batch) =&gt; torch dataloaders  def preprocess_fn(*inputs):     \"\"\"Preprocessing function from     https://github.com/chenyaofo/pytorch-cifar-models     \"\"\"     x = inputs[0] / 255.0     x = transforms.Normalize(         (0.4914, 0.4822, 0.4465),         (0.2023, 0.1994, 0.2010)     )(x)     return tuple([x] + list(inputs[1:]))  ds_fit = oods_fit.prepare(batch_size=batch_size, shuffle=True, preprocess_fn=preprocess_fn) ds_in = oods_in.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn) ds_out = oods_out.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn)  clear_output() In\u00a0[7]: Copied! <pre># === load model ===\n# resnet20 pretrained on CIFAR-10\nmodel = torch.hub.load(\n    repo_or_dir=\"chenyaofo/pytorch-cifar-models\", model=\"cifar10_resnet20\",\n    pretrained=True, verbose=False).to(device)\nmodel.eval()\n\n# evaluate model\nlabels, preds = [], []\nfor (x, y) in ds_in:\n    x = x.to(device)\n    preds.append(torch.argmax(model(x), dim=-1).detach().cpu())\n    labels.append(y)\nprint(f\"Test accuracy:\\t{accuracy_score(torch.cat(labels), torch.cat(preds)):.6f}\")\n\n# penultimate features 2d visualization\nprint(\"\\n=== Penultimate features viz ===\")\nplt.figure(figsize=(4.5, 3))\nplot_2D_features(\n    model=model,\n    in_dataset=ds_in,\n    out_dataset=ds_out,\n    output_layer_id=-2,\n)\nplt.tight_layout()\nplt.show()\n</pre> # === load model === # resnet20 pretrained on CIFAR-10 model = torch.hub.load(     repo_or_dir=\"chenyaofo/pytorch-cifar-models\", model=\"cifar10_resnet20\",     pretrained=True, verbose=False).to(device) model.eval()  # evaluate model labels, preds = [], [] for (x, y) in ds_in:     x = x.to(device)     preds.append(torch.argmax(model(x), dim=-1).detach().cpu())     labels.append(y) print(f\"Test accuracy:\\t{accuracy_score(torch.cat(labels), torch.cat(preds)):.6f}\")  # penultimate features 2d visualization print(\"\\n=== Penultimate features viz ===\") plt.figure(figsize=(4.5, 3)) plot_2D_features(     model=model,     in_dataset=ds_in,     out_dataset=ds_out,     output_layer_id=-2, ) plt.tight_layout() plt.show() In\u00a0[\u00a0]: Copied! <pre># === energy scores ===\nenergy = Energy()\nenergy.fit(model)\nscores_in, _ = energy.score(ds_in)\nscores_out, _ = energy.score(ds_out)\n\n# === metrics ===\n# auroc / fpr95\nmetrics = bench_metrics(\n    (scores_in, scores_out),\n    metrics=[\"auroc\", \"fpr95tpr\"],\n)\nprint(\"=== Metrics ===\")\nfor k, v in metrics.items():\n    print(f\"{k:&lt;10} {v:.6f}\")\n\nprint(\"\\n=== Plots ===\")\n# hists / roc\nplt.figure(figsize=(9, 3))\nplt.subplot(121)\nplot_ood_scores(scores_in, scores_out, log_scale=False)\nplt.subplot(122)\nplot_roc_curve(scores_in, scores_out)\nplt.tight_layout()\nplt.show()\n</pre> # === energy scores === energy = Energy() energy.fit(model) scores_in, _ = energy.score(ds_in) scores_out, _ = energy.score(ds_out)  # === metrics === # auroc / fpr95 metrics = bench_metrics(     (scores_in, scores_out),     metrics=[\"auroc\", \"fpr95tpr\"], ) print(\"=== Metrics ===\") for k, v in metrics.items():     print(f\"{k:&lt;10} {v:.6f}\")  print(\"\\n=== Plots ===\") # hists / roc plt.figure(figsize=(9, 3)) plt.subplot(121) plot_ood_scores(scores_in, scores_out, log_scale=False) plt.subplot(122) plot_roc_curve(scores_in, scores_out) plt.tight_layout() plt.show() <pre>=== Metrics ===\nauroc      0.906313\nfpr95tpr   0.302700\n\n=== Plots ===\n</pre>"},{"location":"notebooks/torch/demo_energy_torch/#energy-method","title":"Energy method\u00b6","text":"<p>This notebook aims at evaluating the Energy method.</p> <p>The method consists in using the energy of the input data computed using the energy  $-\\log \\sum_{c=0}^C \\exp(l_c)$ computed using the logits $l_c$ such that $\\text{model}(x)=(l_{c})_{c=1}^{C}$.</p> <p>Here, we focus on a toy convolutional network trained on MNIST[0-4] and a ResNet20 model trained on CIFAR-10, respectively challenged on MNIST[5-9] and SVHN OOD datasets.</p> <p>Reference Energy-based Out-of-distribution Detection, Neurips 2020.</p>"},{"location":"notebooks/torch/demo_energy_torch/#imports","title":"Imports\u00b6","text":""},{"location":"notebooks/torch/demo_energy_torch/#first-exp-mnist0-4-vs-mnist5-9","title":"First exp: MNIST[0-4] vs MNIST[5-9]\u00b6","text":"<p>For this first experiment, we train a toy convolutional network on the MNIST dataset restricted to digits 0 to 4. After fitting the train subset of this dataset to the Energy method, we will compare the scores returned for MNIST[0-4] (in-distrubtion) and MNIST[5-9] (out-of-distribution) test subsets.</p>"},{"location":"notebooks/torch/demo_energy_torch/#data-loading","title":"Data loading\u00b6","text":"<ul> <li>In-distribution data: MNIST[0-4]</li> <li>Out-of-distribution data: MNIST[5-9]</li> </ul> <p>Note: We denote In-Distribution (ID) data with <code>_in</code> and Out-Of-Distribution (OOD) data</p> <p>with <code>_out</code> to avoid confusion with OOD detection which is the name of the task, and is therefore used to denote core classes such as <code>OODDataset</code> and <code>OODBaseDetector</code>.</p>"},{"location":"notebooks/torch/demo_energy_torch/#model-training","title":"Model training\u00b6","text":"<p>Now let's train a simple model on MNIST[0-4] using <code>train_torch_model</code> function.</p>"},{"location":"notebooks/torch/demo_energy_torch/#energy-score","title":"Energy score\u00b6","text":"<p>We now fit a Energy detector with MNIST[0-4] train dataset, and compare OOD scores returned for MNIST[0-4] (ID) and MNIST[5-9] (OOD) test datasets.</p>"},{"location":"notebooks/torch/demo_energy_torch/#second-exp-cifar-10-vs-svhn","title":"Second exp: CIFAR-10 vs SVHN\u00b6","text":"<p>For this second experiment, we oppose CIFAR-10 (in-distribution dataset) to SVHN (out-of-distribution dataset).</p>"},{"location":"notebooks/torch/demo_energy_torch/#data-loading","title":"Data loading\u00b6","text":"<ul> <li>In-distribution data: CIFAR-10</li> <li>Out-of-distribution data: SVHN</li> </ul>"},{"location":"notebooks/torch/demo_energy_torch/#model-loading","title":"Model loading\u00b6","text":"<p>The model is a ResNet20 pretrained on CIFAR-10 and getting an accuracy score of 92.60%, loaded from pytorch-cifar-models repository.</p>"},{"location":"notebooks/torch/demo_energy_torch/#energy-score","title":"Energy score\u00b6","text":"<p>We now fit a Energy detector with CIFAR-10 train dataset, and compare OOD scores returned for CIFAR-10 (ID) and SVHN (OOD) test datasets.</p>"},{"location":"notebooks/torch/demo_entropy_torch/","title":"Entropy","text":"In\u00a0[1]: Copied! <pre>%load_ext autoreload\n%autoreload 2\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport os\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n\nfrom IPython.display import clear_output\nfrom sklearn.metrics import accuracy_score\nimport matplotlib.pyplot as plt\nimport torch\nfrom torchvision import transforms\n\nfrom oodeel.methods import Entropy\nfrom oodeel.eval.metrics import bench_metrics\nfrom oodeel.eval.plots import plot_ood_scores, plot_roc_curve, plot_2D_features\nfrom oodeel.datasets import OODDataset\nfrom oodeel.utils.torch_training_tools import train_torch_model\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n</pre> %load_ext autoreload %autoreload 2  import warnings warnings.filterwarnings(\"ignore\") import os os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"  from IPython.display import clear_output from sklearn.metrics import accuracy_score import matplotlib.pyplot as plt import torch from torchvision import transforms  from oodeel.methods import Entropy from oodeel.eval.metrics import bench_metrics from oodeel.eval.plots import plot_ood_scores, plot_roc_curve, plot_2D_features from oodeel.datasets import OODDataset from oodeel.utils.torch_training_tools import train_torch_model  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") <p>Note that models are saved at ~/.oodeel/saved_models and data is supposed to be found at ~/.oodeel/datasets by default. Change the following cell for a custom path.</p> In\u00a0[2]: Copied! <pre>model_path = os.path.expanduser(\"~/\") + \".oodeel/saved_models\"\ndata_path = os.path.expanduser(\"~/\") + \".oodeel/datasets\"\nos.makedirs(model_path, exist_ok=True)\nos.makedirs(data_path, exist_ok=True)\n</pre> model_path = os.path.expanduser(\"~/\") + \".oodeel/saved_models\" data_path = os.path.expanduser(\"~/\") + \".oodeel/datasets\" os.makedirs(model_path, exist_ok=True) os.makedirs(data_path, exist_ok=True) In\u00a0[3]: Copied! <pre># === load ID and OOD data ===\nbatch_size = 128\nin_labels = [0, 1, 2, 3, 4]\n\n# 1- load train/test MNIST dataset\nmnist_train = OODDataset(\n    dataset_id='MNIST', backend=\"torch\",\n    load_kwargs={\"root\": data_path, \"train\": True, \"download\": True}\n)\nmnist_test = OODDataset(\n    dataset_id='MNIST', backend=\"torch\",\n    load_kwargs={\"root\": data_path, \"train\": False, \"download\": True}\n)\n\n# 2- split ID / OOD data depending on label value:\n# in-distribution: MNIST[0-4] / out-of-distribution: MNIST[5-9]\noods_fit, _ = mnist_train.split_by_class(in_labels=in_labels)\noods_in, oods_out = mnist_test.split_by_class(in_labels=in_labels)\n\n# 3- prepare data (preprocess, shuffle, batch) =&gt; torch dataloaders\ndef preprocess_fn(*inputs):\n\"\"\"Simple preprocessing function to normalize images in [0, 1].\n    \"\"\"\n    x = inputs[0] / 255.0\n    return tuple([x] + list(inputs[1:]))\n\nds_fit = oods_fit.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn, shuffle=True)\nds_in = oods_in.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn)\nds_out = oods_out.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn)\n\nclear_output()\n</pre> # === load ID and OOD data === batch_size = 128 in_labels = [0, 1, 2, 3, 4]  # 1- load train/test MNIST dataset mnist_train = OODDataset(     dataset_id='MNIST', backend=\"torch\",     load_kwargs={\"root\": data_path, \"train\": True, \"download\": True} ) mnist_test = OODDataset(     dataset_id='MNIST', backend=\"torch\",     load_kwargs={\"root\": data_path, \"train\": False, \"download\": True} )  # 2- split ID / OOD data depending on label value: # in-distribution: MNIST[0-4] / out-of-distribution: MNIST[5-9] oods_fit, _ = mnist_train.split_by_class(in_labels=in_labels) oods_in, oods_out = mnist_test.split_by_class(in_labels=in_labels)  # 3- prepare data (preprocess, shuffle, batch) =&gt; torch dataloaders def preprocess_fn(*inputs):     \"\"\"Simple preprocessing function to normalize images in [0, 1].     \"\"\"     x = inputs[0] / 255.0     return tuple([x] + list(inputs[1:]))  ds_fit = oods_fit.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn, shuffle=True) ds_in = oods_in.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn) ds_out = oods_out.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn)  clear_output() In\u00a0[4]: Copied! <pre># === Train / Load model ===\n# model path\nmodel_path_mnist_04 = os.path.join(model_path, \"mnist_model_0-4\")\n\ntry:\n    # if the model exists, load it\n    model = torch.load(os.path.join(model_path_mnist_04, \"best.pt\")).to(device)\nexcept OSError:\n    # else, train a new model\n    train_config = {\n        \"model\": \"toy_convnet\",\n        \"num_classes\": 10,\n        \"epochs\": 5,\n        \"save_dir\": model_path_mnist_04,\n        \"validation_data\": ds_in\n    }\n    model = train_torch_model(ds_fit, **train_config).to(device)\n    clear_output()\n\n# evaluate model\nmodel.eval()\nlabels, preds = [], []\nfor (x, y) in ds_in:\n    x = x.to(device)\n    preds.append(torch.argmax(model(x), dim=-1).detach().cpu())\n    labels.append(y)\nprint(f\"Test accuracy:\\t{accuracy_score(torch.cat(labels), torch.cat(preds)):.6f}\")\n\n# penultimate features 2d visualization\nprint(\"\\n=== Penultimate features viz ===\")\nplt.figure(figsize=(4.5, 3))\nplot_2D_features(\n    model=model,\n    in_dataset=ds_in,\n    out_dataset=ds_out,\n    output_layer_id=-2,\n)\nplt.tight_layout()\nplt.show()\n</pre> # === Train / Load model === # model path model_path_mnist_04 = os.path.join(model_path, \"mnist_model_0-4\")  try:     # if the model exists, load it     model = torch.load(os.path.join(model_path_mnist_04, \"best.pt\")).to(device) except OSError:     # else, train a new model     train_config = {         \"model\": \"toy_convnet\",         \"num_classes\": 10,         \"epochs\": 5,         \"save_dir\": model_path_mnist_04,         \"validation_data\": ds_in     }     model = train_torch_model(ds_fit, **train_config).to(device)     clear_output()  # evaluate model model.eval() labels, preds = [], [] for (x, y) in ds_in:     x = x.to(device)     preds.append(torch.argmax(model(x), dim=-1).detach().cpu())     labels.append(y) print(f\"Test accuracy:\\t{accuracy_score(torch.cat(labels), torch.cat(preds)):.6f}\")  # penultimate features 2d visualization print(\"\\n=== Penultimate features viz ===\") plt.figure(figsize=(4.5, 3)) plot_2D_features(     model=model,     in_dataset=ds_in,     out_dataset=ds_out,     output_layer_id=-2, ) plt.tight_layout() plt.show() <pre>Test accuracy:\t0.995914\n\n=== Penultimate features viz ===\n</pre> In\u00a0[5]: Copied! <pre># === Entropy scores ===\nentropy = Entropy()\nentropy.fit(model)\nscores_in, _ = entropy.score(ds_in)\nscores_out, _ = entropy.score(ds_out)\n\n# === metrics ===\n# auroc / fpr95\nmetrics = bench_metrics(\n    (scores_in, scores_out),\n    metrics=[\"auroc\", \"fpr95tpr\"],\n)\nprint(\"=== Metrics ===\")\nfor k, v in metrics.items():\n    print(f\"{k:&lt;10} {v:.6f}\")\n\nprint(\"\\n=== Plots ===\")\n# hists / roc\nplt.figure(figsize=(9, 3))\nplt.subplot(121)\nplot_ood_scores(scores_in, scores_out, log_scale=True)\nplt.subplot(122)\nplot_roc_curve(scores_in, scores_out)\nplt.tight_layout()\nplt.show()\n</pre> # === Entropy scores === entropy = Entropy() entropy.fit(model) scores_in, _ = entropy.score(ds_in) scores_out, _ = entropy.score(ds_out)  # === metrics === # auroc / fpr95 metrics = bench_metrics(     (scores_in, scores_out),     metrics=[\"auroc\", \"fpr95tpr\"], ) print(\"=== Metrics ===\") for k, v in metrics.items():     print(f\"{k:&lt;10} {v:.6f}\")  print(\"\\n=== Plots ===\") # hists / roc plt.figure(figsize=(9, 3)) plt.subplot(121) plot_ood_scores(scores_in, scores_out, log_scale=True) plt.subplot(122) plot_roc_curve(scores_in, scores_out) plt.tight_layout() plt.show() <pre>=== Metrics ===\nauroc      0.907685\nfpr95tpr   0.616852\n\n=== Plots ===\n</pre> In\u00a0[6]: Copied! <pre># === load ID and OOD data ===\nbatch_size = 128\n\n# 1a- load in-distribution dataset: CIFAR-10\noods_fit = OODDataset(\n    dataset_id='CIFAR10', backend=\"torch\",\n    load_kwargs={\"root\": data_path, \"train\": True, \"download\": True}\n)\noods_in = OODDataset(\n    dataset_id='CIFAR10', backend=\"torch\",\n    load_kwargs={\"root\": data_path, \"train\": False, \"download\": True}\n)\n# 1b- load out-of-distribution dataset: SVHN\noods_out = OODDataset(\n    dataset_id='SVHN', backend=\"torch\",\n    load_kwargs={\"root\": data_path, \"split\": \"test\", \"download\": True})\n\n\n# 2- prepare data (preprocess, shuffle, batch) =&gt; torch dataloaders\n\ndef preprocess_fn(*inputs):\n\"\"\"Preprocessing function from\n    https://github.com/chenyaofo/pytorch-cifar-models\n    \"\"\"\n    x = inputs[0] / 255.0\n    x = transforms.Normalize(\n        (0.4914, 0.4822, 0.4465),\n        (0.2023, 0.1994, 0.2010)\n    )(x)\n    return tuple([x] + list(inputs[1:]))\n\nds_fit = oods_fit.prepare(batch_size=batch_size, shuffle=True, preprocess_fn=preprocess_fn)\nds_in = oods_in.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn)\nds_out = oods_out.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn)\n\nclear_output()\n</pre> # === load ID and OOD data === batch_size = 128  # 1a- load in-distribution dataset: CIFAR-10 oods_fit = OODDataset(     dataset_id='CIFAR10', backend=\"torch\",     load_kwargs={\"root\": data_path, \"train\": True, \"download\": True} ) oods_in = OODDataset(     dataset_id='CIFAR10', backend=\"torch\",     load_kwargs={\"root\": data_path, \"train\": False, \"download\": True} ) # 1b- load out-of-distribution dataset: SVHN oods_out = OODDataset(     dataset_id='SVHN', backend=\"torch\",     load_kwargs={\"root\": data_path, \"split\": \"test\", \"download\": True})   # 2- prepare data (preprocess, shuffle, batch) =&gt; torch dataloaders  def preprocess_fn(*inputs):     \"\"\"Preprocessing function from     https://github.com/chenyaofo/pytorch-cifar-models     \"\"\"     x = inputs[0] / 255.0     x = transforms.Normalize(         (0.4914, 0.4822, 0.4465),         (0.2023, 0.1994, 0.2010)     )(x)     return tuple([x] + list(inputs[1:]))  ds_fit = oods_fit.prepare(batch_size=batch_size, shuffle=True, preprocess_fn=preprocess_fn) ds_in = oods_in.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn) ds_out = oods_out.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn)  clear_output() In\u00a0[7]: Copied! <pre># === load model ===\n# resnet20 pretrained on CIFAR-10\nmodel = torch.hub.load(\n    repo_or_dir=\"chenyaofo/pytorch-cifar-models\", model=\"cifar10_resnet20\",\n    pretrained=True, verbose=False).to(device)\nmodel.eval()\n\n# evaluate model\nlabels, preds = [], []\nfor (x, y) in ds_in:\n    x = x.to(device)\n    preds.append(torch.argmax(model(x), dim=-1).detach().cpu())\n    labels.append(y)\nprint(f\"Test accuracy:\\t{accuracy_score(torch.cat(labels), torch.cat(preds)):.6f}\")\n\n# penultimate features 2d visualization\nprint(\"\\n=== Penultimate features viz ===\")\nplt.figure(figsize=(4.5, 3))\nplot_2D_features(\n    model=model,\n    in_dataset=ds_in,\n    out_dataset=ds_out,\n    output_layer_id=-2,\n)\nplt.tight_layout()\nplt.show()\n</pre> # === load model === # resnet20 pretrained on CIFAR-10 model = torch.hub.load(     repo_or_dir=\"chenyaofo/pytorch-cifar-models\", model=\"cifar10_resnet20\",     pretrained=True, verbose=False).to(device) model.eval()  # evaluate model labels, preds = [], [] for (x, y) in ds_in:     x = x.to(device)     preds.append(torch.argmax(model(x), dim=-1).detach().cpu())     labels.append(y) print(f\"Test accuracy:\\t{accuracy_score(torch.cat(labels), torch.cat(preds)):.6f}\")  # penultimate features 2d visualization print(\"\\n=== Penultimate features viz ===\") plt.figure(figsize=(4.5, 3)) plot_2D_features(     model=model,     in_dataset=ds_in,     out_dataset=ds_out,     output_layer_id=-2, ) plt.tight_layout() plt.show() <pre>Test accuracy:\t0.926000\n\n=== Penultimate features viz ===\n</pre> In\u00a0[8]: Copied! <pre># === Entropy scores ===\nentropy = Entropy()\nentropy.fit(model)\nscores_in, _ = entropy.score(ds_in)\nscores_out, _ = entropy.score(ds_out)\n\n# === metrics ===\n# auroc / fpr95\nmetrics = bench_metrics(\n    (scores_in, scores_out),\n    metrics=[\"auroc\", \"fpr95tpr\"],\n)\nprint(\"=== Metrics ===\")\nfor k, v in metrics.items():\n    print(f\"{k:&lt;10} {v:.6f}\")\n\nprint(\"\\n=== Plots ===\")\n# hists / roc\nplt.figure(figsize=(9, 3))\nplt.subplot(121)\nplot_ood_scores(scores_in, scores_out, log_scale=True)\nplt.subplot(122)\nplot_roc_curve(scores_in, scores_out)\nplt.tight_layout()\nplt.show()\n</pre> # === Entropy scores === entropy = Entropy() entropy.fit(model) scores_in, _ = entropy.score(ds_in) scores_out, _ = entropy.score(ds_out)  # === metrics === # auroc / fpr95 metrics = bench_metrics(     (scores_in, scores_out),     metrics=[\"auroc\", \"fpr95tpr\"], ) print(\"=== Metrics ===\") for k, v in metrics.items():     print(f\"{k:&lt;10} {v:.6f}\")  print(\"\\n=== Plots ===\") # hists / roc plt.figure(figsize=(9, 3)) plt.subplot(121) plot_ood_scores(scores_in, scores_out, log_scale=True) plt.subplot(122) plot_roc_curve(scores_in, scores_out) plt.tight_layout() plt.show() <pre>=== Metrics ===\nauroc      0.880753\nfpr95tpr   0.340900\n\n=== Plots ===\n</pre>"},{"location":"notebooks/torch/demo_entropy_torch/#entropy-method","title":"Entropy method\u00b6","text":"<p>This notebook aims at evaluating the Entropy method.</p> <p>The method consists in using the Entropy of the input data computed using the Entropy  $-\\log \\sum_{c=0}^C \\exp(l_c)$ computed using the logits $l_c$ such that $\\text{model}(x)=(l_{c})_{c=1}^{C}$.</p> <p>Here, we focus on a toy convolutional network trained on MNIST[0-4] and a ResNet20 model trained on CIFAR-10, respectively challenged on MNIST[5-9] and SVHN OOD datasets.</p> <p>Reference Likelihood Ratios for Out-of-Distribution Detection, Neurips 2019.</p>"},{"location":"notebooks/torch/demo_entropy_torch/#imports","title":"Imports\u00b6","text":""},{"location":"notebooks/torch/demo_entropy_torch/#first-exp-mnist0-4-vs-mnist5-9","title":"First exp: MNIST[0-4] vs MNIST[5-9]\u00b6","text":"<p>For this first experiment, we train a toy convolutional network on the MNIST dataset restricted to digits 0 to 4. After fitting the train subset of this dataset to the Entropy method, we will compare the scores returned for MNIST[0-4] (in-distrubtion) and MNIST[5-9] (out-of-distribution) test subsets.</p>"},{"location":"notebooks/torch/demo_entropy_torch/#data-loading","title":"Data loading\u00b6","text":"<ul> <li>In-distribution data: MNIST[0-4]</li> <li>Out-of-distribution data: MNIST[5-9]</li> </ul> <p>Note: We denote In-Distribution (ID) data with <code>_in</code> and Out-Of-Distribution (OOD) data</p> <p>with <code>_out</code> to avoid confusion with OOD detection which is the name of the task, and is therefore used to denote core classes such as <code>OODDataset</code> and <code>OODBaseDetector</code>.</p>"},{"location":"notebooks/torch/demo_entropy_torch/#model-training","title":"Model training\u00b6","text":"<p>Now let's train a simple model on MNIST[0-4] using <code>train_torch_model</code> function.</p>"},{"location":"notebooks/torch/demo_entropy_torch/#entropy-score","title":"Entropy score\u00b6","text":"<p>We now fit a Entropy detector with MNIST[0-4] train dataset, and compare OOD scores returned for MNIST[0-4] (ID) and MNIST[5-9] (OOD) test datasets.</p>"},{"location":"notebooks/torch/demo_entropy_torch/#second-exp-cifar-10-vs-svhn","title":"Second exp: CIFAR-10 vs SVHN\u00b6","text":"<p>For this second experiment, we oppose CIFAR-10 (in-distribution dataset) to SVHN (out-of-distribution dataset).</p>"},{"location":"notebooks/torch/demo_entropy_torch/#data-loading","title":"Data loading\u00b6","text":"<ul> <li>In-distribution data: CIFAR-10</li> <li>Out-of-distribution data: SVHN</li> </ul>"},{"location":"notebooks/torch/demo_entropy_torch/#model-loading","title":"Model loading\u00b6","text":"<p>The model is a ResNet20 pretrained on CIFAR-10 and getting an accuracy score of 92.60%, loaded from pytorch-cifar-models repository.</p>"},{"location":"notebooks/torch/demo_entropy_torch/#entropy-score","title":"Entropy score\u00b6","text":"<p>We now fit a Entropy detector with CIFAR-10 train dataset, and compare OOD scores returned for CIFAR-10 (ID) and SVHN (OOD) test datasets.</p>"},{"location":"notebooks/torch/demo_gen_torch/","title":"GEN","text":"In\u00a0[1]: Copied! <pre>%load_ext autoreload\n%autoreload 2\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport os\n\nfrom IPython.display import clear_output\nfrom sklearn.metrics import accuracy_score\nimport matplotlib.pyplot as plt\nimport torch\nfrom torchvision import transforms\n\nfrom oodeel.methods import GEN\nfrom oodeel.eval.metrics import bench_metrics\nfrom oodeel.eval.plots import plot_ood_scores, plot_roc_curve, plot_2D_features\nfrom oodeel.datasets import OODDataset\nfrom oodeel.utils.torch_training_tools import train_torch_model\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n</pre> %load_ext autoreload %autoreload 2  import warnings warnings.filterwarnings(\"ignore\") import os  from IPython.display import clear_output from sklearn.metrics import accuracy_score import matplotlib.pyplot as plt import torch from torchvision import transforms  from oodeel.methods import GEN from oodeel.eval.metrics import bench_metrics from oodeel.eval.plots import plot_ood_scores, plot_roc_curve, plot_2D_features from oodeel.datasets import OODDataset from oodeel.utils.torch_training_tools import train_torch_model  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") <p>Note that models are saved at ~/.oodeel/saved_models and data is supposed to be found at ~/.oodeel/datasets by default. Change the following cell for a custom path.</p> In\u00a0[2]: Copied! <pre>model_path = os.path.expanduser(\"~/\") + \".oodeel/saved_models\"\ndata_path = os.path.expanduser(\"~/\") + \".oodeel/datasets\"\nos.makedirs(model_path, exist_ok=True)\nos.makedirs(data_path, exist_ok=True)\n</pre> model_path = os.path.expanduser(\"~/\") + \".oodeel/saved_models\" data_path = os.path.expanduser(\"~/\") + \".oodeel/datasets\" os.makedirs(model_path, exist_ok=True) os.makedirs(data_path, exist_ok=True) In\u00a0[3]: Copied! <pre># === load ID and OOD data ===\nbatch_size = 128\nin_labels = [0, 1, 2, 3, 4]\n\n# 1- load train/test MNIST dataset\nmnist_train = OODDataset(\n    dataset_id=\"MNIST\",\n    backend=\"torch\",\n    load_kwargs={\"root\": data_path, \"train\": True, \"download\": True},\n)\nmnist_test = OODDataset(\n    dataset_id=\"MNIST\",\n    backend=\"torch\",\n    load_kwargs={\"root\": data_path, \"train\": False, \"download\": True},\n)\n\n# 2- split ID / OOD data depending on label value:\n# in-distribution: MNIST[0-4] / out-of-distribution: MNIST[5-9]\noods_fit, _ = mnist_train.split_by_class(in_labels=in_labels)\noods_in, oods_out = mnist_test.split_by_class(in_labels=in_labels)\n\n\n# 3- prepare data (preprocess, shuffle, batch) =&gt; torch dataloaders\ndef preprocess_fn(*inputs):\n\"\"\"Simple preprocessing function to normalize images in [0, 1].\"\"\"\n    x = inputs[0] / 255.0\n    return tuple([x] + list(inputs[1:]))\n\n\nds_fit = oods_fit.prepare(\n    batch_size=batch_size, preprocess_fn=preprocess_fn, shuffle=True\n)\nds_in = oods_in.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn)\nds_out = oods_out.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn)\n\nclear_output()\n</pre> # === load ID and OOD data === batch_size = 128 in_labels = [0, 1, 2, 3, 4]  # 1- load train/test MNIST dataset mnist_train = OODDataset(     dataset_id=\"MNIST\",     backend=\"torch\",     load_kwargs={\"root\": data_path, \"train\": True, \"download\": True}, ) mnist_test = OODDataset(     dataset_id=\"MNIST\",     backend=\"torch\",     load_kwargs={\"root\": data_path, \"train\": False, \"download\": True}, )  # 2- split ID / OOD data depending on label value: # in-distribution: MNIST[0-4] / out-of-distribution: MNIST[5-9] oods_fit, _ = mnist_train.split_by_class(in_labels=in_labels) oods_in, oods_out = mnist_test.split_by_class(in_labels=in_labels)   # 3- prepare data (preprocess, shuffle, batch) =&gt; torch dataloaders def preprocess_fn(*inputs):     \"\"\"Simple preprocessing function to normalize images in [0, 1].\"\"\"     x = inputs[0] / 255.0     return tuple([x] + list(inputs[1:]))   ds_fit = oods_fit.prepare(     batch_size=batch_size, preprocess_fn=preprocess_fn, shuffle=True ) ds_in = oods_in.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn) ds_out = oods_out.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn)  clear_output() In\u00a0[4]: Copied! <pre># === Train / Load model ===\n# model path\nmodel_path_mnist_04 = os.path.join(model_path, \"mnist_model_0-4\")\n\ntry:\n    # if the model exists, load it\n    model = torch.load(os.path.join(model_path_mnist_04, \"best.pt\")).to(device)\nexcept OSError:\n    # else, train a new model\n    train_config = {\n        \"model\": \"toy_convnet\",\n        \"num_classes\": 10,\n        \"epochs\": 5,\n        \"save_dir\": model_path_mnist_04,\n        \"validation_data\": ds_in,\n    }\n    model = train_torch_model(ds_fit, **train_config).to(device)\n    clear_output()\n\n# evaluate model\nmodel.eval()\nlabels, preds = [], []\nfor x, y in ds_in:\n    x = x.to(device)\n    preds.append(torch.argmax(model(x), dim=-1).detach().cpu())\n    labels.append(y)\nprint(f\"Test accuracy:\\t{accuracy_score(torch.cat(labels), torch.cat(preds)):.6f}\")\n\n# penultimate features 2d visualization\nprint(\"\\n=== Penultimate features viz ===\")\nplt.figure(figsize=(4.5, 3))\nplot_2D_features(\n    model=model,\n    in_dataset=ds_in,\n    out_dataset=ds_out,\n    output_layer_id=-2,\n)\nplt.tight_layout()\nplt.show()\n</pre> # === Train / Load model === # model path model_path_mnist_04 = os.path.join(model_path, \"mnist_model_0-4\")  try:     # if the model exists, load it     model = torch.load(os.path.join(model_path_mnist_04, \"best.pt\")).to(device) except OSError:     # else, train a new model     train_config = {         \"model\": \"toy_convnet\",         \"num_classes\": 10,         \"epochs\": 5,         \"save_dir\": model_path_mnist_04,         \"validation_data\": ds_in,     }     model = train_torch_model(ds_fit, **train_config).to(device)     clear_output()  # evaluate model model.eval() labels, preds = [], [] for x, y in ds_in:     x = x.to(device)     preds.append(torch.argmax(model(x), dim=-1).detach().cpu())     labels.append(y) print(f\"Test accuracy:\\t{accuracy_score(torch.cat(labels), torch.cat(preds)):.6f}\")  # penultimate features 2d visualization print(\"\\n=== Penultimate features viz ===\") plt.figure(figsize=(4.5, 3)) plot_2D_features(     model=model,     in_dataset=ds_in,     out_dataset=ds_out,     output_layer_id=-2, ) plt.tight_layout() plt.show() <pre>Test accuracy:\t0.996692\n\n=== Penultimate features viz ===\n</pre> In\u00a0[5]: Copied! <pre># === GEN scores ===\ngen = GEN()\ngen.fit(model)\nscores_in, _ = gen.score(ds_in)\nscores_out, _ = gen.score(ds_out)\n\n# === metrics ===\n# auroc / fpr95\nmetrics = bench_metrics(\n    (scores_in, scores_out),\n    metrics=[\"auroc\", \"fpr95tpr\"],\n)\nprint(\"=== Metrics ===\")\nfor k, v in metrics.items():\n    print(f\"{k:&lt;10} {v:.6f}\")\n\nprint(\"\\n=== Plots ===\")\n# hists / roc\nplt.figure(figsize=(9, 3))\nplt.subplot(121)\nplot_ood_scores(scores_in, scores_out, log_scale=False)\nplt.subplot(122)\nplot_roc_curve(scores_in, scores_out)\nplt.tight_layout()\nplt.show()\n</pre> # === GEN scores === gen = GEN() gen.fit(model) scores_in, _ = gen.score(ds_in) scores_out, _ = gen.score(ds_out)  # === metrics === # auroc / fpr95 metrics = bench_metrics(     (scores_in, scores_out),     metrics=[\"auroc\", \"fpr95tpr\"], ) print(\"=== Metrics ===\") for k, v in metrics.items():     print(f\"{k:&lt;10} {v:.6f}\")  print(\"\\n=== Plots ===\") # hists / roc plt.figure(figsize=(9, 3)) plt.subplot(121) plot_ood_scores(scores_in, scores_out, log_scale=False) plt.subplot(122) plot_roc_curve(scores_in, scores_out) plt.tight_layout() plt.show() <pre>=== Metrics ===\nauroc      0.911527\nfpr95tpr   0.508659\n\n=== Plots ===\n</pre> In\u00a0[6]: Copied! <pre># === load ID and OOD data ===\nbatch_size = 128\n\n# 1a- load in-distribution dataset: CIFAR-10\noods_fit = OODDataset(\n    dataset_id=\"CIFAR10\",\n    backend=\"torch\",\n    load_kwargs={\"root\": data_path, \"train\": True, \"download\": True},\n)\noods_in = OODDataset(\n    dataset_id=\"CIFAR10\",\n    backend=\"torch\",\n    load_kwargs={\"root\": data_path, \"train\": False, \"download\": True},\n)\n# 1b- load out-of-distribution dataset: SVHN\noods_out = OODDataset(\n    dataset_id=\"SVHN\",\n    backend=\"torch\",\n    load_kwargs={\"root\": data_path, \"split\": \"test\", \"download\": True},\n)\n\n\n# 2- prepare data (preprocess, shuffle, batch) =&gt; torch dataloaders\n\n\ndef preprocess_fn(*inputs):\n\"\"\"Preprocessing function from\n    https://github.com/chenyaofo/pytorch-cifar-models\n    \"\"\"\n    x = inputs[0] / 255.0\n    x = transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))(x)\n    return tuple([x] + list(inputs[1:]))\n\n\nds_fit = oods_fit.prepare(\n    batch_size=batch_size, shuffle=True, preprocess_fn=preprocess_fn\n)\nds_in = oods_in.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn)\nds_out = oods_out.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn)\n\nclear_output()\n</pre> # === load ID and OOD data === batch_size = 128  # 1a- load in-distribution dataset: CIFAR-10 oods_fit = OODDataset(     dataset_id=\"CIFAR10\",     backend=\"torch\",     load_kwargs={\"root\": data_path, \"train\": True, \"download\": True}, ) oods_in = OODDataset(     dataset_id=\"CIFAR10\",     backend=\"torch\",     load_kwargs={\"root\": data_path, \"train\": False, \"download\": True}, ) # 1b- load out-of-distribution dataset: SVHN oods_out = OODDataset(     dataset_id=\"SVHN\",     backend=\"torch\",     load_kwargs={\"root\": data_path, \"split\": \"test\", \"download\": True}, )   # 2- prepare data (preprocess, shuffle, batch) =&gt; torch dataloaders   def preprocess_fn(*inputs):     \"\"\"Preprocessing function from     https://github.com/chenyaofo/pytorch-cifar-models     \"\"\"     x = inputs[0] / 255.0     x = transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))(x)     return tuple([x] + list(inputs[1:]))   ds_fit = oods_fit.prepare(     batch_size=batch_size, shuffle=True, preprocess_fn=preprocess_fn ) ds_in = oods_in.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn) ds_out = oods_out.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn)  clear_output() In\u00a0[7]: Copied! <pre># === load model ===\n# resnet20 pretrained on CIFAR-10\nmodel = torch.hub.load(\n    repo_or_dir=\"chenyaofo/pytorch-cifar-models\",\n    model=\"cifar10_resnet20\",\n    pretrained=True,\n    verbose=False,\n).to(device)\nmodel.eval()\n\n# evaluate model\nlabels, preds = [], []\nfor x, y in ds_in:\n    x = x.to(device)\n    preds.append(torch.argmax(model(x), dim=-1).detach().cpu())\n    labels.append(y)\nprint(f\"Test accuracy:\\t{accuracy_score(torch.cat(labels), torch.cat(preds)):.6f}\")\n\n# penultimate features 2d visualization\nprint(\"\\n=== Penultimate features viz ===\")\nplt.figure(figsize=(4.5, 3))\nplot_2D_features(\n    model=model,\n    in_dataset=ds_in,\n    out_dataset=ds_out,\n    output_layer_id=-2,\n)\nplt.tight_layout()\nplt.show()\n</pre> # === load model === # resnet20 pretrained on CIFAR-10 model = torch.hub.load(     repo_or_dir=\"chenyaofo/pytorch-cifar-models\",     model=\"cifar10_resnet20\",     pretrained=True,     verbose=False, ).to(device) model.eval()  # evaluate model labels, preds = [], [] for x, y in ds_in:     x = x.to(device)     preds.append(torch.argmax(model(x), dim=-1).detach().cpu())     labels.append(y) print(f\"Test accuracy:\\t{accuracy_score(torch.cat(labels), torch.cat(preds)):.6f}\")  # penultimate features 2d visualization print(\"\\n=== Penultimate features viz ===\") plt.figure(figsize=(4.5, 3)) plot_2D_features(     model=model,     in_dataset=ds_in,     out_dataset=ds_out,     output_layer_id=-2, ) plt.tight_layout() plt.show() <pre>Test accuracy:\t0.926000\n\n=== Penultimate features viz ===\n</pre> In\u00a0[8]: Copied! <pre># === GEN scores ===\ngen = GEN()\ngen.fit(model)\nscores_in, _ = gen.score(ds_in)\nscores_out, _ = gen.score(ds_out)\n\n# === metrics ===\n# auroc / fpr95\nmetrics = bench_metrics(\n    (scores_in, scores_out),\n    metrics=[\"auroc\", \"fpr95tpr\"],\n)\nprint(\"=== Metrics ===\")\nfor k, v in metrics.items():\n    print(f\"{k:&lt;10} {v:.6f}\")\n\nprint(\"\\n=== Plots ===\")\n# hists / roc\nplt.figure(figsize=(9, 3))\nplt.subplot(121)\nplot_ood_scores(scores_in, scores_out, log_scale=False)\nplt.subplot(122)\nplot_roc_curve(scores_in, scores_out)\nplt.tight_layout()\nplt.show()\n</pre> # === GEN scores === gen = GEN() gen.fit(model) scores_in, _ = gen.score(ds_in) scores_out, _ = gen.score(ds_out)  # === metrics === # auroc / fpr95 metrics = bench_metrics(     (scores_in, scores_out),     metrics=[\"auroc\", \"fpr95tpr\"], ) print(\"=== Metrics ===\") for k, v in metrics.items():     print(f\"{k:&lt;10} {v:.6f}\")  print(\"\\n=== Plots ===\") # hists / roc plt.figure(figsize=(9, 3)) plt.subplot(121) plot_ood_scores(scores_in, scores_out, log_scale=False) plt.subplot(122) plot_roc_curve(scores_in, scores_out) plt.tight_layout() plt.show() <pre>=== Metrics ===\nauroc      0.902954\nfpr95tpr   0.312700\n\n=== Plots ===\n</pre>"},{"location":"notebooks/torch/demo_gen_torch/#generalized-entropy","title":"Generalized Entropy\u00b6","text":"<p>This notebook aims at evaluating the GEN method (Generalized ENtropy).</p> <p>This method consists in computing a generalized entropy score based on the softmax probabilities. Considering the softmax output values $p_i$ (one per class), the OOD score is defined as</p> $$ S(p) = \\sum \\_{j=1}^k p_i^\\gamma (1-p_i)^\\gamma. $$<p>The two parameters the method are:</p> <ul> <li>$\\gamma$, corresponding to the order of the generalized entropy form, between 0 and 1. The authors of the original paper propose to set $\\gamma=0.1$.</li> <li>$k$, corresponding to the top-k largest softmax values to keep in the entropy computation. Removing the smallest values makes the method more robust to small variations.</li> </ul> <p>Here, we focus on a toy convolutional network trained on MNIST[0-4] and a ResNet20 model trained on CIFAR-10, respectively challenged on MNIST[5-9] and SVHN OOD datasets.</p> <p>Reference</p> <p>GEN: Pushing the Limits of Softmax-Based Out-of-Distribution Detection, CVPR 2023</p>"},{"location":"notebooks/torch/demo_gen_torch/#imports","title":"Imports\u00b6","text":""},{"location":"notebooks/torch/demo_gen_torch/#first-exp-mnist0-4-vs-mnist5-9","title":"First exp: MNIST[0-4] vs MNIST[5-9]\u00b6","text":"<p>For this first experiment, we train a toy convolutional network on the MNIST dataset restricted to digits 0 to 4.</p>"},{"location":"notebooks/torch/demo_gen_torch/#data-loading","title":"Data loading\u00b6","text":"<ul> <li>In-distribution data: MNIST[0-4]</li> <li>Out-of-distribution data: MNIST[5-9]</li> </ul> <p>Note: We denote In-Distribution (ID) data with <code>_in</code> and Out-Of-Distribution (OOD) data with <code>_out</code> to avoid confusion with OOD detection which is the name of the task, and is therefore used to denote core classes such as <code>OODDataset</code> and <code>OODBaseDetector</code>.</p>"},{"location":"notebooks/torch/demo_gen_torch/#model-training","title":"Model training\u00b6","text":"<p>Now let's train a simple model on MNIST[0-4] using <code>train_torch_model</code> function.</p>"},{"location":"notebooks/torch/demo_gen_torch/#gen-score","title":"GEN score\u00b6","text":"<p>We now fit a GEN detector with MNIST[0-4] train dataset, and compare OOD scores returned for MNIST[0-4] (ID) and MNIST[5-9] (OOD) test datasets.</p>"},{"location":"notebooks/torch/demo_gen_torch/#second-exp-cifar-10-vs-svhn","title":"Second exp: CIFAR-10 vs SVHN\u00b6","text":"<p>For this second experiment, we oppose CIFAR-10 (in-distribution dataset) to SVHN (out-of-distribution dataset).</p>"},{"location":"notebooks/torch/demo_gen_torch/#data-loading","title":"Data loading\u00b6","text":"<ul> <li>In-distribution data: CIFAR-10</li> <li>Out-of-distribution data: SVHN</li> </ul>"},{"location":"notebooks/torch/demo_gen_torch/#model-loading","title":"Model loading\u00b6","text":"<p>The model is a ResNet20 pretrained on CIFAR-10 and getting an accuracy score of 92.60%, loaded from pytorch-cifar-models repository.</p>"},{"location":"notebooks/torch/demo_gen_torch/#gen-score","title":"GEN score\u00b6","text":"<p>We now fit a GEN detector with CIFAR-10 train dataset, and compare OOD scores returned for CIFAR-10 (ID) and SVHN (OOD) test datasets.</p>"},{"location":"notebooks/torch/demo_gram_torch/","title":"Gram","text":"In\u00a0[1]: Copied! <pre>%load_ext autoreload\n%autoreload 2\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport os\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n\nfrom IPython.display import clear_output\nfrom sklearn.metrics import accuracy_score\nimport matplotlib.pyplot as plt\nimport torch\nfrom torchvision import transforms\nimport numpy as np\n\nfrom oodeel.methods import Gram\nfrom oodeel.eval.metrics import bench_metrics\nfrom oodeel.eval.plots import plot_ood_scores, plot_roc_curve, plot_2D_features\nfrom oodeel.datasets import OODDataset\nfrom oodeel.utils.torch_training_tools import train_torch_model\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n</pre> %load_ext autoreload %autoreload 2  import warnings warnings.filterwarnings(\"ignore\") import os os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"  from IPython.display import clear_output from sklearn.metrics import accuracy_score import matplotlib.pyplot as plt import torch from torchvision import transforms import numpy as np  from oodeel.methods import Gram from oodeel.eval.metrics import bench_metrics from oodeel.eval.plots import plot_ood_scores, plot_roc_curve, plot_2D_features from oodeel.datasets import OODDataset from oodeel.utils.torch_training_tools import train_torch_model  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") <p>Note that models are saved at ~/.oodeel/saved_models and data is supposed to be found at ~/.oodeel/datasets by default. Change the following cell for a custom path.</p> In\u00a0[2]: Copied! <pre>model_path = os.path.expanduser(\"~/\") + \".oodeel/saved_models\"\ndata_path = os.path.expanduser(\"~/\") + \".oodeel/datasets\"\nos.makedirs(model_path, exist_ok=True)\nos.makedirs(data_path, exist_ok=True)\n</pre> model_path = os.path.expanduser(\"~/\") + \".oodeel/saved_models\" data_path = os.path.expanduser(\"~/\") + \".oodeel/datasets\" os.makedirs(model_path, exist_ok=True) os.makedirs(data_path, exist_ok=True) In\u00a0[3]: Copied! <pre># === load ID and OOD data ===\nbatch_size = 128\nin_labels = [0, 1, 2, 3, 4]\n\n# 1- load train/test MNIST dataset\nmnist_train = OODDataset(\n    dataset_id=\"MNIST\",\n    backend=\"torch\",\n    load_kwargs={\"root\": data_path, \"train\": True, \"download\": True},\n)\nmnist_test = OODDataset(\n    dataset_id=\"MNIST\",\n    backend=\"torch\",\n    load_kwargs={\"root\": data_path, \"train\": False, \"download\": True},\n)\n\n# 2- split ID / OOD data depending on label value:\n# in-distribution: MNIST[0-4] / out-of-distribution: MNIST[5-9]\noods_fit, _ = mnist_train.split_by_class(in_labels=in_labels)\noods_in, oods_out = mnist_test.split_by_class(in_labels=in_labels)\n\n\n# 3- prepare data (preprocess, shuffle, batch) =&gt; torch dataloaders\ndef preprocess_fn(*inputs):\n\"\"\"Simple preprocessing function to normalize images in [0, 1].\"\"\"\n    x = inputs[0] / 255.0\n    return tuple([x] + list(inputs[1:]))\n\n\nds_fit = oods_fit.prepare(\n    batch_size=batch_size, preprocess_fn=preprocess_fn, shuffle=True\n)\nds_in = oods_in.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn)\nds_out = oods_out.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn)\n\nclear_output()\n</pre> # === load ID and OOD data === batch_size = 128 in_labels = [0, 1, 2, 3, 4]  # 1- load train/test MNIST dataset mnist_train = OODDataset(     dataset_id=\"MNIST\",     backend=\"torch\",     load_kwargs={\"root\": data_path, \"train\": True, \"download\": True}, ) mnist_test = OODDataset(     dataset_id=\"MNIST\",     backend=\"torch\",     load_kwargs={\"root\": data_path, \"train\": False, \"download\": True}, )  # 2- split ID / OOD data depending on label value: # in-distribution: MNIST[0-4] / out-of-distribution: MNIST[5-9] oods_fit, _ = mnist_train.split_by_class(in_labels=in_labels) oods_in, oods_out = mnist_test.split_by_class(in_labels=in_labels)   # 3- prepare data (preprocess, shuffle, batch) =&gt; torch dataloaders def preprocess_fn(*inputs):     \"\"\"Simple preprocessing function to normalize images in [0, 1].\"\"\"     x = inputs[0] / 255.0     return tuple([x] + list(inputs[1:]))   ds_fit = oods_fit.prepare(     batch_size=batch_size, preprocess_fn=preprocess_fn, shuffle=True ) ds_in = oods_in.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn) ds_out = oods_out.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn)  clear_output() In\u00a0[4]: Copied! <pre># === Train / Load model ===\n# model path\nmodel_path_mnist_04 = os.path.join(model_path, \"mnist_mlp_0-4\")\n\ntry:\n    # if the model exists, load it\n    model = torch.load(os.path.join(model_path_mnist_04, \"best.pt\")).to(device)\nexcept OSError:\n    # else, train a new model\n    train_config = {\n        \"model\": \"toy_mlp\",\n        \"num_classes\": 10,\n        \"epochs\": 5,\n        \"save_dir\": model_path_mnist_04,\n        \"validation_data\": ds_in,\n    }\n    model = train_torch_model(ds_fit, **train_config).to(device)\n    clear_output()\n\n# evaluate model\nmodel.eval()\nlabels, preds = [], []\nfor x, y in ds_in:\n    x = x.to(device)\n    preds.append(torch.argmax(model(x), dim=-1).detach().cpu())\n    labels.append(y)\nprint(f\"Test accuracy:\\t{accuracy_score(torch.cat(labels), torch.cat(preds)):.6f}\")\n\n# penultimate features 2d visualization\nprint(\"\\n=== Penultimate features viz ===\")\nplt.figure(figsize=(4.5, 3))\nplot_2D_features(\n    model=model,\n    in_dataset=ds_in,\n    out_dataset=ds_out,\n    output_layer_id=-2,\n)\nplt.tight_layout()\nplt.show()\n</pre> # === Train / Load model === # model path model_path_mnist_04 = os.path.join(model_path, \"mnist_mlp_0-4\")  try:     # if the model exists, load it     model = torch.load(os.path.join(model_path_mnist_04, \"best.pt\")).to(device) except OSError:     # else, train a new model     train_config = {         \"model\": \"toy_mlp\",         \"num_classes\": 10,         \"epochs\": 5,         \"save_dir\": model_path_mnist_04,         \"validation_data\": ds_in,     }     model = train_torch_model(ds_fit, **train_config).to(device)     clear_output()  # evaluate model model.eval() labels, preds = [], [] for x, y in ds_in:     x = x.to(device)     preds.append(torch.argmax(model(x), dim=-1).detach().cpu())     labels.append(y) print(f\"Test accuracy:\\t{accuracy_score(torch.cat(labels), torch.cat(preds)):.6f}\")  # penultimate features 2d visualization print(\"\\n=== Penultimate features viz ===\") plt.figure(figsize=(4.5, 3)) plot_2D_features(     model=model,     in_dataset=ds_in,     out_dataset=ds_out,     output_layer_id=-2, ) plt.tight_layout() plt.show() <pre>Test accuracy:\t0.991243\n\n=== Penultimate features viz ===\n</pre> In\u00a0[5]: Copied! <pre># === gram scores ===\ngram = Gram(quantile=0.2)\ngram.fit(model, ds_fit, feature_layers_id=[\"relu1\", \"relu2\"])\nscores_in, _ = gram.score(ds_in)\nscores_out, _ = gram.score(ds_out)\n\n\n# Since many scores are equal to 0, we add a random noise to avoid bugs\n# in Auroc and TPR computation.\nscores_in += np.random.random_sample(size=scores_in.shape) * 10e-6\nscores_out += np.random.random_sample(size=scores_out.shape) * 10e-6\n\n# === metrics ===\n# auroc / fpr95\nmetrics = bench_metrics(\n    (scores_in, scores_out),\n    metrics=[\"auroc\", \"fpr95tpr\"],\n)\nprint(\"=== Metrics ===\")\nfor k, v in metrics.items():\n    print(f\"{k:&lt;10} {v:.6f}\")\n</pre> # === gram scores === gram = Gram(quantile=0.2) gram.fit(model, ds_fit, feature_layers_id=[\"relu1\", \"relu2\"]) scores_in, _ = gram.score(ds_in) scores_out, _ = gram.score(ds_out)   # Since many scores are equal to 0, we add a random noise to avoid bugs # in Auroc and TPR computation. scores_in += np.random.random_sample(size=scores_in.shape) * 10e-6 scores_out += np.random.random_sample(size=scores_out.shape) * 10e-6  # === metrics === # auroc / fpr95 metrics = bench_metrics(     (scores_in, scores_out),     metrics=[\"auroc\", \"fpr95tpr\"], ) print(\"=== Metrics ===\") for k, v in metrics.items():     print(f\"{k:&lt;10} {v:.6f}\")  <pre>=== Metrics ===\nauroc      0.894014\nfpr95tpr   0.380424\n</pre> In\u00a0[6]: Copied! <pre>print(\"\\n=== Plots ===\")\n# hists / roc\nplt.figure(figsize=(9, 3))\nplt.subplot(121)\nplot_ood_scores(scores_in, scores_out, log_scale=True)\nplt.subplot(122)\nplot_roc_curve(scores_in, scores_out)\nplt.tight_layout()\nplt.show()\n</pre>  print(\"\\n=== Plots ===\") # hists / roc plt.figure(figsize=(9, 3)) plt.subplot(121) plot_ood_scores(scores_in, scores_out, log_scale=True) plt.subplot(122) plot_roc_curve(scores_in, scores_out) plt.tight_layout() plt.show() <pre>\n=== Plots ===\n</pre> In\u00a0[7]: Copied! <pre># === load ID and OOD data ===\nbatch_size = 128\n\n# 1a- load in-distribution dataset: CIFAR-10\noods_fit = OODDataset(\n    dataset_id=\"CIFAR10\",\n    backend=\"torch\",\n    load_kwargs={\"root\": data_path, \"train\": True, \"download\": True},\n)\noods_in = OODDataset(\n    dataset_id=\"CIFAR10\",\n    backend=\"torch\",\n    load_kwargs={\"root\": data_path, \"train\": False, \"download\": True},\n)\n# 1b- load out-of-distribution dataset: SVHN\noods_out = OODDataset(\n    dataset_id=\"SVHN\",\n    backend=\"torch\",\n    load_kwargs={\"root\": data_path, \"split\": \"test\", \"download\": True},\n)\n\n\n# 2- prepare data (preprocess, shuffle, batch) =&gt; torch dataloaders\n\n\ndef preprocess_fn(*inputs):\n\"\"\"Preprocessing function from\n    https://github.com/chenyaofo/pytorch-cifar-models\n    \"\"\"\n    x = inputs[0] / 255.0\n    x = transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))(x)\n    return tuple([x] + list(inputs[1:]))\n\n\nds_fit = oods_fit.prepare(\n    batch_size=batch_size, shuffle=True, preprocess_fn=preprocess_fn\n)\nds_in = oods_in.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn)\nds_out = oods_out.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn)\n\nclear_output()\n</pre> # === load ID and OOD data === batch_size = 128  # 1a- load in-distribution dataset: CIFAR-10 oods_fit = OODDataset(     dataset_id=\"CIFAR10\",     backend=\"torch\",     load_kwargs={\"root\": data_path, \"train\": True, \"download\": True}, ) oods_in = OODDataset(     dataset_id=\"CIFAR10\",     backend=\"torch\",     load_kwargs={\"root\": data_path, \"train\": False, \"download\": True}, ) # 1b- load out-of-distribution dataset: SVHN oods_out = OODDataset(     dataset_id=\"SVHN\",     backend=\"torch\",     load_kwargs={\"root\": data_path, \"split\": \"test\", \"download\": True}, )   # 2- prepare data (preprocess, shuffle, batch) =&gt; torch dataloaders   def preprocess_fn(*inputs):     \"\"\"Preprocessing function from     https://github.com/chenyaofo/pytorch-cifar-models     \"\"\"     x = inputs[0] / 255.0     x = transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))(x)     return tuple([x] + list(inputs[1:]))   ds_fit = oods_fit.prepare(     batch_size=batch_size, shuffle=True, preprocess_fn=preprocess_fn ) ds_in = oods_in.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn) ds_out = oods_out.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn)  clear_output() In\u00a0[8]: Copied! <pre># === load model ===\n# resnet20 pretrained on CIFAR-10\nmodel = torch.hub.load(\n    repo_or_dir=\"chenyaofo/pytorch-cifar-models\",\n    model=\"cifar10_resnet20\",\n    pretrained=True,\n    verbose=False,\n).to(device)\nmodel.eval()\nclear_output()\n</pre> # === load model === # resnet20 pretrained on CIFAR-10 model = torch.hub.load(     repo_or_dir=\"chenyaofo/pytorch-cifar-models\",     model=\"cifar10_resnet20\",     pretrained=True,     verbose=False, ).to(device) model.eval() clear_output() In\u00a0[9]: Copied! <pre># evaluate model\nlabels, preds = [], []\nfor x, y in ds_in:\n    x = x.to(device)\n    preds.append(torch.argmax(model(x), dim=-1).detach().cpu())\n    labels.append(y)\nprint(f\"Test accuracy:\\t{accuracy_score(torch.cat(labels), torch.cat(preds)):.6f}\")\n\n# penultimate features 2d visualization\nprint(\"\\n=== Penultimate features viz ===\")\nplt.figure(figsize=(4.5, 3))\nplot_2D_features(\n    model=model,\n    in_dataset=ds_in,\n    out_dataset=ds_out,\n    output_layer_id=-2,\n)\nplt.tight_layout()\nplt.show()\n</pre>  # evaluate model labels, preds = [], [] for x, y in ds_in:     x = x.to(device)     preds.append(torch.argmax(model(x), dim=-1).detach().cpu())     labels.append(y) print(f\"Test accuracy:\\t{accuracy_score(torch.cat(labels), torch.cat(preds)):.6f}\")  # penultimate features 2d visualization print(\"\\n=== Penultimate features viz ===\") plt.figure(figsize=(4.5, 3)) plot_2D_features(     model=model,     in_dataset=ds_in,     out_dataset=ds_out,     output_layer_id=-2, ) plt.tight_layout() plt.show() <pre>Test accuracy:\t0.926000\n\n=== Penultimate features viz ===\n</pre> In\u00a0[10]: Copied! <pre># === gram scores ===\ngram = Gram(quantile=0.01)\ngram.fit(\n    model, \n    ds_fit, \n    feature_layers_id=[\"layer1.2.conv2\", \"layer1.2.relu\", \"layer2.2.conv2\", \"layer2.2.relu\", \"layer3.2.conv2\", \"layer3.2.relu\"], \n    val_split=0.5\n)\nscores_in, _ = gram.score(ds_in)\nscores_out, _ = gram.score(ds_out)\nscores_in += np.random.random_sample(size=scores_in.shape) * 10e-6\nscores_out += np.random.random_sample(size=scores_out.shape) * 10e-6\n# === metrics ===\n# auroc / fpr95\nmetrics = bench_metrics(\n    (scores_in, scores_out),\n    metrics=[\"auroc\", \"fpr95tpr\"],\n)\nprint(\"=== Metrics ===\")\nfor k, v in metrics.items():\n    print(f\"{k:&lt;10} {v:.6f}\")\n\nprint(\"\\n=== Plots ===\")\n# hists / roc\nplt.figure(figsize=(9, 3))\nplt.subplot(121)\nplot_ood_scores(scores_in, scores_out, log_scale=True)\nplt.subplot(122)\nplot_roc_curve(scores_in, scores_out)\nplt.tight_layout()\nplt.show()\n</pre> # === gram scores === gram = Gram(quantile=0.01) gram.fit(     model,      ds_fit,      feature_layers_id=[\"layer1.2.conv2\", \"layer1.2.relu\", \"layer2.2.conv2\", \"layer2.2.relu\", \"layer3.2.conv2\", \"layer3.2.relu\"],      val_split=0.5 ) scores_in, _ = gram.score(ds_in) scores_out, _ = gram.score(ds_out) scores_in += np.random.random_sample(size=scores_in.shape) * 10e-6 scores_out += np.random.random_sample(size=scores_out.shape) * 10e-6 # === metrics === # auroc / fpr95 metrics = bench_metrics(     (scores_in, scores_out),     metrics=[\"auroc\", \"fpr95tpr\"], ) print(\"=== Metrics ===\") for k, v in metrics.items():     print(f\"{k:&lt;10} {v:.6f}\")  print(\"\\n=== Plots ===\") # hists / roc plt.figure(figsize=(9, 3)) plt.subplot(121) plot_ood_scores(scores_in, scores_out, log_scale=True) plt.subplot(122) plot_roc_curve(scores_in, scores_out) plt.tight_layout() plt.show() <pre>=== Metrics ===\nauroc      0.992835\nfpr95tpr   0.019300\n\n=== Plots ===\n</pre>"},{"location":"notebooks/torch/demo_gram_torch/#gram-method","title":"Gram method\u00b6","text":"<p>This notebook aims at evaluating the gram method.</p> <p>The method consists in computing the Gram matrices of several layers to evaluate the channel-wise correlation of internal features. A score is built by computing these correlations for a new input and evaluating their deviation from regular correlations values computed on the in-distribution dataset.</p> <p>Important Disclaimer: Taking the statistics of min/max deviation, as in the paper raises some problems.</p> <p>The method often yields a score of zero for some tasks. This is expected since the min/max among the samples of a random variable becomes more and more extreme with the sample size. As a result, computing the min/max over the training set is likely to produce min/max values that are so extreme that none of the in distribution correlations of the validation set goes beyond these threshold. The worst is that a significant part of ood data does not exceed the thresholds either. This can be aleviated by computing the min/max over a limited number of sample. However, it is counter-intuitive and, in our opinion, not desirable: adding some more information should only improve a method.</p> <p>Hence, we decided to replace the min/max by the q / 1-q quantile, with q a new parameter of the method. Specifically, instead of the deviation as defined in eq. 3 of the paper, we use the definition $$ \\delta(t_q, t_{1-q}, value) = \\begin{cases}     0 &amp; \\text{if} \\; t_q \\leq value \\leq t_{1-q} \\\\     \\frac{t_q - value}{|t_q|} &amp; \\text{if } value &lt; t_q,  \\\\     \\frac{value - t_{1-q}}{|t_q|} &amp; \\text{if } value &gt; t_{1-q} \\end{cases} $$ With this new deviation, the more point we add, the more accurate the quantile becomes. In addition, the method can be made more or less discriminative by toggling the value of q.</p> <p>Finally, we found that this approach improved the performance of the baseline in our experiments.</p> <p>Here, we focus on a toy convolutional network trained on MNIST[0-4] and a ResNet model trained on CIFAR-10, respectively challenged on MNIST[5-9] and SVHN OOD datasets.</p> <p>Reference Detecting Out-of-Distribution Examples with Gram Matrices, ICML 2020</p>"},{"location":"notebooks/torch/demo_gram_torch/#imports","title":"Imports\u00b6","text":""},{"location":"notebooks/torch/demo_gram_torch/#first-exp-mnist0-4-vs-mnist5-9","title":"First exp: MNIST[0-4] vs MNIST[5-9]\u00b6","text":"<p>For this first experiment, we train a toy convolutional network on the MNIST dataset restricted to digits 0 to 4. After fitting the train subset of this dataset to the Gram method, we will compare the scores returned for MNIST[0-4] (in-distrubtion) and MNIST[5-9] (out-of-distribution) test subsets.</p>"},{"location":"notebooks/torch/demo_gram_torch/#data-loading","title":"Data loading\u00b6","text":"<ul> <li>In-distribution data: MNIST[0-4]</li> <li>Out-of-distribution data: MNIST[5-9]</li> </ul> <p>Note: We denote In-Distribution (ID) data with <code>_in</code> and Out-Of-Distribution (OOD) data with <code>_out</code> to avoid confusion with OOD detection which is the name of the task, and is therefore used to denote core classes such as <code>OODDataset</code> and <code>OODBaseDetector</code>.</p>"},{"location":"notebooks/torch/demo_gram_torch/#model-training","title":"Model training\u00b6","text":"<p>Now let's train a simple model on MNIST[0-4] using <code>train_torch_model</code> function.</p>"},{"location":"notebooks/torch/demo_gram_torch/#gram-score","title":"Gram score\u00b6","text":"<p>We now fit a Gram detector with MNIST[0-4] train dataset, and compare OOD scores returned for MNIST[0-4] (ID) and MNIST[5-9] (OOD) test datasets.</p>"},{"location":"notebooks/torch/demo_gram_torch/#second-exp-cifar-10-vs-svhn","title":"Second exp: CIFAR-10 vs SVHN\u00b6","text":"<p>For this second experiment, we oppose CIFAR-10 (in-distribution dataset) to SVHN (out-of-distribution dataset).</p>"},{"location":"notebooks/torch/demo_gram_torch/#data-loading","title":"Data loading\u00b6","text":"<ul> <li>In-distribution data: CIFAR-10</li> <li>Out-of-distribution data: SVHN</li> </ul>"},{"location":"notebooks/torch/demo_gram_torch/#model-loading","title":"Model loading\u00b6","text":"<p>The model is a ResNet20 pretrained on CIFAR-10 and getting an accuracy score of 92.60%, loaded from pytorch-cifar-models repository.</p>"},{"location":"notebooks/torch/demo_gram_torch/#gram-score","title":"Gram score\u00b6","text":"<p>We now fit a Gram detector with CIFAR-10 train dataset, and compare OOD scores returned for CIFAR-10 (ID) and SVHN (OOD) test datasets.</p>"},{"location":"notebooks/torch/demo_mahalanobis_torch/","title":"Mahalanobis","text":"In\u00a0[1]: Copied! <pre>import sys\nsys.path.append('..\\..')\n</pre> import sys sys.path.append('..\\..') In\u00a0[2]: Copied! <pre>%load_ext autoreload\n%autoreload 2\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport os\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n\nfrom IPython.display import clear_output\nfrom sklearn.metrics import accuracy_score\nimport matplotlib.pyplot as plt\nimport torch\nfrom torchvision import transforms\n\nfrom oodeel.methods import Mahalanobis\nfrom oodeel.eval.metrics import bench_metrics\nfrom oodeel.eval.plots import plot_ood_scores, plot_roc_curve, plot_2D_features\nfrom oodeel.datasets import OODDataset\nfrom oodeel.utils.torch_training_tools import train_torch_model\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n</pre> %load_ext autoreload %autoreload 2  import warnings warnings.filterwarnings(\"ignore\") import os os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"  from IPython.display import clear_output from sklearn.metrics import accuracy_score import matplotlib.pyplot as plt import torch from torchvision import transforms  from oodeel.methods import Mahalanobis from oodeel.eval.metrics import bench_metrics from oodeel.eval.plots import plot_ood_scores, plot_roc_curve, plot_2D_features from oodeel.datasets import OODDataset from oodeel.utils.torch_training_tools import train_torch_model  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") <p>Note that models are saved at ~/.oodeel/saved_models and data is supposed to be found at ~/.oodeel/datasets by default. Change the following cell for a custom path.</p> In\u00a0[3]: Copied! <pre>model_path = os.path.expanduser(\"~/\") + \".oodeel/saved_models\"\ndata_path = os.path.expanduser(\"~/\") + \".oodeel/datasets\"\nos.makedirs(model_path, exist_ok=True)\nos.makedirs(data_path, exist_ok=True)\n</pre> model_path = os.path.expanduser(\"~/\") + \".oodeel/saved_models\" data_path = os.path.expanduser(\"~/\") + \".oodeel/datasets\" os.makedirs(model_path, exist_ok=True) os.makedirs(data_path, exist_ok=True) In\u00a0[4]: Copied! <pre># === load ID and OOD data ===\nbatch_size = 128\nin_labels = [0, 1, 2, 3, 4]\n\n# 1- load train/test MNIST dataset\nmnist_train = OODDataset(\n    dataset_id='MNIST', backend=\"torch\",\n    load_kwargs={\"root\": data_path, \"train\": True, \"download\": True}\n)\nmnist_test = OODDataset(\n    dataset_id='MNIST', backend=\"torch\",\n    load_kwargs={\"root\": data_path, \"train\": False, \"download\": True}\n)\n\n# 2- split ID / OOD data depending on label value:\n# in-distribution: MNIST[0-4] / out-of-distribution: MNIST[5-9]\noods_fit, _ = mnist_train.split_by_class(in_labels=in_labels)\noods_in, oods_out = mnist_test.split_by_class(in_labels=in_labels)\n\n# 3- prepare data (preprocess, shuffle, batch) =&gt; torch dataloaders\ndef preprocess_fn(*inputs):\n\"\"\"Simple preprocessing function to normalize images in [0, 1].\n    \"\"\"\n    x = inputs[0] / 255.0\n    return tuple([x] + list(inputs[1:]))\n\nds_fit = oods_fit.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn, shuffle=True)\nds_in = oods_in.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn)\nds_out = oods_out.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn)\n\nclear_output()\n</pre> # === load ID and OOD data === batch_size = 128 in_labels = [0, 1, 2, 3, 4]  # 1- load train/test MNIST dataset mnist_train = OODDataset(     dataset_id='MNIST', backend=\"torch\",     load_kwargs={\"root\": data_path, \"train\": True, \"download\": True} ) mnist_test = OODDataset(     dataset_id='MNIST', backend=\"torch\",     load_kwargs={\"root\": data_path, \"train\": False, \"download\": True} )  # 2- split ID / OOD data depending on label value: # in-distribution: MNIST[0-4] / out-of-distribution: MNIST[5-9] oods_fit, _ = mnist_train.split_by_class(in_labels=in_labels) oods_in, oods_out = mnist_test.split_by_class(in_labels=in_labels)  # 3- prepare data (preprocess, shuffle, batch) =&gt; torch dataloaders def preprocess_fn(*inputs):     \"\"\"Simple preprocessing function to normalize images in [0, 1].     \"\"\"     x = inputs[0] / 255.0     return tuple([x] + list(inputs[1:]))  ds_fit = oods_fit.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn, shuffle=True) ds_in = oods_in.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn) ds_out = oods_out.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn)  clear_output() In\u00a0[5]: Copied! <pre># === Train / Load model ===\n# model path\nmodel_path_mnist_04 = os.path.join(model_path, \"mnist_model_0-4\")\n\ntry:\n    # if the model exists, load it\n    model = torch.load(os.path.join(model_path_mnist_04, \"best.pt\")).to(device)\nexcept OSError:\n    # else, train a new model\n    train_config = {\n        \"model\": \"toy_convnet\",\n        \"num_classes\": 10,\n        \"epochs\": 5,\n        \"save_dir\": model_path_mnist_04,\n        \"validation_data\": ds_in\n    }\n    model = train_torch_model(ds_fit, **train_config).to(device)\n    clear_output()\n\n# evaluate model\nmodel.eval()\nlabels, preds = [], []\nfor (x, y) in ds_in:\n    x = x.to(device)\n    preds.append(torch.argmax(model(x), dim=-1).detach().cpu())\n    labels.append(y)\nprint(f\"Test accuracy:\\t{accuracy_score(torch.cat(labels), torch.cat(preds)):.6f}\")\n\n# penultimate features 2d visualization\nprint(\"\\n=== Penultimate features viz ===\")\nplt.figure(figsize=(4.5, 3))\nplot_2D_features(\n    model=model,\n    in_dataset=ds_in,\n    out_dataset=ds_out,\n    output_layer_id=-2,\n)\nplt.tight_layout()\nplt.show()\n</pre> # === Train / Load model === # model path model_path_mnist_04 = os.path.join(model_path, \"mnist_model_0-4\")  try:     # if the model exists, load it     model = torch.load(os.path.join(model_path_mnist_04, \"best.pt\")).to(device) except OSError:     # else, train a new model     train_config = {         \"model\": \"toy_convnet\",         \"num_classes\": 10,         \"epochs\": 5,         \"save_dir\": model_path_mnist_04,         \"validation_data\": ds_in     }     model = train_torch_model(ds_fit, **train_config).to(device)     clear_output()  # evaluate model model.eval() labels, preds = [], [] for (x, y) in ds_in:     x = x.to(device)     preds.append(torch.argmax(model(x), dim=-1).detach().cpu())     labels.append(y) print(f\"Test accuracy:\\t{accuracy_score(torch.cat(labels), torch.cat(preds)):.6f}\")  # penultimate features 2d visualization print(\"\\n=== Penultimate features viz ===\") plt.figure(figsize=(4.5, 3)) plot_2D_features(     model=model,     in_dataset=ds_in,     out_dataset=ds_out,     output_layer_id=-2, ) plt.tight_layout() plt.show() <pre>Test accuracy:\t0.996108\n\n=== Penultimate features viz ===\n</pre> In\u00a0[6]: Copied! <pre># === mahalanobis scores ===\nmahalanobis = Mahalanobis(eps=0.002)\nmahalanobis.fit(model, feature_layers_id=[-2], fit_dataset=ds_fit)\nscores_in, _ = mahalanobis.score(ds_in)\nscores_out, _ = mahalanobis.score(ds_out)\n\n# === metrics ===\n# auroc / fpr95\nmetrics = bench_metrics(\n    (scores_in, scores_out),\n    metrics=[\"auroc\", \"fpr95tpr\"],\n)\nprint(\"=== Metrics ===\")\nfor k, v in metrics.items():\n    print(f\"{k:&lt;10} {v:.6f}\")\n\nprint(\"\\n=== Plots ===\")\n# hists / roc\nplt.figure(figsize=(9, 3))\nplt.subplot(121)\nplot_ood_scores(scores_in, scores_out, log_scale=False)\nplt.subplot(122)\nplot_roc_curve(scores_in, scores_out)\nplt.tight_layout()\nplt.show()\n</pre> # === mahalanobis scores === mahalanobis = Mahalanobis(eps=0.002) mahalanobis.fit(model, feature_layers_id=[-2], fit_dataset=ds_fit) scores_in, _ = mahalanobis.score(ds_in) scores_out, _ = mahalanobis.score(ds_out)  # === metrics === # auroc / fpr95 metrics = bench_metrics(     (scores_in, scores_out),     metrics=[\"auroc\", \"fpr95tpr\"], ) print(\"=== Metrics ===\") for k, v in metrics.items():     print(f\"{k:&lt;10} {v:.6f}\")  print(\"\\n=== Plots ===\") # hists / roc plt.figure(figsize=(9, 3)) plt.subplot(121) plot_ood_scores(scores_in, scores_out, log_scale=False) plt.subplot(122) plot_roc_curve(scores_in, scores_out) plt.tight_layout() plt.show() <pre>shape of centered feature vector:  torch.Size([5923, 1600])\nshape of covariance matrix:  torch.Size([1600, 1600])\nshape of centered feature vector:  torch.Size([6742, 1600])\nshape of covariance matrix:  torch.Size([1600, 1600])\nshape of centered feature vector:  torch.Size([5958, 1600])\nshape of covariance matrix:  torch.Size([1600, 1600])\nshape of centered feature vector:  torch.Size([6131, 1600])\nshape of covariance matrix:  torch.Size([1600, 1600])\nshape of centered feature vector:  torch.Size([5842, 1600])\nshape of covariance matrix:  torch.Size([1600, 1600])\n=== Metrics ===\nauroc      0.874499\nfpr95tpr   0.482390\n\n=== Plots ===\n</pre> In\u00a0[7]: Copied! <pre># === load ID and OOD data ===\nbatch_size = 128\n\n# 1a- load in-distribution dataset: CIFAR-10\noods_fit = OODDataset(\n    dataset_id='CIFAR10', backend=\"torch\",\n    load_kwargs={\"root\": data_path, \"train\": True, \"download\": True}\n)\noods_in = OODDataset(\n    dataset_id='CIFAR10', backend=\"torch\",\n    load_kwargs={\"root\": data_path, \"train\": False, \"download\": True}\n)\n# 1b- load out-of-distribution dataset: SVHN\noods_out = OODDataset(\n    dataset_id='SVHN', backend=\"torch\",\n    load_kwargs={\"root\": data_path, \"split\": \"test\", \"download\": True})\n\n\n# 2- prepare data (preprocess, shuffle, batch) =&gt; torch dataloaders\n\ndef preprocess_fn(*inputs):\n\"\"\"Preprocessing function from\n    https://github.com/chenyaofo/pytorch-cifar-models\n    \"\"\"\n    x = inputs[0] / 255.0\n    x = transforms.Normalize(\n        (0.4914, 0.4822, 0.4465),\n        (0.2023, 0.1994, 0.2010)\n    )(x)\n    return tuple([x] + list(inputs[1:]))\n\nds_fit = oods_fit.prepare(batch_size=batch_size, shuffle=True, preprocess_fn=preprocess_fn)\nds_in = oods_in.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn)\nds_out = oods_out.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn)\n\nclear_output()\n</pre> # === load ID and OOD data === batch_size = 128  # 1a- load in-distribution dataset: CIFAR-10 oods_fit = OODDataset(     dataset_id='CIFAR10', backend=\"torch\",     load_kwargs={\"root\": data_path, \"train\": True, \"download\": True} ) oods_in = OODDataset(     dataset_id='CIFAR10', backend=\"torch\",     load_kwargs={\"root\": data_path, \"train\": False, \"download\": True} ) # 1b- load out-of-distribution dataset: SVHN oods_out = OODDataset(     dataset_id='SVHN', backend=\"torch\",     load_kwargs={\"root\": data_path, \"split\": \"test\", \"download\": True})   # 2- prepare data (preprocess, shuffle, batch) =&gt; torch dataloaders  def preprocess_fn(*inputs):     \"\"\"Preprocessing function from     https://github.com/chenyaofo/pytorch-cifar-models     \"\"\"     x = inputs[0] / 255.0     x = transforms.Normalize(         (0.4914, 0.4822, 0.4465),         (0.2023, 0.1994, 0.2010)     )(x)     return tuple([x] + list(inputs[1:]))  ds_fit = oods_fit.prepare(batch_size=batch_size, shuffle=True, preprocess_fn=preprocess_fn) ds_in = oods_in.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn) ds_out = oods_out.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn)  clear_output() In\u00a0[8]: Copied! <pre># === load model ===\n# resnet20 pretrained on CIFAR-10\nmodel = torch.hub.load(\n    repo_or_dir=\"chenyaofo/pytorch-cifar-models\", model=\"cifar10_resnet20\",\n    pretrained=True, verbose=False).to(device)\nmodel.eval();\n\n# evaluate model\nlabels, preds = [], []\nfor (x, y) in ds_in:\n    x = x.to(device)\n    preds.append(torch.argmax(model(x), dim=-1).detach().cpu())\n    labels.append(y)\nprint(f\"Test accuracy:\\t{accuracy_score(torch.cat(labels), torch.cat(preds)):.6f}\")\n\n# penultimate features 2d visualization\nprint(\"\\n=== Penultimate features viz ===\")\nplt.figure(figsize=(4.5, 3))\nplot_2D_features(\n    model=model,\n    in_dataset=ds_in,\n    out_dataset=ds_out,\n    output_layer_id=-2,\n)\nplt.tight_layout()\nplt.show()\n</pre> # === load model === # resnet20 pretrained on CIFAR-10 model = torch.hub.load(     repo_or_dir=\"chenyaofo/pytorch-cifar-models\", model=\"cifar10_resnet20\",     pretrained=True, verbose=False).to(device) model.eval();  # evaluate model labels, preds = [], [] for (x, y) in ds_in:     x = x.to(device)     preds.append(torch.argmax(model(x), dim=-1).detach().cpu())     labels.append(y) print(f\"Test accuracy:\\t{accuracy_score(torch.cat(labels), torch.cat(preds)):.6f}\")  # penultimate features 2d visualization print(\"\\n=== Penultimate features viz ===\") plt.figure(figsize=(4.5, 3)) plot_2D_features(     model=model,     in_dataset=ds_in,     out_dataset=ds_out,     output_layer_id=-2, ) plt.tight_layout() plt.show() <pre>Downloading: \"https://github.com/chenyaofo/pytorch-cifar-models/zipball/master\" to /home/joseba.dalmau/.cache/torch/hub/master.zip\nDownloading: \"https://github.com/chenyaofo/pytorch-cifar-models/releases/download/resnet/cifar10_resnet20-4118986f.pt\" to /home/joseba.dalmau/.cache/torch/hub/checkpoints/cifar10_resnet20-4118986f.pt\n</pre> <pre>  0%|          | 0.00/1.09M [00:00&lt;?, ?B/s]</pre> <pre>Test accuracy:\t0.926000\n\n=== Penultimate features viz ===\n</pre> In\u00a0[9]: Copied! <pre># === mahalanobis scores ===\nmahalanobis = Mahalanobis(eps=0.002)\nmahalanobis.fit(model, feature_layers_id=[-2], fit_dataset=ds_fit)\nscores_in, _ = mahalanobis.score(ds_in)\nscores_out, _ = mahalanobis.score(ds_out)\n\n# === metrics ===\n# auroc / fpr95\nmetrics = bench_metrics(\n    (scores_in, scores_out),\n    metrics=[\"auroc\", \"fpr95tpr\"],\n)\nprint(\"=== Metrics ===\")\nfor k, v in metrics.items():\n    print(f\"{k:&lt;10} {v:.6f}\")\n\nprint(\"\\n=== Plots ===\")\n# hists / roc\nplt.figure(figsize=(9, 3))\nplt.subplot(121)\nplot_ood_scores(scores_in, scores_out, log_scale=False)\nplt.subplot(122)\nplot_roc_curve(scores_in, scores_out)\nplt.tight_layout()\nplt.show()\n</pre> # === mahalanobis scores === mahalanobis = Mahalanobis(eps=0.002) mahalanobis.fit(model, feature_layers_id=[-2], fit_dataset=ds_fit) scores_in, _ = mahalanobis.score(ds_in) scores_out, _ = mahalanobis.score(ds_out)  # === metrics === # auroc / fpr95 metrics = bench_metrics(     (scores_in, scores_out),     metrics=[\"auroc\", \"fpr95tpr\"], ) print(\"=== Metrics ===\") for k, v in metrics.items():     print(f\"{k:&lt;10} {v:.6f}\")  print(\"\\n=== Plots ===\") # hists / roc plt.figure(figsize=(9, 3)) plt.subplot(121) plot_ood_scores(scores_in, scores_out, log_scale=False) plt.subplot(122) plot_roc_curve(scores_in, scores_out) plt.tight_layout() plt.show() <pre>shape of centered feature vector:  torch.Size([5000, 64])\nshape of covariance matrix:  torch.Size([64, 64])\nshape of centered feature vector:  torch.Size([5000, 64])\nshape of covariance matrix:  torch.Size([64, 64])\nshape of centered feature vector:  torch.Size([5000, 64])\nshape of covariance matrix:  torch.Size([64, 64])\nshape of centered feature vector:  torch.Size([5000, 64])\nshape of covariance matrix:  torch.Size([64, 64])\nshape of centered feature vector:  torch.Size([5000, 64])\nshape of covariance matrix:  torch.Size([64, 64])\nshape of centered feature vector:  torch.Size([5000, 64])\nshape of covariance matrix:  torch.Size([64, 64])\nshape of centered feature vector:  torch.Size([5000, 64])\nshape of covariance matrix:  torch.Size([64, 64])\nshape of centered feature vector:  torch.Size([5000, 64])\nshape of covariance matrix:  torch.Size([64, 64])\nshape of centered feature vector:  torch.Size([5000, 64])\nshape of covariance matrix:  torch.Size([64, 64])\nshape of centered feature vector:  torch.Size([5000, 64])\nshape of covariance matrix:  torch.Size([64, 64])\n=== Metrics ===\nauroc      0.926789\nfpr95tpr   0.335000\n\n=== Plots ===\n</pre>"},{"location":"notebooks/torch/demo_mahalanobis_torch/#mahalanobis-method","title":"Mahalanobis method\u00b6","text":"<p>This notebook aims at evaluating the Mahalanobis method.</p> <p>Here, we focus on a toy convolutional network trained on MNIST[0-4] and a ResNet20 model trained on CIFAR-10, respectively challenged on MNIST[5-9] and SVHN OOD datasets.</p> <p>Reference A Simple Unified Framework for Detecting Out-of-Distribution Samples and Adversarial Attacks LEE, Kimin, LEE, Kibok, LEE, Honglak, et al. Advances in neural information processing systems, 2018, vol. 31. https://arxiv.org/abs/1807.03888</p>"},{"location":"notebooks/torch/demo_mahalanobis_torch/#imports","title":"Imports\u00b6","text":""},{"location":"notebooks/torch/demo_mahalanobis_torch/#first-exp-mnist0-4-vs-mnist5-9","title":"First exp: MNIST[0-4] vs MNIST[5-9]\u00b6","text":"<p>For this first experiment, we train a toy convolutional network on the MNIST dataset restricted to digits 0 to 4. After fitting the train subset of this dataset to the Mahalanobis method, we will compare the scores returned for MNIST[0-4] (in-distrubtion) and MNIST[5-9] (out-of-distribution) test subsets.</p>"},{"location":"notebooks/torch/demo_mahalanobis_torch/#data-loading","title":"Data loading\u00b6","text":"<ul> <li>In-distribution data: MNIST[0-4]</li> <li>Out-of-distribution data: MNIST[5-9]</li> </ul> <p>Note: We denote In-Distribution (ID) data with <code>_in</code> and Out-Of-Distribution (OOD) data</p> <p>with <code>_out</code> to avoid confusion with OOD detection which is the name of the task, and is therefore used to denote core classes such as <code>OODDataset</code> and <code>OODBaseDetector</code>.</p>"},{"location":"notebooks/torch/demo_mahalanobis_torch/#model-training","title":"Model training\u00b6","text":"<p>Now let's train a simple model on MNIST[0-4] using <code>train_torch_model</code> function.</p>"},{"location":"notebooks/torch/demo_mahalanobis_torch/#mahalanobis-score","title":"Mahalanobis score\u00b6","text":"<p>We now fit a Mahalanobis detector with MNIST[0-4] train dataset, and compare OOD scores returned for MNIST[0-4] (ID) and MNIST[5-9] (OOD) test datasets.</p>"},{"location":"notebooks/torch/demo_mahalanobis_torch/#second-exp-cifar-10-vs-svhn","title":"Second exp: CIFAR-10 vs SVHN\u00b6","text":"<p>For this second experiment, we oppose CIFAR-10 (in-distribution dataset) to SVHN (out-of-distribution dataset).</p>"},{"location":"notebooks/torch/demo_mahalanobis_torch/#data-loading","title":"Data loading\u00b6","text":"<ul> <li>In-distribution data: CIFAR-10</li> <li>Out-of-distribution data: SVHN</li> </ul>"},{"location":"notebooks/torch/demo_mahalanobis_torch/#model-loading","title":"Model loading\u00b6","text":"<p>The model is a ResNet20 pretrained on CIFAR-10 and getting an accuracy score of 92.60%, loaded from pytorch-cifar-models repository.</p>"},{"location":"notebooks/torch/demo_mahalanobis_torch/#mahalanobis-score","title":"Mahalanobis score\u00b6","text":"<p>We now fit a Mahalanobis detector with CIFAR-10 train dataset, and compare OOD scores returned for CIFAR-10 (ID) and SVHN (OOD) test datasets.</p>"},{"location":"notebooks/torch/demo_mls_msp_torch/","title":"MLS/MSP","text":"In\u00a0[1]: Copied! <pre>%load_ext autoreload\n%autoreload 2\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport os\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n\nfrom IPython.display import clear_output\nfrom sklearn.metrics import accuracy_score\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch\nfrom torchvision import transforms\n\nfrom oodeel.methods import MLS\nfrom oodeel.eval.metrics import bench_metrics\nfrom oodeel.eval.plots import plot_ood_scores, plot_roc_curve, plot_2D_features\nfrom oodeel.datasets import OODDataset\nfrom oodeel.utils.torch_training_tools import train_torch_model\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n</pre> %load_ext autoreload %autoreload 2  import warnings warnings.filterwarnings(\"ignore\") import os os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"  from IPython.display import clear_output from sklearn.metrics import accuracy_score import matplotlib.pyplot as plt import numpy as np import torch from torchvision import transforms  from oodeel.methods import MLS from oodeel.eval.metrics import bench_metrics from oodeel.eval.plots import plot_ood_scores, plot_roc_curve, plot_2D_features from oodeel.datasets import OODDataset from oodeel.utils.torch_training_tools import train_torch_model  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") <p>Note that models are saved at ~/.oodeel/saved_models and data is supposed to be found at ~/.oodeel/datasets by default. Change the following cell for a custom path.</p> In\u00a0[2]: Copied! <pre>model_path = os.path.expanduser(\"~/\") + \".oodeel/saved_models\"\ndata_path = os.path.expanduser(\"~/\") + \".oodeel/datasets\"\nos.makedirs(model_path, exist_ok=True)\nos.makedirs(data_path, exist_ok=True)\n</pre> model_path = os.path.expanduser(\"~/\") + \".oodeel/saved_models\" data_path = os.path.expanduser(\"~/\") + \".oodeel/datasets\" os.makedirs(model_path, exist_ok=True) os.makedirs(data_path, exist_ok=True) In\u00a0[3]: Copied! <pre># === load ID and OOD data ===\nbatch_size = 128\nin_labels = [0, 1, 2, 3, 4]\n\n# 1- load train/test MNIST dataset\nmnist_train = OODDataset(\n    dataset_id='MNIST', backend=\"torch\",\n    load_kwargs={\"root\": data_path, \"train\": True, \"download\": True}\n)\nmnist_test = OODDataset(\n    dataset_id='MNIST', backend=\"torch\",\n    load_kwargs={\"root\": data_path, \"train\": False, \"download\": True}\n)\n\n# 2- split ID / OOD data depending on label value:\n# in-distribution: MNIST[0-4] / out-of-distribution: MNIST[5-9]\noods_fit, _ = mnist_train.split_by_class(in_labels=in_labels)\noods_in, oods_out = mnist_test.split_by_class(in_labels=in_labels)\n\n# 3- prepare data (preprocess, shuffle, batch) =&gt; torch dataloaders\ndef preprocess_fn(*inputs):\n\"\"\"Simple preprocessing function to normalize images in [0, 1].\n    \"\"\"\n    x = inputs[0] / 255.0\n    return tuple([x] + list(inputs[1:]))\n\nds_fit = oods_fit.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn, shuffle=True)\nds_in = oods_in.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn)\nds_out = oods_out.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn)\n\nclear_output()\n</pre> # === load ID and OOD data === batch_size = 128 in_labels = [0, 1, 2, 3, 4]  # 1- load train/test MNIST dataset mnist_train = OODDataset(     dataset_id='MNIST', backend=\"torch\",     load_kwargs={\"root\": data_path, \"train\": True, \"download\": True} ) mnist_test = OODDataset(     dataset_id='MNIST', backend=\"torch\",     load_kwargs={\"root\": data_path, \"train\": False, \"download\": True} )  # 2- split ID / OOD data depending on label value: # in-distribution: MNIST[0-4] / out-of-distribution: MNIST[5-9] oods_fit, _ = mnist_train.split_by_class(in_labels=in_labels) oods_in, oods_out = mnist_test.split_by_class(in_labels=in_labels)  # 3- prepare data (preprocess, shuffle, batch) =&gt; torch dataloaders def preprocess_fn(*inputs):     \"\"\"Simple preprocessing function to normalize images in [0, 1].     \"\"\"     x = inputs[0] / 255.0     return tuple([x] + list(inputs[1:]))  ds_fit = oods_fit.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn, shuffle=True) ds_in = oods_in.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn) ds_out = oods_out.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn)  clear_output() In\u00a0[4]: Copied! <pre># === Train / Load model ===\n# model path\nmodel_path_mnist_04 = os.path.join(model_path, \"mnist_model_0-4\")\n\ntry:\n    # if the model exists, load it\n    model = torch.load(os.path.join(model_path_mnist_04, \"best.pt\")).to(device)\nexcept OSError:\n    # else, train a new model\n    train_config = {\n        \"model\": \"toy_convnet\",\n        \"num_classes\": 10,\n        \"epochs\": 5,\n        \"save_dir\": model_path_mnist_04,\n        \"validation_data\": ds_in\n    }\n    model = train_torch_model(ds_fit, **train_config).to(device)\n    clear_output()\n\n# evaluate model\nmodel.eval()\nlabels, preds = [], []\nfor (x, y) in ds_in:\n    x = x.to(device)\n    preds.append(torch.argmax(model(x), dim=-1).detach().cpu())\n    labels.append(y)\nprint(f\"Test accuracy:\\t{accuracy_score(torch.cat(labels), torch.cat(preds)):.6f}\")\n\n# penultimate features 2d visualization\nprint(\"\\n=== Penultimate features viz ===\")\nplt.figure(figsize=(4.5, 3))\nplot_2D_features(\n    model=model,\n    in_dataset=ds_in,\n    out_dataset=ds_out,\n    output_layer_id=-2,\n)\nplt.tight_layout()\nplt.show()\n</pre> # === Train / Load model === # model path model_path_mnist_04 = os.path.join(model_path, \"mnist_model_0-4\")  try:     # if the model exists, load it     model = torch.load(os.path.join(model_path_mnist_04, \"best.pt\")).to(device) except OSError:     # else, train a new model     train_config = {         \"model\": \"toy_convnet\",         \"num_classes\": 10,         \"epochs\": 5,         \"save_dir\": model_path_mnist_04,         \"validation_data\": ds_in     }     model = train_torch_model(ds_fit, **train_config).to(device)     clear_output()  # evaluate model model.eval() labels, preds = [], [] for (x, y) in ds_in:     x = x.to(device)     preds.append(torch.argmax(model(x), dim=-1).detach().cpu())     labels.append(y) print(f\"Test accuracy:\\t{accuracy_score(torch.cat(labels), torch.cat(preds)):.6f}\")  # penultimate features 2d visualization print(\"\\n=== Penultimate features viz ===\") plt.figure(figsize=(4.5, 3)) plot_2D_features(     model=model,     in_dataset=ds_in,     out_dataset=ds_out,     output_layer_id=-2, ) plt.tight_layout() plt.show() <pre>Test accuracy:\t0.995914\n\n=== Penultimate features viz ===\n</pre> In\u00a0[5]: Copied! <pre># === mls scores ===\nmls = MLS()\nmls.fit(model)\nscores_in, _ = mls.score(ds_in)\nscores_out, _ = mls.score(ds_out)\n\n# === metrics ===\n# auroc / fpr95\nmetrics = bench_metrics(\n    (scores_in, scores_out),\n    metrics=[\"auroc\", \"fpr95tpr\"],\n)\nprint(\"=== Metrics ===\")\nfor k, v in metrics.items():\n    print(f\"{k:&lt;10} {v:.6f}\")\n\nprint(\"\\n=== Plots ===\")\n# hists / roc\nplt.figure(figsize=(9, 3))\nplt.subplot(121)\nplot_ood_scores(scores_in, scores_out, log_scale=False)\nplt.subplot(122)\nplot_roc_curve(scores_in, scores_out)\nplt.tight_layout()\nplt.show()\n</pre> # === mls scores === mls = MLS() mls.fit(model) scores_in, _ = mls.score(ds_in) scores_out, _ = mls.score(ds_out)  # === metrics === # auroc / fpr95 metrics = bench_metrics(     (scores_in, scores_out),     metrics=[\"auroc\", \"fpr95tpr\"], ) print(\"=== Metrics ===\") for k, v in metrics.items():     print(f\"{k:&lt;10} {v:.6f}\")  print(\"\\n=== Plots ===\") # hists / roc plt.figure(figsize=(9, 3)) plt.subplot(121) plot_ood_scores(scores_in, scores_out, log_scale=False) plt.subplot(122) plot_roc_curve(scores_in, scores_out) plt.tight_layout() plt.show() <pre>=== Metrics ===\nauroc      0.896637\nfpr95tpr   0.514886\n\n=== Plots ===\n</pre> In\u00a0[6]: Copied! <pre># === msp scores ===\nmsp = MLS(output_activation=\"softmax\")\nmsp.fit(model)\nscores_in, _ = msp.score(ds_in)\nscores_out, _ = msp.score(ds_out)\n\n# === metrics ===\n# auroc / fpr95\nmetrics = bench_metrics(\n    (scores_in, scores_out),\n    metrics=[\"auroc\", \"fpr95tpr\"],\n)\nprint(\"=== Metrics ===\")\nfor k, v in metrics.items():\n    print(f\"{k:&lt;10} {v:.6f}\")\n\nprint(\"\\n=== Plots ===\")\n# Normalize scores for a better hist visualization\nminim = np.min([np.min(scores_in), np.min(scores_out)])\nscores_in_ = scores_in - 2 * minim + np.min(scores_in[np.where(scores_in != minim)])\nscores_out_ = scores_out - 2 * minim + np.min(scores_in[np.where(scores_in != minim)])\n\n# hists / roc\nplt.figure(figsize=(9, 3))\nplt.subplot(121)\nplot_ood_scores(scores_in_, scores_out_, log_scale=True)\nplt.subplot(122)\nplot_roc_curve(scores_in, scores_out)\nplt.tight_layout()\nplt.show()\n</pre> # === msp scores === msp = MLS(output_activation=\"softmax\") msp.fit(model) scores_in, _ = msp.score(ds_in) scores_out, _ = msp.score(ds_out)  # === metrics === # auroc / fpr95 metrics = bench_metrics(     (scores_in, scores_out),     metrics=[\"auroc\", \"fpr95tpr\"], ) print(\"=== Metrics ===\") for k, v in metrics.items():     print(f\"{k:&lt;10} {v:.6f}\")  print(\"\\n=== Plots ===\") # Normalize scores for a better hist visualization minim = np.min([np.min(scores_in), np.min(scores_out)]) scores_in_ = scores_in - 2 * minim + np.min(scores_in[np.where(scores_in != minim)]) scores_out_ = scores_out - 2 * minim + np.min(scores_in[np.where(scores_in != minim)])  # hists / roc plt.figure(figsize=(9, 3)) plt.subplot(121) plot_ood_scores(scores_in_, scores_out_, log_scale=True) plt.subplot(122) plot_roc_curve(scores_in, scores_out) plt.tight_layout() plt.show() <pre>=== Metrics ===\nauroc      0.907393\nfpr95tpr   0.616073\n\n=== Plots ===\n</pre> In\u00a0[7]: Copied! <pre># === load ID and OOD data ===\nbatch_size = 128\n\n# 1a- load in-distribution dataset: CIFAR-10\noods_fit = OODDataset(\n    dataset_id='CIFAR10', backend=\"torch\",\n    load_kwargs={\"root\": data_path, \"train\": True, \"download\": True}\n)\noods_in = OODDataset(\n    dataset_id='CIFAR10', backend=\"torch\",\n    load_kwargs={\"root\": data_path, \"train\": False, \"download\": True}\n)\n# 1b- load out-of-distribution dataset: SVHN\noods_out = OODDataset(\n    dataset_id='SVHN', backend=\"torch\",\n    load_kwargs={\"root\": data_path, \"split\": \"test\", \"download\": True})\n\n\n# 2- prepare data (preprocess, shuffle, batch) =&gt; torch dataloaders\n\ndef preprocess_fn(*inputs):\n\"\"\"Preprocessing function from\n    https://github.com/chenyaofo/pytorch-cifar-models\n    \"\"\"\n    x = inputs[0] / 255.0\n    x = transforms.Normalize(\n        (0.4914, 0.4822, 0.4465),\n        (0.2023, 0.1994, 0.2010)\n    )(x)\n    return tuple([x] + list(inputs[1:]))\n\nds_fit = oods_fit.prepare(batch_size=batch_size, shuffle=True, preprocess_fn=preprocess_fn)\nds_in = oods_in.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn)\nds_out = oods_out.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn)\n\nclear_output()\n</pre> # === load ID and OOD data === batch_size = 128  # 1a- load in-distribution dataset: CIFAR-10 oods_fit = OODDataset(     dataset_id='CIFAR10', backend=\"torch\",     load_kwargs={\"root\": data_path, \"train\": True, \"download\": True} ) oods_in = OODDataset(     dataset_id='CIFAR10', backend=\"torch\",     load_kwargs={\"root\": data_path, \"train\": False, \"download\": True} ) # 1b- load out-of-distribution dataset: SVHN oods_out = OODDataset(     dataset_id='SVHN', backend=\"torch\",     load_kwargs={\"root\": data_path, \"split\": \"test\", \"download\": True})   # 2- prepare data (preprocess, shuffle, batch) =&gt; torch dataloaders  def preprocess_fn(*inputs):     \"\"\"Preprocessing function from     https://github.com/chenyaofo/pytorch-cifar-models     \"\"\"     x = inputs[0] / 255.0     x = transforms.Normalize(         (0.4914, 0.4822, 0.4465),         (0.2023, 0.1994, 0.2010)     )(x)     return tuple([x] + list(inputs[1:]))  ds_fit = oods_fit.prepare(batch_size=batch_size, shuffle=True, preprocess_fn=preprocess_fn) ds_in = oods_in.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn) ds_out = oods_out.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn)  clear_output() In\u00a0[8]: Copied! <pre># === load model ===\n# resnet20 pretrained on CIFAR-10\nmodel = torch.hub.load(\n    repo_or_dir=\"chenyaofo/pytorch-cifar-models\", model=\"cifar10_resnet20\",\n    pretrained=True, verbose=False).to(device)\nmodel.eval();\n\n# evaluate model\nlabels, preds = [], []\nfor (x, y) in ds_in:\n    x = x.to(device)\n    preds.append(torch.argmax(model(x), dim=-1).detach().cpu())\n    labels.append(y)\nprint(f\"Test accuracy:\\t{accuracy_score(torch.cat(labels), torch.cat(preds)):.6f}\")\n\n# penultimate features 2d visualization\nprint(\"\\n=== Penultimate features viz ===\")\nplt.figure(figsize=(4.5, 3))\nplot_2D_features(\n    model=model,\n    in_dataset=ds_in,\n    out_dataset=ds_out,\n    output_layer_id=-2,\n)\nplt.tight_layout()\nplt.show()\n</pre> # === load model === # resnet20 pretrained on CIFAR-10 model = torch.hub.load(     repo_or_dir=\"chenyaofo/pytorch-cifar-models\", model=\"cifar10_resnet20\",     pretrained=True, verbose=False).to(device) model.eval();  # evaluate model labels, preds = [], [] for (x, y) in ds_in:     x = x.to(device)     preds.append(torch.argmax(model(x), dim=-1).detach().cpu())     labels.append(y) print(f\"Test accuracy:\\t{accuracy_score(torch.cat(labels), torch.cat(preds)):.6f}\")  # penultimate features 2d visualization print(\"\\n=== Penultimate features viz ===\") plt.figure(figsize=(4.5, 3)) plot_2D_features(     model=model,     in_dataset=ds_in,     out_dataset=ds_out,     output_layer_id=-2, ) plt.tight_layout() plt.show() <pre>Test accuracy:\t0.926000\n\n=== Penultimate features viz ===\n</pre> In\u00a0[9]: Copied! <pre># === mls scores ===\nmls = MLS()\nmls.fit(model)\nscores_in, _ = mls.score(ds_in)\nscores_out, _ = mls.score(ds_out)\n\n# === metrics ===\n# auroc / fpr95\nmetrics = bench_metrics(\n    (scores_in, scores_out),\n    metrics=[\"auroc\", \"fpr95tpr\"],\n)\nprint(\"=== Metrics ===\")\nfor k, v in metrics.items():\n    print(f\"{k:&lt;10} {v:.6f}\")\n\nprint(\"\\n=== Plots ===\")\n# hists / roc\nplt.figure(figsize=(9, 3))\nplt.subplot(121)\nplot_ood_scores(scores_in, scores_out, log_scale=False)\nplt.subplot(122)\nplot_roc_curve(scores_in, scores_out)\nplt.tight_layout()\nplt.show()\n</pre> # === mls scores === mls = MLS() mls.fit(model) scores_in, _ = mls.score(ds_in) scores_out, _ = mls.score(ds_out)  # === metrics === # auroc / fpr95 metrics = bench_metrics(     (scores_in, scores_out),     metrics=[\"auroc\", \"fpr95tpr\"], ) print(\"=== Metrics ===\") for k, v in metrics.items():     print(f\"{k:&lt;10} {v:.6f}\")  print(\"\\n=== Plots ===\") # hists / roc plt.figure(figsize=(9, 3)) plt.subplot(121) plot_ood_scores(scores_in, scores_out, log_scale=False) plt.subplot(122) plot_roc_curve(scores_in, scores_out) plt.tight_layout() plt.show() <pre>=== Metrics ===\nauroc      0.904943\nfpr95tpr   0.303800\n\n=== Plots ===\n</pre> In\u00a0[10]: Copied! <pre># === msp scores ===\nmsp = MLS(output_activation=\"softmax\")\nmsp.fit(model)\nscores_in, _ = msp.score(ds_in)\nscores_out, _ = msp.score(ds_out)\n\n# === metrics ===\n# auroc / fpr95\nmetrics = bench_metrics(\n    (scores_in, scores_out),\n    metrics=[\"auroc\", \"fpr95tpr\"],\n)\nprint(\"=== Metrics ===\")\nfor k, v in metrics.items():\n    print(f\"{k:&lt;10} {v:.6f}\")\n\nprint(\"\\n=== Plots ===\")\n# Normalize scores for a better hist visualization\nminim = np.min([np.min(scores_in), np.min(scores_out)])\nscores_in_ = scores_in - 2 * minim + np.min(scores_in[np.where(scores_in != minim)])\nscores_out_ = scores_out - 2 * minim + np.min(scores_in[np.where(scores_in != minim)])\n\n# hists / roc\nplt.figure(figsize=(9, 3))\nplt.subplot(121)\nplot_ood_scores(scores_in_, scores_out_, log_scale=True)\nplt.subplot(122)\nplot_roc_curve(scores_in, scores_out)\nplt.tight_layout()\nplt.show()\n</pre> # === msp scores === msp = MLS(output_activation=\"softmax\") msp.fit(model) scores_in, _ = msp.score(ds_in) scores_out, _ = msp.score(ds_out)  # === metrics === # auroc / fpr95 metrics = bench_metrics(     (scores_in, scores_out),     metrics=[\"auroc\", \"fpr95tpr\"], ) print(\"=== Metrics ===\") for k, v in metrics.items():     print(f\"{k:&lt;10} {v:.6f}\")  print(\"\\n=== Plots ===\") # Normalize scores for a better hist visualization minim = np.min([np.min(scores_in), np.min(scores_out)]) scores_in_ = scores_in - 2 * minim + np.min(scores_in[np.where(scores_in != minim)]) scores_out_ = scores_out - 2 * minim + np.min(scores_in[np.where(scores_in != minim)])  # hists / roc plt.figure(figsize=(9, 3)) plt.subplot(121) plot_ood_scores(scores_in_, scores_out_, log_scale=True) plt.subplot(122) plot_roc_curve(scores_in, scores_out) plt.tight_layout() plt.show() <pre>=== Metrics ===\nauroc      0.874827\nfpr95tpr   0.342100\n\n=== Plots ===\n</pre>"},{"location":"notebooks/torch/demo_mls_msp_torch/#maximum-logit-score-maximum-softmax-probability","title":"Maximum Logit Score / Maximum Softmax Probability\u00b6","text":"<p>This notebook aims at evaluating the MLS and MSP methods.</p> <p>These methods return an OOD score based on the maximum value of the output logits or softmax activations.</p> <p>Here, we focus on a toy convolutional network trained on MNIST[0-4] and a ResNet20 model trained on CIFAR-10, respectively challenged on MNIST[5-9] and SVHN OOD datasets.</p> <p>References</p> <ul> <li>MLS: Open-Set Recognition: a Good Closed-Set Classifier is All You Need?, ICLR 2022.</li> <li>MSP: A Baseline for Detecting Misclassified and Out-of-Distribution Examples in Neural Networks, ICLR 2017.</li> </ul>"},{"location":"notebooks/torch/demo_mls_msp_torch/#imports","title":"Imports\u00b6","text":""},{"location":"notebooks/torch/demo_mls_msp_torch/#first-exp-mnist0-4-vs-mnist5-9","title":"First exp: MNIST[0-4] vs MNIST[5-9]\u00b6","text":"<p>For this first experiment, we train a toy convolutional network on the MNIST dataset restricted to digits 0 to 4. After fitting the train subset of this dataset to the MLS method, we will compare the scores returned for MNIST[0-4] (in-distrubtion) and MNIST[5-9] (out-of-distribution) test subsets.</p>"},{"location":"notebooks/torch/demo_mls_msp_torch/#data-loading","title":"Data loading\u00b6","text":"<ul> <li>In-distribution data: MNIST[0-4]</li> <li>Out-of-distribution data: MNIST[5-9]</li> </ul> <p>Note: We denote In-Distribution (ID) data with <code>_in</code> and Out-Of-Distribution (OOD) data</p> <p>with <code>_out</code> to avoid confusion with OOD detection which is the name of the task, and is therefore used to denote core classes such as <code>OODDataset</code> and <code>OODBaseDetector</code>.</p>"},{"location":"notebooks/torch/demo_mls_msp_torch/#model-training","title":"Model training\u00b6","text":"<p>Now let's train a simple model on MNIST[0-4] using <code>train_torch_model</code> function.</p>"},{"location":"notebooks/torch/demo_mls_msp_torch/#mls-score","title":"MLS score\u00b6","text":"<p>We now fit an MLS detector with MNIST[0-4] train dataset, and compare OOD scores returned for MNIST[0-4] (ID) and MNIST[5-9] (OOD) test datasets.</p>"},{"location":"notebooks/torch/demo_mls_msp_torch/#msp-score","title":"MSP score\u00b6","text":"<p>Using the softmax activations instead, we get the MSP scores for MNIST[0-4] (ID) and MNIST[5-9] (OOD) test datasets.</p>"},{"location":"notebooks/torch/demo_mls_msp_torch/#second-exp-cifar-10-vs-svhn","title":"Second exp: CIFAR-10 vs SVHN\u00b6","text":"<p>For this second experiment, we oppose CIFAR-10 (in-distribution dataset) to SVHN (out-of-distribution dataset).</p>"},{"location":"notebooks/torch/demo_mls_msp_torch/#data-loading","title":"Data loading\u00b6","text":"<ul> <li>In-distribution data: CIFAR-10</li> <li>Out-of-distribution data: SVHN</li> </ul>"},{"location":"notebooks/torch/demo_mls_msp_torch/#model-loading","title":"Model loading\u00b6","text":"<p>The model is a ResNet20 pretrained on CIFAR-10 and getting an accuracy score of 92.60%, loaded from pytorch-cifar-models repository.</p>"},{"location":"notebooks/torch/demo_mls_msp_torch/#mls-score","title":"MLS score\u00b6","text":"<p>We now fit an MLS detector with CIFAR-10 train dataset, and compare OOD scores returned for CIFAR-10 (ID) and SVHN (OOD) test datasets.</p>"},{"location":"notebooks/torch/demo_mls_msp_torch/#msp-score","title":"MSP score\u00b6","text":"<p>Using the softmax activations instead, we get the MSP scores for CIFAR-10 (ID) and SVHN (OOD) test datasets.</p>"},{"location":"notebooks/torch/demo_odin_torch/","title":"ODIN","text":"In\u00a0[1]: Copied! <pre>%load_ext autoreload\n%autoreload 2\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport os\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n\nfrom IPython.display import clear_output\nfrom sklearn.metrics import accuracy_score\nimport matplotlib.pyplot as plt\nimport torch\nfrom torchvision import transforms\n\nfrom oodeel.methods import ODIN\nfrom oodeel.eval.metrics import bench_metrics\nfrom oodeel.eval.plots import plot_ood_scores, plot_roc_curve, plot_2D_features\nfrom oodeel.datasets import OODDataset\nfrom oodeel.utils.torch_training_tools import train_torch_model\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n</pre> %load_ext autoreload %autoreload 2  import warnings warnings.filterwarnings(\"ignore\") import os os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"  from IPython.display import clear_output from sklearn.metrics import accuracy_score import matplotlib.pyplot as plt import torch from torchvision import transforms  from oodeel.methods import ODIN from oodeel.eval.metrics import bench_metrics from oodeel.eval.plots import plot_ood_scores, plot_roc_curve, plot_2D_features from oodeel.datasets import OODDataset from oodeel.utils.torch_training_tools import train_torch_model  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") <p>Note that models are saved at ~/.oodeel/saved_models and data is supposed to be found at ~/.oodeel/datasets by default. Change the following cell for a custom path.</p> In\u00a0[2]: Copied! <pre>model_path = os.path.expanduser(\"~/\") + \".oodeel/saved_models\"\ndata_path = os.path.expanduser(\"~/\") + \".oodeel/datasets\"\nos.makedirs(model_path, exist_ok=True)\nos.makedirs(data_path, exist_ok=True)\n</pre> model_path = os.path.expanduser(\"~/\") + \".oodeel/saved_models\" data_path = os.path.expanduser(\"~/\") + \".oodeel/datasets\" os.makedirs(model_path, exist_ok=True) os.makedirs(data_path, exist_ok=True) In\u00a0[3]: Copied! <pre># === load ID and OOD data ===\nbatch_size = 128\nin_labels = [0, 1, 2, 3, 4]\n\n# 1- load train/test MNIST dataset\nmnist_train = OODDataset(\n    dataset_id='MNIST', backend=\"torch\",\n    load_kwargs={\"root\": data_path, \"train\": True, \"download\": True}\n)\nmnist_test = OODDataset(\n    dataset_id='MNIST', backend=\"torch\",\n    load_kwargs={\"root\": data_path, \"train\": False, \"download\": True}\n)\n\n# 2- split ID / OOD data depending on label value:\n# in-distribution: MNIST[0-4] / out-of-distribution: MNIST[5-9]\noods_fit, _ = mnist_train.split_by_class(in_labels=in_labels)\noods_in, oods_out = mnist_test.split_by_class(in_labels=in_labels)\n\n# 3- prepare data (preprocess, shuffle, batch) =&gt; torch dataloaders\ndef preprocess_fn(*inputs):\n\"\"\"Simple preprocessing to normalize images in [0, 1].\n    \"\"\"\n    x = inputs[0] / 255.0\n    return tuple([x] + list(inputs[1:]))\n\nds_fit = oods_fit.prepare(\n    batch_size=batch_size, preprocess_fn=preprocess_fn, shuffle=True\n)\nds_in = oods_in.prepare(\n    batch_size=batch_size, with_ood_labels=False, preprocess_fn=preprocess_fn\n)\nds_out = oods_out.prepare(\n    batch_size=batch_size, with_ood_labels=False, preprocess_fn=preprocess_fn\n)\n\nclear_output()\n</pre> # === load ID and OOD data === batch_size = 128 in_labels = [0, 1, 2, 3, 4]  # 1- load train/test MNIST dataset mnist_train = OODDataset(     dataset_id='MNIST', backend=\"torch\",     load_kwargs={\"root\": data_path, \"train\": True, \"download\": True} ) mnist_test = OODDataset(     dataset_id='MNIST', backend=\"torch\",     load_kwargs={\"root\": data_path, \"train\": False, \"download\": True} )  # 2- split ID / OOD data depending on label value: # in-distribution: MNIST[0-4] / out-of-distribution: MNIST[5-9] oods_fit, _ = mnist_train.split_by_class(in_labels=in_labels) oods_in, oods_out = mnist_test.split_by_class(in_labels=in_labels)  # 3- prepare data (preprocess, shuffle, batch) =&gt; torch dataloaders def preprocess_fn(*inputs):     \"\"\"Simple preprocessing to normalize images in [0, 1].     \"\"\"     x = inputs[0] / 255.0     return tuple([x] + list(inputs[1:]))  ds_fit = oods_fit.prepare(     batch_size=batch_size, preprocess_fn=preprocess_fn, shuffle=True ) ds_in = oods_in.prepare(     batch_size=batch_size, with_ood_labels=False, preprocess_fn=preprocess_fn ) ds_out = oods_out.prepare(     batch_size=batch_size, with_ood_labels=False, preprocess_fn=preprocess_fn )  clear_output() In\u00a0[4]: Copied! <pre># === Train / Load model ===\n# model path\nmodel_path_mnist_04 = os.path.join(model_path, \"mnist_model_0-4\")\n\ntry:\n    # if the model exists, load it\n    model = torch.load(os.path.join(model_path_mnist_04, \"best.pt\")).to(device)\nexcept OSError:\n    # else, train a new model\n    train_config = {\n        \"model\": \"toy_convnet\",\n        \"num_classes\": 10,\n        \"epochs\": 5,\n        \"save_dir\": model_path_mnist_04,\n        \"validation_data\": ds_in\n    }\n    model = train_torch_model(ds_fit, **train_config).to(device)\n    clear_output()\n\n# evaluate model\nmodel.eval()\nlabels, preds = [], []\nfor (x, y) in ds_in:\n    x = x.to(device)\n    preds.append(torch.argmax(model(x), dim=-1).detach().cpu())\n    labels.append(y)\nprint(f\"Test accuracy:\\t{accuracy_score(torch.cat(labels), torch.cat(preds)):.6f}\")\n\n# penultimate features 2d visualization\nprint(\"\\n=== Penultimate features viz ===\")\nplt.figure(figsize=(4.5, 3))\nplot_2D_features(\n    model=model,\n    in_dataset=ds_in,\n    out_dataset=ds_out,\n    output_layer_id=-2,\n)\nplt.tight_layout()\nplt.show()\n</pre> # === Train / Load model === # model path model_path_mnist_04 = os.path.join(model_path, \"mnist_model_0-4\")  try:     # if the model exists, load it     model = torch.load(os.path.join(model_path_mnist_04, \"best.pt\")).to(device) except OSError:     # else, train a new model     train_config = {         \"model\": \"toy_convnet\",         \"num_classes\": 10,         \"epochs\": 5,         \"save_dir\": model_path_mnist_04,         \"validation_data\": ds_in     }     model = train_torch_model(ds_fit, **train_config).to(device)     clear_output()  # evaluate model model.eval() labels, preds = [], [] for (x, y) in ds_in:     x = x.to(device)     preds.append(torch.argmax(model(x), dim=-1).detach().cpu())     labels.append(y) print(f\"Test accuracy:\\t{accuracy_score(torch.cat(labels), torch.cat(preds)):.6f}\")  # penultimate features 2d visualization print(\"\\n=== Penultimate features viz ===\") plt.figure(figsize=(4.5, 3)) plot_2D_features(     model=model,     in_dataset=ds_in,     out_dataset=ds_out,     output_layer_id=-2, ) plt.tight_layout() plt.show() <pre>Test accuracy:\t0.995914\n\n=== Penultimate features viz ===\n</pre> In\u00a0[5]: Copied! <pre># === odin scores ===\nodin = ODIN(temperature=1000)\nodin.fit(model)\nscores_in, _ = odin.score(ds_in)\nscores_out, _ = odin.score(ds_out)\n\n# === metrics ===\n# auroc / fpr95\nmetrics = bench_metrics(\n    (scores_in, scores_out),\n    metrics=[\"auroc\", \"fpr95tpr\"],\n)\nprint(\"=== Metrics ===\")\nfor k, v in metrics.items():\n    print(f\"{k:&lt;10} {v:.6f}\")\n\nprint(\"\\n=== Plots ===\")\n# hists / roc\nplt.figure(figsize=(9, 3))\nplt.subplot(121)\nplot_ood_scores(scores_in, scores_out, log_scale=False)\nplt.subplot(122)\nplot_roc_curve(scores_in, scores_out)\nplt.tight_layout()\nplt.show()\n</pre> # === odin scores === odin = ODIN(temperature=1000) odin.fit(model) scores_in, _ = odin.score(ds_in) scores_out, _ = odin.score(ds_out)  # === metrics === # auroc / fpr95 metrics = bench_metrics(     (scores_in, scores_out),     metrics=[\"auroc\", \"fpr95tpr\"], ) print(\"=== Metrics ===\") for k, v in metrics.items():     print(f\"{k:&lt;10} {v:.6f}\")  print(\"\\n=== Plots ===\") # hists / roc plt.figure(figsize=(9, 3)) plt.subplot(121) plot_ood_scores(scores_in, scores_out, log_scale=False) plt.subplot(122) plot_roc_curve(scores_in, scores_out) plt.tight_layout() plt.show() <pre>=== Metrics ===\nauroc      0.786271\nfpr95tpr   0.631640\n\n=== Plots ===\n</pre> In\u00a0[6]: Copied! <pre># === load ID and OOD data ===\nbatch_size = 128\n\n# 1a- load in-distribution dataset: CIFAR-10\noods_fit = OODDataset(\n    dataset_id='CIFAR10', backend=\"torch\",\n    load_kwargs={\"root\": data_path, \"train\": True, \"download\": True}\n)\noods_in = OODDataset(\n    dataset_id='CIFAR10', backend=\"torch\",\n    load_kwargs={\"root\": data_path, \"train\": False, \"download\": True}\n)\n# 1b- load out-of-distribution dataset: SVHN\noods_out = OODDataset(\n    dataset_id='SVHN', backend=\"torch\",\n    load_kwargs={\"root\": data_path, \"split\": \"test\", \"download\": True})\n\n\n# 2- prepare data (preprocess, shuffle, batch) =&gt; torch dataloaders\n\ndef preprocess_fn(*inputs):\n\"\"\"Preprocessing function from\n    https://github.com/chenyaofo/pytorch-cifar-models\n    \"\"\"\n    x = inputs[0] / 255.0\n    x = transforms.Normalize(\n        (0.4914, 0.4822, 0.4465),\n        (0.2023, 0.1994, 0.2010)\n    )(x)\n    return tuple([x] + list(inputs[1:]))\n\nds_fit = oods_in.prepare(batch_size=batch_size, shuffle=True, preprocess_fn=preprocess_fn)\nds_in = oods_in.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn)\nds_out = oods_out.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn)\n\nclear_output()\n</pre> # === load ID and OOD data === batch_size = 128  # 1a- load in-distribution dataset: CIFAR-10 oods_fit = OODDataset(     dataset_id='CIFAR10', backend=\"torch\",     load_kwargs={\"root\": data_path, \"train\": True, \"download\": True} ) oods_in = OODDataset(     dataset_id='CIFAR10', backend=\"torch\",     load_kwargs={\"root\": data_path, \"train\": False, \"download\": True} ) # 1b- load out-of-distribution dataset: SVHN oods_out = OODDataset(     dataset_id='SVHN', backend=\"torch\",     load_kwargs={\"root\": data_path, \"split\": \"test\", \"download\": True})   # 2- prepare data (preprocess, shuffle, batch) =&gt; torch dataloaders  def preprocess_fn(*inputs):     \"\"\"Preprocessing function from     https://github.com/chenyaofo/pytorch-cifar-models     \"\"\"     x = inputs[0] / 255.0     x = transforms.Normalize(         (0.4914, 0.4822, 0.4465),         (0.2023, 0.1994, 0.2010)     )(x)     return tuple([x] + list(inputs[1:]))  ds_fit = oods_in.prepare(batch_size=batch_size, shuffle=True, preprocess_fn=preprocess_fn) ds_in = oods_in.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn) ds_out = oods_out.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn)  clear_output() In\u00a0[7]: Copied! <pre># === load model ===\n# resnet20 pretrained on CIFAR-10\nmodel = torch.hub.load(\n    repo_or_dir=\"chenyaofo/pytorch-cifar-models\", model=\"cifar10_resnet20\",\n    pretrained=True, verbose=False).to(device)\nmodel.eval();\n\n# evaluate model\nlabels, preds = [], []\nfor (x, y) in ds_in:\n    x = x.to(device)\n    preds.append(torch.argmax(model(x), dim=-1).detach().cpu())\n    labels.append(y)\nprint(f\"Test accuracy:\\t{accuracy_score(torch.cat(labels), torch.cat(preds)):.6f}\")\n\n# penultimate features 2d visualization\nprint(\"\\n=== Penultimate features viz ===\")\nplt.figure(figsize=(4.5, 3))\nplot_2D_features(\n    model=model,\n    in_dataset=ds_in,\n    out_dataset=ds_out,\n    output_layer_id=-2,\n)\nplt.tight_layout()\nplt.show()\n</pre> # === load model === # resnet20 pretrained on CIFAR-10 model = torch.hub.load(     repo_or_dir=\"chenyaofo/pytorch-cifar-models\", model=\"cifar10_resnet20\",     pretrained=True, verbose=False).to(device) model.eval();  # evaluate model labels, preds = [], [] for (x, y) in ds_in:     x = x.to(device)     preds.append(torch.argmax(model(x), dim=-1).detach().cpu())     labels.append(y) print(f\"Test accuracy:\\t{accuracy_score(torch.cat(labels), torch.cat(preds)):.6f}\")  # penultimate features 2d visualization print(\"\\n=== Penultimate features viz ===\") plt.figure(figsize=(4.5, 3)) plot_2D_features(     model=model,     in_dataset=ds_in,     out_dataset=ds_out,     output_layer_id=-2, ) plt.tight_layout() plt.show() <pre>Test accuracy:\t0.926000\n\n=== Penultimate features viz ===\n</pre> In\u00a0[8]: Copied! <pre># === odin scores ===\nodin = ODIN(temperature=1000)\nodin.fit(model)\nscores_in, _ = odin.score(ds_in)\nscores_out, _ = odin.score(ds_out)\n\n# === metrics ===\n# auroc / fpr95\nmetrics = bench_metrics(\n    (scores_in, scores_out),\n    metrics=[\"auroc\", \"fpr95tpr\"],\n)\nprint(\"=== Metrics ===\")\nfor k, v in metrics.items():\n    print(f\"{k:&lt;10} {v:.6f}\")\n\nprint(\"\\n=== Plots ===\")\n# hists / roc\nplt.figure(figsize=(9, 3))\nplt.subplot(121)\nplot_ood_scores(scores_in, scores_out, log_scale=False)\nplt.subplot(122)\nplot_roc_curve(scores_in, scores_out)\nplt.tight_layout()\nplt.show()\n</pre> # === odin scores === odin = ODIN(temperature=1000) odin.fit(model) scores_in, _ = odin.score(ds_in) scores_out, _ = odin.score(ds_out)  # === metrics === # auroc / fpr95 metrics = bench_metrics(     (scores_in, scores_out),     metrics=[\"auroc\", \"fpr95tpr\"], ) print(\"=== Metrics ===\") for k, v in metrics.items():     print(f\"{k:&lt;10} {v:.6f}\")  print(\"\\n=== Plots ===\") # hists / roc plt.figure(figsize=(9, 3)) plt.subplot(121) plot_ood_scores(scores_in, scores_out, log_scale=False) plt.subplot(122) plot_roc_curve(scores_in, scores_out) plt.tight_layout() plt.show() <pre>=== Metrics ===\nauroc      0.872353\nfpr95tpr   0.490100\n\n=== Plots ===\n</pre>"},{"location":"notebooks/torch/demo_odin_torch/#odin-method","title":"ODIN method\u00b6","text":"<p>This notebook aims at evaluating the ODIN method.</p> <p>Here, we focus on a toy convolutional network trained on MNIST[0-4] and a ResNet20 model trained on CIFAR-10, respectively challenged on MNIST[5-9] and SVHN OOD datasets.</p> <p>Reference Enhancing The Reliability of Out-of-distribution Image Detection in Neural Networks Liang, Shiyu and Li, Yixuan and Srikant, R. International Conference on Learning Representations, 2018 https://openreview.net/forum?id=H1VGkIxRZ</p>"},{"location":"notebooks/torch/demo_odin_torch/#imports","title":"Imports\u00b6","text":""},{"location":"notebooks/torch/demo_odin_torch/#first-exp-mnist0-4-vs-mnist5-9","title":"First exp: MNIST[0-4] vs MNIST[5-9]\u00b6","text":"<p>For this first experiment, we train a toy convolutional network on the MNIST dataset restricted to digits 0 to 4. After fitting the train subset of this dataset to the ODIN method, we will compare the scores returned for MNIST[0-4] (in-distrubtion) and MNIST[5-9] (out-of-distribution) test subsets.</p>"},{"location":"notebooks/torch/demo_odin_torch/#data-loading","title":"Data loading\u00b6","text":"<ul> <li>In-distribution data: MNIST[0-4]</li> <li>Out-of-distribution data: MNIST[5-9]</li> </ul> <p>Note: We denote In-Distribution (ID) data with <code>_in</code> and Out-Of-Distribution (OOD) data</p> <p>with <code>_out</code> to avoid confusion with OOD detection which is the name of the task, and is therefore used to denote core classes such as <code>OODDataset</code> and <code>OODBaseDetector</code>.</p>"},{"location":"notebooks/torch/demo_odin_torch/#model-training","title":"Model training\u00b6","text":"<p>Now let's train a simple model on MNIST[0-4] using <code>train_torch_model</code> function.</p>"},{"location":"notebooks/torch/demo_odin_torch/#odin-score","title":"ODIN score\u00b6","text":"<p>We now fit an ODIN detector with MNIST[0-4] train dataset, and compare OOD scores returned for MNIST[0-4] (ID) and MNIST[5-9] (OOD) test datasets.</p>"},{"location":"notebooks/torch/demo_odin_torch/#second-exp-cifar-10-vs-svhn","title":"Second exp: CIFAR-10 vs SVHN\u00b6","text":"<p>For this second experiment, we oppose CIFAR-10 (in-distribution dataset) to SVHN (out-of-distribution dataset).</p>"},{"location":"notebooks/torch/demo_odin_torch/#data-loading","title":"Data loading\u00b6","text":"<ul> <li>In-distribution data: CIFAR-10</li> <li>Out-of-distribution data: SVHN</li> </ul>"},{"location":"notebooks/torch/demo_odin_torch/#model-loading","title":"Model loading\u00b6","text":"<p>The model is a ResNet20 pretrained on CIFAR-10 and getting an accuracy score of 92.60%, loaded from pytorch-cifar-models repository.</p>"},{"location":"notebooks/torch/demo_odin_torch/#odin-score","title":"ODIN score\u00b6","text":"<p>We now fit an ODIN detector with CIFAR-10 train dataset, and compare OOD scores returned for CIFAR-10 (ID) and SVHN (OOD) test datasets.</p>"},{"location":"notebooks/torch/demo_react_torch/","title":"React","text":"In\u00a0[1]: Copied! <pre>%load_ext autoreload\n%autoreload 2\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport os\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n\nfrom IPython.display import clear_output\nfrom sklearn.metrics import accuracy_score\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch\n\nfrom oodeel.methods import MLS, Energy, Entropy, ODIN\nfrom oodeel.eval.metrics import bench_metrics\nfrom oodeel.eval.plots import plot_ood_scores, plot_roc_curve, plot_2D_features\nfrom oodeel.datasets import OODDataset\nfrom oodeel.utils.torch_training_tools import train_torch_model\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n</pre> %load_ext autoreload %autoreload 2  import warnings warnings.filterwarnings(\"ignore\") import os os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"  from IPython.display import clear_output from sklearn.metrics import accuracy_score import matplotlib.pyplot as plt import numpy as np import torch  from oodeel.methods import MLS, Energy, Entropy, ODIN from oodeel.eval.metrics import bench_metrics from oodeel.eval.plots import plot_ood_scores, plot_roc_curve, plot_2D_features from oodeel.datasets import OODDataset from oodeel.utils.torch_training_tools import train_torch_model  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") <p>Note that models are saved at ~/.oodeel/saved_models and data is supposed to be found at ~/.oodeel/datasets by default. Change the following cell for a custom path.</p> In\u00a0[2]: Copied! <pre>model_path = os.path.expanduser(\"~/\") + \".oodeel/saved_models\"\ndata_path = os.path.expanduser(\"~/\") + \".oodeel/datasets\"\nos.makedirs(model_path, exist_ok=True)\nos.makedirs(data_path, exist_ok=True)\n</pre> model_path = os.path.expanduser(\"~/\") + \".oodeel/saved_models\" data_path = os.path.expanduser(\"~/\") + \".oodeel/datasets\" os.makedirs(model_path, exist_ok=True) os.makedirs(data_path, exist_ok=True) In\u00a0[3]: Copied! <pre># === load ID and OOD data ===\nbatch_size = 128\nin_labels = [0, 1, 2, 3, 4]\n\n# 1- load train/test MNIST dataset\nmnist_train = OODDataset(\n    dataset_id='MNIST', backend=\"torch\",\n    load_kwargs={\"root\": data_path, \"train\": True, \"download\": True}\n)\nmnist_test = OODDataset(\n    dataset_id='MNIST', backend=\"torch\",\n    load_kwargs={\"root\": data_path, \"train\": False, \"download\": True}\n)\n\n# 2- split ID / OOD data depending on label value:\n# in-distribution: MNIST[0-4] / out-of-distribution: MNIST[5-9]\noods_fit, _ = mnist_train.split_by_class(in_labels=in_labels)\noods_in, oods_out = mnist_test.split_by_class(in_labels=in_labels)\n\n# 3- prepare data (preprocess, shuffle, batch) =&gt; torch dataloaders\ndef preprocess_fn(*inputs):\n\"\"\"Simple preprocessing to normalize images in [0, 1].\n    \"\"\"\n    x = inputs[0] / 255.0\n    return tuple([x] + list(inputs[1:]))\n\nds_fit = oods_fit.prepare(\n    batch_size=batch_size, preprocess_fn=preprocess_fn, shuffle=True\n)\nds_in = oods_in.prepare(\n    batch_size=batch_size, with_ood_labels=False, preprocess_fn=preprocess_fn\n)\nds_out = oods_out.prepare(\n    batch_size=batch_size, with_ood_labels=False, preprocess_fn=preprocess_fn\n)\n\nclear_output()\n</pre> # === load ID and OOD data === batch_size = 128 in_labels = [0, 1, 2, 3, 4]  # 1- load train/test MNIST dataset mnist_train = OODDataset(     dataset_id='MNIST', backend=\"torch\",     load_kwargs={\"root\": data_path, \"train\": True, \"download\": True} ) mnist_test = OODDataset(     dataset_id='MNIST', backend=\"torch\",     load_kwargs={\"root\": data_path, \"train\": False, \"download\": True} )  # 2- split ID / OOD data depending on label value: # in-distribution: MNIST[0-4] / out-of-distribution: MNIST[5-9] oods_fit, _ = mnist_train.split_by_class(in_labels=in_labels) oods_in, oods_out = mnist_test.split_by_class(in_labels=in_labels)  # 3- prepare data (preprocess, shuffle, batch) =&gt; torch dataloaders def preprocess_fn(*inputs):     \"\"\"Simple preprocessing to normalize images in [0, 1].     \"\"\"     x = inputs[0] / 255.0     return tuple([x] + list(inputs[1:]))  ds_fit = oods_fit.prepare(     batch_size=batch_size, preprocess_fn=preprocess_fn, shuffle=True ) ds_in = oods_in.prepare(     batch_size=batch_size, with_ood_labels=False, preprocess_fn=preprocess_fn ) ds_out = oods_out.prepare(     batch_size=batch_size, with_ood_labels=False, preprocess_fn=preprocess_fn )  clear_output() In\u00a0[4]: Copied! <pre># === Train / Load model ===\n# model path\nmodel_path_mnist_04 = os.path.join(model_path, \"mnist_model_0-4\")\n\ntry:\n    # if the model exists, load it\n    model = torch.load(os.path.join(model_path_mnist_04, \"best.pt\")).to(device)\nexcept OSError:\n    # else, train a new model\n    train_config = {\n        \"model\": \"toy_convnet\",\n        \"num_classes\": 10,\n        \"epochs\": 5,\n        \"save_dir\": model_path_mnist_04,\n        \"validation_data\": ds_in\n    }\n    model = train_torch_model(ds_fit, **train_config).to(device)\n    clear_output()\n\n# evaluate model\nmodel.eval()\nlabels, preds = [], []\nfor (x, y) in ds_in:\n    x = x.to(device)\n    preds.append(torch.argmax(model(x), dim=-1).detach().cpu())\n    labels.append(y)\nprint(f\"Test accuracy:\\t{accuracy_score(torch.cat(labels), torch.cat(preds)):.6f}\")\n\n# penultimate features 2d visualization\nprint(\"\\n=== Penultimate features viz ===\")\nplt.figure(figsize=(4.5, 3))\nplot_2D_features(\n    model=model,\n    in_dataset=ds_in,\n    out_dataset=ds_out,\n    output_layer_id=-2,\n)\nplt.tight_layout()\nplt.show()\n</pre> # === Train / Load model === # model path model_path_mnist_04 = os.path.join(model_path, \"mnist_model_0-4\")  try:     # if the model exists, load it     model = torch.load(os.path.join(model_path_mnist_04, \"best.pt\")).to(device) except OSError:     # else, train a new model     train_config = {         \"model\": \"toy_convnet\",         \"num_classes\": 10,         \"epochs\": 5,         \"save_dir\": model_path_mnist_04,         \"validation_data\": ds_in     }     model = train_torch_model(ds_fit, **train_config).to(device)     clear_output()  # evaluate model model.eval() labels, preds = [], [] for (x, y) in ds_in:     x = x.to(device)     preds.append(torch.argmax(model(x), dim=-1).detach().cpu())     labels.append(y) print(f\"Test accuracy:\\t{accuracy_score(torch.cat(labels), torch.cat(preds)):.6f}\")  # penultimate features 2d visualization print(\"\\n=== Penultimate features viz ===\") plt.figure(figsize=(4.5, 3)) plot_2D_features(     model=model,     in_dataset=ds_in,     out_dataset=ds_out,     output_layer_id=-2, ) plt.tight_layout() plt.show() <pre>Test accuracy:\t0.997665\n\n=== Penultimate features viz ===\n</pre> In\u00a0[5]: Copied! <pre>detectors = {\n    \"odin\": {\n        \"class\": ODIN,\n        \"kwargs\": dict(temperature=1000),\n    },\n    \"mls\": {\n        \"class\": MLS,\n        \"kwargs\": dict(),\n    },\n    \"msp\": {\n        \"class\": MLS,\n        \"kwargs\": dict(output_activation=\"softmax\"),\n    },\n    \"energy\": {\n        \"class\": Energy,\n        \"kwargs\": dict(),\n    },\n    \"entropy\": {\n        \"class\": Entropy,\n        \"kwargs\": dict(),\n    },\n}\n\nfor d in detectors.keys():\n    print(f\"=== {d.upper()} ===\")\n\n    for use_react in [False, True]:\n        print([\"~ Without\", \"~ With\"][int(use_react)] + \" react ~\")\n        # === ood scores ===\n        d_kwargs = detectors[d][\"kwargs\"]\n        d_kwargs.update(dict(\n            use_react=use_react,\n            react_quantile=0.8,\n        ))\n        detector = detectors[d][\"class\"](**d_kwargs)\n        detector.fit(model, fit_dataset=ds_fit)\n        scores_in, _ = detector.score(ds_in)\n        scores_out, _ = detector.score(ds_out)\n\n        # === metrics ===\n        # auroc / fpr95\n        metrics = bench_metrics(\n            (scores_in, scores_out),\n            metrics=[\"auroc\", \"fpr95tpr\"],\n        )\n        for k, v in metrics.items():\n            print(f\"{k:&lt;10} {v:.6f}\")\n\n        log_scale = d in [\"msp\", \"entropy\"]\n        # hists / roc\n        plt.figure(figsize=(9, 3))\n        plt.subplot(121)\n        if d == \"msp\":\n            # Normalize scores for a better hist visualization\n            minim = np.min([np.min(scores_in), np.min(scores_out)])\n            scores_in_ = scores_in - 2 * minim + np.min(scores_in[np.where(scores_in != minim)])\n            scores_out_ = scores_out - 2 * minim + np.min(scores_in[np.where(scores_in != minim)])\n            plot_ood_scores(scores_in_, scores_out_, log_scale=log_scale)\n        else:\n            plot_ood_scores(scores_in, scores_out, log_scale=log_scale)\n        plt.subplot(122)\n        plot_roc_curve(scores_in, scores_out)\n        plt.tight_layout()\n        plt.show()\n</pre> detectors = {     \"odin\": {         \"class\": ODIN,         \"kwargs\": dict(temperature=1000),     },     \"mls\": {         \"class\": MLS,         \"kwargs\": dict(),     },     \"msp\": {         \"class\": MLS,         \"kwargs\": dict(output_activation=\"softmax\"),     },     \"energy\": {         \"class\": Energy,         \"kwargs\": dict(),     },     \"entropy\": {         \"class\": Entropy,         \"kwargs\": dict(),     }, }  for d in detectors.keys():     print(f\"=== {d.upper()} ===\")      for use_react in [False, True]:         print([\"~ Without\", \"~ With\"][int(use_react)] + \" react ~\")         # === ood scores ===         d_kwargs = detectors[d][\"kwargs\"]         d_kwargs.update(dict(             use_react=use_react,             react_quantile=0.8,         ))         detector = detectors[d][\"class\"](**d_kwargs)         detector.fit(model, fit_dataset=ds_fit)         scores_in, _ = detector.score(ds_in)         scores_out, _ = detector.score(ds_out)          # === metrics ===         # auroc / fpr95         metrics = bench_metrics(             (scores_in, scores_out),             metrics=[\"auroc\", \"fpr95tpr\"],         )         for k, v in metrics.items():             print(f\"{k:&lt;10} {v:.6f}\")          log_scale = d in [\"msp\", \"entropy\"]         # hists / roc         plt.figure(figsize=(9, 3))         plt.subplot(121)         if d == \"msp\":             # Normalize scores for a better hist visualization             minim = np.min([np.min(scores_in), np.min(scores_out)])             scores_in_ = scores_in - 2 * minim + np.min(scores_in[np.where(scores_in != minim)])             scores_out_ = scores_out - 2 * minim + np.min(scores_in[np.where(scores_in != minim)])             plot_ood_scores(scores_in_, scores_out_, log_scale=log_scale)         else:             plot_ood_scores(scores_in, scores_out, log_scale=log_scale)         plt.subplot(122)         plot_roc_curve(scores_in, scores_out)         plt.tight_layout()         plt.show() <pre>=== ODIN ===\n~ Without react ~\nauroc      0.815820\nfpr95tpr   0.584939\n</pre> <pre>~ With react ~\nauroc      0.850621\nfpr95tpr   0.458066\n</pre> <pre>=== MLS ===\n~ Without react ~\nauroc      0.934931\nfpr95tpr   0.395018\n</pre> <pre>~ With react ~\nauroc      0.963472\nfpr95tpr   0.171629\n</pre> <pre>=== MSP ===\n~ Without react ~\nauroc      0.937643\nfpr95tpr   0.455925\n</pre> <pre>~ With react ~\nauroc      0.958121\nfpr95tpr   0.182137\n</pre> <pre>=== ENERGY ===\n~ Without react ~\nauroc      0.933363\nfpr95tpr   0.395213\n</pre> <pre>~ With react ~\nauroc      0.960470\nfpr95tpr   0.174742\n</pre> <pre>=== ENTROPY ===\n~ Without react ~\nauroc      0.938045\nfpr95tpr   0.457287\n</pre> <pre>~ With react ~\nauroc      0.960350\nfpr95tpr   0.180191\n</pre>"},{"location":"notebooks/torch/demo_react_torch/#react-method","title":"ReAct method\u00b6","text":"<p>This notebook aims at evaluating the ReAct method.</p> <p>ReAct method basically consists in re-using existing logit-based OOD methods, but with penultimate layer activations clipped to a certain threshold value. In practice, this threshold is set based on the $p$-th percentile of penultimate activations estimated on the ID data.</p> <p>Here, we focus on a toy convolutional network trained on MNIST[0-4] challenged on MNIST[5-9].</p> <p>Reference React: Out-of-distribution detection with rectified activations. Sun, Yiyou, Chuan Guo, and Yixuan Li. Advances in Neural Information Processing Systems 34 (2021) https://arxiv.org/pdf/2111.12797.pdf</p>"},{"location":"notebooks/torch/demo_react_torch/#imports","title":"Imports\u00b6","text":""},{"location":"notebooks/torch/demo_react_torch/#mnist0-4-vs-mnist5-9","title":"MNIST[0-4] vs MNIST[5-9]\u00b6","text":"<p>We train a toy convolutional network on the MNIST dataset restricted to digits 0 to 4. After fitting the train subset of this dataset to different OOD methods with react option enabled, we will compare the scores returned for MNIST[0-4] (in-distrubtion) and MNIST[5-9] (out-of-distribution) test subsets.</p>"},{"location":"notebooks/torch/demo_react_torch/#data-loading","title":"Data loading\u00b6","text":"<ul> <li>In-distribution data: MNIST[0-4]</li> <li>Out-of-distribution data: MNIST[5-9]</li> </ul> <p>Note: We denote In-Distribution (ID) data with <code>_in</code> and Out-Of-Distribution (OOD) data</p> <p>with <code>_out</code> to avoid confusion with OOD detection which is the name of the task, and is therefore used to denote core classes such as <code>OODDataset</code> and <code>OODBaseDetector</code>.</p>"},{"location":"notebooks/torch/demo_react_torch/#model-training","title":"Model training\u00b6","text":"<p>Now let's train a simple model on MNIST[0-4] using <code>train_torch_model</code> function.</p>"},{"location":"notebooks/torch/demo_react_torch/#react-scores","title":"ReAct scores\u00b6","text":"<p>We now fit some OOD detectors using ReAct + [MLS, MSP, Energy, Entropy, ODIN] with MNIST[0-4] train dataset, and compare OOD scores returned for MNIST[0-4] (ID) and MNIST[5-9] (OOD) test datasets.</p>"},{"location":"notebooks/torch/demo_rmds_torch/","title":"RMDS","text":"In\u00a0[1]: Copied! <pre>import sys\nsys.path.append('..\\..')\n</pre> import sys sys.path.append('..\\..') In\u00a0[2]: Copied! <pre>%load_ext autoreload\n%autoreload 2\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport os\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n\nfrom IPython.display import clear_output\nfrom sklearn.metrics import accuracy_score\nimport matplotlib.pyplot as plt\nimport torch\nfrom torchvision import transforms\n\nfrom oodeel.methods import RMDS\nfrom oodeel.eval.metrics import bench_metrics\nfrom oodeel.eval.plots import plot_ood_scores, plot_roc_curve, plot_2D_features\nfrom oodeel.datasets import OODDataset\nfrom oodeel.utils.torch_training_tools import train_torch_model\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n</pre> %load_ext autoreload %autoreload 2  import warnings warnings.filterwarnings(\"ignore\") import os os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"  from IPython.display import clear_output from sklearn.metrics import accuracy_score import matplotlib.pyplot as plt import torch from torchvision import transforms  from oodeel.methods import RMDS from oodeel.eval.metrics import bench_metrics from oodeel.eval.plots import plot_ood_scores, plot_roc_curve, plot_2D_features from oodeel.datasets import OODDataset from oodeel.utils.torch_training_tools import train_torch_model  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") <p>Note that models are saved at ~/.oodeel/saved_models and data is supposed to be found at ~/.oodeel/datasets by default. Change the following cell for a custom path.</p> In\u00a0[3]: Copied! <pre>model_path = os.path.expanduser(\"~/\") + \".oodeel/saved_models\"\ndata_path = os.path.expanduser(\"~/\") + \".oodeel/datasets\"\nos.makedirs(model_path, exist_ok=True)\nos.makedirs(data_path, exist_ok=True)\n</pre> model_path = os.path.expanduser(\"~/\") + \".oodeel/saved_models\" data_path = os.path.expanduser(\"~/\") + \".oodeel/datasets\" os.makedirs(model_path, exist_ok=True) os.makedirs(data_path, exist_ok=True) In\u00a0[4]: Copied! <pre># === load ID and OOD data ===\nbatch_size = 128\nin_labels = [0, 1, 2, 3, 4]\n\n# 1- load train/test MNIST dataset\nmnist_train = OODDataset(\n    dataset_id='MNIST', backend=\"torch\",\n    load_kwargs={\"root\": data_path, \"train\": True, \"download\": True}\n)\nmnist_test = OODDataset(\n    dataset_id='MNIST', backend=\"torch\",\n    load_kwargs={\"root\": data_path, \"train\": False, \"download\": True}\n)\n\n# 2- split ID / OOD data depending on label value:\n# in-distribution: MNIST[0-4] / out-of-distribution: MNIST[5-9]\noods_fit, _ = mnist_train.split_by_class(in_labels=in_labels)\noods_in, oods_out = mnist_test.split_by_class(in_labels=in_labels)\n\n# 3- prepare data (preprocess, shuffle, batch) =&gt; torch dataloaders\ndef preprocess_fn(*inputs):\n\"\"\"Simple preprocessing function to normalize images in [0, 1].\n    \"\"\"\n    x = inputs[0] / 255.0\n    return tuple([x] + list(inputs[1:]))\n\nds_fit = oods_fit.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn, shuffle=True)\nds_in = oods_in.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn)\nds_out = oods_out.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn)\n\nclear_output()\n</pre> # === load ID and OOD data === batch_size = 128 in_labels = [0, 1, 2, 3, 4]  # 1- load train/test MNIST dataset mnist_train = OODDataset(     dataset_id='MNIST', backend=\"torch\",     load_kwargs={\"root\": data_path, \"train\": True, \"download\": True} ) mnist_test = OODDataset(     dataset_id='MNIST', backend=\"torch\",     load_kwargs={\"root\": data_path, \"train\": False, \"download\": True} )  # 2- split ID / OOD data depending on label value: # in-distribution: MNIST[0-4] / out-of-distribution: MNIST[5-9] oods_fit, _ = mnist_train.split_by_class(in_labels=in_labels) oods_in, oods_out = mnist_test.split_by_class(in_labels=in_labels)  # 3- prepare data (preprocess, shuffle, batch) =&gt; torch dataloaders def preprocess_fn(*inputs):     \"\"\"Simple preprocessing function to normalize images in [0, 1].     \"\"\"     x = inputs[0] / 255.0     return tuple([x] + list(inputs[1:]))  ds_fit = oods_fit.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn, shuffle=True) ds_in = oods_in.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn) ds_out = oods_out.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn)  clear_output() In\u00a0[5]: Copied! <pre># === Train / Load model ===\n# model path\nmodel_path_mnist_04 = os.path.join(model_path, \"mnist_model_0-4\")\n\ntry:\n    # if the model exists, load it\n    model = torch.load(os.path.join(model_path_mnist_04, \"best.pt\")).to(device)\nexcept OSError:\n    # else, train a new model\n    train_config = {\n        \"model\": \"toy_convnet\",\n        \"num_classes\": 10,\n        \"epochs\": 5,\n        \"save_dir\": model_path_mnist_04,\n        \"validation_data\": ds_in\n    }\n    model = train_torch_model(ds_fit, **train_config).to(device)\n    clear_output()\n\n# evaluate model\nmodel.eval()\nlabels, preds = [], []\nfor (x, y) in ds_in:\n    x = x.to(device)\n    preds.append(torch.argmax(model(x), dim=-1).detach().cpu())\n    labels.append(y)\nprint(f\"Test accuracy:\\t{accuracy_score(torch.cat(labels), torch.cat(preds)):.6f}\")\n\n# penultimate features 2d visualization\nprint(\"\\n=== Penultimate features viz ===\")\nplt.figure(figsize=(4.5, 3))\nplot_2D_features(\n    model=model,\n    in_dataset=ds_in,\n    out_dataset=ds_out,\n    output_layer_id=-2,\n)\nplt.tight_layout()\nplt.show()\n</pre> # === Train / Load model === # model path model_path_mnist_04 = os.path.join(model_path, \"mnist_model_0-4\")  try:     # if the model exists, load it     model = torch.load(os.path.join(model_path_mnist_04, \"best.pt\")).to(device) except OSError:     # else, train a new model     train_config = {         \"model\": \"toy_convnet\",         \"num_classes\": 10,         \"epochs\": 5,         \"save_dir\": model_path_mnist_04,         \"validation_data\": ds_in     }     model = train_torch_model(ds_fit, **train_config).to(device)     clear_output()  # evaluate model model.eval() labels, preds = [], [] for (x, y) in ds_in:     x = x.to(device)     preds.append(torch.argmax(model(x), dim=-1).detach().cpu())     labels.append(y) print(f\"Test accuracy:\\t{accuracy_score(torch.cat(labels), torch.cat(preds)):.6f}\")  # penultimate features 2d visualization print(\"\\n=== Penultimate features viz ===\") plt.figure(figsize=(4.5, 3)) plot_2D_features(     model=model,     in_dataset=ds_in,     out_dataset=ds_out,     output_layer_id=-2, ) plt.tight_layout() plt.show() <pre>Test accuracy:\t0.996108\n\n=== Penultimate features viz ===\n</pre> In\u00a0[6]: Copied! <pre># === RMDS scores ===\nrmds = RMDS(eps=0.002)\nrmds.fit(model, feature_layers_id=[-2], fit_dataset=ds_fit)\nscores_in, _ = rmds.score(ds_in)\nscores_out, _ = rmds.score(ds_out)\n\n# === metrics ===\n# auroc / fpr95\nmetrics = bench_metrics(\n    (scores_in, scores_out),\n    metrics=[\"auroc\", \"fpr95tpr\"],\n)\nprint(\"=== Metrics ===\")\nfor k, v in metrics.items():\n    print(f\"{k:&lt;10} {v:.6f}\")\n\nprint(\"\\n=== Plots ===\")\n# hists / roc\nplt.figure(figsize=(9, 3))\nplt.subplot(121)\nplot_ood_scores(scores_in, scores_out, log_scale=False)\nplt.subplot(122)\nplot_roc_curve(scores_in, scores_out)\nplt.tight_layout()\nplt.show()\n</pre> # === RMDS scores === rmds = RMDS(eps=0.002) rmds.fit(model, feature_layers_id=[-2], fit_dataset=ds_fit) scores_in, _ = rmds.score(ds_in) scores_out, _ = rmds.score(ds_out)  # === metrics === # auroc / fpr95 metrics = bench_metrics(     (scores_in, scores_out),     metrics=[\"auroc\", \"fpr95tpr\"], ) print(\"=== Metrics ===\") for k, v in metrics.items():     print(f\"{k:&lt;10} {v:.6f}\")  print(\"\\n=== Plots ===\") # hists / roc plt.figure(figsize=(9, 3)) plt.subplot(121) plot_ood_scores(scores_in, scores_out, log_scale=False) plt.subplot(122) plot_roc_curve(scores_in, scores_out) plt.tight_layout() plt.show() <pre>=== Metrics ===\nauroc      0.859574\nfpr95tpr   0.515275\n\n=== Plots ===\n</pre> In\u00a0[7]: Copied! <pre># === load ID and OOD data ===\nbatch_size = 128\n\n# 1a- load in-distribution dataset: CIFAR-10\noods_fit = OODDataset(\n    dataset_id='CIFAR10', backend=\"torch\",\n    load_kwargs={\"root\": data_path, \"train\": True, \"download\": True}\n)\noods_in = OODDataset(\n    dataset_id='CIFAR10', backend=\"torch\",\n    load_kwargs={\"root\": data_path, \"train\": False, \"download\": True}\n)\n# 1b- load out-of-distribution dataset: SVHN\noods_out = OODDataset(\n    dataset_id='SVHN', backend=\"torch\",\n    load_kwargs={\"root\": data_path, \"split\": \"test\", \"download\": True})\n\n\n# 2- prepare data (preprocess, shuffle, batch) =&gt; torch dataloaders\n\ndef preprocess_fn(*inputs):\n\"\"\"Preprocessing function from\n    https://github.com/chenyaofo/pytorch-cifar-models\n    \"\"\"\n    x = inputs[0] / 255.0\n    x = transforms.Normalize(\n        (0.4914, 0.4822, 0.4465),\n        (0.2023, 0.1994, 0.2010)\n    )(x)\n    return tuple([x] + list(inputs[1:]))\n\nds_fit = oods_fit.prepare(batch_size=batch_size, shuffle=True, preprocess_fn=preprocess_fn)\nds_in = oods_in.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn)\nds_out = oods_out.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn)\n\nclear_output()\n</pre> # === load ID and OOD data === batch_size = 128  # 1a- load in-distribution dataset: CIFAR-10 oods_fit = OODDataset(     dataset_id='CIFAR10', backend=\"torch\",     load_kwargs={\"root\": data_path, \"train\": True, \"download\": True} ) oods_in = OODDataset(     dataset_id='CIFAR10', backend=\"torch\",     load_kwargs={\"root\": data_path, \"train\": False, \"download\": True} ) # 1b- load out-of-distribution dataset: SVHN oods_out = OODDataset(     dataset_id='SVHN', backend=\"torch\",     load_kwargs={\"root\": data_path, \"split\": \"test\", \"download\": True})   # 2- prepare data (preprocess, shuffle, batch) =&gt; torch dataloaders  def preprocess_fn(*inputs):     \"\"\"Preprocessing function from     https://github.com/chenyaofo/pytorch-cifar-models     \"\"\"     x = inputs[0] / 255.0     x = transforms.Normalize(         (0.4914, 0.4822, 0.4465),         (0.2023, 0.1994, 0.2010)     )(x)     return tuple([x] + list(inputs[1:]))  ds_fit = oods_fit.prepare(batch_size=batch_size, shuffle=True, preprocess_fn=preprocess_fn) ds_in = oods_in.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn) ds_out = oods_out.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn)  clear_output() In\u00a0[8]: Copied! <pre># === load model ===\n# resnet20 pretrained on CIFAR-10\nmodel = torch.hub.load(\n    repo_or_dir=\"chenyaofo/pytorch-cifar-models\", model=\"cifar10_resnet20\",\n    pretrained=True, verbose=False).to(device)\nmodel.eval();\n\n# evaluate model\nlabels, preds = [], []\nfor (x, y) in ds_in:\n    x = x.to(device)\n    preds.append(torch.argmax(model(x), dim=-1).detach().cpu())\n    labels.append(y)\nprint(f\"Test accuracy:\\t{accuracy_score(torch.cat(labels), torch.cat(preds)):.6f}\")\n\n# penultimate features 2d visualization\nprint(\"\\n=== Penultimate features viz ===\")\nplt.figure(figsize=(4.5, 3))\nplot_2D_features(\n    model=model,\n    in_dataset=ds_in,\n    out_dataset=ds_out,\n    output_layer_id=-2,\n)\nplt.tight_layout()\nplt.show()\n</pre> # === load model === # resnet20 pretrained on CIFAR-10 model = torch.hub.load(     repo_or_dir=\"chenyaofo/pytorch-cifar-models\", model=\"cifar10_resnet20\",     pretrained=True, verbose=False).to(device) model.eval();  # evaluate model labels, preds = [], [] for (x, y) in ds_in:     x = x.to(device)     preds.append(torch.argmax(model(x), dim=-1).detach().cpu())     labels.append(y) print(f\"Test accuracy:\\t{accuracy_score(torch.cat(labels), torch.cat(preds)):.6f}\")  # penultimate features 2d visualization print(\"\\n=== Penultimate features viz ===\") plt.figure(figsize=(4.5, 3)) plot_2D_features(     model=model,     in_dataset=ds_in,     out_dataset=ds_out,     output_layer_id=-2, ) plt.tight_layout() plt.show() <pre>Test accuracy:\t0.926000\n\n=== Penultimate features viz ===\n</pre> In\u00a0[9]: Copied! <pre># === mahalanobis scores ===\nrmds = RMDS(eps=0.002)\nrmds.fit(model, feature_layers_id=[-2], fit_dataset=ds_fit)\nscores_in, _ = rmds.score(ds_in)\nscores_out, _ = rmds.score(ds_out)\n\n# === metrics ===\n# auroc / fpr95\nmetrics = bench_metrics(\n    (scores_in, scores_out),\n    metrics=[\"auroc\", \"fpr95tpr\"],\n)\nprint(\"=== Metrics ===\")\nfor k, v in metrics.items():\n    print(f\"{k:&lt;10} {v:.6f}\")\n\nprint(\"\\n=== Plots ===\")\n# hists / roc\nplt.figure(figsize=(9, 3))\nplt.subplot(121)\nplot_ood_scores(scores_in, scores_out, log_scale=False)\nplt.subplot(122)\nplot_roc_curve(scores_in, scores_out)\nplt.tight_layout()\nplt.show()\n</pre> # === mahalanobis scores === rmds = RMDS(eps=0.002) rmds.fit(model, feature_layers_id=[-2], fit_dataset=ds_fit) scores_in, _ = rmds.score(ds_in) scores_out, _ = rmds.score(ds_out)  # === metrics === # auroc / fpr95 metrics = bench_metrics(     (scores_in, scores_out),     metrics=[\"auroc\", \"fpr95tpr\"], ) print(\"=== Metrics ===\") for k, v in metrics.items():     print(f\"{k:&lt;10} {v:.6f}\")  print(\"\\n=== Plots ===\") # hists / roc plt.figure(figsize=(9, 3)) plt.subplot(121) plot_ood_scores(scores_in, scores_out, log_scale=False) plt.subplot(122) plot_roc_curve(scores_in, scores_out) plt.tight_layout() plt.show() <pre>=== Metrics ===\nauroc      0.882040\nfpr95tpr   0.522200\n\n=== Plots ===\n</pre>"},{"location":"notebooks/torch/demo_rmds_torch/#rmds-method","title":"RMDS method\u00b6","text":"<p>This notebook aims at evaluating the RMDS method.</p> <p>Here, we focus on a toy convolutional network trained on MNIST[0-4] and a ResNet20 model trained on CIFAR-10, respectively challenged on MNIST[5-9] and SVHN OOD datasets.</p> <p>Reference A Simple Fix to Mahalanobis Distance for Improving Near-OOD Detection REN, Jie, FORT, Stanislav, LIU, Jeremiah, et al. preprint https://arxiv.org/abs/2106.09022</p>"},{"location":"notebooks/torch/demo_rmds_torch/#imports","title":"Imports\u00b6","text":""},{"location":"notebooks/torch/demo_rmds_torch/#first-exp-mnist0-4-vs-mnist5-9","title":"First exp: MNIST[0-4] vs MNIST[5-9]\u00b6","text":"<p>For this first experiment, we train a toy convolutional network on the MNIST dataset restricted to digits 0 to 4. After fitting the train subset of this dataset to the Mahalanobis method, we will compare the scores returned for MNIST[0-4] (in-distrubtion) and MNIST[5-9] (out-of-distribution) test subsets.</p>"},{"location":"notebooks/torch/demo_rmds_torch/#data-loading","title":"Data loading\u00b6","text":"<ul> <li>In-distribution data: MNIST[0-4]</li> <li>Out-of-distribution data: MNIST[5-9]</li> </ul> <p>Note: We denote In-Distribution (ID) data with <code>_in</code> and Out-Of-Distribution (OOD) data</p> <p>with <code>_out</code> to avoid confusion with OOD detection which is the name of the task, and is therefore used to denote core classes such as <code>OODDataset</code> and <code>OODBaseDetector</code>.</p>"},{"location":"notebooks/torch/demo_rmds_torch/#model-training","title":"Model training\u00b6","text":"<p>Now let's train a simple model on MNIST[0-4] using <code>train_torch_model</code> function.</p>"},{"location":"notebooks/torch/demo_rmds_torch/#rmds-score","title":"RMDS score\u00b6","text":"<p>We now fit a RMDS detector with MNIST[0-4] train dataset, and compare OOD scores returned for MNIST[0-4] (ID) and MNIST[5-9] (OOD) test datasets.</p>"},{"location":"notebooks/torch/demo_rmds_torch/#second-exp-cifar-10-vs-svhn","title":"Second exp: CIFAR-10 vs SVHN\u00b6","text":"<p>For this second experiment, we oppose CIFAR-10 (in-distribution dataset) to SVHN (out-of-distribution dataset).</p>"},{"location":"notebooks/torch/demo_rmds_torch/#data-loading","title":"Data loading\u00b6","text":"<ul> <li>In-distribution data: CIFAR-10</li> <li>Out-of-distribution data: SVHN</li> </ul>"},{"location":"notebooks/torch/demo_rmds_torch/#model-loading","title":"Model loading\u00b6","text":"<p>The model is a ResNet20 pretrained on CIFAR-10 and getting an accuracy score of 92.60%, loaded from pytorch-cifar-models repository.</p>"},{"location":"notebooks/torch/demo_rmds_torch/#rmds-score","title":"RMDS score\u00b6","text":"<p>We now fit a Mahalanobis detector with CIFAR-10 train dataset, and compare OOD scores returned for CIFAR-10 (ID) and SVHN (OOD) test datasets.</p>"},{"location":"notebooks/torch/demo_scale_torch/","title":"SCALE","text":"In\u00a0[1]: Copied! <pre>%load_ext autoreload\n%autoreload 2\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport os\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n\nfrom IPython.display import clear_output\nfrom sklearn.metrics import accuracy_score\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch\nfrom torchvision import transforms\n\nfrom oodeel.methods import MLS, Energy, ODIN, GEN\nfrom oodeel.eval.metrics import bench_metrics\nfrom oodeel.eval.plots import plot_ood_scores, plot_roc_curve, plot_2D_features\nfrom oodeel.datasets import OODDataset\nfrom oodeel.utils.torch_training_tools import train_torch_model\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n</pre> %load_ext autoreload %autoreload 2  import warnings warnings.filterwarnings(\"ignore\") import os os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"  from IPython.display import clear_output from sklearn.metrics import accuracy_score import matplotlib.pyplot as plt import numpy as np import torch from torchvision import transforms  from oodeel.methods import MLS, Energy, ODIN, GEN from oodeel.eval.metrics import bench_metrics from oodeel.eval.plots import plot_ood_scores, plot_roc_curve, plot_2D_features from oodeel.datasets import OODDataset from oodeel.utils.torch_training_tools import train_torch_model  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") <p>Note that models are saved at ~/.oodeel/saved_models and data is supposed to be found at ~/.oodeel/datasets by default. Change the following cell for a custom path.</p> In\u00a0[2]: Copied! <pre>model_path = os.path.expanduser(\"~/\") + \".oodeel/saved_models\"\ndata_path = os.path.expanduser(\"~/\") + \".oodeel/datasets\"\nos.makedirs(model_path, exist_ok=True)\nos.makedirs(data_path, exist_ok=True)\n</pre> model_path = os.path.expanduser(\"~/\") + \".oodeel/saved_models\" data_path = os.path.expanduser(\"~/\") + \".oodeel/datasets\" os.makedirs(model_path, exist_ok=True) os.makedirs(data_path, exist_ok=True) In\u00a0[3]: Copied! <pre># === load ID and OOD data ===\nbatch_size = 128\n\n# 1a- load in-distribution dataset: CIFAR-10\noods_fit = OODDataset(\n    dataset_id=\"CIFAR10\",\n    backend=\"torch\",\n    load_kwargs={\"root\": data_path, \"train\": True, \"download\": True},\n)\noods_in = OODDataset(\n    dataset_id=\"CIFAR10\",\n    backend=\"torch\",\n    load_kwargs={\"root\": data_path, \"train\": False, \"download\": True},\n)\n# 1b- load out-of-distribution dataset: SVHN\noods_out = OODDataset(\n    dataset_id=\"SVHN\",\n    backend=\"torch\",\n    load_kwargs={\"root\": data_path, \"split\": \"test\", \"download\": True},\n)\n\n\n# 2- prepare data (preprocess, shuffle, batch) =&gt; torch dataloaders\n\n\ndef preprocess_fn(*inputs):\n\"\"\"Preprocessing function from\n    https://github.com/chenyaofo/pytorch-cifar-models\n    \"\"\"\n    x = inputs[0] / 255.0\n    x = transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))(x)\n    return tuple([x] + list(inputs[1:]))\n\n\nds_fit = oods_fit.prepare(\n    batch_size=batch_size, shuffle=True, preprocess_fn=preprocess_fn\n)\nds_in = oods_in.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn)\nds_out = oods_out.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn)\n\nclear_output()\n</pre> # === load ID and OOD data === batch_size = 128  # 1a- load in-distribution dataset: CIFAR-10 oods_fit = OODDataset(     dataset_id=\"CIFAR10\",     backend=\"torch\",     load_kwargs={\"root\": data_path, \"train\": True, \"download\": True}, ) oods_in = OODDataset(     dataset_id=\"CIFAR10\",     backend=\"torch\",     load_kwargs={\"root\": data_path, \"train\": False, \"download\": True}, ) # 1b- load out-of-distribution dataset: SVHN oods_out = OODDataset(     dataset_id=\"SVHN\",     backend=\"torch\",     load_kwargs={\"root\": data_path, \"split\": \"test\", \"download\": True}, )   # 2- prepare data (preprocess, shuffle, batch) =&gt; torch dataloaders   def preprocess_fn(*inputs):     \"\"\"Preprocessing function from     https://github.com/chenyaofo/pytorch-cifar-models     \"\"\"     x = inputs[0] / 255.0     x = transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))(x)     return tuple([x] + list(inputs[1:]))   ds_fit = oods_fit.prepare(     batch_size=batch_size, shuffle=True, preprocess_fn=preprocess_fn ) ds_in = oods_in.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn) ds_out = oods_out.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn)  clear_output() In\u00a0[4]: Copied! <pre># === load model ===\n# resnet20 pretrained on CIFAR-10\nmodel = torch.hub.load(\n    repo_or_dir=\"chenyaofo/pytorch-cifar-models\",\n    model=\"cifar10_resnet20\",\n    pretrained=True,\n    verbose=False,\n).to(device)\nmodel.eval()\n\n# evaluate model\nlabels, preds = [], []\nfor x, y in ds_in:\n    x = x.to(device)\n    preds.append(torch.argmax(model(x), dim=-1).detach().cpu())\n    labels.append(y)\nprint(f\"Test accuracy:\\t{accuracy_score(torch.cat(labels), torch.cat(preds)):.6f}\")\n</pre> # === load model === # resnet20 pretrained on CIFAR-10 model = torch.hub.load(     repo_or_dir=\"chenyaofo/pytorch-cifar-models\",     model=\"cifar10_resnet20\",     pretrained=True,     verbose=False, ).to(device) model.eval()  # evaluate model labels, preds = [], [] for x, y in ds_in:     x = x.to(device)     preds.append(torch.argmax(model(x), dim=-1).detach().cpu())     labels.append(y) print(f\"Test accuracy:\\t{accuracy_score(torch.cat(labels), torch.cat(preds)):.6f}\") <pre>Test accuracy:\t0.925900\n</pre> In\u00a0[5]: Copied! <pre>detectors = {\n    \"odin\": {\n        \"class\": ODIN,\n        \"kwargs\": dict(temperature=1000),\n    },\n    \"mls\": {\n        \"class\": MLS,\n        \"kwargs\": dict(),\n    },\n    \"energy\": {\n        \"class\": Energy,\n        \"kwargs\": dict(),\n    },\n}\n\nfor d in detectors.keys():\n    print(f\"=== {d.upper()} ===\")\n\n    for use_scale in [False, True]:\n        print([\"~ Without\", \"~ With\"][int(use_scale)] + \" SCALE ~\")\n        # === ood scores ===\n        d_kwargs = detectors[d][\"kwargs\"]\n        d_kwargs.update(\n            dict(\n                use_scale=use_scale,\n                scale_percentile=0.85,\n            )\n        )\n        detector = detectors[d][\"class\"](**d_kwargs)\n        detector.fit(model)\n        scores_in, _ = detector.score(ds_in)\n        scores_out, _ = detector.score(ds_out)\n\n        # === metrics ===\n        # auroc / fpr95\n        metrics = bench_metrics(\n            (scores_in, scores_out),\n            metrics=[\"auroc\", \"fpr95tpr\"],\n        )\n        for k, v in metrics.items():\n            print(f\"{k:&lt;10} {v:.6f}\")\n\n        # hists / roc\n        plt.figure(figsize=(9, 3))\n        plt.subplot(121)\n        plot_ood_scores(scores_in, scores_out)\n        plt.subplot(122)\n        plot_roc_curve(scores_in, scores_out)\n        plt.tight_layout()\n        plt.show()\n</pre> detectors = {     \"odin\": {         \"class\": ODIN,         \"kwargs\": dict(temperature=1000),     },     \"mls\": {         \"class\": MLS,         \"kwargs\": dict(),     },     \"energy\": {         \"class\": Energy,         \"kwargs\": dict(),     }, }  for d in detectors.keys():     print(f\"=== {d.upper()} ===\")      for use_scale in [False, True]:         print([\"~ Without\", \"~ With\"][int(use_scale)] + \" SCALE ~\")         # === ood scores ===         d_kwargs = detectors[d][\"kwargs\"]         d_kwargs.update(             dict(                 use_scale=use_scale,                 scale_percentile=0.85,             )         )         detector = detectors[d][\"class\"](**d_kwargs)         detector.fit(model)         scores_in, _ = detector.score(ds_in)         scores_out, _ = detector.score(ds_out)          # === metrics ===         # auroc / fpr95         metrics = bench_metrics(             (scores_in, scores_out),             metrics=[\"auroc\", \"fpr95tpr\"],         )         for k, v in metrics.items():             print(f\"{k:&lt;10} {v:.6f}\")          # hists / roc         plt.figure(figsize=(9, 3))         plt.subplot(121)         plot_ood_scores(scores_in, scores_out)         plt.subplot(122)         plot_roc_curve(scores_in, scores_out)         plt.tight_layout()         plt.show() <pre>=== ODIN ===\n~ Without SCALE ~\nauroc      0.872446\nfpr95tpr   0.489400\n</pre> <pre>~ With SCALE ~\nauroc      0.574931\nfpr95tpr   0.847300\n</pre> <pre>=== MLS ===\n~ Without SCALE ~\nauroc      0.904973\nfpr95tpr   0.303800\n</pre> <pre>~ With SCALE ~\nauroc      0.635033\nfpr95tpr   0.845700\n</pre> <pre>=== ENERGY ===\n~ Without SCALE ~\nauroc      0.906344\nfpr95tpr   0.302700\n</pre> <pre>~ With SCALE ~\nauroc      0.634927\nfpr95tpr   0.845700\n</pre>"},{"location":"notebooks/torch/demo_scale_torch/#scale-method","title":"SCALE method\u00b6","text":"<p>This notebook aims at evaluating the SCALE method.</p> <p>SCALE method basically consists in re-using existing logit-based OOD methods, but with penultimate layer activations scaled. Let $a$ be the activation vector, and $P_p(a)$ the $p$-th percentile of $a$'s values. The scaling is computed using the formula $$ s = \\exp(\\frac{\\sum_{i} a_i}{\\sum_{a_i &gt; P_p(a)} a_i}) $$</p> <p>Here, we focus on a Resnet trained on CIFAR10, challenged on SVHN.</p> <p>Reference Scaling for Training Time and Post-hoc Out-of-distribution Detection Enhancement, ICLR 2024 http://arxiv.org/abs/2310.00227</p>"},{"location":"notebooks/torch/demo_scale_torch/#imports","title":"Imports\u00b6","text":""},{"location":"notebooks/torch/demo_scale_torch/#data-loading","title":"Data loading\u00b6","text":"<ul> <li>In-distribution data: CIFAR-10</li> <li>Out-of-distribution data: SVHN</li> </ul> <p>Note: We denote In-Distribution (ID) data with <code>_in</code> and Out-Of-Distribution (OOD) data</p> <p>with <code>_out</code> to avoid confusion with OOD detection which is the name of the task, and is therefore used to denote core classes such as <code>OODDataset</code> and <code>OODBaseDetector</code>.</p>"},{"location":"notebooks/torch/demo_scale_torch/#model-training","title":"Model training\u00b6","text":"<p>Now let's train a simple model on MNIST[0-4] using <code>train_torch_model</code> function.</p>"},{"location":"notebooks/torch/demo_scale_torch/#scale-scores","title":"SCALE scores\u00b6","text":"<p>We now fit some OOD detectors using SCALE + [MLS, MSP, Energy, Entropy, ODIN] with MNIST[0-4] train dataset, and compare OOD scores returned for MNIST[0-4] (ID) and MNIST[5-9] (OOD) test datasets.</p>"},{"location":"notebooks/torch/demo_she_torch/","title":"SHE","text":"In\u00a0[1]: Copied! <pre>%load_ext autoreload\n%autoreload 2\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport os\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n\nfrom IPython.display import clear_output\nfrom sklearn.metrics import accuracy_score\nimport matplotlib.pyplot as plt\nimport torch\nfrom torchvision import transforms\nimport numpy as np\n\nfrom oodeel.methods import SHE\nfrom oodeel.eval.metrics import bench_metrics\nfrom oodeel.eval.plots import plot_ood_scores, plot_roc_curve, plot_2D_features\nfrom oodeel.datasets import OODDataset\nfrom oodeel.utils.torch_training_tools import train_torch_model\nfrom oodeel.preprocess import TorchRandomPatchPermutation\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n</pre> %load_ext autoreload %autoreload 2  import warnings warnings.filterwarnings(\"ignore\") import os os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\" os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"  from IPython.display import clear_output from sklearn.metrics import accuracy_score import matplotlib.pyplot as plt import torch from torchvision import transforms import numpy as np  from oodeel.methods import SHE from oodeel.eval.metrics import bench_metrics from oodeel.eval.plots import plot_ood_scores, plot_roc_curve, plot_2D_features from oodeel.datasets import OODDataset from oodeel.utils.torch_training_tools import train_torch_model from oodeel.preprocess import TorchRandomPatchPermutation  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") <p>Note that models are saved at ~/.oodeel/saved_models and data is supposed to be found at ~/.oodeel/datasets by default. Change the following cell for a custom path.</p> In\u00a0[2]: Copied! <pre>model_path = os.path.expanduser(\"~/\") + \".oodeel/saved_models\"\ndata_path = os.path.expanduser(\"~/\") + \".oodeel/datasets\"\nos.makedirs(model_path, exist_ok=True)\nos.makedirs(data_path, exist_ok=True)\n</pre> model_path = os.path.expanduser(\"~/\") + \".oodeel/saved_models\" data_path = os.path.expanduser(\"~/\") + \".oodeel/datasets\" os.makedirs(model_path, exist_ok=True) os.makedirs(data_path, exist_ok=True) In\u00a0[3]: Copied! <pre># === load ID and OOD data ===\nbatch_size = 128\nin_labels = [0, 1, 2, 3, 4]\n\n# 1- load train/test MNIST dataset\nmnist_train = OODDataset(\n    dataset_id=\"MNIST\",\n    backend=\"torch\",\n    load_kwargs={\"root\": data_path, \"train\": True, \"download\": True},\n)\nmnist_test = OODDataset(\n    dataset_id=\"MNIST\",\n    backend=\"torch\",\n    load_kwargs={\"root\": data_path, \"train\": False, \"download\": True},\n)\n\n# 2- split ID / OOD data depending on label value:\n# in-distribution: MNIST[0-4] / out-of-distribution: MNIST[5-9]\noods_fit, _ = mnist_train.split_by_class(in_labels=in_labels)\noods_in, oods_out = mnist_test.split_by_class(in_labels=in_labels)\n\n\n# 3- prepare data (preprocess, shuffle, batch) =&gt; torch dataloaders\ndef preprocess_fn(*inputs):\n\"\"\"Simple preprocessing function to normalize images in [0, 1].\"\"\"\n    x = inputs[0] / 255.0\n    return tuple([x] + list(inputs[1:]))\n\n\nds_fit = oods_fit.prepare(\n    batch_size=batch_size, preprocess_fn=preprocess_fn, shuffle=True\n)\nds_in = oods_in.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn)\nds_out = oods_out.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn)\n\nclear_output()\n</pre> # === load ID and OOD data === batch_size = 128 in_labels = [0, 1, 2, 3, 4]  # 1- load train/test MNIST dataset mnist_train = OODDataset(     dataset_id=\"MNIST\",     backend=\"torch\",     load_kwargs={\"root\": data_path, \"train\": True, \"download\": True}, ) mnist_test = OODDataset(     dataset_id=\"MNIST\",     backend=\"torch\",     load_kwargs={\"root\": data_path, \"train\": False, \"download\": True}, )  # 2- split ID / OOD data depending on label value: # in-distribution: MNIST[0-4] / out-of-distribution: MNIST[5-9] oods_fit, _ = mnist_train.split_by_class(in_labels=in_labels) oods_in, oods_out = mnist_test.split_by_class(in_labels=in_labels)   # 3- prepare data (preprocess, shuffle, batch) =&gt; torch dataloaders def preprocess_fn(*inputs):     \"\"\"Simple preprocessing function to normalize images in [0, 1].\"\"\"     x = inputs[0] / 255.0     return tuple([x] + list(inputs[1:]))   ds_fit = oods_fit.prepare(     batch_size=batch_size, preprocess_fn=preprocess_fn, shuffle=True ) ds_in = oods_in.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn) ds_out = oods_out.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn)  clear_output() In\u00a0[4]: Copied! <pre># === Train / Load model ===\n# model path\nmodel_path_mnist_04 = os.path.join(model_path, \"mnist_mlp_0-4\")\n\ntry:\n    # if the model exists, load it\n    model = torch.load(os.path.join(model_path_mnist_04, \"best.pt\")).to(device)\nexcept OSError:\n    # else, train a new model\n    train_config = {\n        \"model\": \"toy_mlp\",\n        \"num_classes\": 10,\n        \"epochs\": 5,\n        \"save_dir\": model_path_mnist_04,\n        \"validation_data\": ds_in,\n    }\n    model = train_torch_model(ds_fit, **train_config).to(device)\n    clear_output()\n\n# evaluate model\nmodel.eval()\nlabels, preds = [], []\nfor x, y in ds_in:\n    x = x.to(device)\n    preds.append(torch.argmax(model(x), dim=-1).detach().cpu())\n    labels.append(y)\nprint(f\"Test accuracy:\\t{accuracy_score(torch.cat(labels), torch.cat(preds)):.6f}\")\n\n# penultimate features 2d visualization\nprint(\"\\n=== Penultimate features viz ===\")\nplt.figure(figsize=(4.5, 3))\nplot_2D_features(\n    model=model,\n    in_dataset=ds_in,\n    out_dataset=ds_out,\n    output_layer_id=-2,\n)\nplt.tight_layout()\nplt.show()\n</pre> # === Train / Load model === # model path model_path_mnist_04 = os.path.join(model_path, \"mnist_mlp_0-4\")  try:     # if the model exists, load it     model = torch.load(os.path.join(model_path_mnist_04, \"best.pt\")).to(device) except OSError:     # else, train a new model     train_config = {         \"model\": \"toy_mlp\",         \"num_classes\": 10,         \"epochs\": 5,         \"save_dir\": model_path_mnist_04,         \"validation_data\": ds_in,     }     model = train_torch_model(ds_fit, **train_config).to(device)     clear_output()  # evaluate model model.eval() labels, preds = [], [] for x, y in ds_in:     x = x.to(device)     preds.append(torch.argmax(model(x), dim=-1).detach().cpu())     labels.append(y) print(f\"Test accuracy:\\t{accuracy_score(torch.cat(labels), torch.cat(preds)):.6f}\")  # penultimate features 2d visualization print(\"\\n=== Penultimate features viz ===\") plt.figure(figsize=(4.5, 3)) plot_2D_features(     model=model,     in_dataset=ds_in,     out_dataset=ds_out,     output_layer_id=-2, ) plt.tight_layout() plt.show() <pre>Test accuracy:\t0.991438\n\n=== Penultimate features viz ===\n</pre> In\u00a0[5]: Copied! <pre>%autoreload 2\n\n# === gram scores ===\nshe = SHE()\nshe.fit(model, ds_fit, feature_layers_id=[\"relu1\", \"relu2\"])\nscores_in, _ = she.score(ds_in)\nscores_out, _ = she.score(ds_out)\n\n# === metrics ===\n# auroc / fpr95\nmetrics = bench_metrics(\n    (scores_in, scores_out),\n    metrics=[\"auroc\", \"fpr95tpr\"],\n)\nprint(\"=== Metrics ===\")\nfor k, v in metrics.items():\n    print(f\"{k:&lt;10} {v:.6f}\")\n</pre> %autoreload 2  # === gram scores === she = SHE() she.fit(model, ds_fit, feature_layers_id=[\"relu1\", \"relu2\"]) scores_in, _ = she.score(ds_in) scores_out, _ = she.score(ds_out)  # === metrics === # auroc / fpr95 metrics = bench_metrics(     (scores_in, scores_out),     metrics=[\"auroc\", \"fpr95tpr\"], ) print(\"=== Metrics ===\") for k, v in metrics.items():     print(f\"{k:&lt;10} {v:.6f}\") <pre>=== Metrics ===\nauroc      0.736096\nfpr95tpr   0.645845\n</pre> In\u00a0[6]: Copied! <pre>print(\"\\n=== Plots ===\")\n# hists / roc\nplt.figure(figsize=(9, 3))\nplt.subplot(121)\nplot_ood_scores(scores_in, scores_out)\nplt.subplot(122)\nplot_roc_curve(scores_in, scores_out)\nplt.tight_layout()\nplt.show()\n</pre> print(\"\\n=== Plots ===\") # hists / roc plt.figure(figsize=(9, 3)) plt.subplot(121) plot_ood_scores(scores_in, scores_out) plt.subplot(122) plot_roc_curve(scores_in, scores_out) plt.tight_layout() plt.show() <pre>\n=== Plots ===\n</pre> In\u00a0[7]: Copied! <pre># === load ID and OOD data ===\nbatch_size = 128\n\n# 1a- load in-distribution dataset: CIFAR-10\noods_fit = OODDataset(\n    dataset_id=\"CIFAR10\",\n    backend=\"torch\",\n    load_kwargs={\"root\": data_path, \"train\": True, \"download\": True},\n)\noods_in = OODDataset(\n    dataset_id=\"CIFAR10\",\n    backend=\"torch\",\n    load_kwargs={\"root\": data_path, \"train\": False, \"download\": True},\n)\n# 1b- load out-of-distribution dataset: SVHN\noods_out = OODDataset(\n    dataset_id=\"SVHN\",\n    backend=\"torch\",\n    load_kwargs={\"root\": data_path, \"split\": \"test\", \"download\": True},\n)\n\n\n# 2- prepare data (preprocess, shuffle, batch) =&gt; torch dataloaders\n\n\ndef preprocess_fn(*inputs):\n\"\"\"Preprocessing function from\n    https://github.com/chenyaofo/pytorch-cifar-models\n    \"\"\"\n    x = inputs[0] / 255.0\n    x = transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))(x)\n    return tuple([x] + list(inputs[1:]))\n\n\npatch_permutation = TorchRandomPatchPermutation(patch_size=(4, 4))\n\n\ndef preprocess_fn_ood(*inputs):\n\"\"\"Simple preprocessing function to normalize images in [0, 1].\"\"\"\n    x = inputs[0] / 255.0\n    x = patch_permutation(x)\n    return tuple([x] + list(inputs[1:]))\n\n\nds_fit = oods_fit.prepare(\n    batch_size=batch_size, preprocess_fn=preprocess_fn, shuffle=True\n)\nds_fit_ood = oods_fit.prepare(\n    batch_size=batch_size, preprocess_fn=preprocess_fn_ood, shuffle=True\n)\nds_in = oods_in.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn)\nds_out = oods_out.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn)\n\nclear_output()\n</pre> # === load ID and OOD data === batch_size = 128  # 1a- load in-distribution dataset: CIFAR-10 oods_fit = OODDataset(     dataset_id=\"CIFAR10\",     backend=\"torch\",     load_kwargs={\"root\": data_path, \"train\": True, \"download\": True}, ) oods_in = OODDataset(     dataset_id=\"CIFAR10\",     backend=\"torch\",     load_kwargs={\"root\": data_path, \"train\": False, \"download\": True}, ) # 1b- load out-of-distribution dataset: SVHN oods_out = OODDataset(     dataset_id=\"SVHN\",     backend=\"torch\",     load_kwargs={\"root\": data_path, \"split\": \"test\", \"download\": True}, )   # 2- prepare data (preprocess, shuffle, batch) =&gt; torch dataloaders   def preprocess_fn(*inputs):     \"\"\"Preprocessing function from     https://github.com/chenyaofo/pytorch-cifar-models     \"\"\"     x = inputs[0] / 255.0     x = transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))(x)     return tuple([x] + list(inputs[1:]))   patch_permutation = TorchRandomPatchPermutation(patch_size=(4, 4))   def preprocess_fn_ood(*inputs):     \"\"\"Simple preprocessing function to normalize images in [0, 1].\"\"\"     x = inputs[0] / 255.0     x = patch_permutation(x)     return tuple([x] + list(inputs[1:]))   ds_fit = oods_fit.prepare(     batch_size=batch_size, preprocess_fn=preprocess_fn, shuffle=True ) ds_fit_ood = oods_fit.prepare(     batch_size=batch_size, preprocess_fn=preprocess_fn_ood, shuffle=True ) ds_in = oods_in.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn) ds_out = oods_out.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn)  clear_output() In\u00a0[8]: Copied! <pre># === load model ===\n# resnet20 pretrained on CIFAR-10\nmodel = torch.hub.load(\n    repo_or_dir=\"chenyaofo/pytorch-cifar-models\",\n    model=\"cifar10_resnet20\",\n    pretrained=True,\n    verbose=False,\n).to(device)\nmodel.eval()\nclear_output()\n</pre> # === load model === # resnet20 pretrained on CIFAR-10 model = torch.hub.load(     repo_or_dir=\"chenyaofo/pytorch-cifar-models\",     model=\"cifar10_resnet20\",     pretrained=True,     verbose=False, ).to(device) model.eval() clear_output() In\u00a0[9]: Copied! <pre># evaluate model\nlabels, preds = [], []\nfor x, y in ds_in:\n    x = x.to(device)\n    preds.append(torch.argmax(model(x), dim=-1).detach().cpu())\n    labels.append(y)\nprint(f\"Test accuracy:\\t{accuracy_score(torch.cat(labels), torch.cat(preds)):.6f}\")\n\n# penultimate features 2d visualization\nprint(\"\\n=== Penultimate features viz ===\")\nplt.figure(figsize=(4.5, 3))\nplot_2D_features(\n    model=model,\n    in_dataset=ds_in,\n    out_dataset=ds_out,\n    output_layer_id=-2,\n)\nplt.tight_layout()\nplt.show()\n</pre> # evaluate model labels, preds = [], [] for x, y in ds_in:     x = x.to(device)     preds.append(torch.argmax(model(x), dim=-1).detach().cpu())     labels.append(y) print(f\"Test accuracy:\\t{accuracy_score(torch.cat(labels), torch.cat(preds)):.6f}\")  # penultimate features 2d visualization print(\"\\n=== Penultimate features viz ===\") plt.figure(figsize=(4.5, 3)) plot_2D_features(     model=model,     in_dataset=ds_in,     out_dataset=ds_out,     output_layer_id=-2, ) plt.tight_layout() plt.show() <pre>Test accuracy:\t0.925900\n\n=== Penultimate features viz ===\n</pre> In\u00a0[10]: Copied! <pre>%autoreload 2\n\n# === gram scores ===\nshe = SHE()\nshe.fit(model, ds_fit, feature_layers_id=[\"layer1.2.conv2\", \"layer2.2.conv2\", \"layer3.2.conv2\"])\n\nscores_in, _ = she.score(ds_in)\nscores_out, _ = she.score(ds_out)\n</pre> %autoreload 2  # === gram scores === she = SHE() she.fit(model, ds_fit, feature_layers_id=[\"layer1.2.conv2\", \"layer2.2.conv2\", \"layer3.2.conv2\"])  scores_in, _ = she.score(ds_in) scores_out, _ = she.score(ds_out) In\u00a0[12]: Copied! <pre># === metrics ===\n# auroc / fpr95\nmetrics = bench_metrics(\n    (scores_in, scores_out),\n    metrics=[\"auroc\", \"fpr95tpr\"],\n)\nprint(\"=== Metrics ===\")\nfor k, v in metrics.items():\n    print(f\"{k:&lt;10} {v:.6f}\")\n\nprint(\"\\n=== Plots ===\")\n# hists / roc\nplt.figure(figsize=(9, 3))\nplt.subplot(121)\nplot_ood_scores(scores_in, scores_out)\nplt.subplot(122)\nplot_roc_curve(scores_in, scores_out)\nplt.tight_layout()\nplt.show()\n</pre> # === metrics === # auroc / fpr95 metrics = bench_metrics(     (scores_in, scores_out),     metrics=[\"auroc\", \"fpr95tpr\"], ) print(\"=== Metrics ===\") for k, v in metrics.items():     print(f\"{k:&lt;10} {v:.6f}\")  print(\"\\n=== Plots ===\") # hists / roc plt.figure(figsize=(9, 3)) plt.subplot(121) plot_ood_scores(scores_in, scores_out) plt.subplot(122) plot_roc_curve(scores_in, scores_out) plt.tight_layout() plt.show() <pre>=== Metrics ===\nauroc      0.990859\nfpr95tpr   0.040200\n\n=== Plots ===\n</pre>"},{"location":"notebooks/torch/demo_she_torch/#she-simplified-hopfield-energy-method","title":"SHE (Simplified Hopfield Energy) method\u00b6","text":"<p>This method first computes the mean of the internal layer representation of ID data for each ID class. This mean is seen as the average of the ID activation patterns as defined in the original paper. The method then returns the maximum value of the dot product between the internal layer representation of the input and the average patterns, which is a simplified version of Hopfield energy as defined in the original paper.</p> <p>Reference Out-of-Distribution Detection based on In-Distribution Data Patterns Memorization with Modern Hopfield Energy, ICLR 2023</p>"},{"location":"notebooks/torch/demo_she_torch/#imports","title":"Imports\u00b6","text":""},{"location":"notebooks/torch/demo_she_torch/#first-exp-mnist0-4-vs-mnist5-9","title":"First exp: MNIST[0-4] vs MNIST[5-9]\u00b6","text":"<p>For this first experiment, we train a toy convolutional network on the MNIST dataset restricted to digits 0 to 4. After fitting the train subset of this dataset to the Gram method, we will compare the scores returned for MNIST[0-4] (in-distrubtion) and MNIST[5-9] (out-of-distribution) test subsets.</p>"},{"location":"notebooks/torch/demo_she_torch/#data-loading","title":"Data loading\u00b6","text":"<ul> <li>In-distribution data: MNIST[0-4]</li> <li>Out-of-distribution data: MNIST[5-9]</li> </ul> <p>Note: We denote In-Distribution (ID) data with <code>_in</code> and Out-Of-Distribution (OOD) data with <code>_out</code> to avoid confusion with OOD detection which is the name of the task, and is therefore used to denote core classes such as <code>OODDataset</code> and <code>OODBaseDetector</code>.</p>"},{"location":"notebooks/torch/demo_she_torch/#model-training","title":"Model training\u00b6","text":"<p>Now let's train a simple model on MNIST[0-4] using <code>train_torch_model</code> function.</p>"},{"location":"notebooks/torch/demo_she_torch/#she-score","title":"SHE score\u00b6","text":"<p>We now fit a SHE detector with MNIST[0-4] train dataset, and compare OOD scores returned for MNIST[0-4] (ID) and MNIST[5-9] (OOD) test datasets.</p>"},{"location":"notebooks/torch/demo_she_torch/#second-exp-cifar-10-vs-svhn","title":"Second exp: CIFAR-10 vs SVHN\u00b6","text":"<p>For this second experiment, we oppose CIFAR-10 (in-distribution dataset) to SVHN (out-of-distribution dataset).</p>"},{"location":"notebooks/torch/demo_she_torch/#data-loading","title":"Data loading\u00b6","text":"<ul> <li>In-distribution data: CIFAR-10</li> <li>Out-of-distribution data: SVHN</li> </ul>"},{"location":"notebooks/torch/demo_she_torch/#model-loading","title":"Model loading\u00b6","text":"<p>The model is a ResNet20 pretrained on CIFAR-10 and getting an accuracy score of 92.60%, loaded from pytorch-cifar-models repository.</p>"},{"location":"notebooks/torch/demo_she_torch/#she-score","title":"SHE score\u00b6","text":"<p>We now fit a SHE detector with CIFAR-10 train dataset, and compare OOD scores returned for CIFAR-10 (ID) and SVHN (OOD) test datasets.</p>"},{"location":"notebooks/torch/demo_vim_torch/","title":"VIM","text":"In\u00a0[1]: Copied! <pre>%load_ext autoreload\n%autoreload 2\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport os\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n\nfrom IPython.display import clear_output\nfrom sklearn.metrics import accuracy_score\nimport matplotlib.pyplot as plt\nimport torch\nfrom torchvision import transforms\n\nfrom oodeel.methods import VIM\nfrom oodeel.eval.metrics import bench_metrics\nfrom oodeel.eval.plots import plot_ood_scores, plot_roc_curve, plot_2D_features\nfrom oodeel.datasets import OODDataset\nfrom oodeel.utils.torch_training_tools import train_torch_model\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n</pre> %load_ext autoreload %autoreload 2  import warnings warnings.filterwarnings(\"ignore\") import os os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"  from IPython.display import clear_output from sklearn.metrics import accuracy_score import matplotlib.pyplot as plt import torch from torchvision import transforms  from oodeel.methods import VIM from oodeel.eval.metrics import bench_metrics from oodeel.eval.plots import plot_ood_scores, plot_roc_curve, plot_2D_features from oodeel.datasets import OODDataset from oodeel.utils.torch_training_tools import train_torch_model  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") <p>Note that models are saved at ~/.oodeel/saved_models and data is supposed to be found at ~/.oodeel/datasets by default. Change the following cell for a custom path.</p> In\u00a0[2]: Copied! <pre>model_path = os.path.expanduser(\"~/\") + \".oodeel/saved_models\"\ndata_path = os.path.expanduser(\"~/\") + \".oodeel/datasets\"\nos.makedirs(model_path, exist_ok=True)\nos.makedirs(data_path, exist_ok=True)\n</pre> model_path = os.path.expanduser(\"~/\") + \".oodeel/saved_models\" data_path = os.path.expanduser(\"~/\") + \".oodeel/datasets\" os.makedirs(model_path, exist_ok=True) os.makedirs(data_path, exist_ok=True) In\u00a0[3]: Copied! <pre># === load ID and OOD data ===\nbatch_size = 128\nin_labels = [0, 1, 2, 3, 4]\n\n# 1- load train/test MNIST dataset\nmnist_train = OODDataset(\n    dataset_id='MNIST', backend=\"torch\",\n    load_kwargs={\"root\": data_path, \"train\": True, \"download\": True}\n)\nmnist_test = OODDataset(\n    dataset_id='MNIST', backend=\"torch\",\n    load_kwargs={\"root\": data_path, \"train\": False, \"download\": True}\n)\n\n# 2- split ID / OOD data depending on label value:\n# in-distribution: MNIST[0-4] / out-of-distribution: MNIST[5-9]\noods_fit, _ = mnist_train.split_by_class(in_labels=in_labels)\noods_in, oods_out = mnist_test.split_by_class(in_labels=in_labels)\n\n# 3- prepare data (preprocess, shuffle, batch) =&gt; torch dataloaders\ndef preprocess_fn(*inputs):\n\"\"\"Simple preprocessing function to normalize images in [0, 1].\n    \"\"\"\n    x = inputs[0] / 255.0\n    return tuple([x] + list(inputs[1:]))\n\nds_fit = oods_fit.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn, shuffle=True)\nds_in = oods_in.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn)\nds_out = oods_out.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn)\n\nclear_output()\n</pre> # === load ID and OOD data === batch_size = 128 in_labels = [0, 1, 2, 3, 4]  # 1- load train/test MNIST dataset mnist_train = OODDataset(     dataset_id='MNIST', backend=\"torch\",     load_kwargs={\"root\": data_path, \"train\": True, \"download\": True} ) mnist_test = OODDataset(     dataset_id='MNIST', backend=\"torch\",     load_kwargs={\"root\": data_path, \"train\": False, \"download\": True} )  # 2- split ID / OOD data depending on label value: # in-distribution: MNIST[0-4] / out-of-distribution: MNIST[5-9] oods_fit, _ = mnist_train.split_by_class(in_labels=in_labels) oods_in, oods_out = mnist_test.split_by_class(in_labels=in_labels)  # 3- prepare data (preprocess, shuffle, batch) =&gt; torch dataloaders def preprocess_fn(*inputs):     \"\"\"Simple preprocessing function to normalize images in [0, 1].     \"\"\"     x = inputs[0] / 255.0     return tuple([x] + list(inputs[1:]))  ds_fit = oods_fit.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn, shuffle=True) ds_in = oods_in.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn) ds_out = oods_out.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn)  clear_output() In\u00a0[4]: Copied! <pre># === Train / Load model ===\n# model path\nmodel_path_mnist_04 = os.path.join(model_path, \"mnist_model_0-4\")\n\ntry:\n    # if the model exists, load it\n    model = torch.load(os.path.join(model_path_mnist_04, \"best.pt\")).to(device)\nexcept OSError:\n    # else, train a new model\n    train_config = {\n        \"model\": \"toy_convnet\",\n        \"num_classes\": 10,\n        \"epochs\": 5,\n        \"save_dir\": model_path_mnist_04,\n        \"validation_data\": ds_in\n    }\n    model = train_torch_model(ds_fit, **train_config).to(device)\n    clear_output()\n\n# evaluate model\nmodel.eval()\nlabels, preds = [], []\nfor (x, y) in ds_in:\n    x = x.to(device)\n    preds.append(torch.argmax(model(x), dim=-1).detach().cpu())\n    labels.append(y)\nprint(f\"Test accuracy:\\t{accuracy_score(torch.cat(labels), torch.cat(preds)):.6f}\")\n\n# penultimate features 2d visualization\nprint(\"\\n=== Penultimate features viz ===\")\nplt.figure(figsize=(4.5, 3))\nplot_2D_features(\n    model=model,\n    in_dataset=ds_in,\n    out_dataset=ds_out,\n    output_layer_id=-2,\n)\nplt.tight_layout()\nplt.show()\n</pre> # === Train / Load model === # model path model_path_mnist_04 = os.path.join(model_path, \"mnist_model_0-4\")  try:     # if the model exists, load it     model = torch.load(os.path.join(model_path_mnist_04, \"best.pt\")).to(device) except OSError:     # else, train a new model     train_config = {         \"model\": \"toy_convnet\",         \"num_classes\": 10,         \"epochs\": 5,         \"save_dir\": model_path_mnist_04,         \"validation_data\": ds_in     }     model = train_torch_model(ds_fit, **train_config).to(device)     clear_output()  # evaluate model model.eval() labels, preds = [], [] for (x, y) in ds_in:     x = x.to(device)     preds.append(torch.argmax(model(x), dim=-1).detach().cpu())     labels.append(y) print(f\"Test accuracy:\\t{accuracy_score(torch.cat(labels), torch.cat(preds)):.6f}\")  # penultimate features 2d visualization print(\"\\n=== Penultimate features viz ===\") plt.figure(figsize=(4.5, 3)) plot_2D_features(     model=model,     in_dataset=ds_in,     out_dataset=ds_out,     output_layer_id=-2, ) plt.tight_layout() plt.show() <pre>Test accuracy:\t0.995914\n\n=== Penultimate features viz ===\n</pre> In\u00a0[5]: Copied! <pre># === vim scores ===\nvim = VIM(princ_dims=500)\nvim.fit(model, feature_layers_id=[-2], fit_dataset=ds_fit)\nscores_in, _ = vim.score(ds_in)\nscores_out, _ = vim.score(ds_out)\n\n# === metrics ===\n# auroc / fpr95\nmetrics = bench_metrics(\n    (scores_in, scores_out),\n    metrics=[\"auroc\", \"fpr95tpr\"],\n)\nprint(\"=== Metrics ===\")\nfor k, v in metrics.items():\n    print(f\"{k:&lt;10} {v:.6f}\")\n\nprint(\"\\n=== Plots ===\")\n# hists / roc\nplt.figure(figsize=(13.5, 3))\nplt.subplot(131)\nplot_ood_scores(scores_in, scores_out, log_scale=False)\nplt.subplot(132)\nplot_roc_curve(scores_in, scores_out)\nplt.subplot(133)\nvim.plot_spectrum()\nplt.tight_layout()\nplt.show()\n</pre> # === vim scores === vim = VIM(princ_dims=500) vim.fit(model, feature_layers_id=[-2], fit_dataset=ds_fit) scores_in, _ = vim.score(ds_in) scores_out, _ = vim.score(ds_out)  # === metrics === # auroc / fpr95 metrics = bench_metrics(     (scores_in, scores_out),     metrics=[\"auroc\", \"fpr95tpr\"], ) print(\"=== Metrics ===\") for k, v in metrics.items():     print(f\"{k:&lt;10} {v:.6f}\")  print(\"\\n=== Plots ===\") # hists / roc plt.figure(figsize=(13.5, 3)) plt.subplot(131) plot_ood_scores(scores_in, scores_out, log_scale=False) plt.subplot(132) plot_roc_curve(scores_in, scores_out) plt.subplot(133) vim.plot_spectrum() plt.tight_layout() plt.show() <pre>=== Metrics ===\nauroc      0.958571\nfpr95tpr   0.156061\n\n=== Plots ===\n</pre> In\u00a0[6]: Copied! <pre># === load ID and OOD data ===\nbatch_size = 128\n\n# 1a- load in-distribution dataset: CIFAR-10\noods_fit = OODDataset(\n    dataset_id='CIFAR10', backend=\"torch\",\n    load_kwargs={\"root\": data_path, \"train\": True, \"download\": True}\n)\noods_in = OODDataset(\n    dataset_id='CIFAR10', backend=\"torch\",\n    load_kwargs={\"root\": data_path, \"train\": False, \"download\": True}\n)\n# 1b- load out-of-distribution dataset: SVHN\noods_out = OODDataset(\n    dataset_id='SVHN', backend=\"torch\",\n    load_kwargs={\"root\": data_path, \"split\": \"test\", \"download\": True})\n\n\n# 2- prepare data (preprocess, shuffle, batch) =&gt; torch dataloaders\n\ndef preprocess_fn(*inputs):\n\"\"\"Preprocessing function from\n    https://github.com/chenyaofo/pytorch-cifar-models\n    \"\"\"\n    x = inputs[0] / 255.0\n    x = transforms.Normalize(\n        (0.4914, 0.4822, 0.4465),\n        (0.2023, 0.1994, 0.2010)\n    )(x)\n    return tuple([x] + list(inputs[1:]))\n\nds_fit = oods_fit.prepare(batch_size=batch_size, shuffle=True, preprocess_fn=preprocess_fn)\nds_in = oods_in.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn)\nds_out = oods_out.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn)\n\nclear_output()\n</pre> # === load ID and OOD data === batch_size = 128  # 1a- load in-distribution dataset: CIFAR-10 oods_fit = OODDataset(     dataset_id='CIFAR10', backend=\"torch\",     load_kwargs={\"root\": data_path, \"train\": True, \"download\": True} ) oods_in = OODDataset(     dataset_id='CIFAR10', backend=\"torch\",     load_kwargs={\"root\": data_path, \"train\": False, \"download\": True} ) # 1b- load out-of-distribution dataset: SVHN oods_out = OODDataset(     dataset_id='SVHN', backend=\"torch\",     load_kwargs={\"root\": data_path, \"split\": \"test\", \"download\": True})   # 2- prepare data (preprocess, shuffle, batch) =&gt; torch dataloaders  def preprocess_fn(*inputs):     \"\"\"Preprocessing function from     https://github.com/chenyaofo/pytorch-cifar-models     \"\"\"     x = inputs[0] / 255.0     x = transforms.Normalize(         (0.4914, 0.4822, 0.4465),         (0.2023, 0.1994, 0.2010)     )(x)     return tuple([x] + list(inputs[1:]))  ds_fit = oods_fit.prepare(batch_size=batch_size, shuffle=True, preprocess_fn=preprocess_fn) ds_in = oods_in.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn) ds_out = oods_out.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn)  clear_output() In\u00a0[7]: Copied! <pre># === load model ===\n# resnet20 pretrained on CIFAR-10\nmodel = torch.hub.load(\n    repo_or_dir=\"chenyaofo/pytorch-cifar-models\", model=\"cifar10_resnet20\",\n    pretrained=True, verbose=False).to(device)\nmodel.eval();\n\n# evaluate model\nlabels, preds = [], []\nfor (x, y) in ds_in:\n    x = x.to(device)\n    preds.append(torch.argmax(model(x), dim=-1).detach().cpu())\n    labels.append(y)\nprint(f\"Test accuracy:\\t{accuracy_score(torch.cat(labels), torch.cat(preds)):.6f}\")\n\n# penultimate features 2d visualization\nprint(\"\\n=== Penultimate features viz ===\")\nplt.figure(figsize=(4.5, 3))\nplot_2D_features(\n    model=model,\n    in_dataset=ds_in,\n    out_dataset=ds_out,\n    output_layer_id=-2,\n)\nplt.tight_layout()\nplt.show()\n</pre> # === load model === # resnet20 pretrained on CIFAR-10 model = torch.hub.load(     repo_or_dir=\"chenyaofo/pytorch-cifar-models\", model=\"cifar10_resnet20\",     pretrained=True, verbose=False).to(device) model.eval();  # evaluate model labels, preds = [], [] for (x, y) in ds_in:     x = x.to(device)     preds.append(torch.argmax(model(x), dim=-1).detach().cpu())     labels.append(y) print(f\"Test accuracy:\\t{accuracy_score(torch.cat(labels), torch.cat(preds)):.6f}\")  # penultimate features 2d visualization print(\"\\n=== Penultimate features viz ===\") plt.figure(figsize=(4.5, 3)) plot_2D_features(     model=model,     in_dataset=ds_in,     out_dataset=ds_out,     output_layer_id=-2, ) plt.tight_layout() plt.show() <pre>Test accuracy:\t0.926000\n\n=== Penultimate features viz ===\n</pre> In\u00a0[8]: Copied! <pre># === vim scores ===\nvim = VIM(princ_dims=40)\nvim.fit(model, feature_layers_id=[-2], fit_dataset=ds_fit)\nscores_in, _ = vim.score(ds_in)\nscores_out, _ = vim.score(ds_out)\n\n# === metrics ===\n# auroc / fpr95\nmetrics = bench_metrics(\n    (scores_in, scores_out),\n    metrics=[\"auroc\", \"fpr95tpr\"],\n)\nprint(\"=== Metrics ===\")\nfor k, v in metrics.items():\n    print(f\"{k:&lt;10} {v:.6f}\")\n\nprint(\"\\n=== Plots ===\")\n# hists / roc\nplt.figure(figsize=(13.5, 3))\nplt.subplot(131)\nplot_ood_scores(scores_in, scores_out, log_scale=False)\nplt.subplot(132)\nplot_roc_curve(scores_in, scores_out)\nplt.subplot(133)\nvim.plot_spectrum()\nplt.tight_layout()\nplt.show()\n</pre> # === vim scores === vim = VIM(princ_dims=40) vim.fit(model, feature_layers_id=[-2], fit_dataset=ds_fit) scores_in, _ = vim.score(ds_in) scores_out, _ = vim.score(ds_out)  # === metrics === # auroc / fpr95 metrics = bench_metrics(     (scores_in, scores_out),     metrics=[\"auroc\", \"fpr95tpr\"], ) print(\"=== Metrics ===\") for k, v in metrics.items():     print(f\"{k:&lt;10} {v:.6f}\")  print(\"\\n=== Plots ===\") # hists / roc plt.figure(figsize=(13.5, 3)) plt.subplot(131) plot_ood_scores(scores_in, scores_out, log_scale=False) plt.subplot(132) plot_roc_curve(scores_in, scores_out) plt.subplot(133) vim.plot_spectrum() plt.tight_layout() plt.show() <pre>=== Metrics ===\nauroc      0.963168\nfpr95tpr   0.185300\n\n=== Plots ===\n</pre>"},{"location":"notebooks/torch/demo_vim_torch/#virtual-logit-matching-vim-method","title":"Virtual Logit Matching (VIM) method\u00b6","text":"<p>This notebook aims at evaluating the VIM method.</p> <p>The method consists in analysing the projection of an input image in a feature subspace that contains the least information about in-distribution data. It is achieved by performing a PCA on the in-distribution dataset in the feature space. The norm of the projection of a new input data's feature representation onto the principal vectors explaining the least variance is then used for scoring.</p> <p>Here, we focus on a toy convolutional network trained on MNIST[0-4] and a ResNet20 model trained on CIFAR-10, respectively challenged on MNIST[5-9] and SVHN OOD datasets.</p> <p>Reference ViM: Out-Of-Distribution with Virtual-logit Matching, CVPR 2022.</p>"},{"location":"notebooks/torch/demo_vim_torch/#imports","title":"Imports\u00b6","text":""},{"location":"notebooks/torch/demo_vim_torch/#first-exp-mnist0-4-vs-mnist5-9","title":"First exp: MNIST[0-4] vs MNIST[5-9]\u00b6","text":"<p>For this first experiment, we train a toy convolutional network on the MNIST dataset restricted to digits 0 to 4. After fitting the train subset of this dataset to the VIM method, we will compare the scores returned for MNIST[0-4] (in-distrubtion) and MNIST[5-9] (out-of-distribution) test subsets.</p>"},{"location":"notebooks/torch/demo_vim_torch/#data-loading","title":"Data loading\u00b6","text":"<ul> <li>In-distribution data: MNIST[0-4]</li> <li>Out-of-distribution data: MNIST[5-9]</li> </ul> <p>Note: We denote In-Distribution (ID) data with <code>_in</code> and Out-Of-Distribution (OOD) data</p> <p>with <code>_out</code> to avoid confusion with OOD detection which is the name of the task, and is therefore used to denote core classes such as <code>OODDataset</code> and <code>OODBaseDetector</code>.</p>"},{"location":"notebooks/torch/demo_vim_torch/#model-training","title":"Model training\u00b6","text":"<p>Now let's train a simple model on MNIST[0-4] using <code>train_torch_model</code> function.</p>"},{"location":"notebooks/torch/demo_vim_torch/#vim-score","title":"VIM score\u00b6","text":"<p>We now fit a VIM detector with MNIST[0-4] train dataset, and compare OOD scores returned for MNIST[0-4] (ID) and MNIST[5-9] (OOD) test datasets.</p>"},{"location":"notebooks/torch/demo_vim_torch/#second-exp-cifar-10-vs-svhn","title":"Second exp: CIFAR-10 vs SVHN\u00b6","text":"<p>For this second experiment, we oppose CIFAR-10 (in-distribution dataset) to SVHN (out-of-distribution dataset).</p>"},{"location":"notebooks/torch/demo_vim_torch/#data-loading","title":"Data loading\u00b6","text":"<ul> <li>In-distribution data: CIFAR-10</li> <li>Out-of-distribution data: SVHN</li> </ul>"},{"location":"notebooks/torch/demo_vim_torch/#model-loading","title":"Model loading\u00b6","text":"<p>The model is a ResNet20 pretrained on CIFAR-10 and getting an accuracy score of 92.60%, loaded from pytorch-cifar-models repository.</p>"},{"location":"notebooks/torch/demo_vim_torch/#vim-score","title":"VIM score\u00b6","text":"<p>We now fit a VIM detector with CIFAR-10 train dataset, and compare OOD scores returned for CIFAR-10 (ID) and SVHN (OOD) test datasets.</p>"},{"location":"pages/datahandler_tuto/","title":"Seamlessly handling torch and tf datasets with DataHandler","text":"<p>coming soon</p>"},{"location":"pages/feature_extractor_tuto/","title":"Important Note On Feature Extractors","text":"<p>When using Oodeel, you have to keep in mind how the detector object works, and specifically, how it extracts features from the model that is given as an argument to the <code>.fit()</code> method of OOD baselines inheriting from <code>OODBaseDetector</code>. Under the hood, <code>OODBaseDetector</code> uses an object called <code>FeatureExtractor</code> (with two child versions, <code>KerasFeatureExtractor</code>or <code>TorchFeatureExtractor</code>, depending on your model's implementation).</p> <p>The key point here is to be able to correctly identify the output layer(s) of your model so that the <code>FeatureExtractor</code> knows what to extract. The layer can be identified by a name or by a slice, if possible. Let's dive into different situations</p> <p>Important</p> <p>     In this notebook, we go through FeatureExtractor class, but this class is never explicitly used by the user. It works under the hood of OODBaseDetector. Still, understanding how it works is mandatory for correct usage of OODBaseDetector, see the Wrap-up section below.   </p> In\u00a0[1]: Copied! <pre>import os\n\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\nimport tensorflow as tf\n\ntf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\nfrom oodeel.extractor import KerasFeatureExtractor\n\nfrom IPython.display import clear_output\n</pre> import os  os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\" import tensorflow as tf  tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR) from oodeel.extractor import KerasFeatureExtractor  from IPython.display import clear_output In\u00a0[2]: Copied! <pre>def generate_model(input_shape=(32, 32, 3), output_shape=10):\n    model = tf.keras.models.Sequential()\n    model.add(tf.keras.layers.Input(shape=input_shape))\n    model.add(tf.keras.layers.Conv2D(4, kernel_size=(2, 2), activation=\"relu\"))\n    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n    model.add(tf.keras.layers.Dropout(0.25))\n    model.add(tf.keras.layers.Flatten())\n    model.add(tf.keras.layers.Dense(output_shape))\n    model.add(tf.keras.layers.Activation(\"softmax\"))\n    model.compile(loss=\"categorical_crossentropy\", optimizer=\"sgd\")\n\n    return model\n\n\nmodel = generate_model()\nmodel.compile(optimizer=\"adam\")\n\nclear_output()\n</pre> def generate_model(input_shape=(32, 32, 3), output_shape=10):     model = tf.keras.models.Sequential()     model.add(tf.keras.layers.Input(shape=input_shape))     model.add(tf.keras.layers.Conv2D(4, kernel_size=(2, 2), activation=\"relu\"))     model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))     model.add(tf.keras.layers.Dropout(0.25))     model.add(tf.keras.layers.Flatten())     model.add(tf.keras.layers.Dense(output_shape))     model.add(tf.keras.layers.Activation(\"softmax\"))     model.compile(loss=\"categorical_crossentropy\", optimizer=\"sgd\")      return model   model = generate_model() model.compile(optimizer=\"adam\")  clear_output() <p>Let's see what's in there</p> In\u00a0[3]: Copied! <pre>model.summary()\n</pre> model.summary() <pre>Model: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv2d (Conv2D)             (None, 31, 31, 4)         52        \n                                                                 \n max_pooling2d (MaxPooling2D  (None, 15, 15, 4)        0         \n )                                                               \n                                                                 \n dropout (Dropout)           (None, 15, 15, 4)         0         \n                                                                 \n flatten (Flatten)           (None, 900)               0         \n                                                                 \n dense (Dense)               (None, 10)                9010      \n                                                                 \n activation (Activation)     (None, 10)                0         \n                                                                 \n=================================================================\nTotal params: 9,062\nTrainable params: 9,062\nNon-trainable params: 0\n_________________________________________________________________\n</pre> <p>Most of the time, it is of interest to take the output of neural networks' penultimate layers to apply OOD methods. Here, we can see that the layer can be identified as the $d-3$-th, with $d$ the depth of the network. To achieve that instantiate the <code>FeatureExtractor</code> as:</p> In\u00a0[4]: Copied! <pre>extractor = KerasFeatureExtractor(model, feature_layers_id=[-3])\n\nx = tf.ones((100, 32, 32, 3))\nx_latent, _ = extractor(x)\nprint(x_latent.shape)\n</pre> extractor = KerasFeatureExtractor(model, feature_layers_id=[-3])  x = tf.ones((100, 32, 32, 3)) x_latent, _ = extractor(x) print(x_latent.shape) <pre>(100, 900)\n</pre> <p>Tip</p> <p>For convenience, the logits are always returned when calling a <code>FeatureExtractor</code>. We do not use them in this notebook, if you want to get them, just replace <code>x_latent, _ = extractor(x)</code> with <code>x_latent, logits = extractor(x)</code></p> <p>Alternatively, you can identify the layer by its name:</p> In\u00a0[5]: Copied! <pre>extractor = KerasFeatureExtractor(model, feature_layers_id=[\"flatten\"])\n\nx = tf.ones((100, 32, 32, 3))\nx_latent, _ = extractor(x)\nprint(x_latent.shape)\n</pre> extractor = KerasFeatureExtractor(model, feature_layers_id=[\"flatten\"])  x = tf.ones((100, 32, 32, 3)) x_latent, _ = extractor(x) print(x_latent.shape) <pre>(100, 900)\n</pre> <p>You can also set the starting point of your extractor, which can be useful to avoid repeated forward passes:</p> In\u00a0[6]: Copied! <pre>extractor_2 = KerasFeatureExtractor(\n    model, input_layer_id=\"dense\", feature_layers_id=[\"activation\"]\n)\n\nx_latent, _ = extractor(x)\nprint(x_latent.shape)\ny, _ = extractor_2(x_latent)\nprint(y.shape)\n</pre> extractor_2 = KerasFeatureExtractor(     model, input_layer_id=\"dense\", feature_layers_id=[\"activation\"] )  x_latent, _ = extractor(x) print(x_latent.shape) y, _ = extractor_2(x_latent) print(y.shape) <pre>(100, 900)\n(100, 10)\n</pre> <p>Warning:</p> <ul> <li>Be careful, the name of the input layer is that of the layer following the previous output layer</li> <li>The extractor may only have one input layer (hence the <code>str</code> format of the argument instead of <code>list</code>)</li> </ul> <p>If needed, you can get the output of several layers at the same time:</p> In\u00a0[3]: Copied! <pre>extractor = KerasFeatureExtractor(model, feature_layers_id=[-3, -1])\n\nx = tf.ones((100, 32, 32, 3))\nx_latent, _ = extractor(x)\nprint(x_latent[0].shape, x_latent[1].shape)\n</pre> extractor = KerasFeatureExtractor(model, feature_layers_id=[-3, -1])  x = tf.ones((100, 32, 32, 3)) x_latent, _ = extractor(x) print(x_latent[0].shape, x_latent[1].shape) <pre>(100, 900) (100, 10)\n</pre> <p>Warning:</p> <p>For this cell to work, you have to clear ipython kernel from the previous extractors</p> In\u00a0[2]: Copied! <pre>import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom oodeel.extractor import TorchFeatureExtractor\n</pre> import torch import torch.nn as nn import torch.nn.functional as F  from oodeel.extractor import TorchFeatureExtractor <p>Now let's consider some Pytorch model</p> In\u00a0[3]: Copied! <pre>class Net(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(3, 6, 5)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 10)\n\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = torch.flatten(x, 1)  # flatten all dimensions except batch\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n\n\nmodel = Net()\n</pre> class Net(nn.Module):     def __init__(self):         super().__init__()         self.conv1 = nn.Conv2d(3, 6, 5)         self.pool = nn.MaxPool2d(2, 2)         self.conv2 = nn.Conv2d(6, 16, 5)         self.fc1 = nn.Linear(16 * 5 * 5, 120)         self.fc2 = nn.Linear(120, 84)         self.fc3 = nn.Linear(84, 10)      def forward(self, x):         x = self.pool(F.relu(self.conv1(x)))         x = self.pool(F.relu(self.conv2(x)))         x = torch.flatten(x, 1)  # flatten all dimensions except batch         x = F.relu(self.fc1(x))         x = F.relu(self.fc2(x))         x = self.fc3(x)         return x   model = Net() <p>Similarly, let's display how the model is constructed:</p> In\u00a0[4]: Copied! <pre>for layer in model.named_modules():\n    print(layer)\n</pre> for layer in model.named_modules():     print(layer) <pre>('', Net(\n  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n  (fc1): Linear(in_features=400, out_features=120, bias=True)\n  (fc2): Linear(in_features=120, out_features=84, bias=True)\n  (fc3): Linear(in_features=84, out_features=10, bias=True)\n))\n('conv1', Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1)))\n('pool', MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False))\n('conv2', Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1)))\n('fc1', Linear(in_features=400, out_features=120, bias=True))\n('fc2', Linear(in_features=120, out_features=84, bias=True))\n('fc3', Linear(in_features=84, out_features=10, bias=True))\n</pre> <p>That case is pretty much the same as for Tensorflow:</p> In\u00a0[5]: Copied! <pre>extractor = TorchFeatureExtractor(model, feature_layers_id=[-3])\n\nx = torch.ones((100, 3, 32, 32))\nx_latent, _ = extractor(x)\nprint(\"numbered output:\\n\", x_latent.shape)\n\nextractor = TorchFeatureExtractor(model, feature_layers_id=[\"fc1\"])\n\nx = torch.ones((100, 3, 32, 32))\nx_latent, _ = extractor(x)\nprint(\"named output:\\n\", x_latent.shape)\n\nextractor = TorchFeatureExtractor(model, feature_layers_id=[\"fc1\", \"fc3\"])\n\nx = torch.ones((100, 3, 32, 32))\nx_latent, _ = extractor(x)\nprint(\"multi output:\\n\", x_latent[0].shape, x_latent[1].shape)\n</pre> extractor = TorchFeatureExtractor(model, feature_layers_id=[-3])  x = torch.ones((100, 3, 32, 32)) x_latent, _ = extractor(x) print(\"numbered output:\\n\", x_latent.shape)  extractor = TorchFeatureExtractor(model, feature_layers_id=[\"fc1\"])  x = torch.ones((100, 3, 32, 32)) x_latent, _ = extractor(x) print(\"named output:\\n\", x_latent.shape)  extractor = TorchFeatureExtractor(model, feature_layers_id=[\"fc1\", \"fc3\"])  x = torch.ones((100, 3, 32, 32)) x_latent, _ = extractor(x) print(\"multi output:\\n\", x_latent[0].shape, x_latent[1].shape) <pre>numbered output:\n torch.Size([100, 120])\nnamed output:\n torch.Size([100, 120])\nmulti output:\n torch.Size([100, 120]) torch.Size([100, 10])\n</pre> <p>Warning:</p> <p>As opposed to Tensorflow, PyTorch extractor can only take internal layers as input for <code>nn.Sequential</code> models.</p> <p>Will not work:</p> In\u00a0[\u00a0]: Copied! <pre>extractor = TorchFeatureExtractor(model, feature_layers_id=[\"fc1\"])\nextractor_2 = TorchFeatureExtractor(\n    model, input_layer_id=\"fc2\", feature_layers_id=[\"fc3\"]\n)\n\nx_latent, _ = extractor(x)\nprint(x_latent.shape)\ny, _ = extractor_2(x_latent)\nprint(y.shape)\n</pre> extractor = TorchFeatureExtractor(model, feature_layers_id=[\"fc1\"]) extractor_2 = TorchFeatureExtractor(     model, input_layer_id=\"fc2\", feature_layers_id=[\"fc3\"] )  x_latent, _ = extractor(x) print(x_latent.shape) y, _ = extractor_2(x_latent) print(y.shape) <p>Will work:</p> In\u00a0[8]: Copied! <pre>from collections import OrderedDict\n\n\ndef named_sequential_model():\n    return nn.Sequential(\n        OrderedDict(\n            [\n                (\"conv1\", nn.Conv2d(3, 6, 5)),\n                (\"relu1\", nn.ReLU()),\n                (\"pool1\", nn.MaxPool2d(2, 2)),\n                (\"conv2\", nn.Conv2d(6, 16, 5)),\n                (\"relu2\", nn.ReLU()),\n                (\"pool2\", nn.MaxPool2d(2, 2)),\n                (\"flatten\", nn.Flatten()),\n                (\"fc1\", nn.Linear(16 * 5 * 5, 120)),\n                (\"fc2\", nn.Linear(120, 84)),\n                (\"fc3\", nn.Linear(84, 10)),\n            ]\n        )\n    )\n\n\nmodel = named_sequential_model()\nextractor = TorchFeatureExtractor(model, feature_layers_id=[\"fc1\"])\n\nx = torch.ones((100, 3, 32, 32))\nx_latent, _ = extractor(x)\nprint(x_latent.shape)\n\n# Be careful, once extractor_2 is instanciated, extractor no longer works\n# because hooks are cleaned\nextractor_2 = TorchFeatureExtractor(\n    model, input_layer_id=\"fc2\", feature_layers_id=[\"fc3\"]\n)\ny, _ = extractor_2(x_latent)\nprint(y.shape)\n</pre> from collections import OrderedDict   def named_sequential_model():     return nn.Sequential(         OrderedDict(             [                 (\"conv1\", nn.Conv2d(3, 6, 5)),                 (\"relu1\", nn.ReLU()),                 (\"pool1\", nn.MaxPool2d(2, 2)),                 (\"conv2\", nn.Conv2d(6, 16, 5)),                 (\"relu2\", nn.ReLU()),                 (\"pool2\", nn.MaxPool2d(2, 2)),                 (\"flatten\", nn.Flatten()),                 (\"fc1\", nn.Linear(16 * 5 * 5, 120)),                 (\"fc2\", nn.Linear(120, 84)),                 (\"fc3\", nn.Linear(84, 10)),             ]         )     )   model = named_sequential_model() extractor = TorchFeatureExtractor(model, feature_layers_id=[\"fc1\"])  x = torch.ones((100, 3, 32, 32)) x_latent, _ = extractor(x) print(x_latent.shape)  # Be careful, once extractor_2 is instanciated, extractor no longer works # because hooks are cleaned extractor_2 = TorchFeatureExtractor(     model, input_layer_id=\"fc2\", feature_layers_id=[\"fc3\"] ) y, _ = extractor_2(x_latent) print(y.shape) <pre>torch.Size([100, 120])\ntorch.Size([100, 10])\n</pre> <p>Once you have identified the way you want to extract data from your model, which boils down to correctly identifying what to put under the <code>feature_layers_id</code> and <code>input_layer_id</code> arguments, you can properly instantiate your <code>OODBaseDetector</code> like this (example with DKNN):</p> In\u00a0[\u00a0]: Copied! <pre>from oodeel.methods import DKNN\n\ndknn = DKNN()\ndknn.fit(\n    model, \n    feature_layers_id=[\"fc1\"], \n    #some_fit_dataset)\n)\n</pre> from oodeel.methods import DKNN  dknn = DKNN() dknn.fit(     model,      feature_layers_id=[\"fc1\"],      #some_fit_dataset) ) <p>In fact, you never have to instantiate the feature extractor by yourself, it is automatically performed by <code>OODBaseDetector</code> (here <code>DKNN</code>). It detects the underlying library of <code>model</code>, and instantiates the adapted <code>FeatureExtractor</code> using the arguments given as input to <code>OODBaseDetector</code>.</p> <p>Note:</p> <p>We recommend that you only identify layers by name; we found it to be less error prone.</p>"},{"location":"pages/feature_extractor_tuto/#tensorflow-models","title":"Tensorflow models\u00b6","text":""},{"location":"pages/feature_extractor_tuto/#a-keras-sequential-model","title":"A keras Sequential model\u00b6","text":""},{"location":"pages/feature_extractor_tuto/#for-non-sequential-keras-models","title":"For non-sequential keras models\u00b6","text":"<p>When your model is built out of a set of layers that are not connected sequentially, your only option is to rely on the identification by layer name, as referred in <code>model.summary()</code></p>"},{"location":"pages/feature_extractor_tuto/#pytorch-models","title":"PyTorch Models\u00b6","text":""},{"location":"pages/feature_extractor_tuto/#wrap-up","title":"Wrap-up\u00b6","text":""},{"location":"pages/getting_started/","title":"Getting started: Maximum Logit Score on MNIST","text":"In\u00a0[1]: Copied! <pre>import os\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\" \nimport tensorflow as tf\ntf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch \nfrom IPython.display import clear_output\n\nfrom oodeel.methods import MLS\nfrom oodeel.eval.metrics import bench_metrics\nfrom oodeel.eval.plots import plot_ood_scores\nfrom oodeel.datasets import OODDataset\nfrom oodeel.utils.tf_training_tools import train_tf_model\nfrom oodeel.utils.torch_training_tools import train_torch_model\n\nfrom sklearn.metrics import accuracy_score, roc_auc_score\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\ncuda_idx = 0 if torch.cuda.is_available() else None\n\nclear_output()\n</pre> import os os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"  import tensorflow as tf tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR) import pandas as pd import numpy as np import matplotlib.pyplot as plt import torch  from IPython.display import clear_output  from oodeel.methods import MLS from oodeel.eval.metrics import bench_metrics from oodeel.eval.plots import plot_ood_scores from oodeel.datasets import OODDataset from oodeel.utils.tf_training_tools import train_tf_model from oodeel.utils.torch_training_tools import train_torch_model  from sklearn.metrics import accuracy_score, roc_auc_score  import warnings warnings.filterwarnings(\"ignore\")  cuda_idx = 0 if torch.cuda.is_available() else None  clear_output() <p>Models are saved at ~/.oodeel/saved_models and data is supposed to be found at ~/.oodeel/datasets by default. Change the following cell for a custom path.</p> In\u00a0[2]: Copied! <pre>model_path = os.path.expanduser(\"~/\") + \".oodeel/saved_models\"\ndata_path = os.path.expanduser(\"~/\") + \".oodeel/datasets\"\nos.makedirs(model_path, exist_ok=True)\nos.makedirs(data_path, exist_ok=True)\n</pre>  model_path = os.path.expanduser(\"~/\") + \".oodeel/saved_models\" data_path = os.path.expanduser(\"~/\") + \".oodeel/datasets\" os.makedirs(model_path, exist_ok=True) os.makedirs(data_path, exist_ok=True) In\u00a0[3]: Copied! <pre>backend = \"torch\"\n\noods_in = OODDataset(\n    'MNIST', \n    load_kwargs = {\"train\": False, \"root\": data_path, \"download\": True}, \n    backend=backend,\n)\noods_out = OODDataset(\n    'FashionMNIST', \n    load_kwargs = {\"train\": False, \"root\": data_path, \"download\": True}, \n    backend=backend,\n)\noods_train = OODDataset(\n    'MNIST', \n    load_kwargs = {\"train\": True, \"root\": data_path, \"download\": True}, \n    backend=backend,\n)\n</pre> backend = \"torch\"  oods_in = OODDataset(     'MNIST',      load_kwargs = {\"train\": False, \"root\": data_path, \"download\": True},      backend=backend, ) oods_out = OODDataset(     'FashionMNIST',      load_kwargs = {\"train\": False, \"root\": data_path, \"download\": True},      backend=backend, ) oods_train = OODDataset(     'MNIST',      load_kwargs = {\"train\": True, \"root\": data_path, \"download\": True},      backend=backend, ) <p>In tensorflow from <code>tensorflow_datasets</code> catalog:</p> In\u00a0[4]: Copied! <pre>backend = \"tensorflow\"\n\noods_in = OODDataset(\n    'mnist', \n    load_kwargs = {\"split\": \"test\"}, \n    backend=backend,\n)\noods_out = OODDataset(\n    'fashion_mnist', \n    load_kwargs = {\"split\": \"test\"}, \n    backend=backend,\n)\noods_train = OODDataset(\n    'mnist', \n    load_kwargs = {\"split\": \"train\"}, \n    backend=backend,\n)\n\nclear_output()\n</pre> backend = \"tensorflow\"  oods_in = OODDataset(     'mnist',      load_kwargs = {\"split\": \"test\"},      backend=backend, ) oods_out = OODDataset(     'fashion_mnist',      load_kwargs = {\"split\": \"test\"},      backend=backend, ) oods_train = OODDataset(     'mnist',      load_kwargs = {\"split\": \"train\"},      backend=backend, )  clear_output() <p>Note</p> <p>When backend is \"torch\", the datasets can still be loaded from <code>tensorflow_datasets</code>, and are converted on the fly and loaded on VRAM as torch tensors. This feature can be useful because tensorflow_datasets's catalog is way larger than torchvision dataset's. In that case, however, the loaded dataset cannot be used for training with <code>train_torch_model</code>.</p> <p>Then, prepare the dataset for scoring and/or training using <code>.prepare</code> method.</p> In\u00a0[5]: Copied! <pre>def preprocess_fn(*inputs):\n    x = inputs[0] / 255\n    return tuple([x] + list(inputs[1:]))\n\nbatch_size = 128\n\nds_in = oods_in.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn)\nds_out = oods_out.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn)\nds_train = oods_train.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn, shuffle=True)\n</pre> def preprocess_fn(*inputs):     x = inputs[0] / 255     return tuple([x] + list(inputs[1:]))  batch_size = 128  ds_in = oods_in.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn) ds_out = oods_out.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn) ds_train = oods_train.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn, shuffle=True) <p><code>ds_in</code>, <code>ds_out</code> and <code>ds_train</code> are regular <code>tf.data.Dataset</code>or <code>torch.DataLoader</code> that you can use like usual!</p> <p>Train or load a model on in-distribution data (MNIST).</p> <p>... a keras model if <code>backend=\"tensorflow\"</code>... or a pytorch one, if <code>backend=\"torch\"</code>.</p> In\u00a0[6]: Copied! <pre>model_path_mnist = os.path.join(model_path, \"mnist_model_tensorflow.h5\")\n\ntry:\n    model_tf = tf.keras.models.load_model(model_path_mnist)\nexcept OSError:\n    train_config = {\n        \"model\": \"toy_convnet\",\n        \"input_shape\": (28, 28, 1),\n        \"num_classes\": 10,\n        \"epochs\": 5,\n        \"save_dir\": model_path_mnist,\n        \"validation_data\": ds_in #ds_in is actually the test set of MNIST\n    }\n\n    model_tf = train_tf_model(ds_train, **train_config)\n</pre> model_path_mnist = os.path.join(model_path, \"mnist_model_tensorflow.h5\")  try:     model_tf = tf.keras.models.load_model(model_path_mnist) except OSError:     train_config = {         \"model\": \"toy_convnet\",         \"input_shape\": (28, 28, 1),         \"num_classes\": 10,         \"epochs\": 5,         \"save_dir\": model_path_mnist,         \"validation_data\": ds_in #ds_in is actually the test set of MNIST     }      model_tf = train_tf_model(ds_train, **train_config)  <p>... or a pytorch one, if <code>backend=\"torch\"</code></p> In\u00a0[7]: Copied! <pre>model_path_mnist = os.path.join(model_path, \"mnist_model_torch\")\ntry:\n    model_torch = torch.load(os.path.join(model_path_mnist, \"best.pt\"))\nexcept OSError:\n    train_config = {\n        \"model\": \"toy_convnet\",\n        \"num_classes\": 10,\n        \"epochs\": 5,\n        \"save_dir\": model_path_mnist,\n        \"validation_data\": ds_in, #ds_in is actually the test set of MNIST\n        \"cuda_idx\": cuda_idx\n    }\n    model_torch = train_torch_model(ds_train,  **train_config)\n</pre> model_path_mnist = os.path.join(model_path, \"mnist_model_torch\") try:     model_torch = torch.load(os.path.join(model_path_mnist, \"best.pt\")) except OSError:     train_config = {         \"model\": \"toy_convnet\",         \"num_classes\": 10,         \"epochs\": 5,         \"save_dir\": model_path_mnist,         \"validation_data\": ds_in, #ds_in is actually the test set of MNIST         \"cuda_idx\": cuda_idx     }     model_torch = train_torch_model(ds_train,  **train_config) In\u00a0[8]: Copied! <pre>if backend == \"tensorflow\":\n    model = model_tf\nelif backend == \"torch\":\n    model = model_torch\n</pre> if backend == \"tensorflow\":     model = model_tf elif backend == \"torch\":     model = model_torch <p>Simply fit the <code>OODBaseDetector</code> to the model and then score the dataset.</p> In\u00a0[9]: Copied! <pre>mls = MLS()\n\nmls.fit(model)\nscores_in, _ = mls.score(ds_in)\nscores_out, _ = mls.score(ds_out)\n</pre> mls = MLS()  mls.fit(model) scores_in, _ = mls.score(ds_in) scores_out, _ = mls.score(ds_out) <p>Tip</p> <p>You can also obtain the prediction of the underlying model using the <code>.score</code> method. Just name a    variable instead of <code>_</code>. For instance, in <code>scores_in, info_in = mls.score(ds_in)</code>, info_in is a dict    containing the predictions of the model from ds_in, and the labels if they are found in ds_in. Here, we use <code>_</code> because we do not need the predictions.</p> <p>Compute the evaluation metrics based on the scores of the test data, and visualize the scores histogram.</p> In\u00a0[10]: Copied! <pre>metrics = bench_metrics(\n    (scores_in, scores_out),  \n    metrics = [\"auroc\", \"fpr95tpr\", accuracy_score], \n    threshold = -7.5 # visually chosen based on the plot\n    )\n\nplt.figure(figsize=(13, 5))\nplot_ood_scores(scores_in, scores_out)\nplt.show()\nmetrics = pd.Series(metrics)\nprint(metrics)\n</pre> metrics = bench_metrics(     (scores_in, scores_out),       metrics = [\"auroc\", \"fpr95tpr\", accuracy_score],      threshold = -7.5 # visually chosen based on the plot     )  plt.figure(figsize=(13, 5)) plot_ood_scores(scores_in, scores_out) plt.show() metrics = pd.Series(metrics) print(metrics)  <pre>auroc             0.992269\nfpr95tpr          0.027700\naccuracy_score    0.873150\ndtype: float64\n</pre> In\u00a0[11]: Copied! <pre>msp = MLS(output_activation=\"softmax\")\nmsp.fit(model)\nscores_in, _ = msp.score(ds_in)\nscores_out, _ = msp.score(ds_out)\n\nmetrics = bench_metrics(\n    (scores_in, scores_out),  \n    metrics = [\"auroc\", \"fpr95tpr\", accuracy_score, roc_auc_score], \n    threshold = -0.95 # visually chosen based on the plot\n    )\n\n# Normalize scores for a better hist visualization\nminim = np.min([np.min(scores_in), np.min(scores_out)])\nscores_in_ = scores_in - 2 * minim + np.min(scores_in[np.where(scores_in != minim)])\nscores_out_ = scores_out - 2 * minim + np.min(scores_in[np.where(scores_in != minim)])\n\nplt.figure(figsize=(13, 5))\nplot_ood_scores(scores_in_, scores_out_, log_scale=True)\nplt.show()\nmetrics = pd.Series(metrics)\nprint(metrics)\n</pre> msp = MLS(output_activation=\"softmax\") msp.fit(model) scores_in, _ = msp.score(ds_in) scores_out, _ = msp.score(ds_out)  metrics = bench_metrics(     (scores_in, scores_out),       metrics = [\"auroc\", \"fpr95tpr\", accuracy_score, roc_auc_score],      threshold = -0.95 # visually chosen based on the plot     )  # Normalize scores for a better hist visualization minim = np.min([np.min(scores_in), np.min(scores_out)]) scores_in_ = scores_in - 2 * minim + np.min(scores_in[np.where(scores_in != minim)]) scores_out_ = scores_out - 2 * minim + np.min(scores_in[np.where(scores_in != minim)])  plt.figure(figsize=(13, 5)) plot_ood_scores(scores_in_, scores_out_, log_scale=True) plt.show() metrics = pd.Series(metrics) print(metrics) <pre>auroc             0.985023\nfpr95tpr          0.057000\naccuracy_score    0.946000\nroc_auc_score     0.985023\ndtype: float64\n</pre> In\u00a0[12]: Copied! <pre>backend = \"torch\"\n\noods_test = OODDataset(\n    'MNIST', \n    load_kwargs = {\"train\": False, \"root\": data_path, \"download\": True}, \n    backend=backend,\n)\noods_train = OODDataset(\n    'MNIST', \n    load_kwargs = {\"train\": True, \"root\": data_path, \"download\": True}, \n    backend=backend,\n)\n</pre> backend = \"torch\"  oods_test = OODDataset(     'MNIST',      load_kwargs = {\"train\": False, \"root\": data_path, \"download\": True},      backend=backend, ) oods_train = OODDataset(     'MNIST',      load_kwargs = {\"train\": True, \"root\": data_path, \"download\": True},      backend=backend, ) <p>or in Tensorflow</p> In\u00a0[13]: Copied! <pre>backend = \"tensorflow\"\n\noods_test = OODDataset(\n    'mnist', \n    load_kwargs = {\"split\": \"test\"}, \n    backend=backend,\n)\noods_train = OODDataset(\n    'mnist', \n    load_kwargs = {\"split\": \"train\"}, \n    backend=backend,\n)\n\nclear_output()\n</pre> backend = \"tensorflow\"  oods_test = OODDataset(     'mnist',      load_kwargs = {\"split\": \"test\"},      backend=backend, ) oods_train = OODDataset(     'mnist',      load_kwargs = {\"split\": \"train\"},      backend=backend, )  clear_output() <p>Then prepare the datasets for scoring and/or training.</p> In\u00a0[14]: Copied! <pre>batch_size = 128\ninc_labels = [0, 1, 2, 3, 4]\noods_train, _ = oods_train.split_by_class(in_labels=inc_labels)\noods_in, oods_out = oods_test.split_by_class(in_labels=inc_labels)\n\ndef preprocess_fn(*inputs):\n    x = inputs[0] / 255\n    return tuple([x] + list(inputs[1:]))\n\nds_train = oods_train.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn, shuffle=True)\nds_in = oods_in.prepare(batch_size=batch_size, with_ood_labels=False, preprocess_fn=preprocess_fn)\nds_out = oods_out.prepare(batch_size=batch_size, with_ood_labels=False, preprocess_fn=preprocess_fn)\n</pre> batch_size = 128 inc_labels = [0, 1, 2, 3, 4] oods_train, _ = oods_train.split_by_class(in_labels=inc_labels) oods_in, oods_out = oods_test.split_by_class(in_labels=inc_labels)  def preprocess_fn(*inputs):     x = inputs[0] / 255     return tuple([x] + list(inputs[1:]))  ds_train = oods_train.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn, shuffle=True) ds_in = oods_in.prepare(batch_size=batch_size, with_ood_labels=False, preprocess_fn=preprocess_fn) ds_out = oods_out.prepare(batch_size=batch_size, with_ood_labels=False, preprocess_fn=preprocess_fn)  <p>Train or load the model.</p> <p>In Tensorflow:</p> In\u00a0[15]: Copied! <pre>model_path_mnist_04 = os.path.join(model_path, \"mnist_model_0-4.h5\")\n\ntry:\n    model_tf = tf.keras.models.load_model(model_path_mnist_04)\nexcept OSError:\n    train_config = {\n        \"model\": \"toy_convnet\",\n        \"input_shape\": (28, 28, 1),\n        \"num_classes\": 5,\n        \"epochs\": 5,\n        \"save_dir\": model_path_mnist_04,\n        \"validation_data\": ds_in #ds_in is actually the test set of MNIST\n    }\n\n    model_tf = train_tf_model(ds_train, **train_config)\n</pre> model_path_mnist_04 = os.path.join(model_path, \"mnist_model_0-4.h5\")  try:     model_tf = tf.keras.models.load_model(model_path_mnist_04) except OSError:     train_config = {         \"model\": \"toy_convnet\",         \"input_shape\": (28, 28, 1),         \"num_classes\": 5,         \"epochs\": 5,         \"save_dir\": model_path_mnist_04,         \"validation_data\": ds_in #ds_in is actually the test set of MNIST     }      model_tf = train_tf_model(ds_train, **train_config)  <p>In Pytorch:</p> In\u00a0[16]: Copied! <pre>model_path_mnist = os.path.join(model_path, \"mnist_model_torch_0-4\")\ntry:\n    model_torch = torch.load(os.path.join(model_path_mnist, \"best.pt\"))\nexcept OSError:\n    train_config = {\n        \"model\": \"toy_convnet\",\n        \"num_classes\": 5,\n        \"epochs\": 5,\n        \"save_dir\": model_path_mnist,\n        \"validation_data\": ds_in, #ds_in is actually the test set of MNIST\n        \"cuda_idx\": cuda_idx\n    }\n    model_torch = train_torch_model(ds_train,  **train_config)\n</pre> model_path_mnist = os.path.join(model_path, \"mnist_model_torch_0-4\") try:     model_torch = torch.load(os.path.join(model_path_mnist, \"best.pt\")) except OSError:     train_config = {         \"model\": \"toy_convnet\",         \"num_classes\": 5,         \"epochs\": 5,         \"save_dir\": model_path_mnist,         \"validation_data\": ds_in, #ds_in is actually the test set of MNIST         \"cuda_idx\": cuda_idx     }     model_torch = train_torch_model(ds_train,  **train_config) In\u00a0[17]: Copied! <pre>if backend == \"tensorflow\":\n    model = model_tf\nelif backend == \"torch\":\n    model = model_torch\n    \nmls = MLS()\nmls.fit(model)\nscores_in, _ = mls.score(ds_in)\nscores_out, _ = mls.score(ds_out)\n\n\nmetrics = bench_metrics(\n    (scores_in, scores_out),  \n    metrics = [\"auroc\", \"fpr95tpr\", accuracy_score, roc_auc_score], \n    threshold = -7.5 # visually chosen based on the plot\n    )\n\nplt.figure(figsize=(13, 5))\nplot_ood_scores(scores_in, scores_out)\nplt.show()\nmetrics = pd.Series(metrics)\nprint(metrics)\n</pre> if backend == \"tensorflow\":     model = model_tf elif backend == \"torch\":     model = model_torch      mls = MLS() mls.fit(model) scores_in, _ = mls.score(ds_in) scores_out, _ = mls.score(ds_out)   metrics = bench_metrics(     (scores_in, scores_out),       metrics = [\"auroc\", \"fpr95tpr\", accuracy_score, roc_auc_score],      threshold = -7.5 # visually chosen based on the plot     )  plt.figure(figsize=(13, 5)) plot_ood_scores(scores_in, scores_out) plt.show() metrics = pd.Series(metrics) print(metrics) <pre>auroc             0.923506\nfpr95tpr          0.395797\naccuracy_score    0.855000\nroc_auc_score     0.923506\ndtype: float64\n</pre> In\u00a0[18]: Copied! <pre>msp = MLS(output_activation=\"softmax\")\nmsp.fit(model)\nscores_in, _ = msp.score(ds_in)\nscores_out, _ = msp.score(ds_out)\n\n\nmetrics = bench_metrics(\n    (scores_in, scores_out),  \n    metrics = [\"auroc\", \"fpr95tpr\", accuracy_score, roc_auc_score], \n    threshold = -0.95 # visually chosen based on the plot\n    )\n\n# Normalize scores for a better hist visualization\nminim = np.min([np.min(scores_in), np.min(scores_out)])\nscores_in_ = scores_in - 2 * minim + np.min(scores_in[np.where(scores_in != minim)])\nscores_out_ = scores_out - 2 * minim + np.min(scores_in[np.where(scores_in != minim)])\n\nplt.figure(figsize=(13, 5))\nplot_ood_scores(scores_in_, scores_out_, log_scale=True)\nplt.show()\nmetrics = pd.Series(metrics)\nprint(metrics)\n</pre> msp = MLS(output_activation=\"softmax\") msp.fit(model) scores_in, _ = msp.score(ds_in) scores_out, _ = msp.score(ds_out)   metrics = bench_metrics(     (scores_in, scores_out),       metrics = [\"auroc\", \"fpr95tpr\", accuracy_score, roc_auc_score],      threshold = -0.95 # visually chosen based on the plot     )  # Normalize scores for a better hist visualization minim = np.min([np.min(scores_in), np.min(scores_out)]) scores_in_ = scores_in - 2 * minim + np.min(scores_in[np.where(scores_in != minim)]) scores_out_ = scores_out - 2 * minim + np.min(scores_in[np.where(scores_in != minim)])  plt.figure(figsize=(13, 5)) plot_ood_scores(scores_in_, scores_out_, log_scale=True) plt.show() metrics = pd.Series(metrics) print(metrics) <pre>auroc             0.935694\nfpr95tpr          0.374003\naccuracy_score    0.835600\nroc_auc_score     0.935693\ndtype: float64\n</pre>"},{"location":"pages/getting_started/#getting-started-maximum-logit-score-on-mnist","title":"Getting started: Maximum Logit Score on MNIST\u00b6","text":"<p>This notebook aims at introducing the core features of <code>oodeel</code>, including :</p> <ul> <li>Instantiation of <code>OODDataset</code> to load a dataset from <code>tensorflow_datasets</code> or <code>torchvision.datasets</code> catalog and to organize in-distribution and out-of-distribution data.</li> <li>Preparation of a <code>tf.data.Dataset</code> or a <code>torch.DataLoader</code> ready for scoring and/or training.</li> <li>A simple utils to train neural nets (adapted when in-distribution is not a standard dataset, such as a subset of class from a dataset)</li> <li>Instantiation of <code>OODBaseDetector</code> based on an already trained model, that is used for scoring data.</li> <li>Some evaluation metrics to assess the quality of OOD detection.</li> </ul> <p>First, some required imports.</p>"},{"location":"pages/getting_started/#mnist-vs-fashion-mnist","title":"MNIST vs Fashion MNIST\u00b6","text":"<ul> <li>In-distribution data: MNIST</li> <li>Out-of-distribution data: Fashion MNIST</li> </ul>"},{"location":"pages/getting_started/#load-and-prepare-the-datasets","title":"Load and prepare the datasets\u00b6","text":"<p>This is performed using the class <code>OODDataset</code>. First, load the datasets.</p> <p>Before loading, choose your backend (tensorflow or torch). You only have to give it as input to <code>OODDataset</code> and that's it. The rest of the code will be exactly the same regardless of the library (except for model loading).</p> <p>When a <code>str</code> is given as argument, <code>OODDataset</code> will automatically search in the <code>tensorflow_datasets</code> or <code>torchision.datasets</code> catalogs. Be careful with the <code>str</code> you give as input, it has to exactly match the name of the dataset in <code>tensorflow_datasets</code> or <code>torchision.datasets</code> (and it is case-sensitive).</p> <p>Loading from existing data objects</p> <p>     In this notebook, the datasets are loaded from platforms, but you can also instanciate OODDataset with your own tf.data.Dataset, tf.Tensor, torch.Dataset or np.arrays   </p> <p>Warning</p> <ul> <li>We denote In-Distribution (ID) data with <code>_in</code> and Out-Of-Distribution (OOD) data with <code>_out</code> to avoid confusion with OOD detection which is the name of the task, and is therefore used to denote core classes such as <code>OODDataset</code> and <code>OODBaseDetector</code>.</li> <li>When loading from <code>tensorflow_datasets</code> or <code>torchision.datasets</code>, do not forget to check which <code>load_kwargs</code> to add. It can change for different datasets, even withing a same platform.</li> </ul> <p>In pytorch from <code>torchision.datasets</code> catalog:</p>"},{"location":"pages/getting_started/#maximum-logit-score-mls","title":"Maximum Logit Score (MLS)\u00b6","text":"<p>Return an OOD score based on the maximum value of the output logits. Introduced in Open-Set Recognition: a Good Closed-Set Classifier is All You Need?, ICLR 2022.</p> <p>In this section, we use <code>model_tf</code> because <code>backend=\"tensorflow\"</code></p>"},{"location":"pages/getting_started/#maximum-softmax-probability-msp","title":"Maximum Softmax Probability (MSP)\u00b6","text":"<p>It is possible to do the same after the softmax activation. Introduced in A Baseline for Detecting Misclassified and Out-of-Distribution Examples in Neural Networks, ICLR 2017.</p>"},{"location":"pages/getting_started/#mnist-0-4-vs-mnist-5-9","title":"MNIST (0-4) vs MNIST (5-9)\u00b6","text":"<ul> <li>In-distribution data: MNIST (0-4)</li> <li>Out-of-distribution data: MNIST (5-9)</li> </ul> <p>We can repeat the procedure in an open-set-recognition or semantic OOD setting by considering a subset of MNIST classes as in-distribution and another subset as out-of-distribution. The datasets are constructed using the <code>OODDataset</code> method <code>.split_by_class</code>. First load and split the dataset.</p> <p>In Pytorch:</p>"},{"location":"pages/getting_started/#maximum-logit-score-mls","title":"Maximum Logit Score (MLS)\u00b6","text":""},{"location":"pages/getting_started/#maximum-softmax-probability-msp","title":"Maximum Softmax Probability (MSP)\u00b6","text":""},{"location":"pages/implementing_baselines_tuto/","title":"Implementing your own baseline","text":"<p>In this notebook, it is explained how to design your own custom baseline using Oodeel.</p> In\u00a0[1]: Copied! <pre>def _fit_to_dataset(self, fit_dataset):\n\"\"\"\n    Fits the detector to fit_dataset.\n    To be overrided in child classes (if needed)\n\n    Args:\n        fit_dataset: dataset to fit the detector on\n    \"\"\"\n    raise NotImplementedError()\n\n\ndef _score_tensor(self, inputs):\n\"\"\"Computes an OOD score for input samples \"inputs\".\n    Method to override with child classes.\n\n    Args:\n        inputs: tensor to score\n\n    Raises:\n        NotImplementedError: _description_\n    \"\"\"\n    raise NotImplementedError()\n</pre> def _fit_to_dataset(self, fit_dataset):     \"\"\"     Fits the detector to fit_dataset.     To be overrided in child classes (if needed)      Args:         fit_dataset: dataset to fit the detector on     \"\"\"     raise NotImplementedError()   def _score_tensor(self, inputs):     \"\"\"Computes an OOD score for input samples \"inputs\".     Method to override with child classes.      Args:         inputs: tensor to score      Raises:         NotImplementedError: _description_     \"\"\"     raise NotImplementedError() <p>Therefore, implementing a custom baseline boils down to implementing those two methods.</p> <p>We will implement a dummy version of Deep K-Nearest-Neighbors. The method will randomly select <code>n_basis</code> vectors from the fit dataset, and score new inputs by computing the distance to their $k$ nearest neighbor with respect to the $L_2$ norm (so $k \\ll$ <code>n_basis</code>).</p> <p>Let first instantiate the <code>__init__</code> function. You need to pass required <code>OODBaseDetector</code> init arguments a argument to <code>.super().__init__()</code>. It is the place to init and declare other attributes. Here, these will be <code>n_basis</code>, <code>k</code>, and <code>basis_vectors</code> (the vectors used for computing the distances).</p> <p>For simplicity, we only use numpy, although we could use tensor operations from pytorch or tensorflow using <code>Operator</code>.</p> In\u00a0[2]: Copied! <pre>def __init__(\n    self,\n    feature_layers_id,\n    n_basis: int = 1000,\n    k: int = 1,\n):\n    super().__init__(\n        feature_layers_id=feature_layers_id,\n    )\n\n    self.n_basis = n_basis\n    self.k = k\n    self.basis_vectors = None\n</pre> def __init__(     self,     feature_layers_id,     n_basis: int = 1000,     k: int = 1, ):     super().__init__(         feature_layers_id=feature_layers_id,     )      self.n_basis = n_basis     self.k = k     self.basis_vectors = None <p>Then, you want to implement the <code>_fit_dataset</code> method. It has to randomly select vectors from the fitting dataset.</p> In\u00a0[3]: Copied! <pre>def _fit_to_dataset(self, fit_dataset):\n\"\"\"\n    Constructs the index from ID data \"fit_dataset\", which will be used for\n    nearest neighbor search.\n\n    Args:\n        fit_dataset: input dataset (ID) to construct the index with.\n    \"\"\"\n    fit_projected = self.feature_extractor.predict(fit_dataset)\n    # self.op is the Operator associated with the object.\n    # It is built automatically and you do not have to bother with it.\n    fit_projected = self.op.convert_to_numpy(fit_projected)\n    fit_projected = fit_projected.reshape(fit_projected.shape[0], -1)\n\n    ind_basis = np.random.choice([i for i in range(len(fit_projected))], replace=False)\n    self.basis_vectors = fit_projected[ind_basis]\n</pre> def _fit_to_dataset(self, fit_dataset):     \"\"\"     Constructs the index from ID data \"fit_dataset\", which will be used for     nearest neighbor search.      Args:         fit_dataset: input dataset (ID) to construct the index with.     \"\"\"     fit_projected = self.feature_extractor.predict(fit_dataset)     # self.op is the Operator associated with the object.     # It is built automatically and you do not have to bother with it.     fit_projected = self.op.convert_to_numpy(fit_projected)     fit_projected = fit_projected.reshape(fit_projected.shape[0], -1)      ind_basis = np.random.choice([i for i in range(len(fit_projected))], replace=False)     self.basis_vectors = fit_projected[ind_basis] <p>Then, <code>_score_tensor</code> has to be implemented so that each input tensor is properly scored.</p> In\u00a0[4]: Copied! <pre>def _score_tensor(self, inputs):\n\"\"\"\n    Computes an OOD score for input samples \"inputs\" based on\n    the distance to nearest neighbors in the feature space of self.model\n\n    Args:\n        inputs: input samples to score\n\n    Returns:\n        scores\n    \"\"\"\n\n    input_projected = self.feature_extractor(inputs)\n    input_projected = self.op.convert_to_numpy(input_projected)\n    input_projected = input_projected.reshape(input_projected.shape[0], -1)\n\n    scores = []\n    for input_p in input_projected:\n        distances = np.sqrt(np.sum((self.basis_vectors - input_p) ** 2))\n        score = np.sort(distances)[self.k]\n        scores.append(score)\n\n    return np.array(scores)\n</pre> def _score_tensor(self, inputs):     \"\"\"     Computes an OOD score for input samples \"inputs\" based on     the distance to nearest neighbors in the feature space of self.model      Args:         inputs: input samples to score      Returns:         scores     \"\"\"      input_projected = self.feature_extractor(inputs)     input_projected = self.op.convert_to_numpy(input_projected)     input_projected = input_projected.reshape(input_projected.shape[0], -1)      scores = []     for input_p in input_projected:         distances = np.sqrt(np.sum((self.basis_vectors - input_p) ** 2))         score = np.sort(distances)[self.k]         scores.append(score)      return np.array(scores) <p>Let's wrap up everything. You have to make your new baselines inherit from <code>OODBaseDetector</code>, put all the previous methods and that's it!</p> In\u00a0[22]: Copied! <pre>from oodeel.methods.base import OODBaseDetector\nimport numpy as np\n\nfrom IPython.display import clear_output\n\n\nclass DKNN_dummy(OODBaseDetector):\n    def __init__(\n        self,\n        n_basis: int = 1000,\n        k: int = 1,\n    ):\n        super().__init__()\n\n        self.n_basis = n_basis\n        self.k = k\n        self.basis_vectors = None\n\n    def _fit_to_dataset(self, fit_dataset):\n\"\"\"\n        Constructs the index from ID data \"fit_dataset\", which will be used for\n        nearest neighbor search.\n\n        Args:\n            fit_dataset: input dataset (ID) to construct the index with.\n        \"\"\"\n        fit_projected, _ = self.feature_extractor.predict(fit_dataset)\n        # self.op is the Operator associated with the object.\n        # It is built automatically and you do not have to bother with it.\n        fit_projected = self.op.convert_to_numpy(fit_projected)\n        fit_projected = fit_projected.reshape(fit_projected.shape[0], -1)\n\n        ind_basis = np.random.choice(\n            [i for i in range(len(fit_projected))], size=(self.n_basis,), replace=False\n        )\n        self.basis_vectors = fit_projected[ind_basis]\n\n    def _score_tensor(self, inputs):\n\"\"\"\n        Computes an OOD score for input samples \"inputs\" based on\n        the distance to nearest neighbors in the feature space of self.model\n\n        Args:\n            inputs: input samples to score\n\n        Returns:\n            scores\n            logits\n        \"\"\"\n\n        input_projected, logits = self.feature_extractor(inputs)\n        input_projected = self.op.convert_to_numpy(input_projected)\n        input_projected = input_projected.reshape(input_projected.shape[0], -1)\n\n        scores = []\n        for input_p in input_projected:\n            distances = np.sqrt(np.sum((self.basis_vectors - input_p) ** 2, axis=1))\n            score = np.sort(distances)[self.k]\n            scores.append(score)\n\n        return np.array(scores), logits\n\n    @property\n    def requires_to_fit_dataset(self) -&gt; bool:\n\"\"\"\n        Whether an OOD detector needs a `fit_dataset` argument in the fit function.\n\n        Returns:\n            bool: True if `fit_dataset` is required else False.\n        \"\"\"\n        return True\n\n    @property\n    def requires_internal_features(self) -&gt; bool:\n\"\"\"\n        Whether an OOD detector acts on internal model features.\n\n        Returns:\n            bool: True if the detector perform computations on an intermediate layer\n            else False.\n        \"\"\"\n        return True\n\nclear_output()\n</pre> from oodeel.methods.base import OODBaseDetector import numpy as np  from IPython.display import clear_output   class DKNN_dummy(OODBaseDetector):     def __init__(         self,         n_basis: int = 1000,         k: int = 1,     ):         super().__init__()          self.n_basis = n_basis         self.k = k         self.basis_vectors = None      def _fit_to_dataset(self, fit_dataset):         \"\"\"         Constructs the index from ID data \"fit_dataset\", which will be used for         nearest neighbor search.          Args:             fit_dataset: input dataset (ID) to construct the index with.         \"\"\"         fit_projected, _ = self.feature_extractor.predict(fit_dataset)         # self.op is the Operator associated with the object.         # It is built automatically and you do not have to bother with it.         fit_projected = self.op.convert_to_numpy(fit_projected)         fit_projected = fit_projected.reshape(fit_projected.shape[0], -1)          ind_basis = np.random.choice(             [i for i in range(len(fit_projected))], size=(self.n_basis,), replace=False         )         self.basis_vectors = fit_projected[ind_basis]      def _score_tensor(self, inputs):         \"\"\"         Computes an OOD score for input samples \"inputs\" based on         the distance to nearest neighbors in the feature space of self.model          Args:             inputs: input samples to score          Returns:             scores             logits         \"\"\"          input_projected, logits = self.feature_extractor(inputs)         input_projected = self.op.convert_to_numpy(input_projected)         input_projected = input_projected.reshape(input_projected.shape[0], -1)          scores = []         for input_p in input_projected:             distances = np.sqrt(np.sum((self.basis_vectors - input_p) ** 2, axis=1))             score = np.sort(distances)[self.k]             scores.append(score)          return np.array(scores), logits      @property     def requires_to_fit_dataset(self) -&gt; bool:         \"\"\"         Whether an OOD detector needs a `fit_dataset` argument in the fit function.          Returns:             bool: True if `fit_dataset` is required else False.         \"\"\"         return True      @property     def requires_internal_features(self) -&gt; bool:         \"\"\"         Whether an OOD detector acts on internal model features.          Returns:             bool: True if the detector perform computations on an intermediate layer             else False.         \"\"\"         return True  clear_output() <p>Watning</p> <ul> <li>Do not forget to add the properties <code>requires_to_fit_dataset</code> and <code>requires_internal_features</code> for the detector to work properly.</li> <li>Do not forget to also return the logits as output of <code>_score_tensor</code>.</li> </ul> In\u00a0[23]: Copied! <pre>import os\n\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\nimport tensorflow as tf\n\ntf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\nfrom IPython.display import clear_output\nimport matplotlib.pyplot as plt\nimport pandas as pd\n</pre> import os  os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\" import tensorflow as tf  tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR) from IPython.display import clear_output import matplotlib.pyplot as plt import pandas as pd In\u00a0[24]: Copied! <pre>from oodeel.datasets import OODDataset\nfrom oodeel.eval.metrics import bench_metrics\nfrom oodeel.eval.plots import plot_ood_scores\n\n\nmodel_path = os.path.expanduser(\"~/\") + \".oodeel/saved_models\"\ndata_path = os.path.expanduser(\"~/\") + \".oodeel/datasets\"\nos.makedirs(model_path, exist_ok=True)\nos.makedirs(data_path, exist_ok=True)\n\nbackend = \"tensorflow\"\n\noods_in = OODDataset(\n    \"mnist\",\n    load_kwargs={\"split\": \"test\"},\n    backend=backend,\n)\noods_out = OODDataset(\n    \"fashion_mnist\",\n    load_kwargs={\"split\": \"test\"},\n    backend=backend,\n)\noods_train = OODDataset(\n    \"mnist\",\n    load_kwargs={\"split\": \"train\"},\n    backend=backend,\n)\n\n\ndef preprocess_fn(*inputs):\n    x = inputs[0] / 255\n    return tuple([x] + list(inputs[1:]))\n\n\nbatch_size = 128\n\nds_in = oods_in.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn)\nds_out = oods_out.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn)\nds_train = oods_train.prepare(\n    batch_size=batch_size, preprocess_fn=preprocess_fn, shuffle=True\n)\n\nclear_output()\n</pre> from oodeel.datasets import OODDataset from oodeel.eval.metrics import bench_metrics from oodeel.eval.plots import plot_ood_scores   model_path = os.path.expanduser(\"~/\") + \".oodeel/saved_models\" data_path = os.path.expanduser(\"~/\") + \".oodeel/datasets\" os.makedirs(model_path, exist_ok=True) os.makedirs(data_path, exist_ok=True)  backend = \"tensorflow\"  oods_in = OODDataset(     \"mnist\",     load_kwargs={\"split\": \"test\"},     backend=backend, ) oods_out = OODDataset(     \"fashion_mnist\",     load_kwargs={\"split\": \"test\"},     backend=backend, ) oods_train = OODDataset(     \"mnist\",     load_kwargs={\"split\": \"train\"},     backend=backend, )   def preprocess_fn(*inputs):     x = inputs[0] / 255     return tuple([x] + list(inputs[1:]))   batch_size = 128  ds_in = oods_in.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn) ds_out = oods_out.prepare(batch_size=batch_size, preprocess_fn=preprocess_fn) ds_train = oods_train.prepare(     batch_size=batch_size, preprocess_fn=preprocess_fn, shuffle=True )  clear_output() <p>Train the model if needed:</p> In\u00a0[25]: Copied! <pre>from oodeel.utils.tf_training_tools import train_tf_model\n\nmodel_path_mnist = os.path.join(model_path, \"mnist_model_tensorflow.h5\")\n\ntry:\n    model = tf.keras.models.load_model(model_path_mnist)\nexcept OSError:\n    train_config = {\n        \"model\": \"toy_convnet\",\n        \"input_shape\": (28, 28, 1),\n        \"num_classes\": 10,\n        \"epochs\": 5,\n        \"save_dir\": model_path_mnist,\n        \"validation_data\": ds_in,  # ds_in is actually the test set of MNIST\n    }\n\n    model = train_tf_model(ds_train, **train_config)\n</pre> from oodeel.utils.tf_training_tools import train_tf_model  model_path_mnist = os.path.join(model_path, \"mnist_model_tensorflow.h5\")  try:     model = tf.keras.models.load_model(model_path_mnist) except OSError:     train_config = {         \"model\": \"toy_convnet\",         \"input_shape\": (28, 28, 1),         \"num_classes\": 10,         \"epochs\": 5,         \"save_dir\": model_path_mnist,         \"validation_data\": ds_in,  # ds_in is actually the test set of MNIST     }      model = train_tf_model(ds_train, **train_config) <p>And then the OOD part:</p> In\u00a0[26]: Copied! <pre>dknn_dummy = DKNN_dummy()\n\ndknn_dummy.fit(model, feature_layers_id=[-2], fit_dataset=ds_train.take(1000))\nscores_in, _ = dknn_dummy.score(ds_in)\nscores_out, _ = dknn_dummy.score(ds_out)\n\nmetrics = bench_metrics(\n    (scores_in, scores_out),\n    metrics=[\"auroc\", \"fpr95tpr\"],\n    threshold=-7.5,  # visually chosen based on the plot\n)\n\n\ndef plot_hist(scores_in, scores_out, bins, log=False):\n    if log:\n        minim = np.min([np.min(scores_in), np.min(scores_out)])\n        scores_in_ = (\n            scores_in - 2 * minim + np.min(scores_in[np.where(scores_in != minim)])\n        )\n        scores_out_ = (\n            scores_out - 2 * minim + np.min(scores_in[np.where(scores_in != minim)])\n        )\n        _, bins = np.histogram(np.concatenate([scores_in_, scores_out_]), bins=30)\n        logbins = np.logspace(np.log10(bins[0]), np.log10(bins[-1]), len(bins))\n        plt.xscale(\"log\")\n        plt.xlabel(\"score (normalized log axis)\")\n    else:\n        logbins = bins\n        scores_in_ = scores_in\n        scores_out_ = scores_out\n        plt.xlabel(\"score\")\n    plt.hist(\n        (scores_out_, scores_in_),\n        bins=logbins,\n        color=(\"blue\", \"orange\"),\n        label=(\"ood\", \"id\"),\n    )\n    plt.legend()\n    plt.show()\n\n\nplt.figure(figsize=(13, 5))\nplot_ood_scores(scores_in, scores_out)\nplt.show()\nmetrics = pd.Series(metrics)\nprint(metrics)\n</pre> dknn_dummy = DKNN_dummy()  dknn_dummy.fit(model, feature_layers_id=[-2], fit_dataset=ds_train.take(1000)) scores_in, _ = dknn_dummy.score(ds_in) scores_out, _ = dknn_dummy.score(ds_out)  metrics = bench_metrics(     (scores_in, scores_out),     metrics=[\"auroc\", \"fpr95tpr\"],     threshold=-7.5,  # visually chosen based on the plot )   def plot_hist(scores_in, scores_out, bins, log=False):     if log:         minim = np.min([np.min(scores_in), np.min(scores_out)])         scores_in_ = (             scores_in - 2 * minim + np.min(scores_in[np.where(scores_in != minim)])         )         scores_out_ = (             scores_out - 2 * minim + np.min(scores_in[np.where(scores_in != minim)])         )         _, bins = np.histogram(np.concatenate([scores_in_, scores_out_]), bins=30)         logbins = np.logspace(np.log10(bins[0]), np.log10(bins[-1]), len(bins))         plt.xscale(\"log\")         plt.xlabel(\"score (normalized log axis)\")     else:         logbins = bins         scores_in_ = scores_in         scores_out_ = scores_out         plt.xlabel(\"score\")     plt.hist(         (scores_out_, scores_in_),         bins=logbins,         color=(\"blue\", \"orange\"),         label=(\"ood\", \"id\"),     )     plt.legend()     plt.show()   plt.figure(figsize=(13, 5)) plot_ood_scores(scores_in, scores_out) plt.show() metrics = pd.Series(metrics) print(metrics) <pre>auroc       0.653761\nfpr95tpr    0.776100\ndtype: float64\n</pre> <p>The results could be better, but it is now yours to improve!</p>"},{"location":"pages/implementing_baselines_tuto/#the-oodbasedetector-class","title":"The OODBaseDetector class\u00b6","text":"<p>The abstraction for OOD baselines is <code>OODBaseDetector</code>. It implements high-level methods such as <code>.score()</code> or <code>.fit()</code> that will be used by the end user. The method <code>.score()</code> calls the code for scoring a tensor along with handling type checking and managing iterable structures and batch-wise concatenation. The method <code>.fit()</code> instantiates a <code>FeatureExtractor</code>, an <code>Operator</code> and a <code>DataHandler</code> depending on the underlying library of the neural network as an attribute to <code>OODBaseDetector</code>. It also calls for the code to fit the OODBaseDetector to some fit data, if needed.</p> <p>Remark:</p> <p>For instance, <code>DKNN</code> needs fit data to construct its nearest neighbor structure, while <code>MLS</code> does not, since it only returns the maximum output logit as the OOD score.</p> <p>Basically, all the code that is baseline specific and that performs OOD-related operations is contained in the methods (Type hinting is omitted for conciseness):</p>"},{"location":"pages/implementing_baselines_tuto/#implementing-a-new-baseline","title":"Implementing a new baseline\u00b6","text":"<p>In this section, we implement a new baseline inheriting from <code>OODBaseDetector</code>.</p>"},{"location":"pages/implementing_baselines_tuto/#testing-your-baseline","title":"Testing your baseline\u00b6","text":"<p>Then, you only have to use your baseline like any other:</p> <p>First, prepare the data</p>"},{"location":"pages/operator_tuto/","title":"Seamlessly handling torch and tf Tensors with Operator","text":"<p>Oodeel is designed to work with both Tensorflow and Pytorch models. However, we wanted to avoid duplicate code as much as possible.</p> <p>Hence, we created the class <code>Operator</code> and the child classes <code>TFOperator</code> (API here) and <code>TorchOperator</code> (API here) to seamlessly perform basic operations on <code>tf.Tensor</code>or <code>torch.tensor</code>, for instance <code>mean</code>, <code>matmul</code>, <code>cat</code>, <code>softmax</code>...</p> <p>Info</p> <p>Using this feature is not required to implement your own baselines with your favorite library, but only if you want your baseline to be usable with both Tensorflow and Pytorch.</p> <p>The implementation shines when performing conditional import. Let's see how it works</p>"},{"location":"pages/operator_tuto/#example","title":"Example","text":""},{"location":"pages/operator_tuto/#basic-usage","title":"Basic usage","text":"<p>Suppose that you use either Tensorflow or PyTorch.</p> <p>For torch, start with</p> <pre><code>import torch\n\nbackend = \"torch\"\ntensor = torch.ones((10,5))\n</code></pre> <p>or for Tensorflow</p> <p><pre><code>import tensorflow as tf\n\nbackend = \"tensorflow\"\ntensor = tf.ones((10,5))\n</code></pre> Then you could conditionally load the correct <code>Operator</code>:</p> <pre><code>if backend == \"torch\":\n    from oodeel.utils import TorchOperator\n    operator = TorchOperator()\n\nelif backend == \"tensorflow\":\n    from oodeel.utils import TFOperator\n    operator = TFOperator()\n</code></pre> <p>Tip</p> <p>If you do not know in advance from which library the input tensor will come from, there is a nice function we implemented for you: <code>is_from</code> (see here)</p> <p>now it is possible to seamlessly use your <code>operator</code> to process your <code>tensor</code>:</p> <pre><code>tensor_mean = operator.mean(tensor, dim=0)\n</code></pre> <p>Note</p> <p>We had to choose between Pytorch and Tensorflow syntax for <code>Operator</code> API. This object is to be mainly used by researchers wanting to make their baseline available for the community, so since Pytorch is the main library used for research, we adopted the Pytorch syntax.</p>"},{"location":"pages/operator_tuto/#get-gradients","title":"Get gradients","text":"<p>It is even possible to obtain the gradient using backprop. Let's take the previously instantiated <code>operator</code> or <code>tensor</code>. The following code is the same for Tensorflow or PyTorch.</p> <p><pre><code>def power(x):\n    return x ** 2\n\n# Get the gradient\ngrads = operator.gradient(power, tensor)\n</code></pre> The operator.gradient() function takes the function and the input tensor as arguments. If you want to perform library-specific operations, you should use the operator API. For instance:</p> <pre><code># Here we use tensorflow\ntensor_1 = tf.ones((10,5))\ntensor_2 = tf.ones((10,5))\n\n# The following code does not depend on the underlying library\ndef mult(x):\n    return operator.matmul(x, operator.t(tensor_2))\n\ngrads = operator.gradient(mult, tensor_1)\n</code></pre> <p>Note</p> <p>The idea is inspired by the great lib EagerPy, but we wanted to have closer control and make our own baked API to facilitate maintenance. In addition, we do not claim to reproduce the full API of tensorflow/pytorch/(soon jax ?) and implement the methods on the fly, if required by the baselines.</p>"},{"location":"pages/operator_tuto/#completing-operator-api","title":"Completing Operator API","text":"<p>As mentioned above, the API is far from exhaustive because we add methods on the fly, depending on the needs of OOD baselines. It is likely that you could need an unimplemented method on your way toward implementing a new baseline. Don't panic: there are two situations:</p>"},{"location":"pages/operator_tuto/#contributor","title":"Contributor?","text":"<p>You are a contributor and you want your baseline to be officially part of Oodeel and available through Pypi. In that case, all you have to do is implement the method for both <code>TFOperator</code> and <code>TorchOperator</code> which is not that bad. For instance, take the method <code>one_hot</code>:</p> <p>For <code>TFOperator</code>:</p> <pre><code>def one_hot(tensor: Union[tf.Tensor, np.ndarray], num_classes: int) -&gt; tf.Tensor:\n\"\"\"One hot function\"\"\"\n    return tf.one_hot(tensor, num_classes)\n</code></pre> <p>and for <code>TorchOperator</code>:</p> <pre><code>def one_hot(\n    tensor: Union[torch.Tensor, np.ndarray], num_classes: int\n) -&gt; torch.Tensor:\n\"\"\"One hot function\"\"\"\n    return torch.nn.functional.one_hot(tensor, num_classes)\n</code></pre>"},{"location":"pages/operator_tuto/#or-simply-user","title":"Or simply User?","text":"<p>If you just want to use Oodeel for your research, you can simply use your favorite lib and develop your brand new baseline like usual, following the tuto here without bothering with <code>Operator</code>.</p>"}]}